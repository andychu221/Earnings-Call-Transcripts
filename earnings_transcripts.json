{
  "AAPL": {
    "ticker": "AAPL",
    "last_updated": "2026-02-04T16:09:10.574Z",
    "total_transcripts": 5,
    "transcripts": [
      {
        "ticker": "AAPL",
        "title": "Yahoo Finance",
        "published_date": "Jan 29, 2026, 5:00 PM EST",
        "fiscal_year": "2026",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/AAPL/earnings/AAPL-Q1-2026-earnings_call-406161.html",
        "content": "**Suhasini Chandramouli** (Director of Investor Relations)\nGood afternoon, and welcome to the Apple Q1 Fiscal Year 2026 earnings conference call. My name is Suhasini Chandramouli, Director of Investor Relations. Today's call is being recorded. Speaking first today is Apple CEO, Tim Cook, and he'll be followed by CFO, Kevan Parekh. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast, including risks related to the potential impact to the company's business and results of operations from macroeconomic conditions, tariffs and other measures, and legal and regulatory proceedings.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nFor more information, please refer to the risk factors discussed in Apple's most recently filed reports on Form 10-Q and Form 10-K, and the Form 8-K filed with the SEC today, along with the associated press release. Additional information will also be in our report on Form 10-Q for the quarter ended December 27, 2025, to be filed tomorrow, and in other reports and filings we make with the SEC. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.\n\n**Tim Cook** (CEO)\nThank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. I am proud to say that we just had a quarter for the record books. We are reporting our best-ever quarter with $143.8 billion in revenue, up 16% from a year ago and exceeding our expectations. The demand for iPhone was simply staggering, with revenue growing 23% year-over-year and all-time records across every geographic segment. Services set an all-time revenue record as well, up 14% from a year ago, and EPS reached an all-time record of $2.84, growing a robust 19% year-over-year. We set all-time revenue records in the Americas, Europe, Japan, and rest of Asia Pacific, and grew in the vast majority of markets we track.\n\n**Tim Cook** (CEO)\nWe continue to gain momentum in emerging markets, which includes India, where we saw strong double-digit revenue growth. Greater China also grew 38% year-over-year, driven by iPhone, which had record upgraders and double-digit growth on switchers. Apple's December quarter results underscore our relentless commitment to innovation, to our customers, and to our mission to build the best products and services in the world. Now I'd like to take a closer look at results from across our lineup, beginning with iPhone. As I mentioned earlier, it was a fantastic quarter for iPhone, with an all-time revenue record of $85.3 billion, up 23% year-over-year. This is the strongest iPhone lineup we've ever had, and by far the most popular. Throughout the quarter, customer enthusiasm for iPhone was simply extraordinary. Users were incredibly excited about everything it enables them to do.\n\n**Tim Cook** (CEO)\niPhone 17 Pro and 17 Pro Max deliver the ultimate iPhone experience. They feature the best-ever performance and battery life on an iPhone, the most advanced camera system, and a striking design. iPhone Air, our slimmest and lightest smartphone yet, packs powerful capabilities into an ultra-slim and sleek design. iPhone 17 is a truly fantastic upgrade and an incredible value. Turning to Mac, revenue was $8.4 billion for the December quarter. We were pleased to see the Mac install base reach another all-time high, with nearly half of customers who purchased a Mac being new to the product. The M5-powered 14-inch MacBook Pro takes a huge leap in AI performance, thanks to the next-generation GPU architecture and a faster Neural Engine.\n\n**Tim Cook** (CEO)\nFrom the world's most popular laptop for consumers and businesses in MacBook Air to the small and spectacular Mac Mini, every Mac in our lineup has something special to offer users. And with the recently released Apple Creator Studio, available across Mac, iPad, and iPhone, creators have more tools at their fingertips to make incredible music or turn their devices into a video production studio. Meanwhile, iPad saw December quarter revenue of $8.6 billion, up 6% from a year ago, with an all-time record for upgraders. We are proud to have our strongest lineup ever, from iPad powered by A16, which is proving to be incredibly popular, to iPad Air, with its amazing versatility, to the unbelievably powerful M5 iPad Pro, with its remarkably thin and light design. It's no wonder that iPad continued to be the most popular tablet in the world.\n\n**Tim Cook** (CEO)\nAcross wearables, home, and accessories, revenue was $11.5 billion. With Apple Watch Ultra 3 and Apple Watch Series 11, users are tapping into a comprehensive set of health and wellness features to help them meet their health goals. In a recent survey, we see an increasing number of users telling us they're wearing their Watch to sleep, which allows them to check their sleep scores each morning and find ways to improve their sleep quality. Apple Watch alerts are enabling important conversations between users and their doctors regarding potential signs of hypertension. These are just some of the many ways that Watch is helping people live healthier lives. The response to AirPods Pro 3 has been amazing. Customers are raving about the rich, immersive sound quality, the unmatched level of active noise cancellation, and the noticeably improved comfort that makes them effortless to wear.\n\n**Tim Cook** (CEO)\nFeatures like Live Translation are also changing the way people can communicate by helping users connect across languages in real time and making everyday conversations feel more natural and accessible. Together, these innovations create an experience that feels both powerful and personal, and the enthusiasm we are seeing reflects just how strongly AirPods Pro 3 are resonating with customers. Across our product categories, we are seeing very high levels of customer satisfaction, and we are proud to report that we have a new record for our installed base, with more than 2.5 billion active devices. During the quarter, we were excited to see that the majority of users on enabled iPhones are actively leveraging the power of Apple Intelligence. Since the launch of Apple Intelligence, we've introduced dozens of features, including writing tools and cleanup, and made it available in 15 languages.\n\n**Tim Cook** (CEO)\nThese AI experiences are personal, private, integrated across our platforms, and relevant to what our users do every day. We are bringing intelligence to more of what people already love about our products, so we can make every experience even more capable and effortless. One of our most popular features is Visual Intelligence, which helps users learn and do more than ever with the content on their iPhone screen, making it faster to search, take action, and answer questions across their apps. And as I touched on earlier, we are hearing powerful stories of people using Live Translation to communicate seamlessly across languages. And these are just some of the many powerful AI features that are enabling our users to do remarkable things with our products, which are far and away the best platforms in the world for AI.\n\n**Tim Cook** (CEO)\nThat's in no small part because of the extraordinary power and performance of Apple Silicon. Building on our efforts in the AI space, we are also collaborating with Google to develop the next generation of Apple Foundation Models. This will help power future Apple Intelligence features, including a more personalized Siri coming this year. We're incredibly excited for what's to come with so many new experiences to unlock. Turning to services, we achieved an all-time revenue record of $30 billion, 14% higher from a year ago. Services also set all-time revenue records in both developed and emerging markets. Apple TV has seen fantastic momentum, with December seeing a 36% increase in viewership over the previous year. It's no wonder with shows like Pluribus, which are creating landmark cultural moments that audiences are loving.\n\n**Tim Cook** (CEO)\nAnticipation is building for upcoming new productions like Cape Fear from Steven Spielberg and Martin Scorsese, and we are thrilled to announce that Ted Lasso will be returning for a fourth season this summer. Six years since launch, we're excited by the growing enthusiasm viewers have for Apple TV, and we are grateful for the accolades that have followed, most recently at the Critics' Choice and Golden Globe Awards. To date, Apple TV productions have earned more than 650 wins and more than 3,200 nominations, including a recently announced Oscar nomination for Best Picture for F1, the movie. And speaking of F1, we're also approaching the start of a new Formula One season, and for F1 fans in the U.S., Apple TV will be the place to watch every practice, qualifying, sprint, and Grand Prix.\n\n**Tim Cook** (CEO)\nMLS fans will also be able to watch every regular and postseason game with their Apple TV subscription this year, and we're looking forward to kickoff in the coming weeks. Looking back, 2025 was a fantastic year for services as we rolled out amazing new features and broke records. Apple Music climbed to all-time highs in both listenership and new subscriber growth. Apple Pay eliminated more than $1 billion in fraud for our partners last year, and we've made it available in more markets than ever before. Last year, we welcomed more than 850 million users every week on average to the App Store, the world's safest and most innovative app marketplace. Developers have now earned more than $550 billion on our platform since 2008.\n\n**Tim Cook** (CEO)\nIn retail, we continue to bring a magical experience to our customers all around the world, and we were thrilled to have our best-ever results in retail during the quarter. We were excited to open our fifth store in India in December and have plans to open another store in Mumbai soon. Wherever we are, we see ourselves as part of a larger whole. That's why we show up with our values in everything we do.... That means working with partners in places like Vietnam to bring more clean water to rural areas. It means celebrating graduations of new classes of innovators from our developer academies in places such as Brazil, Indonesia, and South Korea. It means 3D printing titanium cases for Apple Watch using recycled materials so that they're better for the planet without compromising quality, and so much more.\n\n**Tim Cook** (CEO)\nWe're especially proud of the work we're doing to support American innovation. Last year, we committed to invest $600 billion over 4 years in vital industries like advanced manufacturing, silicon engineering, and artificial intelligence. As we're building on our long-standing investments in America, we're supporting nearly 500,000 jobs with thousands of suppliers across all 50 states. In the year since we made our initial commitment, we're making great progress. Today, we're shipping servers to power Apple Intelligence from our new manufacturing facility in Houston. Through our advanced manufacturing program, we're working with Corning in Kentucky to make 100% of cover glass for iPhone and Apple Watch.\n\n**Tim Cook** (CEO)\nWe're working with Micron, which broke ground on a new advanced chip packaging and test facility, and we continue to advance the development of an end-to-end silicon supply chain across the country, sourcing 20 billion U.S. chips in 2025. Through our Apple Manufacturing Academy in Detroit, we're already training American businesses and innovators on the latest smart manufacturing and artificial intelligence techniques. Six months since opening, the academy is already making an enormously positive impact for businesses working alongside Apple engineers to drive productivity, efficiency, and quality in their supply chains. As I said at the beginning of my remarks, this was, in so many ways, a remarkable quarter for Apple, and we're excited for all the opportunities we'll have in the year ahead to deliver innovations that have never been seen before and enrich the lives of users every step of the way.\n\n**Tim Cook** (CEO)\nWith so much to look forward to in the weeks and months ahead, I have every confidence that our best work is yet to come. With that, I'll turn it over to Kevan.\n\n**Kevan Parekh** (CFO)\nThanks, Tim, and good afternoon, everyone. Our revenue of $143.8 billion was up 16% year-over-year, our best quarter ever. Across the world, we set all-time revenue records in both developed and emerging markets, and we saw double-digit growth year-over-year across the majority of the markets we track, including the U.S., Latin America, Western Europe, Greater China, India, and South Asia. Products revenue was $113.7 billion, up 16% year-over-year, driven by double-digit growth in iPhone, setting a new all-time record. And as Tim mentioned, thanks to our strong levels of customer loyalty and satisfaction, our installed base of active devices has now surpassed 2.5 billion, reaching another all-time high across all product categories and geographic segments. Services revenue was $30 billion, up 14% year-over-year.\n\n**Kevan Parekh** (CFO)\nThis performance continues to be broad-based, with double-digit growth in almost every market we track. We also reached all-time revenue records for advertising, cloud services, music, and payment services, with December quarter records on the App Store and video. Company gross margin was at 48.2%, above the high end of our guidance range and up 100 basis points sequentially, driven by favorable mix and leverage. Products gross margin was 40.7%, up 450 basis points sequentially, driven by favorable mix and leverage. Services gross margin was 76.5%, up 120 basis points sequentially, driven by mix. Operating expenses landed at $18.4 billion, up 19% year-over-year. This was within the range we provided and driven by increased investment in R&D.\n\n**Kevan Parekh** (CFO)\nNet income was $42.1 billion, and diluted earnings per share was $2.84, up 19% year-over-year. Both net income and diluted EPS were all-time records, and these incredibly strong business results drove an all-time record for operating cash flow, coming in at $53.9 billion. Now, I'm going to provide some more details for each of our revenue categories. iPhone revenue was $85.3 billion, up 23% year-over-year, driven by the iPhone 17 family. iPhone saw strength around the world, reaching all-time revenue records in many of the markets we track, including the U.S., Greater China, Latin America, Western Europe, the Middle East, Australia, and South Asia, as well as a December quarter record in India.\n\n**Kevan Parekh** (CFO)\nThe iPhone active install base grew to an all-time high and set a new all-time record for upgraders in aggregate and across many countries, including the U.S., China Mainland, Japan, and India. According to a recent survey from Worldpanel, iPhone was the top-selling model in the U.S., urban China, the U.K., Australia, and Japan. Customers are loving the latest iPhone lineup. The latest customer satisfaction for the iPhone 17 family in the U.S. was measured at 99% by 451 Research. Mac revenue was $8.4 billion, down 7% year-over-year. As we described in the last call, we faced a very difficult compare against the M4 MacBook Pro, Mac Mini, and iMac launches in the year-ago quarter. Despite this difficult compare, we continued to see growth in several emerging markets, including Brazil, India, Malaysia, Vietnam, and more.\n\n**Kevan Parekh** (CFO)\nAs Tim mentioned earlier, the Mac install base reached another all-time high, with nearly half of the customers who purchased a Mac being new to the product. In the U.S., customer satisfaction for Mac was measured at 97%. iPad revenue was $8.6 billion, up 6% year-over-year, driven by the M5-powered iPad Pro and the A16-powered iPad. We continued to add new users to the iPad. In fact, over half the customers who purchased an iPad during the quarter were new to the product. This helped the iPad install base to reach an all-time high, and we also reached an all-time high for upgraders. Based on the latest reports from 451 Research, customer satisfaction was 98% in the U.S. Wearables, home, and accessories revenue was $11.5 billion, down 2% year-over-year.\n\n**Kevan Parekh** (CFO)\nDuring the quarter, we experienced constraints on the AirPods Pro 3, and we believe the overall category would have grown had it not been for these constraints. The wearables install base reached a new all-time high, with over half of customers purchasing an Apple Watch during the quarter being new to the product. In the U.S., customer satisfaction was recently reported at 96%. Our services revenue reached an all-time high of $30 billion, up 14% year-over-year. As we said earlier, we had all-time revenue records on advertising, music, payment services, and cloud services, where we saw a double-digit growth on paid subscribers. We continue to be optimistic about the future of our services business. With our install base of over 2.5 billion active devices, we have an incredibly strong foundation for new growth opportunities.\n\n**Kevan Parekh** (CFO)\nWe saw increased customer engagement across our service offerings, with both transacting and paid accounts reaching all-time highs in the quarter. We continue to improve the quality and expand the breadth of our services offerings. From new Wallet features like Digital ID, which provides a way for users to create an ID in Wallet using information from their U.S. passport, to additional ads coming to search in the App Store, which provides advertisers more ways to drive downloads from search. Turning now to enterprise, organizations are continuing to expand their fleet of Apple devices to drive productivity while remaining secure. Snowflake has deployed over 9,000 Mac devices company-wide, establishing Mac as a primary laptop across all business units, resulting in increased performance and a reduction in support tickets.\n\n**Kevan Parekh** (CFO)\nAstraZeneca is rolling out over 5,000 M5-powered iPad Pros to its pharmaceutical sales team to take advantage of AI capabilities, including Apple Intelligence, while meeting with clinicians daily. In Mexico, Coppel, the country's largest domestic retailer, recently added MacBook Air in addition to a growing fleet of over 10,000 iPad devices. Let's turn to our cash position and capital return program. We ended the quarter with $145 billion in cash and marketable securities. We had $2.2 billion of debt maturities and decreased commercial paper by $6 billion, resulting in $91 billion in total debt. Therefore, at the end of the quarter, net cash was $54 billion. During the quarter, we returned nearly $32 billion to shareholders.\n\n**Kevan Parekh** (CFO)\nThis included $3.9 billion in dividends and equivalents and $25 billion through open market repurchases of 93 million Apple shares. As we move ahead into the March quarter, I'd like to review our outlook, which includes the types of forward-looking information that Suhasini referred to. Importantly, the color we're providing assumes that global tariff rates, policies, and their application remain in effect as of this call, and the global macroeconomic outlook does not worsen from today. We expect our March quarter total company revenue to grow by 13%-16% year-over-year, which comprehends our best estimates of constrained iPhone supply during the quarter. We expect services revenue to grow at a year-over-year rate, similar to what we reported in the December quarter. We expect gross margin to be between 48% and 49%.\n\n**Kevan Parekh** (CFO)\nWe expect operating expenses to be between $18.4 billion and $18.7 billion, which is at a similar level to what we reported in the December quarter and driven by higher R&D on a year-over-year basis. We expect OI&E to be around $100 million, excluding any potential impact from the Mark-to-Market of minority investments and our tax rate to be around 17.5%. Finally, today, our board of directors has declared a cash dividend of $0.26 per share of common stock payable on February 12th, 2026, to shareholders of record as of February 9th, 2026. With that, let's open the call to questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Kevin. We ask that you limit yourself to two questions. Operator, may we have the first question, please?\n\n**Operator**\nCertainly. We'll go ahead and take our first question from Amit Daryanani of Evercore.\n\n**Amit Daryanani** (Senior Managing Director of Equity Research)\nYes, I have two. Maybe to start with, you know, there's a lot of focus on the impact of memory to a host of companies, and I'd love to kind of get your perspective when you folks are guiding gross margins up into the March quarter. Just talk about, you know, A, your comfort in securing the bits that you need for shipment, and B, how do we think about memory inflation flowing through Apple's model over time?\n\n**Tim Cook** (CEO)\n... Yeah, Amit. Hi, it's Tim. Let me back up a bit and talk about the constraints that Kevin referred to in his remarks and memory, and try to get both of these out at once. First of all, we were thrilled with the customer response on the latest iPhone lineup. It exceeded our expectations, to say the least, and, you know, iPhone grew 23%. What the result of that was was that we exited the December quarter with very lean channel inventory due to that staggering level of demand. And based on that, we're in a supply chase mode to meet the very high levels of customer demand. We are currently constrained, and at this point, it's difficult to predict when supply and demand will balance.\n\n**Tim Cook** (CEO)\nThe constraints that we have are driven by the availability of the advanced nodes that our SoCs are produced on. At this time, we're seeing less flexibility in the supply chain than normal, partly because of our increased demand that I just spoke about. From a memory point of view, to answer your question, memory had a minimal impact on the Q1, the December quarter gross margin. We do expect it to be a bit more of an impact to the Q2 gross margin, and that was comprehended in the outlook of 48%-49% that Kevan gave earlier. Beyond Q2, you know, we don't obviously provide outlooks beyond the current quarter, but we do continue to see market pricing for memory increasing significantly. As always, we'll look at a range of options to deal with that.\n\n**Tim Cook** (CEO)\nHopefully that gives you the full, full view.\n\n**Amit Daryanani** (Senior Managing Director of Equity Research)\nYep. No, thank you, and I appreciate all the clarity on that, Tim. You know, maybe the other second question I have for you is, you know, maybe just touch on the China strength you folks had. I think this is very close to all-time high revenues you've had in China. What's driving the strength over here? And just sort of the durability of the growth rate we saw in, in the December quarter would be helpful to understand. Thank you.\n\n**Tim Cook** (CEO)\nSure. Greater China was up 38% year-over-year. It was driven by iPhone, where we set an all-time revenue record. So it was the best iPhone quarter in history in Greater China. It's driven by the customer enthusiasm for the iPhone 17 lineup. And I would tell you that during the quarter, traffic in our stores in China grew by strong double digits year-over-year. It was a terrific quarter. Our installed base reached an all-time high in both Greater China and Mainland China, and we set an all-time record for the upgraders, and we saw strong double-digit growth on switchers. And according to a survey from Worldpanel, iPhones were the top three smartphones in urban China during the quarter.\n\n**Tim Cook** (CEO)\nSo it was and it's really driven primarily by the product strength and the customer response to the product strength. We do see on non-iPhone products that the majority of customers that are buying a Mac, an iPad, a watch, are still new to that product, so that's a very good sign for us. And if you look at iPad, on that same survey, iPad was the top tablet model in urban China. And according to Counterpoint, the MacBook Air was the top-selling laptop model, and Mac Mini was the top-selling desktop model in the December quarter. So overall, a great quarter in China. We could not be more happy with it.\n\n**Operator**\nAwesome. Thank you, Amit. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Eric Woodring of Morgan Stanley. Please go ahead.\n\n**Erik Woodring** (Managing Director of Equity Research)\nGreat, guys. Thank you for taking my questions. Tim, congrats on announcing the partnership with Google, and we're all excited to see what you bring to market later this year. When I think about your AI initiatives, you know, it's clear there are added costs associated with that. We're obviously seeing that flow through in OpEx. You know, can you help us understand maybe what the revenue upside potential that exists with AI? You know, many of your competitors have already integrated AI into their devices, and it's just not clear yet what incremental monetization they're seeing because of AI, but you're always disciplined with investing. You obviously have a differentiated product. So how do you monetize AI, and what's the timeline to realizing that ROI? Then a quick follow-up. Thank you.\n\n**Tim Cook** (CEO)\nWell, let me just say that we're bringing intelligence to more of what people love, and we're integrating it across the operating system in a personal and private way. I think that by doing so, it creates great value, and that opens up a range of opportunities across our products and services. And we are-\n\n**Erik Woodring** (Managing Director of Equity Research)\nOkay, super helpful.\n\n**Tim Cook** (CEO)\nAnd we're-\n\n**Erik Woodring** (Managing Director of Equity Research)\nThanks.\n\n**Tim Cook** (CEO)\nWe're very happy with the collaboration with Google as well, I should add.\n\n**Erik Woodring** (Managing Director of Equity Research)\n... Thank you, Tim. And then maybe just a follow-up. Now, now that you have kind of more time and, and data to evaluate this cycle, can you maybe help us understand what the primary factors are driving strength in the iPhone? I'm sure there's a number of factors, but if you, if you had to point to one or two, just what would they be, and how sustainable do you think those are?\n\n**Tim Cook** (CEO)\nI think it's different for different cohorts of where people are coming from and the device that they have. But it's a combination of things always that make the product sing. It's the display, it's the camera, it's the performance, it's the new selfie camera, it's the design. The design is beloved. And so it's all of these things that come together at once and are producing a very strong product cycle, as witnessed by our December quarter results.\n\n**Erik Woodring** (Managing Director of Equity Research)\nGreat. Thank you, Tim. Best of luck.\n\n**Tim Cook** (CEO)\nYeah, thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAwesome. Thank you, Eric. Operator, could we get the next question, please?\n\n**Operator**\nWe'll now go to Michael Ng of Goldman Sachs. Please go ahead.\n\n**Michael Ng** (Research Analyst in Hardware and Tech)\nWonderful. Good afternoon, and thank you for the questions. I have two as well, if I could. First, you know, it was encouraging to hear about the revenue growth outlook of 13%-16% for the March quarter. I was just wondering if you could, you know, talk about any comps that we should be particularly aware of as we kind of think about each of the product categories. I know last year you guys had, you know, MacBook Air with M4, the iPhone 16e, the iPad A16, and the iPad Air with M3. So just wanted to, you know, ask if those things would create tough comps, or is it just less of an issue just given the new product outlook? Thank you.\n\n**Kevan Parekh** (CFO)\nYeah, Mike, it's Kevan. How are you? Thanks for the question. Yeah, I wouldn't say there's any particular comp issue that we'd note. As you recall, last quarter, we talked about the difficult comparison we had on Mac, but there's nothing that rises to that kind of color that we'd outline, you know, in the outlook. And so I think it's just, you know, continuation of the strong cycle we're seeing, subject to the constraints that I had mentioned in the prepared remarks and that Tim, you know, alluded to a little earlier as well.\n\n**Michael Ng** (Research Analyst in Hardware and Tech)\nGreat. Wonderful. And then, you know, just on services, you know, advertising, you know, strong in the quarter. I wanted to ask about some of the, you know, new growth opportunities in advertising. I know you guys are doing the new ad slots in the App Store. Maybe you could just talk a little bit about that and then any plans to do more in advertising across other products like Maps or TV. Thank you.\n\n**Kevan Parekh** (CFO)\nYeah, sure. Mike, what I would say, just if I step back, in general, I think as we outlined, we saw really good broad-based performance in our cross-sell services business, so ranging from, you know, all-time records in advertising, music, payment services, and cloud services. So I think we see really good opportunities across a lot of our service categories, and we continue to, you know, add new service offerings. We talked about, you know, what we added to the Wallet, like Digital ID, and you referenced the additional kind of additional ads coming into search in the App Store, which we are excited about. It provides, you know, advertisers more ways to be discovered. And so I think we'll continue to look for ways to expand opportunities to add value to users and also, you know, create opportunities for Apple.\n\n**Kevan Parekh** (CFO)\nI think as we talked about, we created, you know, across a really significant milestone of 2.5 billion, you know, active devices, so we really feel excited about the opportunity that provides for our services business as well.\n\n**Michael Ng** (Research Analyst in Hardware and Tech)\nWonderful. Thanks for the thoughts, Kevan.\n\n**Kevan Parekh** (CFO)\nSure thing.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Mike. Operator, could we get the next question, please?\n\n**Operator**\nThe next question will be coming from, Ben Reitzes of Melius. Please go ahead.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nYeah. Hey, guys. How are you?\n\n**Tim Cook** (CEO)\nHi, Ben.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nHey, Tim. First question is on Google partnership again. I wanted to understand how you came to that decision with regard to the AI and Siri in particular, and if there's an opportunity for you guys to share in revenue, too, with that partnership like you do in search. Thanks.\n\n**Tim Cook** (CEO)\nYeah, we basically determined that Google's AI technology would provide the most capable foundation for AFM, or I'm sorry, Apple Foundation Models. And we believe that we can unlock a lot of experiences and innovate in a key way due to the collaboration. We'll continue to run on the device and run in Private Cloud Compute and maintain our industry-leading privacy standards in doing so. In terms of the arrangement with Google, we're not releasing the details of that.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nAh, bummer.\n\n**Tim Cook** (CEO)\nYeah.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nOkay, well, I tried.\n\n**Tim Cook** (CEO)\nYou did.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nSo, yeah, you knew it would be me. So the next question is on gross margin. You know, I'm pretty shocked, I gotta hand it to you, Tim, you know, that you're able to do 48%-49%. What's really going on there? How are you doing that with this memory, the NAND prices? Is it due to mix that there's, you know, a good less hardware and more services, and services margins are going up? How are you doing it to keep it at 48%-49%?\n\n**Kevan Parekh** (CFO)\n... Yeah, Ben, this is Kevin. How are you doing? Let me start maybe by just reflecting on the Q1 gross margin. I think we talked about the fact that we landed at 48.2%, so just above the high end of the range that we provided, you know, on the last call. And I think if you look at that performance, you know, we were up 100 basis points sequentially. We talked about the fact that we had favorable mix. I mean, as you know, when we have a good product cycle, strong product cycle, we're seeing for iPhone, that does lend itself to a bit more favorable opportunity on the mix and leverage side. So we're having a strong iPhone cycle, as Tim outlined, and so that also translated itself.\n\n**Kevan Parekh** (CFO)\nWe talked about products sequentially went up by 450 basis points. So I think in general, I think we're just seeing, you know, favorable mix dynamics as well. You know, services continues to contribute as well. That business is growing, you know, you know, double digits, so that also is a contributor. And I think that, you know, if you looked at our guidance, you know, we're providing a similar range to where we reported in December, and there's going to be a few puts and takes. You know, we do expect to see favorable mix in the services. As you know, when we move from Q1 to Q2, that tends to be the case, and that's partly offset by a seasonal loss of leverage.\n\n**Kevan Parekh** (CFO)\nThere'll be puts and takes, but, you know, again, we feel pretty good about the guide of 48%-49%, which is similar to the range we reported in December.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nWow! Okay, great. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thanks, Ben. Operator, could we get the next question, please?\n\n**Operator**\nThe next question will be coming from David Vogt of UBS.\n\n**David Vogt** (Managing Director)\nGreat. Thanks, guys, for taking my question. Maybe, maybe Tim or Kevan, if we could pull out a little bit, can you help us understand how you're thinking about the overall kind of smartphone market demand, particularly given where memory prices are headed? And we've heard some conversations with some other OEMs as well as component providers that are worried about either the availability of components, potential market weakness in terms of demand destruction, and some of the actions to offset or higher prices. I know you don't give outlooks for the full year, but how are you thinking about all of those different vectors and what that might mean for the overall smartphone market, and then ultimately what that might mean for demand for iPhones as we move through the rest of this calendar year?\n\n**Tim Cook** (CEO)\nYeah, on the supply side, I had made comments earlier about the constraint that we are seeing in Q2. You know, that's reflected in the revenue guidance that Kevan gave earlier. The constraint, as I'd mentioned, is due to the advanced node capacity, and it's really a result of growing so well in Q1 with the 23% and having less flexibility, partly due to that in the process, to increase it as much as we would like to increase it. Beyond Q2, I don't really want to comment on supply, you know, it's supply is a function of a lot of things in the industry that move around a lot. So I wouldn't want to comment on that. I...\n\n**Tim Cook** (CEO)\nI commented before on the memory pricing, and so, hopefully, that answers your question.\n\n**David Vogt** (Managing Director)\nIt does, maybe I'll-\n\n**Tim Cook** (CEO)\nIn terms of smartphone demand-\n\n**David Vogt** (Managing Director)\nYeah.\n\n**Tim Cook** (CEO)\nYou know, we believe that based on the information that we've got is we gained share in the December quarter. Obviously, the market wasn't growing at 23%, so we feel good about doing that. But I wouldn't want to predict how the market reacts in the future. It's very difficult to do that.\n\n**David Vogt** (Managing Director)\nGot it. At the risk of not getting this answered, I'm going to follow up with, can you maybe help us understand, you know, you mentioned there's a range of options that you're looking at. What should we think about kind of like LTAs in the marketplace? I mean, is that an option as we move through the year, or is it more spot-based from a, on a perspective, particularly around memory? Just want to get a better sense for how we should think about kind of the dynamics in the marketplace.\n\n**Tim Cook** (CEO)\nIt's a range, and so I don't want to get more specific than that. I mean, there are different levers that we can push, and who knows how successful they'll be, but there's just a range of options.\n\n**David Vogt** (Managing Director)\nGreat. Thanks, guys.\n\n**Tim Cook** (CEO)\nYeah.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nGreat. Thank you, David. Operator, could we get the next question, please?\n\n**Operator**\nWe'll now be taking a question from Wamsi Mohan from Bank of America. Sorry for the pronunciation.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nThat's fine. Thank you. Tim, on services, you grew a pretty impressive 14%, and I know you said that the App Store was a record for the December quarter, but third-party data is showing a notable deceleration in App Store growth, maybe 7% in the December quarter relative to your 14% growth. I was hoping if you could maybe confirm that, and secondarily, if it's correct, what might be some of the drivers of that, and what could be things that you could do to reverse that in future quarters? And I have a follow-up.\n\n**Kevan Parekh** (CFO)\nHey, Wamsi, it's Kevan here. Look, I think we want to reiterate the fact that during the summer quarter, you know, we had a quarterly record on the App Store. As you know, we don't provide, you know, specific color on how the individual services categories have done. But again, if we step back, I think we saw, you know, again, broad-based growth across all the different categories, also across, you know, various geographies. We had, you know, all-time records in both developed and emerging markets as well, so, and double-digit growth in both of those too. And so I think in general, you know, we don't provide, you know, the color at the detailed, you know, services level.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\n... Okay, thanks, Kevan. I guess back to the memory price. I appreciate you have a range of options to address that. Historically, Apple's not used a pricing lever unless, you know, FX markets got maybe very dislocated to prevent arbitrage or issues like that. But, given some of these unprecedented moves in memory, would pricing be a lever that you would be willing to pull or push and, outside of every other thing that, you know, outside of everything else that you can do?\n\n**Tim Cook** (CEO)\nYeah, I wouldn't want to speculate on that one.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nOkay, thanks, Tim.\n\n**Tim Cook** (CEO)\nYeah.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Wamsi. Operator, could we have the next question, please?\n\n**Operator**\nWe'll now go to Samik Chatterjee of JPMorgan. Please go ahead. Your line is open.\n\n**Samik Chatterjee** (Managing Director and Equity Research Analyst)\nYep. Hi, thanks for taking my questions. Maybe for the first one, I'm just looking at your capital investment in the first quarter, which did moderate from the last one, and wondering if the partnership with Google on Gemini and sort of help collaboration to develop the next generation of Apple Foundation Models, does that have any near-term sort of impact on your intent to use Apple Private Cloud Compute? I know you emphasize sort of the role Apple Private Cloud Compute plays in the long term, but are there any changes on that front through this collaboration? Any thoughts around that? And I have a quick follow-up. Thank you.\n\n**Kevan Parekh** (CFO)\nYeah, sure. I think this is Kevan here. I think in general, you know, as Tim outlined, we weren't going to provide any details on our, you know, arrangement and collaboration with Google. Just speaking of CapEx in general, you know, as you know, we have a hybrid, you know, model for CapEx. And so I think that, you know, what happens is our CapEx can be volatile, independent of kind of the volume and performance of our business. And as you know, our CapEx is made of several different line items that include tooling, our facilities, retail investments, or investments in our retail store, data centers. And on tooling and data centers, we leverage this hybrid model that I mentioned before, which we leverage a combination of first and third-party capacity.\n\n**Kevan Parekh** (CFO)\nIn general, it's hard to read into the CapEx and, you know, draw any conclusions. I think I would just say there's going to be some ebbs and flows in CapEx. Last year, remember, we did build out our Private Cloud Compute environment, and so we did have CapEx spending related to that in our results in December.\n\n**Samik Chatterjee** (Managing Director and Equity Research Analyst)\nGot it. Got it. And my follow-up probably is for you, again. You did mention product gross margin and the sort of drivers there for the product gross margin improvement. When you sort of highlighted mix as a driver, can you just sort of talk through what are the big differences in mix you're seeing for iPhone 17 versus 16? And, did tariffs and tariffs coming in more favorable play a role at all, and what are you expecting for tariffs for the next quarter?\n\n**Kevan Parekh** (CFO)\nYeah, so there's a few things to unpack there. So on the overall margin and product side, I think I mentioned that we had favorable mix of products and leverage. I think given the strong iPhone cycle we're seeing, that was, I would say, probably a higher favorability than you might have seen in maybe other cycles. And as well, as you know, in Q1, typically we do see the impact of the cost structure of our new products that we launch. And in this case, we are seeing a more favorable offset from mix of products and leverage versus historical, you know, sequential changes from Q4 to Q1.\n\n**Kevan Parekh** (CFO)\nOn the tariff piece, we had outlined an amount of $1.4 billion for the December quarter, and we landed roughly in that range, you know, at that level.\n\n**Samik Chatterjee** (Managing Director and Equity Research Analyst)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAwesome. Thank you, Samik. Operator, could we have the next question, please?\n\n**Operator**\nWe'll now go to Krish Sankar of TD Cowen. Please go ahead.\n\n**Krish Sankar** (Managing Director)\nOkay. Hi, thanks for taking my question. The first one I have for us, for Tim, I think you touched upon this earlier on the Gemini integration and Apple foundational model. How to think about kind of like the, you know, the difference between Apple foundational model functionality and third-party models? Like, you know, does the Apple foundational model evolve to a different layer in the AI software stack? How to think about it as you partner with third-party frontier models? I had a follow-up.\n\n**Tim Cook** (CEO)\nYeah, Krish, you should think of it as a collaboration. Not... And we'll, we'll obviously independently continue to do some of our own stuff, but you should think of what is going to power the personalized version of Siri as a collaboration with Google.\n\n**Krish Sankar** (Managing Director)\nGot it. Got it. So then a quick follow-up for maybe Kevin or Tim. Just, you know, a lot of discussion on memory pricing. Given that the memory constraint or commodities scarcity is impacting both the smartphone and the PC markets, and Apple arguably having more purchasing power, do you think this is a chance for you to increase your market share, both in iPhone and Mac, at the expense of competition, who might have more constraints in getting access to memory?\n\n**Tim Cook** (CEO)\nYeah, I'd only want to talk about, kind of what has happened. We do believe, as I had shared, that iPhone gained share in the December quarter. If you look at Mac for the full year of, full calendar year of 2025, we also believe we gained share. So we feel, very good about our position.\n\n**Krish Sankar** (Managing Director)\nThanks, Tim.\n\n**Krish Sankar** (Managing Director)\nYeah.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Krish. Operator, could we have the next question, please?\n\n**Operator**\nWe'll now go to Atif Malik calling from Citi. Please go ahead.\n\n**Aatif Malik** (SVP)\nHi, thank you for taking my questions. The first one for Tim. Tim, some of the industry pundits are comparing the iPhone 17 upgrade cycle to the 2020, 2021 years as some of the iPhone 12, 13 users upgrade. Curious if you agree with that view, and also if you can layer on the impact from Apple Intelligence to the refresh rate.\n\n**Tim Cook** (CEO)\nI think each iPhone cycle has its own unique characteristics, and so I wouldn't compare it to a specific one. I think iPhone 17, the family of 17 is a unique product that brings several very compelling features in one product, and it has done extremely well. And so we feel, you know, quite good about it.\n\n**Kevan Parekh** (CFO)\nYeah, and I'll just add to Tim's comment that we talked about the fact we have a large and diverse installed base of customers, and so this product has really resonated with multiple cohorts, whether you're on older devices or newer, newer iPhones as well. So we've seen really strong reaction to the product lineup.\n\n**Aatif Malik** (SVP)\nGreat. As my follow-up, there was a lot of discussion, supply constraints, and I'm surprised that you guys are constrained on advanced packaging as you generally get your share at the big foundry. How long will these supply impact your ability to ship to true demand?\n\n**Tim Cook** (CEO)\nIt's difficult to estimate demand when you haven't met the demand. And so, we've obviously. We have internal estimates on that, but I don't want to share those. But it's very difficult. And just to be clear, it's the advanced nodes that, like 3 nanometer, to be specific, where our SoCs are. The latest SoCs are produced on, as to what is gating the Q2 supply. And it's a the-\n\n**Aatif Malik** (SVP)\nThank you.\n\n**Tim Cook** (CEO)\nIt's a direct result of the 23% growth and, you know, that far outstripping what we had internally estimated and having more limited flexibility in the supply chain for some period of time. But I don't want to estimate when supply and demand will balance at this point.\n\n**Aatif Malik** (SVP)\nVery helpful. Thanks.\n\n**Kevan Parekh** (CFO)\nAll right.\n\n**Tim Cook** (CEO)\nYep.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Atif. Operator, could we have the next question, please?\n\n**Operator**\nThe next question will be coming from Aaron Rakers, calling from Wells Fargo. Please go ahead.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYeah, thanks for taking the question. I have two as well, and I'll try and stay away from the memory question. I'm curious, and, you know, obviously, a lot of focus on the China demand, but I'm curious, you also called out India. And so can you maybe unpack some of the things that you're seeing in the Indian market, you know, as far as iPhone traction? Any kind of color on, you know, what is a very large installed base in India that seems to be a good growth opportunity for Apple still?\n\n**Tim Cook** (CEO)\nYeah, thanks for the question. We did set a quarterly revenue record during the December quarter. To go a little further down, we set quarterly revenue records on iPhone and Mac and iPad, and an all-time revenue record on services. So it was a terrific quarter in India. We really like what we see there. It's the second largest smartphone market in the world and the fourth largest PC market. We still have, despite a very nice growth history, modest share there, and so we think there's a huge opportunity for us there. We could not be more excited about it. If you look at the...\n\n**Tim Cook** (CEO)\nThe other thing that I would point out is that the majority of customers that are buying iPhone and Mac and iPad and Watch are all new to that product, and so it speaks very well to opportunity there.\n\n**Kevan Parekh** (CFO)\nYeah, and Aaron, I'd add, you mentioned the install base. We're seeing strong double-digit growth in the install base in India as well, which is really encouraging.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYep. And then as a quick follow-up, you know, kind of tied to memory, maybe not so much, but, you know, part of this, this current generation, you know, iPhone cycle is you, you clearly deepen some of your own internal silicon capabilities on the device. I'm curious if that, if we should think about that as a lever and maybe a supportive factor to gross margin that might be underappreciated. And, you know, any thoughts on, you know, where we go from here as far as continual opportunities of internalizing your own silicon? Thank you.\n\n**Tim Cook** (CEO)\nYeah, I'll let Kevin talk about the gross margin, but in terms of the product, which is, at the heart of what we think about in the user, Apple Silicon has just been an incredible game changer for us, starting with iPhone and then on iPad and of course, the Mac as of a few years ago. And so we, we believe it's a game changer and a major competitive advantage.\n\n**Kevan Parekh** (CFO)\nYeah, and as far as impact on gross margin, yeah, we have been, as you know, investing in core technologies like our own silicon, our own modem. Certainly, while those do provide opportunities for cost savings and can be reflected in margins, they also importantly provide, you know, the differentiation that's really important for our products as well and give us more control over our roadmap. So I think there's a lot of strategic value to it, but also we are seeing, you know, investments in our core technologies impacting, you know, gross margin in a positive way.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYep. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAwesome. Thank you, Aaron. Operator, could we have our last question, please?\n\n**Operator**\nMost certainly. Our last question will be coming from Richard Kramer, calling from Arete Research. Please go ahead.\n\n**Richard Kramer** (Founder and Managing Director)\nThanks very much. I have two questions. Tim, when you think about how Apple might manage AI, do you see that evolving towards more edge AI or on-device services versus cloud-based AI? And are you confident you've reserved sufficient data center capacity to support the widespread Siri adoption, especially given that you're not following the other hyperscalers in sharply increasing CapEx?\n\n**Tim Cook** (CEO)\nThe answer is that we see both being important, the on-device and the Private Cloud Compute. And so we don't see it as an either/or. We see it as a both. And, you know, and we believe it's a differentiator because of our privacy approach. In terms of do we have enough capacity, it's hard to estimate with precision what the demand will be. But we've done the best job that we can do, and we either have or are putting capacity in for it.\n\n**Richard Kramer** (Founder and Managing Director)\nOkay. And you also mentioned the 2.5 billion active device number, but Apple Intelligence features have only been available since the 15 Pro. So can you speak at all to roughly what portion of your iPhone or overall active device install base is now AI-capable? And has this been a factor in maybe a more gradual pace of launching wider AI services?\n\n**Kevan Parekh** (CFO)\nYeah, Richard, this is Kevin. You know, we don't provide that specific number, but it is a growing number, as you can imagine, in our Install Base, and so we're encouraged by the amount of devices now that are capable. But we're not going to provide a specific figure on that today.\n\n**Richard Kramer** (Founder and Managing Director)\nOkay. Well, I had to try. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, Richard. A replay of today's call will be available for two weeks on Apple Podcasts as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 8902968, followed by the pound sign. These replays will be available by approximately 5 P.M. Pacific Time tonight. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142, and financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-8-",
        "fetched_at": "2026-02-04T16:08:45.519Z"
      },
      {
        "ticker": "AAPL",
        "title": "Yahoo Finance",
        "published_date": "Oct 30, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/AAPL/earnings/AAPL-Q4-2025-earnings_call-369370.html",
        "content": "**Suhasini Chandramouli** (Director of Investor Relations)\nAfternoon, and welcome to the Apple Q4 Fiscal Year 2025 Earnings Conference call. My name is Suhasini Chandramouli, Director of Investor Relations. Today's call is being recorded. Speaking first today is Apple's CEO, Tim Cook, and he'll be followed by CFO, Kevin Parekh. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast, including risks related to the potential impact to the company's business and results of operations from macroeconomic conditions, tariffs and other measures, and legal and regulatory proceedings.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nFor more information, please refer to the risk factors discussed in Apple's most recently filed reports on Form 10-Q and Form 10-K, and the Form 8-K filed with the SEC today, along with the associated press release. Additional information will also be in our report on Form 10-K for the year ended September 27, 2025, to be filed tomorrow and in other reports and filings we make with the SEC. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. Additionally, today's discussion will refer to certain non-GAAP financial measures. You can find a reconciliation of these measures in our fourth quarter earnings release, which is available on our Investor Relations website. I'd now like to turn the call over to Tim for introductory remarks.\n\n**Tim Cook** (CEO)\nThank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Today, Apple Inc. is proud to report $102.5 billion in revenue, up 8% from a year ago and a September quarter record. Services achieved an all-time revenue record of $28.8 billion, growing 15% from a year ago. EPS came in at $1.85, setting a September quarter record. We grew in the vast majority of markets we track and had September quarter revenue records in dozens of markets, including the U.S., Canada, Latin America, Western Europe, the Middle East, Japan, Korea, and South Asia. We also set a September quarter revenue record in emerging markets and an all-time revenue record in India. These results come at the close of an extraordinary year for Apple Inc., in which we achieved an all-time revenue record of $416 billion for the fiscal year.\n\n**Tim Cook** (CEO)\nWe set all-time revenue records in emerging and developed markets. We set an all-time revenue record for iPhone. In services, we achieved all-time records across every geographic segment. These results reflect the tremendous customer enthusiasm for Apple Inc. products and services, as well as our deep commitment to innovation. We are incredibly excited about the strength we're seeing across our products and services, and we expect the December quarter's revenue to be the best ever for the company and the best ever for iPhone. We are heading into the holiday season with a truly remarkable lineup that includes the biggest leap ever for iPhone, which has had a tremendous response from our users around the world. Our Apple Watch lineup is more capable than ever too, giving users ways to take charge of their health like never before through new features like hypertension notifications and sleep score.\n\n**Tim Cook** (CEO)\nThe next-level sound quality and active noise cancellation of AirPods Pro 3 are hitting all the right notes for our users. In October, we also broke new ground in power-efficient performance with the uncomparably fast M5 chip, packed with neural accelerators in each GPU core to supercharge AI workloads. iPad Pro combines game-changing features in iPadOS 26 with the power of M5 to create our most capable iPad ever. At the same time, the M5 MacBook Pro raises the bar for what users can do with a laptop, while the new M5-powered Apple Vision Pro opens up amazing possibilities on its infinite canvas. We also launched a beautiful new software design that creates a unified experience across all of our platforms for the very first time. The design is crafted with a new material called Liquid Glass that brings fluidity, vitality, and flexibility to our products.\n\n**Tim Cook** (CEO)\nAlong with the new design, we delivered powerful new features to enable users to do even more with their devices. That includes updates to the phone and messages apps in iOS 26 to help users stay connected, continuity enhancements in Mac to deliver an even more seamless experience across devices, and a powerful new windowing system that fundamentally transforms the user experience in iPadOS 26. As we continue to expand our investment in AI, we're bringing intelligence to more of what people already love about our products and services, making every experience even more personal, capable, and effortless. At the heart of it all is Apple Silicon, and we were thrilled to launch new products powered by the A19 Pro chip and M5. These incredibly advanced chips make Apple products the very best place to experience the power of AI.\n\n**Tim Cook** (CEO)\nWith Apple Intelligence, we've introduced dozens of new features that are powerful, intuitive, private, and deeply integrated into the things people do every day. Features like live translation, which help users communicate across languages in real time, and visual intelligence, which opens new ways to learn about and explore the world. We also introduced Workout Buddy, a new experience that uses AI to provide personalized motivational insights based on a user's workout data and fitness history. These join so many others, from cleanup in photos and new image creation tools to powerful writing tools. We're also seeing developers take advantage of our on-device foundation models to create entirely new experiences for users around the world. We're also excited for a more personalized Siri. We're making good progress on it, and as we've shared, we expect to release it next year.\n\n**Tim Cook** (CEO)\nNow let's take a closer look at the September quarter results across our lineup, starting with iPhone. iPhone set a revenue record for the September quarter at $49 billion, up 6% from a year ago, with growth in the vast majority of markets we track, despite supply constraints we faced on several iPhone 16 and iPhone 17 models given strong demand. Redesigned from the inside out and powered by the outstanding A19 Pro chip, the iPhone 17 Pro is by far the most powerful iPhone we've ever made, setting a whole new standard for the smartphone industry. The iPhone 17 Pro also offers our best camera system ever, with an all-new 8x telephoto camera, and looks stunning with bold new finishes like Cosmic Orange.\n\n**Tim Cook** (CEO)\nThe iPhone Air introduces an incredibly breakthrough design, and with a bigger and brighter display with ProMotion, the iPhone 17 is a fantastic upgrade packed with features users will love. In Mac, we had a strong September quarter with revenue of $8.7 billion, up 13% year over year, driven by the strength of the MacBook Air. The MacBook Air enables users to get things done easily on the world's most popular laptop. Mac Mini users are loving how much performance is packed into our smallest Mac ever made, while Mac Studio customers are pushing the envelope of what's possible with our most powerful Mac ever. The latest 14-inch MacBook Pro unlocks incredible speed and next-level performance with the all-new M5 chip, which delivers three and a half times faster AI performance than M4. Turning to iPad, revenue was $7 billion for the September quarter.\n\n**Tim Cook** (CEO)\nLast month, we released one of the most attention-grabbing software updates we've had in years with iPadOS 26, and we recently gave iPad users even more to love with the launch of the incredible M5 iPad Pro, which offers an incredible boost in AI performance. With an unmatched combination of power and versatility, the new iPad Pro makes every interaction delightful with its thin, light, and portable design. In wearables, home and accessories, revenue was $9 billion. As I mentioned earlier, we were excited to unlock new possibilities for users with the launch of our newest Apple Watch lineup, making the world's most popular watch even better. That includes Apple Watch Ultra 3 with the largest display ever in an Apple Watch, improved battery life, and emergency SOS via satellite.\n\n**Tim Cook** (CEO)\nApple Watch Series 11 brings our users the most comprehensive set of health features yet, and Apple Watch SE 3 delivers advanced capabilities at an incredible value. AI and advanced machine learning are at the core of powerful health features like heart rate monitoring, fall detection, crash detection, and more. With our latest Apple Watch lineup, we were proud to introduce hypertension notifications developed using large-scale machine learning models. Hypertension is one of the leading risk factors for heart attack and stroke, affecting more than 1 billion adults worldwide, and we expect to notify more than a million users of this life-threatening condition. We're also excited about SleepScore, a simple, intuitive way to help users better understand their sleep quality and discover ways to improve it. That's something I'm sure we can all benefit from. Meanwhile, AirPods Pro 3 have been a huge hit.\n\n**Tim Cook** (CEO)\nYou have to hear them to really understand just how remarkable they are. Users and reviewers alike are praising their incredible sound quality and improved fit. They feature the world's best in-ear active noise cancellation, removing up to two times as much noise as the previous generation. With live translation powered by Apple Intelligence, AirPods deliver an incredibly new and exciting experience for users around the world. Turning to services, as I mentioned earlier, revenue was $28.8 billion for the September quarter, 15% higher year over year and an all-time record. We saw double-digit growth in both developed and emerging markets and set new all-time records across advertising, App Store, cloud services, music, payment services, and video. Apple TV+ celebrated a big night at this year's Emmy Awards with 22 wins. The studio led the night with 13 wins, the most of any comedy series in Emmy's history.\n\n**Tim Cook** (CEO)\nSeverance topped all dramas with eight wins, adding to the accolades for this landmark series. To date, Apple TV+ productions have now earned over 600 wins and 2,800 nominations in total, driven by powerful, original storytelling. We're excited for audiences to discover new productions like Pluribus and to catch returning favorites like Slow Horses and The Morning Show. Soon, Apple TV+ will be the destination for F1 fans across the U.S. on track day, thanks to a new partnership with Formula One. F1 is one of the most exciting and fastest-growing sports in the world, and starting next year, Apple TV+ will be the place for subscribers to follow every twist and turn of the new season. In addition, F1: The Movie, one of the year's biggest blockbusters, will be coming to Apple TV+ on December 12th. During the September quarter, we also marked the 10-year anniversary of Apple News.\n\n**Tim Cook** (CEO)\nApple News provides access to front-page news from all around the world, putting hundreds of publications right at users' fingertips. Turning to retail, we're heading into our busiest time of year with our best-ever lineup. In the last few months, we've opened new stores in emerging markets like India and the UAE and new locations in the U.S. and China. I was also in Tokyo last month for the opening of the redesigned and reimagined Apple Ginza store, and the energy among the crowd was truly remarkable. When it originally opened, it was our first store outside the U.S., and so it was especially meaningful to come back to welcome customers to the beautiful new space.\n\n**Tim Cook** (CEO)\nEverywhere we operate and in everything we do, we strive to give the best to our users while living by our values, whether that's building new accessibility features into our most recent software releases, advancing our environmental work by using even more recycled materials in our latest lineup, or providing free educational programming to train and support American businesses with our new Apple Manufacturing Academy in Detroit. We're continuing to invest in innovation and user experiences that will transform our future. A great example is the work we're doing in the U.S., where we're committed to invest $600 billion over the next four years with a focus on innovation in strategic areas like advanced manufacturing, silicon engineering, and artificial intelligence. These commitments build on our longstanding investments in America while supporting more than 450,000 jobs with thousands of suppliers across all 50 states.\n\n**Tim Cook** (CEO)\nWe built a new factory in Houston for advanced AI service, for example, which just started shipping its first products off the line, and we're leading the creation of end-to-end silicon supply chain across the country. In recent months, I've connected with developers, innovators, artists, entrepreneurs, and so many others around the world, people passionate about innovation and all the things they can do with Apple products. Each one is another reminder of why we do what we do. We're driven to empower people to do more of the things that matter most to them and enrich their lives along the way. As we head into the holiday season with our most powerful lineup ever, I couldn't be more excited for what's to come. With that, I'll turn it over to Kevin.\n\n**Kevan Parekh** (CFO)\nThanks, Tim, and good afternoon, everyone. Our revenue of $102.5 billion was up 8% year over year and is a new September quarter record. We set September quarter records in the Americas, Europe, Japan, and the rest of Asia-Pacific, and grew in the vast majority of markets we track. Products revenue was $73.7 billion, up 5% year over year, driven by growth across iPhone and Mac, and reached a September quarter record. Thanks to our exceptional customer satisfaction and strong levels of loyalty, our install base of active devices has reached another all-time high across all product categories and geographic segments. Services revenue was $28.8 billion, up 15% year over year, and an all-time record. The performance was broad-based, with double-digit growth in the vast majority of the markets we track and double-digit growth across most of our services categories.\n\n**Kevan Parekh** (CFO)\nCompany gross margin was 47.2%, above the high end of our guidance range and up 70 basis points sequentially, driven by favorable mix. This includes approximately $1.1 billion of tariff-related costs, which is in line with what we had estimated on our last call. Products gross margin was 36.2%, up 170 basis points sequentially, driven by favorable mix. Services gross margin was 75.3%, down 30 basis points sequentially. Operating expenses landed at $15.9 billion, up 11% year over year, driven by increased investment in R&D. These strong levels of business performance led to September quarter records for both net income and diluted earnings per share. Net income was $27.5 billion. Diluted earnings per share was $1.85, up 13% year over year on an adjusted basis, excluding the one-time charge we recognized during the fourth quarter of 2024. Operating cash flow was also a September quarter record at $29.7 billion.\n\n**Kevan Parekh** (CFO)\nNow, I'm going to provide some more details for each of our revenue categories. iPhone revenue was $49 billion, up 6% year over year, driven by the iPhone 16 family. iPhone grew in the vast majority of the markets we track, with September quarter records in many emerging markets, including Latin America, the Middle East, and South Asia, and an all-time record in India. The iPhone active install base grew to an all-time high, and we set a September quarter record for upgraders. According to the recent survey from World Panel, iPhone was a top-selling model in the U.S., urban China, the UK, France, Australia, and Japan. We continue to see very high levels of customer satisfaction in the U.S. at 98%, as measured by 451 Research. Mac revenue was $8.7 billion, up 13% year over year, driven by MacBook Air.\n\n**Kevan Parekh** (CFO)\nWe grew in every geographic segment with strong double-digit growth in emerging markets. The Mac install base reached another all-time high, with nearly half of customers who purchased a Mac being new to the product. The latest customer satisfaction for Mac in the U.S. was reported at 96%. iPad revenue was $7 billion, flat year over year. Keep in mind we faced a difficult compare against the full quarter impact of the iPad Air and iPad Pro launch from last year, offset by the better-than-expected performance on the iPad. The install base reached an all-time high, with a September quarter record for upgraders, and over half of the customers who purchased an iPad during the quarter were new to the product. Based on the latest reports from 451 Research, customer satisfaction was 98% in the U.S. Wearables, home, and accessories revenue was $9 billion, flat year over year.\n\n**Kevan Parekh** (CFO)\nThis was driven by growth on Watch and AirPods, offset by accessories, which was impacted by strong performance in the year-ago quarter, driven by the iPad launches. Both the Apple Watch and AirPods install bases reached new all-time highs. Over half of the customers purchasing an Apple Watch during the quarter were new to the product. We also set a September record for upgraders on Apple Watch. In the U.S., customer satisfaction was recently measured at 95%. Our services revenue reached an all-time high of $28.8 billion, up 15% year over year. We achieved all-time revenue records in the Americas, Europe, Japan, and rest of Asia-Pacific, as well as a September quarter record in Greater China.\n\n**Kevan Parekh** (CFO)\nThe majority of categories saw a sequential acceleration, and as Tim mentioned, we set many all-time revenue records, including payment services, where we reached an all-time revenue record and saw double-digit growth year over year on Apple Pay active users. This strong momentum in the September quarter drove our total fiscal year services revenue to surpass $100 billion, up 14% year over year and our best ever. The growth of our install base of active devices continues to offer us great opportunities for the future. Customer engagement across our services offerings also continued to grow. Both transacting and paid accounts reached new all-time highs. We continue to improve the quality and expand the reach of our services offerings, from additional markets for Apple Pay, now available in nearly 90 countries, to Apple Care One, a great new way to cover multiple Apple products in a single plan.\n\n**Kevan Parekh** (CFO)\nTurning to enterprise, we are seeing an adoption of Apple products accelerate across industries to improve productivity and drive innovation. The BMW Group has been deploying tens of thousands of iPhones, including to factory employees, to further strengthen its digital capabilities and advanced innovation at the company. Capital One has expanded its Mac Choice program by adding thousands more MacBook Airs across its workforce. In the Czech Republic, its largest bank, esk Spoitelna, continues to invest in the Apple ecosystem with over 5,000 iPhones in addition to its existing thousands of iPads and Macs. Purdue University has launched a spatial computing hub built around Apple Vision Pro, designed to help prepare students to lead the next wave of innovation in critical industries like semiconductor and pharmaceutical manufacturing. Let's turn to our cash position and capital return program. We ended the quarter with $132 billion in cash and marketable securities.\n\n**Kevan Parekh** (CFO)\nWe had $1.3 billion of debt maturities and decreased commercial paper by $1.9 billion, resulting in $99 billion in total debt. Therefore, at the end of the quarter, net cash was $34 billion. During the quarter, we returned $24 billion to shareholders. This included $3.9 billion in dividends and equivalents and $20 billion through open market repurchases of 89 million Apple shares. Taking a step back, we are very pleased with our record fiscal year 2025 results. As Tim Cook mentioned, total company revenue for the year was $416 billion, with growth in iPhone, Mac, iPad, and services, and all-time records in the vast majority of markets we track. This revenue performance led to very strong full-year operating results, with all-time records for net income and for diluted EPS, which grew double digits year over year on an adjusted basis.\n\n**Kevan Parekh** (CFO)\nAs we move ahead into the December quarter, I'd like to review our outlook, which includes the types of forward-looking information Suhasini referred to. Importantly, the color we're providing assumes that the global tariff rates, policies, and application remain in effect as of this call, and the global macroeconomic outlook does not worsen from today. We expect our December quarter total company revenue to grow by 10% to 12% year over year, which would be our best quarter ever. We expect iPhone revenue to grow double digits year over year, which would be our best iPhone quarter ever. On Mac, keep in mind we expect to face a very difficult compare against the M4 MacBook Pro, Mac Mini, and iMac launches in the year-ago quarter. We expect services revenue to grow at a year-over-year rate similar to what we reported in the fiscal year 2025.\n\n**Kevan Parekh** (CFO)\nWe expect gross margin to be between 47% and 48%, which includes an estimated impact of $1.4 billion of tariff-related costs. As we've said before, we are significantly increasing our investments in AI while continuing to invest in our product roadmap. For the December quarter, we expect operating expenses to be between $18.1 billion and $18.5 billion. We expect OI&E to be around $150 million, excluding any potential impact from the mark-to-market of minority investments, and our tax rate to be around 17%. Today our board of directors has declared a cash dividend of $0.26 per share of common stock payable on November 13, 2025, to shareholders of record as of November 10, 2025. With that, let's open the call to questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Kevin. We ask that you limit yourself to two questions. Operator, may we have the first question, please?\n\n**Operator**\nCertainly. We will go ahead and take our first question from Eric Woodring with Morgan Stanley. Please go ahead.\n\n**Erik Woodring** (Managing Director and Head of US Technology Hardware Equity Research)\nHey, good afternoon, guys. Thank you for taking my question. Congrats on the results. Tim, can you maybe share a bit more detail on why you think the iPhone 17 is having the degree of success that it is at this point? The question is, do you believe this is the age install base replacement cycle kicking in, or are there specific features or functionality you believe stand out this cycle versus past cycles that consumers are really looking for? Just a quick follow-up, thanks.\n\n**Tim Cook** (CEO)\nEric, thanks for your comments. I think it's all about the product. The product lineup is incredibly strong. They're strongest ever. The 17 Pro is the most pro phone we've ever done. It's incredible in the design. The iPhone Air feels so thin and so light in your hand, it feels like it's going to fly away. The 17 phone is an incredible value and takes several of the features that were reserved for Pro before and brings them down to the consumer lineup. Overall, strongest iPhone lineup ever, and it's resonating around the world.\n\n**Erik Woodring** (Managing Director and Head of US Technology Hardware Equity Research)\nGreat. Thank you. Thank you, Tim. Maybe a follow-up for you, Kevin. Can you just discuss your approach to managing component cost inflation during this time? You're obviously increasing the memory content in your devices quite substantially. At the same time, memory prices are going through some pretty significant inflation. Just how are you managing through this cycle? Thanks so much, guys.\n\n**Kevan Parekh** (CFO)\nYeah. Hey, Eric, thanks for the question. Look, as you know, we've got a pretty incredible world-class procurement team, and we're constantly finding ways to continue to drive cost opportunities.\n\n**Kevan Parekh** (CFO)\nRight now, on the commodity side, I would say we're seeing a slight tailwind on memory and storage prices, so nothing really to note there. As we saw from our gross margin performance, we landed in a pretty good spot above the high end of the guidance range we provided at 47.2%. As well, we're guiding at 47% to 48%. I think we're managing costs pretty well. As you'll recall, when we talk about this time in the cycle, we just launched a bunch of new products. Those new products do have a slightly higher cost structure than the products they replace, but the team does a very good job of focusing our efforts on getting those costs down over time. We feel pretty good about the performance we're seeing right now overall on material cost savings.\n\n**Erik Woodring** (Managing Director and Head of US Technology Hardware Equity Research)\nGreat. Thanks so much. Good luck, guys.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right.\n\n**Kevan Parekh** (CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Eric. Operator, can we get the next question, please?\n\n**Operator**\nOur next question is from Ben Ricey with Melius Research. Please go ahead.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nHey, guys. Thanks for this. Tim, can you talk a little bit about iPhone in China specifically? How is that going to trend in the December quarter? Have you turned the corner there, and how do you think that trajectory is going? I have a quick follow-up. Thanks.\n\n**Tim Cook** (CEO)\nYeah. Ben, I was just there. It's incredibly vibrant and dynamic. The store traffic is up significantly year over year. The iPhone 17 family has been very well received there. We do believe that we'll return to growth in Q1, and that is largely based on the reception of the iPhone there. I couldn't be more pleased with how things are going there in the early going.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nAll right. That's great. Services, great upside there. A little surprising, right? We were a little worried about that one only a few quarters ago. I was wondering if there were any tax payments in there or if the resolution that we saw with the antitrust ruling with one of your partners was a boost and if that played a role or if it was all really just organic outperformance with many of the things you mentioned. Thanks.\n\n**Kevan Parekh** (CFO)\nYeah. Hey, Ben. It's Kevin here. Let me try to answer that question. You're referring, just wanted to clarify. When you're referring to the antitrust piece, you're talking about the Google trial. Is that what you're referring to?\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nYes, sir.\n\n**Kevan Parekh** (CFO)\nThere was no tax-related impact. What I would say is our strong performance for the quarter is really organically driven. Just to reiterate, we had an all-time revenue record here for the quarter at $28.8 billion. As well, we surpassed $100 billion, so best year ever at 14% YoY. That was all organic growth. As Tim outlined and I outlined in the prepared remarks, we saw a majority of the categories have sequential acceleration, and we had many all-time revenue records, but nothing abnormal at all, really pretty much all organic growth.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Ben. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Michael Ng. Please go ahead.\n\n**Michael Ng** (Managing Director of Global Investment Research)\nHi. Good afternoon. Thank you for the question. I just have two as well. First, just to follow up on the last one. The services revenue growth, I think, was the fastest across many categories and certainly the fastest in the last two years. I was just wondering if you could just unpack a little bit more of the drivers of the acceleration. Was there kind of cross-selling with the new iPhone launch? Was it just installed base growth? I know you've been doing a lot of bundling with Apple One and Apple Care One. Any thoughts on that would be very helpful. I just have a quick follow-up. Thank you.\n\n**Kevan Parekh** (CFO)\nHi, Michael. It's Kevin. Thanks for the question. Let me build on the answer there. I think that the way we look at it is not one thing to point to that would have driven this higher performance. You're right that it is slightly higher than we've seen in the last few quarters. As you know, our services portfolio is very broad with a broad range of businesses. All have different growth profiles and different performance characteristics, so those can vary in any given quarter. I would say our strength, again, was very broad-based, both across categories and also geographically. I wouldn't point to any particular factor that drove any kind of outperformance at all. We were just very pleased to see that result.\n\n**Michael Ng** (Managing Director of Global Investment Research)\nGreat. Thank you. Just on iPhone sell-through, I was wondering if you were seeing any notable shifts in trends between the sell-through coming from upgraders versus switchers. Is the U.S. carrier competitive dynamic helping at all in terms of promotional activity? Any thoughts on channel inventory? Thank you.\n\n**Tim Cook** (CEO)\nWe did set a September quarter record for upgraders, and it was a great quarter from that point of view. It's really too early in the cycle on 17 to make any comments about upgraders or switchers. In terms of channel inventory, we ended the quarter toward the low end of the targeted range, obviously because we had constraints on several models of the 16 and the 17. For complete transparency and clarity, we're constrained today on several models of the iPhone 17. There's not a ramp issue. We just have very strong demand, and we're working very hard to fulfill all the orders that we have.\n\n**Michael Ng** (Managing Director of Global Investment Research)\nThank you, Tim. Thank you, Kevin.\n\n**Kevan Parekh** (CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Mike. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Amit Daryanani with Evercore. Please go ahead.\n\n**Amit Daryanani** (Senior Managing Director)\nThanks a lot. I have two as well. Kevin, maybe just to start with gross margins, can you walk through the expectations for December quarter? I think it implies up 30 basis points or so sequentially. Can you talk about the percentage on gross margin given you do have very sizable operating leverage in the quarter? What are the percentages around that would be really helpful.\n\n**Kevan Parekh** (CFO)\nYeah, sure. Let me walk through the outlook. As we mentioned in our outlook, we're targeting a range of 47% to 48%. We take the midpoint of that range at 47.5%. You said it's roughly 25 basis points, 30 basis points higher. There are a lot of percent takes, as I talked about earlier. This is a quarter we launched with a lot of new products. Those new products tend to have a higher cost structure than the products they replace, so there's definitely an impact from the cost side of things, but that was more than offset by favorable mix, especially on the product side. As you outlined, we typically see higher leverage in this quarter. I would say those are the two big drivers, and the sequential increase is really going to be driven by favorable mix, particularly from the product side.\n\n**Amit Daryanani** (Senior Managing Director)\nGot it. If I go back to the China discussion for a minute, the performance in China, at least in September quarter, was a bit muted. Could you talk about what resulted in the weakness over there? Do you think it was a bit more of a pause given iPhone Air, for example, I don't think was available until a few weeks ago? Just talk about what drove the weakness in September, and is the uptick or better expectations for December there just from the iPhone Air coming out, or are there other factors as well? Thank you.\n\n**Tim Cook** (CEO)\nYeah. The Greater China revenue was down 4% year over year in the September quarter. It was driven by iPhone. If you look at the iPhone, the majority of the sequential year-over-year change was due to supply constraints that I mentioned earlier. It was basically supply constraints that drove the results. We're thrilled with what we're seeing right now, with traffic being up significantly year over year and the reception of the iPhone 17 family. We expect to return to growth this quarter.\n\n**Amit Daryanani** (Senior Managing Director)\nGreat. Thank you.\n\n**Tim Cook** (CEO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Amit. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Wamsi Mohan with Bank of America. Please go ahead.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nYes. Thank you so much. Tim, I'd probably follow up on your comments about the constrained supply in the quarter, just given the very strong demand for iPhones. Do you expect that, as you can see your visibility across demand and supply, do you think that you will be exiting December at a point where you wouldn't be constrained anymore, or do you still expect that there could be constraints as you exit the December quarter? Any way to quantify sort of what revenue could have been, a bit of a follow-up to Ben's question. Given that there are some concerns around search volumes decelerating at the expense of AI, how do you think about the broader sustainability of these very strong mid-teens growth rates for services for an extended period of time, not just for next quarter where you're obviously guiding to 14%?\n\n**Tim Cook** (CEO)\nThis is Tim. The advertising category, which is a combination of third-party and first-party, did set a record during the quarter. Okay. Sorry, just to be clear, both Apple's own internal advertising and within the licensing individually set records? Actually, I'm not saying that. I'm just saying that the combination of the two set a record. I'm dodging the question intentionally because we don't split it at that level.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nOkay. Okay. Understood. Thank you.\n\n**Tim Cook** (CEO)\nYeah. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, Wamsi. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Samik Chatterjee with JPMorgan. Please go ahead.\n\n**Samik Chatterjee** (Managing Director and Senior Equity Research Analyst)\nHi, Mel. Thanks for taking my question. Maybe for the first one, Tim, you talked about the strong momentum you're seeing in China, which is also driving your confidence for the December quarter. Any thoughts on the role that the smartphone subsidies in that region are playing in this momentum? How do you think about sort of what portion of consumers are maybe using some of those subsidies, leveraging the subsidies at this point? Any more insights into that? I have a follow-up. Thank you.\n\n**Tim Cook** (CEO)\nYeah. The subsidies play a favorable role. The subsidies, as you know, are sort of across multiple categories from PCs to tablets to smartwatches and smartphones. However, it's important to note they only apply to certain price ranges. There's a maximum price, and there's several of our products that sell above that price and therefore are not eligible for a subsidy. It does have a favorable effect, and it's clearly, at least from our vantage point, driving some consumer demand.\n\n**Samik Chatterjee** (Managing Director and Senior Equity Research Analyst)\nOkay. Got it. A follow-up for Kevin here on the OpEx increase going into the December quarter, fairly sizable step up. If you could just dig into that number a bit more, what are sort of the components towards what you're spending? That increase year over year in OpEx does sort of exceed your revenue growth. Is that sort of what we should expect on a going-forward basis as well, where you probably need to invest a bit more in the near future? Thank you.\n\n**Kevan Parekh** (CFO)\nYeah. Samik, thanks for that question. As we've been outlining and reiterated in our last call, we are increasing our investments in AI. We'll also continue to invest in our product roadmap. The vast majority of the increase to our operating expenses are driven by R&D. While we continue to manage the company in a thoughtful and disciplined way, we're also managing the business for the long term and are super excited about all the opportunities we see ahead. As it relates to the question around OpEx and revenue growth, while OpEx has been growing at a faster rate than revenue, we have seen gross margin expansion. When we look at that on a combined basis, it does allow us to have healthy operating leverage, and our operating income growth has been generally outpacing revenue growth for the past several years.\n\n**Samik Chatterjee** (Managing Director and Senior Equity Research Analyst)\nClear. Thank you. Thanks a lot.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAwesome. Thank you, Samik. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from David Vogt with UBS. Please go ahead.\n\n**David Vogt** (Managing Director and Senior Equity Analyst)\nGreat. Thanks, guys, for taking my questions. Maybe, Kevin, can I ask first, can you help us understand the tariff impact sequentially from the September quarter to the December quarter, particularly around iPhone supply constraints? I think I heard you say tariffs go from $1.1 billion to $1.4 billion, but the sequential uplift in iPhone revenue and presumably production, given supply chain constraints, is dramatically bigger. Can you help us understand how to think about the timing of those tariff headwinds as we move forward and that correlation? I have a follow-up.\n\n**Tim Cook** (CEO)\nDavid, I'll take this one. You're right. It goes from $1.1 billion to a projection of $1.4 billion. The $1.4 billion is based on what we know right now and where the tariff rates and policies are. It assumes a stable kind of environment for the quarter. It does comprehend the change that was just made, which we're very encouraged to see, with the tariffs moving from 20% to 10% in China. That is factored in, and that is one of the reasons why it's not linear to volume, if you will. Does that make sense?\n\n**David Vogt** (Managing Director and Senior Equity Analyst)\nGot it. No, that's helpful. That's what I was asking, if the change is reflected in that outlook. As a follow-up, when you think about, I think on the Mac, I know people aren't asking about it, you talked about the tough comp, you're going into a holiday season. I understand that. When you think about the attached possibility for other products to the iPhone in the holiday season, how do we think about where the consumer's head is at and their wallet is at this point in the cycle? Granted, it is a tough comp, but is there an opportunity to see some upside from an attached rate perspective given the strength of the iPhone portfolio?\n\n**Tim Cook** (CEO)\nWe always like to remind people that by an iPhone, all the other things that we offer. You can bet that we're doing that. From a Mac point of view, the challenge is that last year was the mother of all Mac launches. All of these, from Mac Mini to iMac to all the MacBook Pros, all launched literally at the same time. This year, that compares to launching the 14-inch MacBook Pro, so there's a very difficult compare. Of course, in the long run, I'm very bullish on the Mac. You can see that the Mac, again, last quarter outgrew the market. We feel really well about how Mac is positioned, but this certain quarter is an extremely difficult compare.\n\n**Kevan Parekh** (CFO)\nTim, I'll add to that that we also had the DRAM upgrades last year for the Mac lineup, which also was another factor.\n\n**David Vogt** (Managing Director and Senior Equity Analyst)\nGreat. Thanks, Tim. Thanks, Kevin.\n\n**Tim Cook** (CEO)\nYeah. Sure.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAwesome. Thank you, David. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Krish Sankar with TD Cowan. Please go ahead.\n\n**Krish Sankar** (Managing Director)\nYeah. Thanks for taking my question. My first one is on the iPhone constraints. Is it a way to quantify how much business you left on the table because of those constraints? Is the different iPhone manufacturing from two different regions contributing to the constraint? I have a follow-up for you.\n\n**Tim Cook** (CEO)\nTo be clear, the constraint was not related to manufacturing capacity per se. It was that we called the number of iPhone 16s that we were going to make and were a bit short of where the demand really was. We could have sold more. We're not, publicly at least, estimating the extent of that. On iPhone 17 family, the demand is very strong. We obviously came out of the Q4 timeframe with lots of backorders.\n\n**Krish Sankar** (Managing Director)\nGot it. Thanks for that, Tim. A quick follow-up. Given the prevalence of chatbots and now some of these AI-infused web services, do you think that could change the consumer behavior on mobile app ecosystems? Are you seeing any of that? Would that have any impact on your App Store?\n\n**Tim Cook** (CEO)\nI think there are opportunities on the App Store with artificial intelligence. As we have made our on-device models available for developers, we've seen developers begin to adopt them. As that proliferates, there's an opportunity for developers and for Apple to benefit from that, from adding features to their apps and so forth.\n\n**Krish Sankar** (Managing Director)\nThanks a lot, Tim. Appreciate it.\n\n**Tim Cook** (CEO)\nYeah. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Krish. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Aaron Rakers with Wells Fargo. Please go ahead.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYeah. Thanks for taking the question. I have two as well. I guess the first question is, when we look at the iPhone 17 demand, which you've repeatedly highlighted as very strong, I'm curious if there's been any discernible kind of change in the mix within the iPhone 17 categories between the Pro and the Pro Max versions relative to prior cycles?\n\n**Tim Cook** (CEO)\nIt's really too early to call the mix, to be honest. We don't like to publicly disclose that for competitive reasons. Frankly, we don't really know what the mix will be yet because we have constraints on both sides of the ledger, at the top and at the entry. We'll see what happens as we get more supply.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nAs a quick follow-up, I'm curious as we work through the AI narrative that continues to build. Could you provide any updated thoughts around the buildout of Apple's Private Cloud Compute and how we should think about that as we look forward?\n\n**Tim Cook** (CEO)\nWe're obviously using PCC, our Private Cloud Compute, today for a number of queries for Siri, and we will continue to build it out. In fact, the manufacturing plant that makes the servers used for Apple Intelligence just started manufacturing in Houston a few weeks ago, and we've got a ramp planned there for use in our data centers. It's robust.\n\n**Kevan Parekh** (CFO)\nAaron, I'll add maybe there too, since you asked the question about Private Cloud Compute, that in 2025, we did have CapEx costs associated with building out our Private Cloud Compute environment in our first-party data centers. You would have seen that in some of the CapEx investment in the year.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nThank you.\n\n**Kevan Parekh** (CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Aaron. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Optus Malik with CITI. Please go ahead.\n\n**Atif Malik** (Semiconductor Capital Equipment and Specialty Semiconductors Analyst)\nHi. Thank you for taking my questions and great execution. The first question is on iPhone Air. Does the consumer reception on iPhone Air give you a feel on perhaps the foldable phone market, or are the two form factors very different?\n\n**Tim Cook** (CEO)\nI'm not sure that one is a proxy for the other. The thing that I would say is that where we don't get into the model kind of demand, at the aggregate level, we are thrilled with how iPhone has been received, and that's the reason that we're expecting double-digit growth in the current quarter.\n\n**Atif Malik** (Semiconductor Capital Equipment and Specialty Semiconductors Analyst)\nGreat. Tim, as a follow-up, good to know that the personalized Siri is making good progress and on track for next year. Will you continue to use a three-pronged approach with your own foundation models and partner with other LLM providers and maybe potential M&A, or is one strategy more emphasized over another?\n\n**Tim Cook** (CEO)\nWe're obviously creating Apple foundation models within Apple. We ship them on-device and use them in the Private Cloud Compute as well, and we've got several in development. We also continually surveil the market on M&A and are open to pursuing M&A if we think that it will advance our roadmap.\n\n**Atif Malik** (Semiconductor Capital Equipment and Specialty Semiconductors Analyst)\nThank you.\n\n**Tim Cook** (CEO)\nYep. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Optus. Operator, can we get our last question, please?\n\n**Operator**\nOur last question is from Richard Kramer with Array Research. Please go ahead.\n\n**Richard Kramer** (Founder and Managing Director)\nThank you very much. Tim, we've often seen Apple be a fast follower with iPhone and new technology, whether large displays or 4G or 5G. With all the hype now around AI, are you seeing evidence that AI capabilities or features are a material purchase consideration for consumers, or are the record sales levels you're reporting simply reflecting other factors like the retention of your iOS base?\n\n**Tim Cook** (CEO)\nI think that there are many factors that influence people's purchasing considerations. We don't have a great in-depth survey yet on the current iPhone 17 because it's very new in the cycle, and we give it some time to formulate. I would say that Apple Intelligence is a factor, and we're very bullish on it becoming a greater factor. That's the way that we look at it.\n\n**Richard Kramer** (Founder and Managing Director)\nOkay. Thanks. One for Kevin. In the wake of nearly every other large tech company massively increasing their CapEx in advance of AI demand and also mentioning that there's scarce capacity, do you anticipate Apple altering its sort of long-standing hybrid approach to your own and third-party data centers? Maybe can you talk a little bit about the role you see for Apple Silicon with the new M5 series of chipsets?\n\n**Kevan Parekh** (CFO)\nHi, Richard. Thanks for the question. In general, I think, as we've talked about before, we are expecting increases in our CapEx spending related to AI investments. For example, as I mentioned earlier, we did end up having investments this year to build out our Private Cloud Compute environment. We do believe this hybrid model has served us very well, and we continue to want to leverage it.I don't see us moving away from this hybrid model where we leverage both first-party capacity as well as leverage third-party capacity. We'll continue to want to build out Private Cloud Compute, as Tim outlined, as we have more usage there over time. In general, we'll want to continue to have this hybrid model.\n\n**Richard Kramer** (Founder and Managing Director)\nOkay. Thanks.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Richard. A replay of today's call will be available for two weeks on Apple Podcasts as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 0689794 followed by the pound sign. These replays will be available by approximately 5:00 P.M. Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142. Financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thanks again for joining us.\n\n**Operator**\nThis does conclude today's conference. We do appreciate your participation.",
        "fetched_at": "2026-02-04T16:08:51.087Z"
      },
      {
        "ticker": "AAPL",
        "title": "Yahoo Finance",
        "published_date": "Jul 31, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/AAPL/earnings/AAPL-Q3-2025-earnings_call-341149.html",
        "content": "**Suhasini Chandramouli** (Director of Investor Relations)\nGood afternoon, and welcome to the Apple q fiscal year twenty twenty five earnings conference call. My name is Suhasini Chandramali, Director of Investor Relations. Today's call is being recorded. Speaking first today is Apple's CEO, Tim Cook, and he'll be followed by CFO, Kevin Parekh. After that, we'll open the call to questions from analysts.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nPlease note that some of the information you'll hear during our discussion today will consist of forward looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation and future business outlook. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast, including risks related to the potential impact to the company's business and results of operations from macroeconomic conditions, tariffs and other measures, and legal and regulatory proceedings. For more information, please refer to the risk factors discussed in Apple's most recently filed reports on Form 10 Q and Form 10 ks and the Form eight ks filed with the SEC today along with the associated press release. Additional information will also be in our report on Form 10 Q for the quarter ended 06/28/2025 to be filed tomorrow and in other reports and filings we make with the SEC. Apple assumes no obligation to update any forward looking statements, which speak only as of the date they are made.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nI'd now like to turn the call over to Tim for introductory remarks.\n\n**Tim Cook** (Chief Executive Officer)\nThank you, Suasini. Good afternoon, everyone, and thanks for joining the call. Today, we are proud to report a June revenue record of $94,000,000,000 up 10% from a year ago, which was better than we expected. EPS set a June record of $1.57 up 12% year over year. We saw an acceleration of growth around the world in the vast majority of markets we track, including Greater China and many emerging markets.\n\n**Tim Cook** (Chief Executive Officer)\nAnd we had June revenue records in more than two dozen countries and regions, including The US, Canada, Latin America, Western Europe, The Middle East, India, and South Asia. These results were driven by double digit growth across iPhone, Mac, and services. We set a June record for iPhone, which grew a strong 13% year over year. We saw iPhone growth in every geographic segment and double digit growth in emerging markets, including India, The Middle East, South Asia and Brazil. Mac continued to see excellent results with revenue up 15% year over year.\n\n**Tim Cook** (Chief Executive Officer)\nAnd we set another all time revenue record in services, which grew 13% with double digit growth in both developed and emerging markets. Last month, we hosted WWDC, an incredible event for our developer community with millions joining us online and more than 1,000 developers here in person at Apple Park. We shared some truly exciting updates, including a stunning new design crafted from a material we call liquid glass. It's both beautiful and expressive. And for the first time ever, this design extends across all of our platforms.\n\n**Tim Cook** (Chief Executive Officer)\nWe can't wait for users everywhere to experience it this fall. And we were excited to share some updates across our AI work. We announced even more capabilities coming later this year, including live translation and WorkoutBuddy. In addition to those new features, we announced new support for a number of languages. And we opened up access to the on device foundation models at the core of Apple Intelligence, enabling developers to build a whole new experience for our users.\n\n**Tim Cook** (Chief Executive Officer)\nIt's wonderful to see great momentum building for our platforms. IOS 26, macOS 26 and iPadOS 26 are by far the most popular developer betas we've had. Taking a step back, we see AI as one of the most profound technologies of our lifetime. We are embedding it across our devices and platforms and across the company. We are also significantly growing our investments.\n\n**Tim Cook** (Chief Executive Officer)\nApple has always been about taking the most advanced technologies and making them easy to use and accessible for everyone, and that's at the heart of our AI strategy. With Apple Intelligence, we're integrating AI features across our platforms in a way that is deeply personal, private, and seamless, right where users need them. We've already released more than 20 Apple Intelligence features, including visual intelligence, cleanup and powerful writing tools. We're making good progress on a more personalized Siri. And as we've said before, we expect to release these features next year.\n\n**Tim Cook** (Chief Executive Officer)\nApple Silicon is at the heart of all of these experiences, enabling powerful Apple intelligence features to run directly on device. For more advanced tasks, our servers, also powered by Apple Silicon, deliver even greater capabilities while preserving user privacy through our private cloud compute architecture. We believe our platforms offer the best way for users to experience the full potential of generative AI. Thanks to the exceptional performance of our systems, our users are able to run generative AI models right on their Mac, iPad and iPhone. We're excited about the work we're doing in this space, and it's incredibly rewarding to see the strong momentum building.\n\n**Tim Cook** (Chief Executive Officer)\nNow let me turn to more details about our results for the quarter, starting with iPhone. IPhone revenue was $44,600,000,000 up 13% from a year ago, and we set a June record for upgraders. This strong broad based performance was driven by the incredible popularity of the iPhone 16 family, which was up strong double digits year over year as compared to the 15 family. We also recently marked a significant milestone. We shipped the three billionth iPhone since its launch in 02/2007.\n\n**Tim Cook** (Chief Executive Officer)\nFrom the Pro models with the powerhouse A18 Pro and innovative Pro camera features to the iPhone 16E with breakthrough battery life and a two in-one camera system, users are finding so many reasons to love the best iPhone lineup we've ever created. And iOS 26 will take that experience even further. In addition to the beautiful new design and powerful Apple intelligence features, it introduces a range of meaningful updates, like real time call screening and hold assist in the phone app, smarter messaging tools and new live translation features. It all adds up to a smarter, more personal iPhone experience that we can't wait for users everywhere to enjoy this fall. In Mac, we had another strong quarter with revenue of $8,000,000,000 up 15% year over year, largely driven by the strength of the M4 MacBook Air.\n\n**Tim Cook** (Chief Executive Officer)\nWe set a June record for upgraders on Mac, and we saw great performance in emerging markets with strong double digit growth on revenue as well as strong double digit growth on both upgraders and customers new to Mac. MacBook Air, the world's most popular laptop, unlocks a whole new level of performance with the power of M4. MacBook Pro customers, meanwhile, continue to be drawn to its incredible power and the longest battery life we've ever had on a Mac. Customers are also loving the newest Mac Studio, which is the most powerful Mac we've ever made with next level capabilities to tackle even the most demanding AI workflows. At the same time, Mac Mini continues to win over customers by packing so much performance into an ultra compact design.\n\n**Tim Cook** (Chief Executive Officer)\nAnd with fantastic new updates in macOS Tahoe 26, from the phone app to live activities to our biggest ever update to Spotlight, Mac users across our entire lineup are going to find delightful new ways to stay connected and productive. For iPad, June revenue was $6,600,000,000 Our incredibly versatile iPad lineup brings together power and portability like never before, And users are already excited for our biggest iPad software update ever with the upcoming release of iPadOS 26. It starts with a new windowing system that's remarkably intuitive, giving users more control than ever of their iPad experience. An enhanced Files app makes it easier than ever to stay organized. And that's all on top of a beautiful new software design that brings these updates to life.\n\n**Tim Cook** (Chief Executive Officer)\nTurning to Wearables, Home and Accessories. Revenue was $7,400,000,000 and we saw a June record for upgraders to Apple Watch. During the quarter, we marked the ten year anniversary of Apple Watch, celebrating a decade of helping users navigate their health and fitness journeys. And with watchOS '20 six, Apple Watch will be more intelligent than ever with smart updates to the workout app and smart stack along with a fresh new design that feels both dynamic and personal. We're also thrilled about what's coming to Apple Vision Pro with Vision OS 26, introducing spatial widgets that let users customize their digital space, more lifelike personas, and new enterprise APIs that empower companies to build their own spatial experiences.\n\n**Tim Cook** (Chief Executive Officer)\nAnd this fall, new features for our latest AirPods lineup will unlock even more possibilities from studio quality audio recording to using AirPods as a camera remote, giving users powerful new ways to capture content and stay connected. As we're innovating across our lineup, we're especially proud of the work we're doing to help our users live healthier lives. Since we first launched our hearing health features for AirPods Pro two, I've received notes from people who are delighted to be able to connect more deeply with loved ones. Whether it's with AirPods Pro two or Apple Watch or iPhone, it's amazing to see the power of our health and safety features, from hearing tests to fall detection alerts to irregular rhythm notifications having such a profound impact. Turning to services.\n\n**Tim Cook** (Chief Executive Officer)\nRevenue for the June was $27,400,000,000 up 13% from a year ago and an all time record. Apple TV plus scored 81 nominations, a record for the platform across nearly every eligible category for this year's Emmy Awards. Severance leads all Emmy nominees with 27 nominations, and the studio follows close behind with 23 nominations, more than any other freshman comedy series ever. It's amazing to see how these and other Apple TV shows have captured the popular imagination. To date, Apple TV plus has earned more than 2,700 award nominations and five eighty five wins on the strength of the highest rated original content of any streaming network.\n\n**Tim Cook** (Chief Executive Officer)\nAnd we continue to see very positive trends in the June with TV plus viewership up strong double digits year over year. In June, we were also thrilled to release F1 in theaters around the world, one of the summer's most unforgettable blockbusters. During the quarter, we celebrated a big anniversary with ten years of Apple Music. To mark the occasion, we launched an all new studio space in Los Angeles for artists to create content and connect with fans. And later this year, we're bringing Apple Music users even more to love, from an enhanced listening experience with automix, which mixes songs like a DJ, to lyrics translation and more.\n\n**Tim Cook** (Chief Executive Officer)\nThe App Store, meanwhile, continues to be the very best place to discover the latest apps from developers around the world in a safe and trusted way, and App Store revenue grew double digits year over year, setting a June record. In retail, we continue to find opportunities in emerging markets to connect with even more customers. We recently launched the Apple Store online in Saudi Arabia, and we couldn't be more excited to open new stores in The UAE and India later this year. We were also delighted to welcome customers in Japan to a new location in the heart of Osaka. Across everything we do at Apple, we show up by leading with our values.\n\n**Tim Cook** (Chief Executive Officer)\nWe feel strongly that the benefits of technology should be shared by everyone. That's why we make technology for everyone. In May, to mark Global Accessibility Awareness Day, we announced updates to help users learn, connect and interact with their worlds, including Magnifier for Mac, a new braille experience and Accessibility Reader, a new system wide reading mode to make it easier to understand content. And we're proud to introduce accessibility nutrition labels, giving users an understanding of accessibility features before they download an app while helping developers educate people on features their app support. This month, we also announced a $05,000,000,000 commitment with NP Materials to strengthen the supply of vital recycled rare earth materials in The U.\n\n**Tim Cook** (Chief Executive Officer)\nS. And support American industry. And in August, we're opening our all new Apple Manufacturing Academy in Detroit to train and support American manufacturers. These investments are part of Apple's largest ever spin commitment, which we announced earlier this year. Over the next four years, Apple is investing $500,000,000,000 in The U.\n\n**Tim Cook** (Chief Executive Officer)\nS, driving innovation and creating jobs in cutting edge fields like advanced manufacturing, silicon engineering, and artificial intelligence. We're proud of this work and all that we're doing to tap into American innovation and bring the best technology experiences to users across the globe. And we continue to look for further opportunities to do even more. Finally, the situation around tariffs is evolving, so let me provide some color there. For the June, we incurred approximately $800,000,000 of tariff related costs.\n\n**Tim Cook** (Chief Executive Officer)\nFor the September, assuming the current global tariff rates policies and applications do not change for the balance of the quarter and no new tariffs are added, we estimate the impact to add about $1,100,000,000 to our costs. This estimate should not be used to make projections for future quarters as there are many factors that could change, including tariff rates. We're really proud of our results for the June, and I want to thank our teams and our customers. In everything we do, we're driven by transformative innovation, delivering the most exceptional products and services we've ever created, and we're especially excited about what's ahead. With that, I'll turn it over to Kevin.\n\n**Kevan Parekh** (SVP &amp; CFO)\nThanks, Tim, and good afternoon, everyone. Our revenue of $94,000,000,000 was up 10% year over year and is a new June record. We grew in every geographic segment and in the vast majority of the markets we track. Products revenue was $66,600,000,000 up 8% year over year, driven by growth across iPhone and Mac. And thanks to our high levels of customer satisfaction and strong loyalty, our installed base of active devices reached another all time high across all product categories and geographic segments.\n\n**Kevan Parekh** (SVP &amp; CFO)\nServices revenue was $27,400,000,000 up 13% year over year and an all time record. We saw strength across the world with double digit growth in the majority of our markets. Company gross margin was 46.5%, at the high end of our guidance range and down 60 basis points sequentially, primarily driven by approximately $800,000,000 in tariff related costs Tim mentioned earlier. Products gross margin was 34.5%, down 140 basis points sequentially, driven by mix and tariff related costs, partly offset by cost savings. Services gross margin was 75.6%, down 10 basis points sequentially.\n\n**Kevan Parekh** (SVP &amp; CFO)\nOperating expenses landed at $15,500,000,000 up 8% year over year. This strong business performance led to June records for both net income at $23,400,000,000 and diluted earnings per share of 1.57 which was up 12% year over year. Operating cash flow was also strong at $27,900,000,000 Now I'm going to provide some more details for each of our revenue categories. IPhone revenue was $44,600,000,000 up 13% year over year driven by the iPhone 16 family. As Tim noted, we saw iPhone growth in every geographic segment and double digit growth in many emerging markets.\n\n**Kevan Parekh** (SVP &amp; CFO)\nThe iPhone active installed base grew to an all time high in total and in every geographic segment, and we reached a June record for upgraders. According to a recent survey from World Panel, formerly of Kantar, iPhone was a top selling model in The U. S, urban China, The U. K, Australia, and Japan during the June. And we continue to see very high levels of customer satisfaction in The U.\n\n**Kevan Parekh** (SVP &amp; CFO)\nS. At 98%, as measured by four fifty one Research. Mac revenue was $8,000,000,000 up 15% year over year, driven by continued strength across the portfolio, including MacBook Air, Mac Mini, and MacBook Pro. We grew in every geographic segment and saw double digit growth in Europe, Greater China, and the rest of Asia Pacific. The Mac installed base reached an all time high and we hit a June record for upgraders.\n\n**Kevan Parekh** (SVP &amp; CFO)\nIn The U. S, customer satisfaction was recently measured at 97%. IPad revenue was $6,600,000,000 down 8% year over year, which was expected given the difficult compare against the launch of the iPad Air and iPad Pro in the year ago quarter. At the same time, the iPad installed base reached another all time high and over half of the customers who purchased an iPad during the quarter were new to the product. And based on the latest reports from four fifty one Research, customer satisfaction was 98% in The U.\n\n**Kevan Parekh** (SVP &amp; CFO)\nS. Wearables, Home and Accessories revenue was $7,400,000,000 down 9% year over year. This was driven by a difficult compare on accessories due to the prior year's iPad launches that I just referred to. The Apple Watch installed base reached a new all time high with over half of customers purchasing an Apple Watch during the quarter being new to the product. We also set a quarterly record for upgraders on Apple Watch.\n\n**Kevan Parekh** (SVP &amp; CFO)\nAnd the latest customer satisfaction for Watch in The U. S. Was reported at 97%. Our services revenue reached an all time high of $27,400,000,000 up 13% year over year. The performance in the June was broad based.\n\n**Kevan Parekh** (SVP &amp; CFO)\nWe saw a sequential acceleration across a majority of the categories, including cloud services where we reached an all time revenue record driven by the year over year growth of iCloud paying accounts. We saw strong momentum during the June, and the growth of our installed base of active devices gives us great opportunities for the future. Customer engagement across our services offerings also continued to grow. Both transacting and paid accounts reached new all time highs, with paid accounts growing double digits year over year. Paid subscriptions also grew double digits.\n\n**Kevan Parekh** (SVP &amp; CFO)\nWe have well over 1,000,000,000 paid subscriptions across the services on our platform. We continue to improve the quality and breadth of our service offerings, from the new Apple Games app to a continued expansion of tap to pay and Wallet. Turning to enterprise, organizations are continuing to invest in Apple products to drive employee innovation and productivity. With companies like PayPal and Roche deploying more Macs for their workforce, we had the best June ever for Mac and Enterprise. In Thailand, Siam Commercial Bank, one of the largest Thai banks, has deployed thousands of iPads across their branches to enhance the quality and efficiency of their banking operations from loan services to wealth management.\n\n**Kevan Parekh** (SVP &amp; CFO)\nCAE, a leader in pilot training and simulation technology, is using Apple Vision Pro to enable pilots to become more familiar with aircraft procedures, leading to more productive in person flight simulator training outcomes. Let's turn to our cash position and capital return program. We ended the quarter with $133,000,000,000 in cash and marketable securities. We had 5,700,000,000 of debt maturities, issued $4,500,000,000 of new debt and increased commercial paper by $4,000,000,000 resulting in $102,000,000,000 in total debt. Therefore, at the end of the quarter, net cash was $31,000,000,000 During the quarter, we returned over $27,000,000,000 to shareholders.\n\n**Kevan Parekh** (SVP &amp; CFO)\nThis included $3,900,000,000 in dividends and equivalents and $21,000,000,000 through open market repurchases of 104,000,000 Apple shares. As we move into the September, I'd like to review our outlook, which includes the types of forward looking information that Suhasim referred to. Importantly, the color we're providing assumes that the global tariff rates, policies, and application remain in effect as of this call, the global macroeconomic outlook does not worsen from today, and the current revenue share agreement with Google continues. We expect our September total company revenue to grow mid to high single digits year over year. We expect services revenue to grow at a year over year rate similar to what we reported in the June.\n\n**Kevan Parekh** (SVP &amp; CFO)\nWe expect gross margin to be between 4647%, which includes the estimated impact of the $1,100,000,000 tariff related costs that Tim referred to earlier. We expect operating expenses to be between $15,600,000,000 and $15,800,000,000 We expect OI and E to be around negative $25,000,000 excluding any potential impact from the mark to market of minority investments and our tax rate to be around 17%. Finally, today our Board of Directors has declared a cash dividend of $0.26 per share of common stock payable on 08/14/2025, to shareholders of record as of 08/11/2025. With that, let's open the call to questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Kevin. We ask that you limit yourself to two questions. Operator, may we have the first question please?\n\n**Operator**\nCertainly. We'll go ahead and take our first question from Michael Ng with Goldman Sachs. Please go ahead.\n\n**Michael Ng** (Analyst)\nHey, good afternoon. Thank you for the questions. I just have one on upgrade rates and one on CapEx. First, on the upgrade rates, it was encouraging to see the records on iPhone, Mac and Watch. I was wondering if you're seeing strength in the upgrade rates?\n\n**Michael Ng** (Analyst)\nOr is the records more a function of the growing installed base? What is your research showing that made upgrades particularly compelling this year? For example, is it product features, tariff pull forward, perhaps Apple Intelligence? And then I'll give my follow-up on CapEx.\n\n**Tim Cook** (Chief Executive Officer)\nYou want to do CapEx first?\n\n**Kevan Parekh** (SVP &amp; CFO)\nYes, let's do CapEx first. Mike,\n\n**Michael Ng** (Analyst)\nthe CapEx, it's up notably year to date. Could you just comment on your capital spending plans this year and next and provide some qualitative color in terms of what's driving that growth? Is it AI related or supply chain diversification, for instance? Thank you.\n\n**Kevan Parekh** (SVP &amp; CFO)\nYeah, Mike. It's it's it's a combination of factors. I would say a pretty significant driver, as Tim talked about, is the fact we are increasing our investment significantly in AI. So that is certainly a a component of it. As you know, we've been investing in private cloud compute, is also in our first party data centers.\n\n**Kevan Parekh** (SVP &amp; CFO)\nThe other piece, as you know, is we do have a hybrid strategy where in cases we do use third parties to make capital investments, and we also invest in our own. So you are going to see an increase in CapEx. We also from time to time have other investments in facilities, in tooling, but I would say a significant portion of the driver of growth that you're seeing now is really driven by some of our AI related investments.\n\n**Tim Cook** (Chief Executive Officer)\nOn the upgrades, Michael, if you look at iPhone, the 16 family grew double digit as opposed to the 15 family from the year ago quarter. And so we did set an upgrade record. I think it directly is because of the strength of the product. Mac also set records on upgrade. And I think, you know, we continue to see a move to Apple Silicon and the performance of Apple Silicon is playing a very key role.\n\n**Tim Cook** (Chief Executive Officer)\nAnd so it was an incredible quarter. In terms of if you're wondering about pull forward, we would estimate the pull forward of demand into April specifically to be about one point of the 10 points in terms of people buying because of discussions about tariffs.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAlright.\n\n**Michael Ng** (Analyst)\nThank you, Tom. Thank you, Kevin.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Mike. Operator, can we have the next question, please?\n\n**Operator**\nOur next question is from Eric Woodring with Morgan Stanley. Please go ahead.\n\n**Erik Woodring** (MD - Equity Research)\nHey, good afternoon, guys. Thank you very much for taking my questions. I have two as well. Pip, maybe starting with You know, shortly after March earnings, there were some reports about searches on Safari declining in April for the first time, I think, in over two decades. Judging by your 13% services growth this quarter, it doesn't seem to indicate that April trends necessarily played out through the remainder of the June quarter.\n\n**Erik Woodring** (MD - Equity Research)\nAnd so I'm I'm really just looking for a little bit more color on on really how the rest of the quarter played out and if you believe Apple products as kind of search access points are losing their strategic value as AI platforms become more valuable or popular or increasing in strategic value? And then I have a follow-up. Thank you.\n\n**Tim Cook** (Chief Executive Officer)\nI think they continue to be very valuable. I think that consumers' behaviors are evolving, and we're monitoring it very closely.\n\n**Erik Woodring** (MD - Equity Research)\nOkay. I appreciate that color. Thanks, Tim. And then maybe second to that, I'd love if you could maybe elaborate a bit on what you're seeing in China. I think in an interview earlier this afternoon, you alluded to some of the promotions being tailwinds.\n\n**Erik Woodring** (MD - Equity Research)\nBut just bigger picture, if we take a step back in China, how would you characterize demand interest in the iPhone 16 and some of your other products? Is that shifting? Or maybe were some of the trends in the June maybe a bit more onetime and unique in nature?\n\n**Tim Cook** (Chief Executive Officer)\nYes.\n\n**Tim Cook** (Chief Executive Officer)\nWe did grow in Greater China by 4% during the quarter versus the previous quarter. It was driven by an acceleration by iPhone, although we also had substantial growth on the Mac year over year. From a as you know, the government has placed certain subsidies that affect some of our products, not all of them, but there are some of them. And I think that had some effect. It was the first full quarter of the subsidy playing out.\n\n**Tim Cook** (Chief Executive Officer)\nThat it cut in during a portion of the previous quarter. The also the other things I would say are the that the installed base hit a record high in Greater China, and we set an all time record for the iPhone installed base. The iPhone upgraders in Mainland China set a record for the June. And according to World Panel, which was formerly known as Kantar, iPhone had the top three models in urban China, which is extraordinary. Also, you look at the other products, Mac, iPad, and Watch, the majority of customers that are buying in China Mainland were new to the product.\n\n**Tim Cook** (Chief Executive Officer)\nSo lots of good things there. And the other thing I would point out, which is an interesting point, the MacBook Air was the top selling laptop model in all of China, and the Mac Mini was the top selling desktop model in in all of China. So overall, a positive very positive quarter.\n\n**Erik Woodring** (MD - Equity Research)\nGreat. Thanks for the color, Tim. Good luck.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nRight. Thank you, Eric. Eric. Operator, can we have the next question, please?\n\n**Operator**\nOur next question is from Ben Reitsis with Melius Research. Please go ahead.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nYeah. Thanks. I I really appreciate it. I wanted to, ask about Siri, Tim, and just overall AI investment. There's a perception that Siri is going to help drive other new products potentially that maybe where voice is quite needed.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nAnd just wondering in your how's your confidence towards launching that next year? Is there anything that's been done internally to increase that confidence? Is it tied to the investment? I just think folks would love to know a little bit more about your confidence and how that's going. And then I have a follow-up. Thanks.\n\n**Tim Cook** (Chief Executive Officer)\nYes. Thanks for the question. We're making good progress on a more personalized Siri, and we do expect to release the features next year as we had said earlier. Our focus from an AI point of view is on putting AI features across the platform that are deeply personal, private, and seamlessly integrated. And, of course, we've done that with more than 20 Apple intelligence features so far from visual intelligence to cleanup to writing tools and all the rest.\n\n**Tim Cook** (Chief Executive Officer)\nWe are significantly growing our investment. We did during the June. We will again in the September. I'm not putting specific numbers behind that at this point, but you can probably tell in the guidance that things are moving up. We are also reallocating a fair number of people to focus on AI features within the company that are you know, we have great, great team, and we're we're putting all of our energy behind it.\n\n**Tim Cook** (Chief Executive Officer)\nTerms of products here. In terms of other products, I you know, I don't want to really comment on specific other products, but we have an exciting road map ahead. And I could not be more excited about it.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nThat's great, Tim. Thanks for the color. Just with regard to my second question, it's about the overall revenue guide. And I appreciate that you guide the best you can see it, but I just wanted to challenge it from a different way is, why would it decelerate if services is staying the same at 13%? What is there a conservatism there?\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nI would think even currency is just as favorable, if not more favorable. So why would it decelerate to the higher single digits from where you were in the quarter? Or is it just being conservative? And if there's something decelerating or a comp, do you mind just pointing that out? Thanks.\n\n**Kevan Parekh** (SVP &amp; CFO)\nYeah, Ben, this is Kevin. Thanks for the question. I think when you look at the growth from Q3, which is reported to the mid to high single digit guide, I think you have to kind of keep in mind two components. The first is the effect of the tariff related pull ahead in demand that Tim referenced earlier, which we estimated to be about one point of the 10 points that we ended up doing in Q3. And then the other factor that I think you have to take into consideration is the fact that in September a year ago, we had the full quarter impact of the iPad launches, which also leads to a difficult compare this year.\n\n**Kevan Parekh** (SVP &amp; CFO)\nSo those two components are things you have to take into consideration as you think about the move from Q3 to Q4. I would say foreign exchange is a very minor tailwind going from Q3 to Q4, so not really a major factor.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nOkay, thanks a lot.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAwesome. Thank you, Ben. Operator, could we have the next question please?\n\n**Operator**\nOur next question is from Wamsi Mohan with Bank of America. Please go ahead.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nHi, yes. Thank you so much. Tim, I know you said similar growth in services and that's predicated with Google payments continuing. Is there any way for us to dimensionalize sort of or maybe just conceptually talk about maybe options if the counter were to happen, if the payments were not allowed in some way, what are some of the things that Apple could do given that it is a significant chunk of profitability? And I have a follow-up.\n\n**Tim Cook** (Chief Executive Officer)\nYeah. Wamsi, I don't really want to speculate on the court ruling and how they would rule and what we would do as a consequence of it.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nOkay. Okay. I guess we'll wait for that ruling to come out. I guess separately, Tim, at a high level, when you look at some of what is perceived fears of new form factors and ways to interact with devices, there was some worry that given some of the developments in AI that there could be a world where dependence on screen based devices significantly diminishes. And I'm kind of curious to get your thoughts on if do you think that would happen and and rate and pace in which, and and how do you think Apple is preparing in in in that case?\n\n**Tim Cook** (Chief Executive Officer)\nYeah. When you when you think about all the things an iPhone can do from connecting people to bringing app and game experiences to life, to taking photos and videos, to helping users explore the world and conduct their financial lives and pay for things and so much more. You know, it's it's difficult to see a world where iPhone's not living in it. And that doesn't mean that we are not thinking about other things as well. But I think that the devices are likely to be complementary devices, not substitution.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nOkay. Thank you so much, Tim.\n\n**Tim Cook** (Chief Executive Officer)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Wamsi. Operator, could we have the next question, please?\n\n**Operator**\nNext question is from Amit Daryanani with Evercore. Please go ahead.\n\n**Amit Daryanani** (Senior MD - Equity Research)\nYes. Good afternoon. I guess to start with, Tim, the tariff assumption of $1,100,000,000 in the September, kind of saw I understand the uptick you folks are talking about. But can you just talk about assuming tariffs remain at these levels or even if they evolve under Section two thirty two, how do you eventually think about offsetting this headwind to your P and L? And when do you decide to execute on the levers to offset this headwind versus just looking at your bottom line?\n\n**Tim Cook** (Chief Executive Officer)\nYou know, right now, we're just estimating the cost of it. And it's up quarter over quarter because our volume is up quarter over quarter. And there was some build ahead in the previous quarter. And so that's the primary reasons that it's up. In terms of what we do to mitigate, we obviously try to optimize our supply chain.\n\n**Tim Cook** (Chief Executive Officer)\nAnd ultimately, we're we will do more in The United States. We've committed 500,000,000,000 investment in The U. S. Over the next four years, and we've already building chips in Arizona. And in fact, we're building semiconductors across 12 states and 24 factories and have a lot of other things in the works.\n\n**Tim Cook** (Chief Executive Officer)\nYou probably saw the investment in MP Materials last week. And so we continue to explore these things and look for more that we can do, which I think ultimately is the objective.\n\n**Amit Daryanani** (Senior MD - Equity Research)\nGot it. Super helpful. And then your services growth, I think, was extremely impressive at 13%, especially given all the fierce folks had. Can you just touch on did you see any impact that was notable from the Epic case and the steering dynamics that came after that? And maybe just touch on what does that appeals process looks like looks like for me as you go forward? Thank you.\n\n**Kevan Parekh** (SVP &amp; CFO)\nYeah. This is Kevin. Let let me take that one. In general, I think, just reminding, I think you just said we had a very strong services quarter. We had an all time record, had the $27,400,000,000 up 13%.\n\n**Kevan Parekh** (SVP &amp; CFO)\nThe one thing I would also say is our services performance is broad based. So we also saw strength in developed and emerging markets, both parts of the world had double digit growth. We also saw a sequential acceleration across the majority of our categories, including cloud services where I mentioned in the prepared remarks that we had an all time revenue record. As it relates to the Epic decision, you know, we keep in mind, we only just introduced the change required by the court in the June. And as you know, we don't provide the level of detail, but but in general, I would say it was a very, very in in The US, we had a double digit growth for The US App Store, and we set an all time record.\n\n**Kevan Parekh** (SVP &amp; CFO)\nAnd so we'll continue to monitor the effects on our business, but we'll continue to innovate and ensure that the App Store delivers the best experience for users and remains a great business opportunity for developers.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, Amit. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from David Vo with UBS. Please go ahead.\n\n**David Vogt** (Managing Director)\nGreat. Thanks, guys. And I have two questions as well. Maybe, Tim, just on the supply chain strategy. I know last quarter, talked about focusing production or assembly to India.\n\n**David Vogt** (Managing Director)\nAnd I just want to get an update on how you're thinking about the strategy holistically given sort of the tariff rates, I think, in India potentially are higher than I think anyone has expected. So I know you mentioned some U. S. Investments would love to kind of get your thoughts on how you're thinking about China versus the rest of Southeast Asia and India going forward. And then I'll give you my second question also.\n\n**David Vogt** (Managing Director)\nSo Kevin, I'm just trying to understand a little bit more about the demand drivers of iPhone in the quarter because obviously the 16 has been in the market for some time. I know there was some promotional activity, but seasonally, you generally don't see this kind of strength in the June quarter. Maybe can you help us understand outside of maybe the promotional activity, what else were some of the drivers that led to what was looks like a pretty significant above seasonal strength in the June? Thanks.\n\n**Tim Cook** (Chief Executive Officer)\nYeah. In terms of the tariff situation and country of origin and so forth, one thing I would say just to remind everyone is keep in mind that the vast majority of our products are covered under the Section two thirty two investigation. And so the today, or I should say last quarter, the bulk of the tariffs that we paid were the IEEPA tariffs that hit early in the year related to China. And so that's just a reminder of where things are and what we assumed as we calculated the projection of $1,100,000,000 that's in our outlook color. In terms of the country of origin, it's the same as I referenced last quarter. There hasn't been a change to that, which is the vast majority of the iPhones sold in The US, or the majority, I should say, have a country of origin of India. And the the vast majority of the products other products, the Mac and the iPad and the Watch, have a country of origin of Vietnam that are sold in The United States.\n\n**Tim Cook** (Chief Executive Officer)\nStill, the products for other international countries, the vast majority of them are coming from China. And so that hopefully gives you a flavor of the of where things are. But I would I would stress again that we do a lot in this country, in The United States, and we've committed $500,000,000,000 and we're always looking to do more. And you could kind of see that in the most recent announcements, whether it's MP Materials or our manufacturing academy that we're standing up in Detroit in a couple weeks or so. And and so we're gonna be doing we're doing more in this country, and that's on top of having roughly 19,000,000,000 chips coming out of The US now, and we're we will do more. And, of course, glass from iPhone and the face ID module. And so there's there's loads of different things that are done in in The United States.\n\n**David Vogt** (Managing Director)\nAnd then, David, as as And then on the and then on the iPhone activity?\n\n**Kevan Parekh** (SVP &amp; CFO)\nYeah. So I was gonna mention the iPhone activity. You asked if there's any kind of unique characteristics this quarter. I would just say, as Tim outlined, we really believe that the strong upgrade performance, which was a, you know, a June record, was really driven by the strength of the product lineup. You know, the iPhone 16 family has done incredibly well compared to the iPhone 15 family.\n\n**Kevan Parekh** (SVP &amp; CFO)\nAnd we also, as you recall, you know, recently introduced the 16 e as well, which also continued to, you know, impact the success of the overall iPhone 16 lineup.\n\n**David Vogt** (Managing Director)\nGreat. Thanks, guys. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nGreat. Thank you, David. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Krish Sankar with TD Cowen.\n\n**Krish Sankar** (Managing Director)\nI have two of The first one is for Kevin. Just on the previous question, do you think there was any pull in of iPhones in the June that led to some of the upside? And how to think about channel inventory in June and how it looks in September relative to seasonal trends? And then I had a longer term follow-up for Tim.\n\n**Tim Cook** (Chief Executive Officer)\nLet me see if can answer the channel inventory question or what I think is the channel inventory question. If you look at iPhone channel inventory from the beginning of the quarter to the end of the quarter, we reduced it and it ended toward the low end of our targeted range. And so that's the answer on the inventory piece of it.\n\n**Kevan Parekh** (SVP &amp; CFO)\nAnd then I think you also asked about the pull ahead impact. I think we referenced that earlier. Just to be clear on what we believe we saw on the June, we did, you know, we did see some obvious signs of pull ahead really in the April time frame around the tariff related, you know, discussions that were out in the marketplace. And so we felt that that was, from what we saw, about a one point impact of the 10 points at a total company level of growth. And so that was the the limited impact that we really we saw for the quarter.\n\n**Krish Sankar** (Managing Director)\nGot it. Very helpful. I know I just had like a a long term follow-up for Tim. Tim, I was kinda curious about your thoughts on AI for edge devices. You know, there's, like, some people who think that LLM could be a commodity in the future.\n\n**Krish Sankar** (Managing Director)\nDo you think do you see a scenario where LLM become a core part of your iOS? Or is the SLM the way to go? And how to think about evolution of edge devices in a futuristic AI world, and is smartphone gonna be the choice of device? Just curious your thoughts on it, broadly speaking. Thank you.\n\n**Tim Cook** (Chief Executive Officer)\nI the way that we look at AI is that it's one of the most profound technologies of our lifetime. And I think it will affect all devices in a significant way. What pieces of the chain are commoditized and not commoditized, I wouldn't want to really talk about today because that gives away some things on our strategy. But I think it's a good question.\n\n**Krish Sankar** (Managing Director)\nThanks, Jim.\n\n**Tim Cook** (Chief Executive Officer)\nYeah.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Krish. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Samik Chatterjee with JPMorgan. Please go ahead.\n\n**Samik Chatterjee** (MD &amp; Equity Research Analyst)\nHi. Thanks for taking my questions. Tim, maybe if I can start with your remarks about the pull ahead being about a one percentage point benefit here. Anything to share in terms of how what's underlying that estimate in terms of what you're seeing for? Is it a pull ahead largely on iPhones?\n\n**Samik Chatterjee** (MD &amp; Equity Research Analyst)\nOr is it across the board? And is it primarily in The US or, again, sort of across multiple regions? Any color there would be helpful in terms of how you're sort of getting to that assumption there. And I have a follow-up.\n\n**Tim Cook** (Chief Executive Officer)\nIt was principally on iPhone and Mac. And it was pretty you know, it was obvious evidence of it. It was an unusual buying pattern there and that largely occurred in April toward the beginning of the quarter. And it was really we believe it was largely United States.\n\n**Samik Chatterjee** (MD &amp; Equity Research Analyst)\nOkay. Okay. Got it. And maybe on the tariff front, when you gave the estimate of $900,000,000 last quarter, which came in at 800,000,000 you did highlight it was there were some unique factors in the quarter. When I take the $1,100,000,000 that you're now sort of expecting for the September quarter, and as we start to think about December, would is there anything unique in the December quarter in terms of sourcing from regions, etcetera, that would uniquely impact December just given sort of that you had highlighted that quarter to quarter or so there would be unique things?\n\n**Samik Chatterjee** (MD &amp; Equity Research Analyst)\nJust curious if December looks very different from September because of any unique factors.\n\n**Tim Cook** (Chief Executive Officer)\nI would be careful about projecting based on the numbers from Q2 and Q3 because, one, we're uncertain of what the rates will be, and so the rates may change. Two, in particularly in last quarter, we had some build ahead inventory that we were that we had within the company and within our supplier within our supply chain. And so those two are a little unique. Also, as you know from following us for so long, Q1 is generally a higher volume quarter. The tariffs are currently are pretty linear with volume.\n\n**Samik Chatterjee** (MD &amp; Equity Research Analyst)\nOkay. No, understood. Thank you.\n\n**Tim Cook** (Chief Executive Officer)\nYeah.\n\n**Samik Chatterjee** (MD &amp; Equity Research Analyst)\nThanks for taking my questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, Samik. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Aaron Rakers from Wells Fargo. Please go ahead.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nYeah.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nThanks for taking the question. I've I've got two as well, and and I'll just ask them together. I I guess the first one is just more housekeeping. Kevin, when we think about, you know, currency impact, how much of a benefit was currency this quarter? And I guess across the business and in particular, maybe on the services segment?\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nAnd on a year on year basis, how much currency benefit should we be thinking about embedded in the guidance into the September? And then the second quick question is CapEx is clearly moving higher. I know you guys don't guide specifically to that number. But just kind of qualitatively, should we as you lean in more on AI, should we really start to see that CapEx, which is running close to about $4,000,000,000 annualized today, really start to move appreciably higher? Any color on that would be helpful.\n\n**Kevan Parekh** (SVP &amp; CFO)\nGreat, Aaron. Thanks for the questions. Let me answer the first one, first around foreign exchange. For Q3, we really had no impact from a foreign exchange standpoint on the year on year results. And so when we look at both the revenue growth as well as the gross margin, there was really, you know, virtually no impact from foreign exchange.\n\n**Kevan Parekh** (SVP &amp; CFO)\nAs we look at going from Q3 to June to the September, again, very, very, as I mentioned earlier, a very small tailwind going from Q3 to Q4 from a foreign exchange standpoint on both revenue as well as gross margin. And then on the second question, sure, on the CapEx side, think I we talked about the fact that we are and Tim mentioned the fact that we are increasing our investments significantly in AI. You are going to continue to see our CapEx grow. It's not going to be exponential growth, but it is going to grow substantially. And a lot of that's a function of the investments we're making in AI.\n\n**Kevan Parekh** (SVP &amp; CFO)\nAs we mentioned, we also have other items that fall into that category, facilities and some of our retail store investments. But I would say a lot of the growth is really being driven by AI. I would remind you that we do have a hybrid model though where we also leverage third party infrastructure in addition to investing in our own first party infrastructure.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nYeah. Thank you.\n\n**Kevan Parekh** (SVP &amp; CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Aaron. Operator, may we have the next question please?\n\n**Operator**\nOur next question is from Atas Malik with Citi. Please go ahead.\n\n**Atif Malik** (Director - Technology Equity Research)\nHi. Thank you for taking my question. Tim, at the WWDC earlier in the quarter, you showed impressive updates on VisionPRO with the use of widgets, facial scenes, persona and new ways to create content. Appears like Meta and Xiaomi are seeing strong momentum on their AI glasses. So is the focus still around enterprises on VisionPRO, or are you thinking of broadening the use cases and maybe tying it to to to more of your devices?\n\n**Atif Malik** (Director - Technology Equity Research)\nAny thoughts on VisionPro as it did not get enough airtime in the prepared remarks?\n\n**Tim Cook** (Chief Executive Officer)\nYeah. Thanks thanks for bringing it up. I was thrilled with the release from the team on VisionOS 26. It includes many things in it like spatial widgets to enable users to customize their digital space. The personas took a huge increase with they're much more lifelike.\n\n**Tim Cook** (Chief Executive Officer)\nAnd, of course, there's new enterprise APIs for companies as well. And we're seeing, as Kevin talked about in his opening remarks, we're seeing those things resonate out with CAE and other customers. And so we continue to be very focused on it. And I don't want to get into the road map on it, but this is an area that we really believe in.\n\n**Atif Malik** (Director - Technology Equity Research)\nGreat. And Kevin, historically, guys have not done much big M and A. Do you feel like you need to accelerate your AI roadmap or just keep the organic focus?\n\n**Tim Cook** (Chief Executive Officer)\nLet me take that one as well. We've acquired around seven companies this year, and that's companies from all walks of life, not all AI oriented. And so we're doing one think of it as one every several weeks. We're very open to M and A that accelerates our road map. We are not stuck on a certain size company, although the ones that we have acquired thus far this year are small in nature.\n\n**Tim Cook** (Chief Executive Officer)\nBut we basically ask ourselves whether a company can help us accelerate a road map. If they do, then we're interested, but we don't have anything to share specifically today.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAlright. Thank you, Atif. A replay of today's call will be available for two weeks on Apple Podcasts, as a webcast on apple.com/investor, and via telephone. The number for the telephone replay is (866) 583-1035. Please enter confirmation code 6287473 followed by the pound sign.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThese replays will be available by approximately 5PM Pacific time today. Members of the press with additional questions can contact Josh Rosenstock at (408) 862-1142, And financial analysts can contact me, Suhasini Chandramali, with additional questions at (408) 974-3123. Thanks again for joining us",
        "fetched_at": "2026-02-04T16:08:56.450Z"
      },
      {
        "ticker": "AAPL",
        "title": "Yahoo Finance",
        "published_date": "May 1, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/AAPL/earnings/AAPL-Q2-2025-earnings_call-311069.html",
        "content": "**Suhasini Chandramouli** (Director of Investor Relations)\nGood afternoon and welcome to the Apple Q2 Fiscal Year 2025 earnings conference call. My name is Suhasini Chandramouli, Director of Investor Relations. Today's call is being recorded. Speaking first today is Apple's CEO, Tim Cook, and he'll be followed by CFO, Kevan Parekh. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook, including the potential impact of tariffs and other trade measures and macroeconomic conditions on the company's business and results of operations. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nFor more information, please refer to the risk factors discussed in Apple's most recently filed reports on Form 10Q and Form 10K, and the Form 8K filed with the SEC today, along with the associated press release. Additional information will also be in our report on Form 10Q for the quarter ended March 29, 2025, to be filed tomorrow, and in other reports and filings we make with the SEC. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.\n\n**Tim Cook** (CEO)\nThank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Today we are reporting $95.4 billion in revenue, up 5% from a year ago and at the high end of the range we provided last quarter. Diluted EPS was $1.65, up 8% year over year and a March quarter record. Services achieved an all-time revenue record, growing 12% compared to the prior year. We also set a number of quarterly records in countries and regions across the world, including the U.K., Spain, Finland, Brazil, Chile, Turkey, Poland, India, and the Philippines. We are as dedicated as ever to the innovation and ingenuity that will enrich our customers' lives and help us leave the world better than we found it.\n\n**Tim Cook** (CEO)\nWe are proud to increase our impact around the world, including here in the United States, where we recently announced plans to spend $500 billion over the next four years. We are going to be expanding our teams and our facilities in several states, including Michigan, Texas, California, Arizona, Nevada, Iowa, Oregon, North Carolina, and Washington. We are going to be opening a new factory for advanced server manufacturing in Texas. During calendar year 2025, we expect to source more than 19 billion chips from a dozen states, including tens of millions of advanced chips being made in Arizona this year. We also sourced glass used in iPhone from an American company. All told, we have more than 9,000 suppliers in the U.S. across all 50 states. Now I will turn to products, starting with iPhone. iPhone revenue was $46.8 billion, up 2% from a year ago.\n\n**Tim Cook** (CEO)\nDuring the quarter, we introduced iPhone 16e, a great new entry-level addition to our iPhone 16 lineup. It's powered by our latest generation A18 chip and includes the all-new Apple-designed C1 modem, the most energy-efficient modem ever in an iPhone, allowing iPhone 16e to have the longest battery life of any 6.1-inch iPhone. iPhone 16 and iPhone 16 Plus users are exploring how they can use camera control, whether capturing stunning images or exploring the world with visual intelligence. Our iPhone 16 Pro models continue to be a hit with our users. They are turbocharged by the remarkable capabilities and efficiency of A18 Pro and feature larger displays and an advanced camera system and a beautiful design. Mac revenue was $7.9 billion, 7% higher year over year, another great quarter for Mac. During the quarter, we introduced significant new updates to our lineup.\n\n**Tim Cook** (CEO)\nThe world's most popular laptop just got even better. The M4-powered MacBook Air features a 12-megapixel center stage camera and delivers a massive boost in performance. Now it comes in a beautiful new sky blue color. The new Mac Studio is the most powerful Mac we've ever shipped, equipped with M4 Max and our new M3 Ultra chip. It's a true AI powerhouse, capable of running large language models with over 600 billion parameters entirely in memory. Apple Intelligence brings great capabilities to the Mac, with features like writing tools and notification summaries that help users stay focused and get more done. Turning to iPad, revenue for the quarter was $6.4 billion, up 15% from a year ago, another strong quarter of double-digit growth. Our iPad lineup continues to help users learn, work, play, and go wherever their imaginations take them.\n\n**Tim Cook** (CEO)\nThe new iPad Air with M3 combines powerful performance and exceptional portability, whether you're taking it across the street or around the world. Apple Intelligence and Apple Pencil Pro are a perfect match, with features like the cleanup tool in Photos to remove distractions and Image Wand in the Notes app to elevate simple sketches into polished illustrations. Across wearables, home, and accessories, revenue was $7.5 billion, down 5% from a year ago. From walking trails to bike paths, Apple Watch Series 10 is an essential partner wherever you are on the health and fitness journey. AirPods 4 with active noise cancellation delivers an extraordinary experience in an open-ear design. Customers continue to tell me how important our hearing health features for AirPods Pro 2 are to them, and we've been expanding their availability to reach even more users around the world.\n\n**Tim Cook** (CEO)\nMillions have already taken hearing tests, and the stories we received about the new hearing aid feature are deeply moving, showing how these innovations are making a real difference in people's daily lives. It's a powerful reminder of the impact technology can have when it's designed with care. Meanwhile, Apple Vision Pro takes the concert experience to a whole new level with Metallica, our latest Apple immersive video, which you have to see to believe. visionOS 2.4 unlocks the first set of Apple Intelligence features for Vision Pro users, while inviting them to explore a curated and regularly updated collection of spatial experiences with the Spatial Gallery app.\n\n**Tim Cook** (CEO)\nIn retail, in addition to the two stores we opened during the quarter, we're also looking forward to a new retail store in the UAE, the arrival of the online store in Saudi Arabia, and new retail stores in India starting later this year. Let's now turn to services, where we achieved an all-time revenue record of $26.6 billion, up 12% from a year ago, with strong performance across all of our categories. From starting their morning with their podcast of choice, to buying a coffee with Apple Pay, to spending an afternoon reading the latest bestseller on Apple Books, to using their favorite app from the App Store, or an evening workout with Fitness+, Apple services are enriching our users' lives all throughout their day.\n\n**Tim Cook** (CEO)\nWith incredible shows like The Studio, Your Friends and Neighbors, and the culture-shaping Severance, Apple TV+ has become a must-see destination with record viewership during the quarter. We are excited for our upcoming movie F1, starring Brad Pitt, which will hit theaters this summer and gives an incredible inside look at one of the most intense sports on Earth. There is so much more to come this year. It is no wonder Apple TV+ has earned more than 2,500 award nominations and 560 wins. We are also reaching sports fans in more ways than ever, from watching their favorite teams go to bat on Friday Night Baseball, to cheering on their local team with MLS Season Pass, to following the results of every Grand Prix with Formula One, now on the Apple Sports app.\n\n**Tim Cook** (CEO)\nTurning to software, we just released iOS 18.4, which brought Apple Intelligence to more languages, including French, German, Italian, Portuguese, Spanish, Japanese, Korean, and simplified Chinese, as well as localized English to Singapore and India. AI and machine learning are core to so many profound features we've rolled out over the years to help our users live a better day. It's why we designed Apple Silicon with a neural engine that powers so many AI features across our products and third-party apps. It's also what makes Apple products the best devices for generative AI. At WWDC24, we announced Apple Intelligence and shared our vision for integrating generative AI across our ecosystem into the apps and features our users rely on every day. To achieve this goal, we built our own highly capable foundation models that are specialized for everyday tasks.\n\n**Tim Cook** (CEO)\nWe designed helpful features that are right where our users need them and are easy to use. We went to great lengths to build a system that protects user privacy, whether requests are processed on-device or in the cloud with Private Cloud Compute, an extraordinary step forward for privacy and AI. Since we launched iOS 18, we've released a number of Apple Intelligence features, from helpful writing tools to Genmoji, Image Playground, Image Wand, Cleanup, Visual Intelligence, and a seamless connection to ChatGPT. We made it possible for users to create movies of their memories with a simple prompt and added AI-powered photo search, smart replies, priority notifications, summaries for mail messages, and more. We've also expanded these capabilities to more languages and regions.\n\n**Tim Cook** (CEO)\nWith regard to the more personal Siri features we announced, we need more time to complete our work on these features so they meet our high-quality bar. We are making progress, and we look forward to getting these features into customers' hands. Turning to sustainability, we just celebrated Earth Day, and we were proud to announce that we've cut our emissions by 60% from our 2015 levels. Today, we're using more clean energy across our operations and more recycled materials in our products than ever. We have worked with suppliers to bring 17.8 gigawatts of renewable electricity online. We're also saving billions of gallons of fresh water and redirecting millions of metric tons of waste from landfills. All of this will help us make important progress towards our goal of carbon neutrality across our supply chain and the lifecycle of our products by 2030.\n\n**Tim Cook** (CEO)\nNow let me walk you through the impacts of tariffs in the March quarter and give you some color on what we expect for the June quarter. For the March quarter, we had a limited impact from tariffs as we were able to optimize our supply chain and inventory. For the June quarter, currently we are not able to precisely estimate the impact of tariffs as we are uncertain of potential future actions prior to the end of the quarter. However, for some color, assuming the current global tariff rates, policies, and applications do not change for the balance of the quarter and no new tariffs are added, we estimate the impact to add $900 million to our costs. This estimate should not be used to make projections for future quarters as there are certain unique factors that benefit the June quarter.\n\n**Tim Cook** (CEO)\nFor our part, we will manage the company the way we always have, with thoughtful and deliberate decisions, with a focus on investing for the long term and with dedication to innovation and the possibilities it creates. As we look ahead, we remain confident, confident that we will continue to build the world's best products and services, confident in our ability to innovate and enrich our users' lives, and confident that we can continue to run our business in a way that has always set Apple apart. Next month, we can't wait to welcome our developer community for the Worldwide Developers Conference, and we look forward to revealing some exciting announcements. With that, I'll turn it over to Kevan.\n\n**Kevan Parekh** (CFO)\nThanks, Tim, and good afternoon, everyone. Our March quarter revenue of $95.4 billion was up 5% year over year, despite a headwind of almost 2.5 percentage points from foreign exchange.\n\n**Kevan Parekh** (CFO)\nWe also grew in the majority of the markets we track. Products revenue was $68.7 billion, up 3% year over year, driven by growth in iPhone, iPad, and Mac. Thanks to our high levels of customer satisfaction and strong loyalty, our installed base of active devices reached an all-time high across all product categories and geographic segments. Services revenue was $26.6 billion, up 12% year over year, despite over 2 percentage points of foreign exchange headwinds. As Tim mentioned, this was an all-time revenue record. We also grew in every geographic segment and saw double-digit growth in both developed and emerging markets. Company gross margin was 47.1% in the middle of our guidance range and up 20 basis points sequentially, primarily driven by favorable mix. Products gross margin was 35.9%, down 340 basis points sequentially, driven by mix, foreign exchange, and a seasonal loss of leverage.\n\n**Kevan Parekh** (CFO)\nServices gross margin was 75.7%, up 70 basis points sequentially, primarily driven by a different mix, partly offset by foreign exchange. Operating expenses landed at $15.3 billion, up 6% year over year. Net income was $24.8 billion, and diluted earnings per share was $1.65, up 8% year over year and a March quarter record. Operating cash flow was also strong at $24 billion. Now I'm going to provide some more details for each of our revenue categories. iPhone revenue was $46.8 billion, up 2% year over year, driven by the iPhone 16 family. The iPhone active install base grew to an all-time high in total and in every geographic segment, and iPhone upgraders grew double digits year over year. According to a recent survey from Kantar, during the March quarter, iPhone was the top-selling model in the U.S., urban China, the U.K., Germany, Australia, and Japan.\n\n**Kevan Parekh** (CFO)\nWe continue to see high levels of customer satisfaction in the U.S. at 97%, as measured by 451 Research. Mac revenue was $7.9 billion, up 7% year over year, driven by the latest MacBook Air, MacBook Pro, and Mac Mini models. This performance was broad-based, with every geographic segment growing year over year. The Mac install base reached an all-time high, and we saw strong growth for both upgraders and customers new to the Mac. Customer satisfaction was reported at 95% in the U.S. iPad revenue was $6.4 billion, up 15% year over year, driven by the new M3-powered iPad Air. The iPad install base reached another all-time high, and over half the customers who purchased an iPad during the quarter were new to the product. Based on the latest reports from 451 Research, customer satisfaction was 97% in the U.S.\n\n**Kevan Parekh** (CFO)\nWearables, home, and accessories revenue was $7.5 billion, down 5% year over year. Keep in mind, we did face a more difficult compare against the launch of the Apple Vision Pro in the year-ago quarter, as well as the Watch Ultra 2 launch last year. At the same time, the Apple Watch install base reached a new all-time high, with over half of customers purchasing an Apple Watch during the quarter being new to the product. Customer satisfaction for Watch in the U.S. was recently measured at 95%. Our services revenue reached an all-time high of $26.6 billion, up 12% year over year. This growth rate was comparable to the December quarter year-over-year growth rate when we removed the negative impact from foreign exchange. We saw strong momentum in the March quarter, and the growth of our install base of active devices gives us great opportunities for the future.\n\n**Kevan Parekh** (CFO)\nCustomer engagement across our services offerings also continued to grow. Both transacting and paid accounts reached new all-time highs, with paid accounts growing double digits year over year. Paid subscriptions also grew double digits. We have well over a billion paid subscriptions across the services on our platform. We continue to improve the quality and breadth of our service offerings, from additional features in News+ to new games available in Arcade. Apple Pay continues to help our customers with an easy, secure, and private payment solution, and we were pleased to see that our active users in Apple Pay reached an all-time record, up double digits year over year. Turning to enterprise, organizations are investing more in Apple products and services to drive productivity and employee engagement. For example, KPMG recently rolled out iPhone 16 for all US employees, reflecting their confidence in Apple's security and privacy features.\n\n**Kevan Parekh** (CFO)\nWe also continue to see strong Mac performance in enterprise. Nubank, the largest digital bank in Latin America, has selected MacBook Air as a standard computer for their thousands of employees. With Vision Pro, companies are continuing to find new and innovative ways to leverage this technology. Dassault Systmes, a leading provider for engineering and 3D design software, has natively integrated Apple Vision Pro into their next-generation platform, bringing a powerful and immersive spatial experience to thousands of enterprise customers. Now let's turn to our cash position and capital return program. We ended the quarter with $133 billion in cash and marketable securities. We had $3 billion in debt maturities and increased commercial paper by $4 billion, resulting in $98 billion in total debt. Therefore, at the end of the quarter, net cash was $35 billion. During the quarter, we returned $29 billion to shareholders.\n\n**Kevan Parekh** (CFO)\nThis included $3.8 billion in dividends and equivalents and $25 billion through open market repurchases of 108 million Apple shares. Given the continued confidence we have in our business now and into the future, today, our board authorized an additional $100 billion for share repurchases as we maintain our goal of getting to net cash neutral. We're also raising our dividend by 4% to $0.26 per share of common stock, and we continue to plan for annual increases in the dividend going forward, as we have done for the last 13 years. This cash dividend will be payable on May 15, 2025, to shareholders of record as of May 12, 2025. As we move ahead into the June quarter, I'd like to review our outlook, which includes the types of forward-looking information that Suhasini referred to.\n\n**Kevan Parekh** (CFO)\nImportantly, the color we're providing assumes that global tariff rates, policies, and application remain in effect as of this call, and the global macroeconomic outlook does not worsen from today for the current quarter. Despite the overall uncertain environment, we will still be providing color at the total company level, subject to these assumptions and the risk factors that we referred to at the beginning of the call. We expect our June quarter total company revenue to grow low to mid-single digits year over year. We expect gross margin to be between 45.5% and 46.5%, which includes the estimated impact of the $900 million of tariff-related costs that Tim referred to earlier. We expect operating expenses to be between $15.3 billion and $15.5 billion. We expect OINE to be around negative $300 million, excluding any potential impact from the mark-to-market of minority investments, and our tax rate to be around 16%.\n\n**Kevan Parekh** (CFO)\nWith that, let's open the call to questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you. Ask that you limit yourself to two questions. Operator, may we have the first question, please?\n\n**Operator**\nCertainly. We'll go ahead and take our first question from Eric Woodring with Morgan Stanley.\n\n**Eric Woodring** (Managing Director and Head of Equity Research)\nGreat. Thanks so much, guys, for taking my questions. Tim, I'd love to maybe touch on the tariff point first. There were comments from you earlier on CNBC talking about 50% of iPhones for the U.S. currently coming from India. Where do you expect the mix of India-sourced iPhones for the U.S. to be by the end of your fiscal year? Is it the goal to source 100% of your U.S.-bound iPhones from India? Can you just help us understand kind of how we should expect that to trend as we look beyond just the June quarter? I have a follow-up. Thank you.\n\n**Tim Cook** (CEO)\nYeah, Eric.\n\n**Tim Cook** (CEO)\nHi, it's Tim. The existing tariffs that apply to Apple today are based on the product's country of origin, as you alluded to. For the June quarter, we do expect the majority of iPhones sold in the U.S. will have India as their country of origin and Vietnam to be the country of origin for almost all iPad, Mac, Apple Watch, and AirPods products sold in the U.S. China would continue to be the country of origin for the vast majority of total product sales outside the U.S. If you look at the categories of tariffs that are applicable to us today, for the June quarter, most of our tariff exposure relates to the February IEEPA-related tariff at the rate of 20%, which applies to imports to the U.S. for products that have China as their country of origin.\n\n**Tim Cook** (CEO)\nIn addition, for China, there was an additional 125% tariff for imports of certain categories of products announced in April. For us, that's some of our U.S. AppleCare and accessories businesses and brings the total rate in China for these products to at least 145%. Also, for transparency and clarity, the vast majority of our products, including iPhone, Mac, iPad, Apple Watch, and Vision Pro, are currently not subject to the global reciprocal tariffs that were announced in April, as the Commerce Department has initiated a Section 232 investigation into imports of semiconductors, semiconductor manufacturing equipment, and downstream products that contain semiconductors. For the June quarter, as I talked about in my opening comments, we estimate the impact, assuming that the current global tariff rates, policies, and applications do not change for the balance of the quarter, to be $900 million to our costs.\n\n**Tim Cook** (CEO)\nI wouldn't want to predict the mix of production in the future, but I wanted to give you clarity for the June quarter of where the country of origins are so you can use that for your modeling.\n\n**Eric Woodring** (Managing Director and Head of Equity Research)\nOkay. I appreciate that, Colette. Thank you, Tim. Maybe my follow-up is there were a number of reports during the quarter that Apple had pulled forward sell-in into the channel to get ahead of tariffs. Can you just help us better kind of understand or clarify if sell-in and sell-through were aligned in the March quarter, if you're assuming that they would be aligned in the June quarter guide, and ultimately, do you believe that consumers are accelerating hardware purchases to get ahead of any potential pricing increases, or was behavior normal? Thank you so much, Tim.\n\n**Tim Cook** (CEO)\nYeah, thanks, Eric, for the question. There are several questions there.\n\n**Tim Cook** (CEO)\nOne, in terms of the pull forward in demand, if you look at the March quarter, we do not believe that we saw obvious evidence of a significant pull forward in demand in the March quarter due to tariffs. If you look at our channel inventory from the beginning of the quarter to the end of the quarter, the unit channel inventory was similar, not only for iPhone, but for the balance of our products. Again, for transparency, you will see that we did build ahead inventory, and that is reflected in our manufacturing purchase obligations that you will see on the quarterly filing when it comes out. I hope that answers all your questions.\n\n**Eric Woodring** (Managing Director and Head of Equity Research)\nThank you so much, Tim. Good luck.\n\n**Tim Cook** (CEO)\nThanks.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you. Eric, Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Ben Ricey with Melius. Please go ahead.\n\n**Ben Reitzes** (Managing Director)\nHey, thanks a lot.\n\n**Ben Reitzes** (Managing Director)\nHey, Tim, if you had told me that on April 2nd that your hit from tariffs was only a nickel a quarter at $900 million, that would have been a pretty good outcome given the panic that ensued. I'm surprised that it's that low. You did make a comment about after the June quarter. Sorry to push you on that, but could it be a multiple of that figure, or is it just completely unknown? We're all just trying to figure out what happens after June, and if there's just any guidance you guys can possibly give that it's bigger, smaller, or what. Hoping you can just give us a little color on that. Thanks.\n\n**Tim Cook** (CEO)\nYeah, Ben, thanks for the question.\n\n**Tim Cook** (CEO)\nI tried to give you some information in the previous question about the country of origin, which currently is the key factor in determining the tariffs that we're paying. I do not want to predict the future because I'm not sure what will happen with the tariffs. There is the Section 232 investigation going on. It is very difficult to predict beyond June. June has the assumptions in it that I mentioned earlier.\n\n**Ben Reitzes** (Managing Director)\nAll right. Thanks, Tim. Just with regard to China, down 2%, I mean, you intuitively would have thought there would have been an increased nationalism there, and perhaps it would have been worse than that. The trajectory there is improving, even with subsidies, because subsidies benefited your competitors too. Just wondering if a little more color there. Can it keep improving?\n\n**Ben Reitzes** (Managing Director)\nWhat are you thinking with regard to that trajectory in China, given all the geopolitical tensions? Thanks.\n\n**Tim Cook** (CEO)\nYeah, we were down 2%, as you point out, for the March quarter. To provide a little more transparency around that, we were roughly flat when you removed the headwinds from foreign exchange. We did see quite a bit of sequential improvement from the December quarter, which was down 11. Going out of the way for transparency, the channel inventory at the end of March, the unit channel inventory was similar to where we started the quarter. There was not a build of channel inventory in there. I do believe that the subsidies played a favorable impact on the results. It is difficult to estimate with precision as to exactly how much, but I think it was positive. Some of our products are included. Some of them are not.\n\n**Tim Cook** (CEO)\nGenerally, on iPhone, if something is priced above RMB 6,000, it is not eligible for the subsidy. The other products have different rules. I do think it helped. I think it is helping others as well, I am sure. iPhone was the key driver of the improvement sequentially. Hopefully, that provides you some color. The other thing I would say is that the Mac, the iPad, and the Watch are attracting a majority of customers new to that product. That continues to look quite good in China. iPhone was the top two models in urban China. iPad was the top two tablets in urban China. There are some positive nuggets there.\n\n**Ben Reitzes** (Managing Director)\nThanks a lot, Tim.\n\n**Tim Cook** (CEO)\nYep. Thank you, Ben.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Ben. Operator, may we have the next question, please?\n\n**Operator**\nOur next question is from Michael Ng with Goldman Sachs. Please go ahead.\n\n**Michael Ng** (Equity Research Analyst)\nHi, good afternoon. Thank you very much for the question. I was just wondering if you could talk a little bit about your responses on some of this trade policy uncertainty. I appreciated the transparency around building ahead with inventory. Will you continue to do that in this interim period until we get some clarity on the Section 232 investigation? Could you talk a little bit about your philosophy on pricing, elevated costs to the extent that comes through, whether that be to resellers or end consumers and other efficiency efforts that you might be able to pursue? Thank you.\n\n**Tim Cook** (CEO)\nYeah, obviously, we're very engaged on the tariff discussions. We believe in engagement and will continue to engage. On the pricing piece, we have nothing to announce today. I'll just say that the operational team has done an incredible job around optimizing the supply chain and the inventory.\n\n**Tim Cook** (CEO)\nWe will obviously continue to do those things to the degree that we can.\n\n**Michael Ng** (Equity Research Analyst)\nGreat. Thanks. Just as a quick follow-up for Kevan, on product gross margins, I was just wondering if you could provide a little bit more color on some of the factors that may have impacted product gross margins in the quarter. Obviously, down sequentially on seasonal factors, but there was a year-over-year decline as well. Any additional color would be helpful. Thank you.\n\n**Kevan Parekh** (CFO)\nYeah, Michael, thanks. This is Kevan. On the sequential, as we mentioned in the prepared remarks, we had a decrease in the product gross margin by 340 basis points sequentially. That was primarily driven by mix, seasonal, loss of leverage, foreign exchange. That was partly offset by cost savings. When we look at the year-on-year performance, we were down 70 basis points on a year-on-year basis.\n\n**Kevan Parekh** (CFO)\nThat was driven by a different mix in foreign exchange.\n\n**Michael Ng** (Equity Research Analyst)\nGreat. Thank you.\n\n**Kevan Parekh** (CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nGreat. Thank you, Mike. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Amit Daryanani with Evercore. Please go ahead.\n\n**Amit Daryanani** (Senior Managing Director)\nYep. Thanks a lot. I guess I'll have to start with the tariff question as well. Tim, I think when you talked about the $900 million impact to your cost of goods sold, you sort of had a statement that there are certain unique factors that benefit you in the June quarter related to that number. Can you just talk about what are these unique factors that are benefiting you in the June quarter, and what would the impact be without those benefits, essentially?\n\n**Tim Cook** (CEO)\nI wouldn't want to go through all of them, but as an example, the build ahead that I mentioned earlier that's in the manufacturing purchase obligations were helpful.\n\n**Amit Daryanani** (Senior Managing Director)\nGot it. As I think about the June quarter guide of low to mid-single-digit revenue growth, do you folks expect services growth to remain in the double-digit range as you go into the back half of the year? I imagine FX is a bit of a benefit as you go to the back half. I'd love to just understand, within that framework, how do you think services stacks up as you go through the June quarter?\n\n**Kevan Parekh** (CFO)\nYeah, Amit. Hey, it's Kevan. I think when we talk about the overall June quarter, we talked about the low to mid-single digits year-over-year. We do expect foreign exchange in the June quarter to improve sequentially.\n\n**Kevan Parekh** (CFO)\nHowever, we are expecting it to be a slight headwind to revenue on a year-on-year basis. With respect to services, given the uncertainty we see from several factors, we aren't providing the category level of color today.\n\n**Amit Daryanani** (Senior Managing Director)\nGot it. Thank you.\n\n**Kevan Parekh** (CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Amit. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Wansi Moen with Bank of America. Please go ahead.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nYes, thank you. Tim McCavern, how should investors think about the gross margin trajectory as you source more from the U.S. in particular or other supply chain changes that you're making, including in India? How should those kind of play into the cost structure, and how should we think about that gross margin trajectory? I will follow up.\n\n**Tim Cook** (CEO)\nWe're excited about bringing more production to the U.S.\n\n**Tim Cook** (CEO)\nAs you know, we've been very key in the TSMC project in Arizona and are the largest and first customer getting product out of that. That's the SSC that's coming out of there. We also have glass coming out of the U.S. and the Face ID module and loads of chips. In fact, there's 19 billion chips coming out across 12 states. This is down to the resistor and capacitor level, obviously. There's some that is already built into the margins that Kevan has quoted. We don't really forecast beyond the current quarter, as you know.\n\n**Kevan Parekh** (CFO)\nYeah, maybe I'll add a couple more points as we think about just the margin going forward. A couple of observations I'd mention is every product cycle is different. Over the years, we have managed gross margin well. We've made good decisions balancing units' revenue margins.\n\n**Kevan Parekh** (CFO)\nWhen we launch new products, they tend to have a higher cost structure than the products they replace as we introduce new features and technologies. We do have a good track record of reducing those cost structures over the life of the product. Our products and services all have different levels of profitability, and their relative success in the marketplace has an impact on the overall gross margin. I hope that's helpful color and context for you.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nYeah, no, that's super helpful. Thank you. I guess you just noted that you weren't going to give services maybe growth forecast here in light of some of the uncertain news. Maybe, Tim, could you share any color around what you have seen in developer behavior in areas like Europe where there has now been emergence of alternate app stores for a little more time?\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nWhat have you seen anecdotally or within your data in terms of maybe developer behavior, whether it's large or small? Any color you can share on what has actually happened?\n\n**Tim Cook** (CEO)\nIt's embedded in our results that Kevan talked about earlier and embedded in the overall company color that was provided. As you know, the Digital Markets Act went into effect in, I believe it was March of last year. The Digital Markets Act has been enacted for a bit over a year. There have been alternate app stores for some period of time of that. At this point in Europe, there are some embedded in the actuals. There may be more to come and so forth. I don't want to predict beyond the current quarter.\n\n**Wamsi Mohan** (Senior Equity Research Analyst)\nOkay. Thank you, Tim.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Wansi. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from David Vogt with UBS. Please go ahead.\n\n**David Vogt** (Managing Director)\nGreat. Thanks, guys. Thanks for taking my questions. I have two as well. Tim, this is more of a big picture supply chain philosophical question. Can you maybe update us on your thoughts on how you're thinking about your sort of resiliency and redundancy following the changes that you guys talked about earlier on the call? I guess what I'm trying to understand is how do we think about where your supply chain is two to three years from now? Is there any risk, at least in the near term, of maybe some export control issues in your outlook for the balance of this year? I'll give you my second one at the same time. You quantified a $900 million hit from tariffs.\n\n**David Vogt** (Managing Director)\nKevin, is there any impact in how you're thinking about the demand backdrop in your outlook for the June quarter on the revenue line holistically? Thanks.\n\n**Tim Cook** (CEO)\nIn terms of the resiliency and risk, etc., we have a complex supply chain. There's always risk in the supply chain. I wouldn't tell you anything different than that. What we learned some time ago was that having everything in one location had too much risk with it. We have, over time, with certain parts of the supply chain, not the whole thing, but certain parts of it, opened up new sources of supply. You could see that kind of thing continuing in the future. I'll let Kevin answer the other question.\n\n**Kevan Parekh** (CFO)\nHi, David. On the other question, I would say that our best thinking is captured in the outlook that we provided.\n\n**Kevan Parekh** (CFO)\nHowever, I did want to reemphasize the point that the assumptions we made on the outlook do assume that the global tariff rates, the policies, and application remain the same as they are today as of this call, and that the global macroeconomic outlook does not worsen from today.\n\n**David Vogt** (Managing Director)\nOkay, but no quantifiable impact on demand to date, at least from where we are over the last month? Is there a way to kind of think about that from early April to early May?\n\n**Kevan Parekh** (CFO)\nI would say our best thinking is reflected in the range that we provided.\n\n**David Vogt** (Managing Director)\nOkay. Thanks, Kevan. Thanks, guys.\n\n**Kevan Parekh** (CFO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, David. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Samik Chatterjee with JP Morgan. Please go ahead.\n\n**Samik Chatterjee** (Senior Equity Research Analyst)\nHi. Good afternoon. Thanks for taking my questions.\n\n**Samik Chatterjee** (Senior Equity Research Analyst)\nI guess, Tim, you made a comment on the last earnings call about Apple Intelligence making a visible impact on iPhone sales in the countries where it was available. I'm just curious if you continue to see that play out similarly in sort of the more broader number of countries you've rolled that out, or the delays that you talked about relative to personalized Siri features, has that had an impact in terms of consumer willingness to upgrade? I have a follow-up.\n\n**Tim Cook** (CEO)\nThank you. Yeah, thank you for the question. During the March quarter, we saw that in markets where we had rolled out Apple Intelligence, that the year-over-year performance on the iPhone 16 family was stronger than those where Apple Intelligence was not available. A lot of the languages that I think you're referring to rolled out in April, and so they actually rolled out in Q3.\n\n**Samik Chatterjee** (Senior Equity Research Analyst)\nOkay.\n\n**Samik Chatterjee** (Senior Equity Research Analyst)\nGot it. Maybe for my follow-up, I mean, you have a lot of insights now in terms of what consumers are, how consumers are reacting to the overall macro. I know you sort of prefaced all your guidance with macro remaining consistent, but what are you seeing in terms of the U.S. consumer, and what's the reaction there in terms of the tariff impact? We saw U.S. GDP also shrink here in Q1. When you look at velocity at the stores or trade down within the sort of iPhone portfolio mix, what are you seeing in terms of how the consumer is reacting to the macro at this point? Thank you.\n\n**Tim Cook** (CEO)\nI'm not an economist, and so I start by saying that. In terms of the, as you can see from a total company point of view, our results accelerated sequentially to the 5% level.\n\n**Tim Cook** (CEO)\nThe U.S. is obviously the vast majority of the Americas segment, and you can see how the Americas performed during the quarter. That is all I would want to say about that. I do not want to try to predict what happens in the months from now. The past, I am quite pleased with the results from Q2.\n\n**Samik Chatterjee** (Senior Equity Research Analyst)\nThank you. Thanks for taking the questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Samik. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Krish Sankar, TD Cowen. Please go ahead.\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nYeah, hi. Thanks for taking my question. I told them to Tim, thanks for that information on the $500 billion U.S. investment. I am kind of curious how to think about the composition of that. How much is CapEx versus R&D? How much is going into the Texas server? How much is going into maybe TSMC Arizona?\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nAny kind of color you can give on that $500 billion investment would be helpful, and then I'd have a follow-up.\n\n**Tim Cook** (CEO)\nThere's lots of all of it is what I would say. We're not giving out the exact split, but as we expand facilities in the different states from Michigan to Texas to California and Arizona and Nevada and Iowa and Oregon and North Carolina and Washington, there will be CapEx involved in that and OpEx involved in it. Standing up advanced server manufacturing in Texas, we'll do that through a partner as we do our manufacturing through a partner. We'll be putting a fair amount in cost of goods sold to do that and some OpEx as well. I'm sure some CapEx as well. It's a bit of all of it.\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nGot it. Got it.\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nI kind of have a long-term, more like a philosophical question. When you look at in the past, you've spoken about AI on the edge. Obviously, it's very topical to you from both the iPhone angle and the Mac angle. I'm just kind of curious. When you look at AI on the edge, are the current smartphone specs or improved hardware and silicon specs good enough to meet future edge LLM for inference? Or do you think we need to come up with a whole new different kind of device? I'm just kind of curious how to think about the evolution of the edge devices from here. Thank you.\n\n**Tim Cook** (CEO)\nYeah. As you know, we're shipping an LLM on the iPhone 16 today.\n\n**Tim Cook** (CEO)\nThere are some of the queries that are being used by our customers are on-device, and then others go to the private cloud where we've essentially mimicked the security and privacy of the device into the cloud. Others for world knowledge with the integration with ChatGPT. We continue to be very excited about the opportunities here. We are very excited about the roadmap. We are pleased with the progress that we're making.\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nThanks, Tim.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Krish. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Richard Kramer with Arete Research. Please go ahead.\n\n**Richard Kramer** (Senior Analyst)\nThank you very much. I won't ask about tariffs.\n\n**Richard Kramer** (Senior Analyst)\nTim, given your recognition that a new Siri assistant is taking longer than you thought to deliver, I'd like to go back to my question from the last call and ask about what some of the learnings you had from those delays and whether you attribute them to organizational factors, to your legacy software stack, or is it a matter of R&D spending? What are some of the key gating factors investors should look for, either at WWDC or beyond, to have a sense that Apple can deliver on some of the promises of the announcements at the prior WWDC? Thanks.\n\n**Tim Cook** (CEO)\nYeah. If you sort of step back from what we said at WWDC, we talked about a number of different features that would launch with iOS 18.\n\n**Tim Cook** (CEO)\nWe have released a slew of those from writing tools to seamlessly connecting to ChatGPT, to Genmoji, to Image Playground, to Image Wand, to Cleanup and Visual Intelligence, making movies or movies of your memories with a simple prompt, AI-powered photo search, smart replies, priority notifications. The list goes on. We have delivered a lot. We just recently, just a few weeks ago, expanded it into several different languages, including French, German, Italian, Portuguese, Spanish, Japanese, Korean, Simplified Chinese, as well as localized English for both Singapore and India. We have delivered a lot. However, with regard to the more personal Siri, as you mentioned, we just need more time to complete the work so they meet our high-quality bar. There is not a lot of other reason for it. It is just taking a bit longer than we thought. We are making progress.\n\n**Tim Cook** (CEO)\nWe're extremely excited to get the more personal Siri features out there.\n\n**Kevan Parekh** (CFO)\nRichard, I'll just add that on your question about investment, we don't underestimate invest in our business. We make significant investments in R&D that continues to grow. We're continuing to grow our R&D investment. We definitely are making all the investments we think we need to enable our roadmap.\n\n**Richard Kramer** (Senior Analyst)\nThanks. Kevin, one for you. I mean, it's hard to ignore some of the ongoing very high-profile legal cases that touch on Apple, be it yesterday's EPIC case injunction or the Google antitrust trial touching on default search. Investors are clearly concerned that these might have material impacts on your services business.\n\n**Richard Kramer** (Senior Analyst)\nDo you feel now that you have ample ways in which you might be able to mitigate some of the potential negative impacts on Apple services business that might come about from what's been proposed or might come about in legal rather than commercial pressures that the business faces?\n\n**Tim Cook** (CEO)\nLet me make a couple of comments on that before Kevan. The case yesterday, we strongly disagree with. We've complied with the court's order, and we're going to appeal. In the DOJ case that you referenced with Google, that case is ongoing, and I don't really have anything to add beyond that. We are monitoring these closely. As you point out, there's risk associated with them, and the outcome is unclear. Yeah.\n\n**Kevan Parekh** (CFO)\nI think Tim answered it really well. I don't have anything to add to that.\n\n**Richard Kramer** (Senior Analyst)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, Richard.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nOperator, we will take our last question, please.\n\n**Operator**\nWe'll go ahead and take our last question from Aaron Rakers with Wells Fargo. Please go ahead.\n\n**Aaron Rakers** (Managing Director and Senior Equity Analyst)\nYeah. Thanks for taking the question. I want to go back to the AI strategy a little bit. I know, Tim, in your prepared comments, you had mentioned building some of your own foundational models. I'm curious of how important you think it is for Apple to have their own foundational models. Kind of dovetailed with that is that how do you think about your data center footprint when we look at Apple spending, call it $3 billion a quarter relative to some of these other companies spending multiples of that? How does the strategy play out in your opinion?\n\n**Tim Cook** (CEO)\nOn the data center side, we have a hybrid strategy.\n\n**Tim Cook** (CEO)\nWe utilize third parties in addition to the data center investments that we're making. As I mentioned in the $500 billion, there's a number of states that we're expanding in. Some of those are data center investments. We do plan on making investments in that area, and we're not gating it. We invest in the business first, as Kevan talked about, is our most important thing to do. In terms of the foundation models, we want to have certain models, and we'll partner as well. I don't view it as all of one or all of the other. We've been working on foundation models for quite some time and are shipping some today, obviously, with what's on device and what's in the private cloud compute.\n\n**Aaron Rakers** (Managing Director and Senior Equity Analyst)\nYeah.\n\n**Aaron Rakers** (Managing Director and Senior Equity Analyst)\nThen as a follow-up, I'm curious with the iPhone 16e launching this quarter, internalizing your C1 modem. I'm curious of how you see kind of the modem strategy playing out or maybe just the continual deepening of that internal silicon opportunity for Apple.\n\n**Tim Cook** (CEO)\nWe're super excited to ship the first one and get it out there, and it's gone well. We love that we can produce better products from a point of view of really focusing on battery life and other things that customers want. We have started on a journey, is the way I would put it.\n\n**Aaron Rakers** (Managing Director and Senior Equity Analyst)\nThank you.\n\n**Tim Cook** (CEO)\nYep.\n\n**Operator**\nThank you, Aaron. A replay of today's call will be available for two weeks on Apple Podcasts as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 3729688 followed by the pound sign.\n\n**Operator**\nThese replays will be available by approximately 5:00 P.M. Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142. Financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thank you again for joining us today.Once again, this does conclude today's conference. We do appreciate your participation.",
        "fetched_at": "2026-02-04T16:09:01.937Z"
      },
      {
        "ticker": "AAPL",
        "title": "Yahoo Finance",
        "published_date": "Jan 30, 2025, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/AAPL/earnings/AAPL-Q1-2025-earnings_call-251672.html",
        "content": "**Suhasini Chandramouli** (Director of Investor Relations)\nGood afternoon and welcome to the Apple Q1 FY 2025 earnings conference call. My name is Suhasini Chandramouli, Director of Investor Relations. Today's call is being recorded. Speaking first today are Apple CEO Tim Cook, and he'll be followed by CFO Kevan Parekh. After that, we'll open the call to questions from analysts. Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements, including, without limitation, those regarding revenue, gross margin, operating expenses, other income and expense, taxes, capital allocation, and future business outlook, including the potential impact of macroeconomic conditions on the company's business and results of operations. These statements involve risks and uncertainties that may cause actual results or trends to differ materially from our forecast.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nFor more information, please refer to the risk factors discussed in Apple's most recently filed annual report on Form 10-K and the Form 8-K filed with the SEC today, along with the associated press release. Apple assumes no obligation to update any forward-looking statements, which speak only as of the date they are made. I'd now like to turn the call over to Tim for introductory remarks.\n\n**Tim Cook** (CEO)\nThank you, Suhasini. Good afternoon, everyone, and thanks for joining the call. Before I talk about our results, I'd like to take a moment to acknowledge the devastating wildfires that impacted the Los Angeles area this month. From our retail teams to Apple TV+, Apple Music, Fitness+, Beats, and more, LA is home to many of our team members. Our thoughts are with everyone who is beginning the road to recovery. For our part, we are contributing to the relief efforts, and we will continue to support our teams and the local community. Now, turning to the quarter. Today, Apple is reporting revenue of $124.3 billion for the December quarter, up 4% from a year ago and an all-time record. EPS also set an all-time record of $2.40, 10% higher year over year.\n\n**Tim Cook** (CEO)\nWe achieved all-time revenue records across the majority of the countries and regions we track, including the Americas, Europe, Japan, and the rest of Asia-Pacific. We also continue to see momentum in emerging markets, setting all-time revenue records in a number of markets, including Latin America, the Middle East, and South Asia, among others. In services, we achieved an all-time revenue record, and in the past year, we've seen nearly $100 billion in revenue from our services business. I'm also pleased to announce that we reached a new record for our installed base, with over 2.35 billion active devices. In October, we released the first set of Apple Intelligence features in U.S. English for iPhone, iPad, and Mac, and we rolled out more features and expanded to more countries in December. Now, users can discover the benefits of these new features in the things they do every day.\n\n**Tim Cook** (CEO)\nThey can use Writing Tools to help find just the right words, create fun and unique images with Image Playground and Genmoji, handle daily tasks and seek out information with a more natural and conversational Siri, create movies of their memories with a simple prompt, and touch up their photos with Clean Up. We introduced Visual Intelligence with Camera Control to help users instantly learn about their surroundings. Users can also seamlessly access ChatGPT across iOS, iPadOS, and macOS, and we were excited to recently begin our international expansion, with Apple Intelligence now available in Australia, Canada, New Zealand, South Africa, and the UK. We're working hard to take Apple Intelligence even further. In April, we're bringing Apple Intelligence to more languages, including French, German, Italian, Portuguese, Spanish, Japanese, Korean, and simplified Chinese, as well as localized English to Singapore and India.\n\n**Tim Cook** (CEO)\nAnd we'll continue to roll out more features in the future, including an even more capable Siri. Apple Intelligence builds on years of innovations we've made across hardware and software to transform how users experience our products. Apple Intelligence also empowers users by delivering personal context that's relevant to them. And importantly, Apple Intelligence is a breakthrough for privacy and AI with innovations like Private Cloud Compute, which extends the industry-leading security and privacy of Apple devices into the cloud. Apple Intelligence opens up an exciting new frontier and is already elevating experiences across iPhone, iPad, and Mac. We're going to keep investing in innovation and in transformative tools that help users in their everyday lives. Let me now turn to our results for the quarter, starting with iPhone. iPhone revenue came in at $69.1 billion, reaching all-time iPhone revenue records in dozens of markets and regions.\n\n**Tim Cook** (CEO)\nOur iPhone 16 lineup takes the smartphone experience to the next level in so many ways, and Apple Intelligence is one of many reasons why customers are excited. With the A18-powered iPhone 16 and iPhone 16 Plus, users are getting a big boost in battery life and incredible camera experiences with camera control. Our amazingly powerful iPhone 16 Pro models go even further, with larger-than-ever displays and a Pro Camera system so advanced it can turn moments into masterpieces. In Mac, revenue was $9 billion for the December quarter, 16% higher year over year, driven by significant excitement around the world for our latest Mac lineup. The Mac is more than just a powerful tool. It's a launchpad to enable users to bring their best ideas and boldest creations to life.\n\n**Tim Cook** (CEO)\nAnd there are so many reasons to choose Mac, from the breathtaking performance of the M4 family of chips to the groundbreaking and growing capabilities of Apple Intelligence. Every product in the Mac lineup offers something extraordinary, whether that's the super-portable MacBook Air, the powerhouse MacBook Pro, the world's best all-in-one iMac, or the small wonder that is the Mac mini, which is not only stunningly capable but is our first carbon-neutral Mac. All of this is enabled by the unparalleled power of Apple Silicon. iPad revenue was $8.1 billion, up 15% from a year ago, driven by strong interest for our latest products. We love hearing from customers who are discovering for the first time the versatility of iPad, from the ultra-portable iPad mini built from the ground up for Apple Intelligence to the powerful M4 iPad Pro in a stunningly thin and light design.\n\n**Tim Cook** (CEO)\niPad is there for our users whenever they need it and wherever they go, and we are pleased to see so much excitement and enthusiasm for our lineup. Wearables, home, and accessories revenue came in at $11.7 billion. With its most advanced display yet and a thinner, more comfortable design, the all-new Apple Watch Series 10 is the perfect companion to help users pursue their health and fitness goals this year. From the powerful Vitals app to more customizable activity rings, users have an ever-increasing set of innovative health tools at their fingertips and watchOS 11. Health innovation has long been a focus for us, and we're committed to continuing to advance this work because we know how much it matters to our users.\n\n**Tim Cook** (CEO)\nWe've introduced new hearing health features on AirPods Pro 2, and new sleep apnea notifications on Apple Watch are also helping users learn of a potentially serious condition that's thought to affect up to a billion people worldwide. During the quarter, we also brought Apple Vision Pro to even more countries, enabling more customers to discover the magic of spatial computing. Users are enjoying incredible immersive entertainment experiences and powerful new features and enhancements to Mac virtual display. Vision Pro is also supercharging the creative process, and the incredibly talented director, John M. Chu, recently shared how its extraordinary capabilities helped him bring the movie Wicked to life. Turning to services, we set an all-time revenue record of $26.3 billion for the December quarter, growing 14% from a year ago. We set all-time records in the Americas, Europe, and rest of Asia-Pacific, and a December quarter record in Japan.\n\n**Tim Cook** (CEO)\nFive years since launch, Apple TV+ continues to be home to incredible storytelling that viewers love. There's nothing quite like the anticipation that comes when a fan favorite returns, and we were thrilled to debut the second season of Severance earlier this month. We have so much in store for our subscribers this year, with new shows like The Studio and Your Friends and Neighbors. And we can't wait for the premiere of Formula 1, starring Brad Pitt on June 27, which will take viewers inside the sport in a truly unprecedented way. We're excited that Apple TV+ continues to draw attention and accolades. To date, Apple TV+ productions have earned more than 2,500 nominations and 538 wins. During the quarter, we were also excited to launch a new Find My service that can help our users when they lose their luggage.\n\n**Tim Cook** (CEO)\nFor the first time, if you put an AirTag in your suitcase, you'll be able to share its location information with many major airlines so they can quickly track down your bags if they get lost. Turning to retail, our teams went above and beyond to help customers find the perfect gift throughout the holiday season. We also celebrated openings of new stores in China, Spain, and the U.S. We were excited to announce plans to connect with even more customers this year by adding a fifth store in the UAE and bringing our online store to Saudi Arabia this summer. We can't wait to welcome customers to the first of several flagship store locations in Saudi Arabia that we're opening beginning in 2026. I just had the chance to visit both countries last month, and I had a great time meeting with customers and team members.\n\n**Tim Cook** (CEO)\nThere's an incredible energy and passion for technology in these growing markets. Every day, I get deeply moving notes about the many ways our technology is enriching our users' lives. I recently got a note from a customer who put his watch on his father's wrist when he feared something was wrong with him. The watch alerted them that the father was in AFib, and they were able to get him to the hospital for potentially lifesaving treatment. Another user put his new watch on for the first time and within 15 minutes was notified of a low heart rate that led to a necessary pacemaker, and there are so many touching notes around the profound impact of our new hearing health feature, like a recent user who told me it had changed her life, allowing her to take part in conversations with her children and grandchildren.\n\n**Tim Cook** (CEO)\nThese are the kind of stories that remind us of how profoundly important our work is, and it drives us to innovate each and every day. At Apple, the future is full of promise and potential. We're always searching across a world of possibilities, finding those places where we can do the most good and putting all of our energy and ingenuity into making something special. With that, I'll turn it over to Kevin.\n\n**Kevan Parekh** (CFO)\nThanks, Tim, and good afternoon, everyone. I'm going to cover the results for the first quarter of our fiscal year. We are very pleased to report an all-time high for revenue, with December quarter revenue of $124.3 billion, up 4% year over year. We achieved all-time revenue records in the Americas, Europe, Japan, and rest of Asia-Pacific, and grew in the vast majority of markets we track.\n\n**Kevan Parekh** (CFO)\nProducts revenue was $98 billion, up 2% year over year, driven by growth from iPad and Mac. Thanks to our incredible customer satisfaction and strong loyalty, our install base of active devices reached an all-time high across all products and geographic segments and is now over 2.35 billion active devices. Services revenue reached an all-time record of $26.3 billion, up 14% year over year. We grew in every geographic segment and achieved all-time records in both developed and emerging markets. Company gross margin was 46.9% at the high end of our guidance range and up 70 basis points sequentially, primarily driven by favorable mix. Products gross margin was 39.3%, up 300 basis points sequentially, primarily driven by favorable mix and leverage. Services gross margin was 75%, up 100 basis points sequentially, primarily driven by mix.\n\n**Kevan Parekh** (CFO)\nOperating expenses of $15.4 billion landed at the midpoint of our guidance range and up 7% year over year. This strong business performance resulted in all-time records for both net income at $36.3 billion and diluted earnings per share of $2.40, up 10% year over year. Operating cash flow was also strong at $29.9 billion, which included the impact of the $11.9 billion we paid during the quarter in connection with the state aid decision. Now I'm going to provide some more details for each of our revenue categories. iPhone revenue was $69.1 billion, roughly flat to the prior year. We grew in the majority of markets we track and reached all-time revenue records in several developed markets, including Canada, Western Europe, and Japan, and in emerging markets like Latin America, the Middle East, and South Asia.\n\n**Kevan Parekh** (CFO)\nThe iPhone active install base grew to an all-time high in total and in every geographic segment. We also set an all-time record for upgraders. According to a recent survey from Kantar, during the December quarter, iPhone was a top-selling model in the U.S., urban China, India, the U.K., France, Australia, and Japan. We continue to see high levels of customer satisfaction in the U.S. at 96%, as measured by 451 Research. Mac generated $9 billion in revenue, up 16% year over year. We saw strength across our lineup, from the new Mac mini to the latest MacBook Air and MacBook Pro models. This incredible performance was broad-based, with double-digit growth in every geographic segment. With our latest advances in Apple Silicon and our fastest Neural Engine ever, customers are able to take advantage of the full capabilities of AI on Mac.\n\n**Kevan Parekh** (CFO)\nThe Mac install base reached an all-time high, and we saw double-digit growth for both upgraders and customers new to the Mac. Additionally, customer satisfaction in the U.S. was recently measured at 94%. iPad revenue was $8.1 billion, up 15% year over year, driven by the new iPad mini and latest iPad Air. The iPad install base reached another all-time high, and over half of the customers who purchased an iPad during the quarter were new to the product. Customer satisfaction was at 96% in the U.S., based on the latest reports from 451 Research. Wearables, home, and accessories revenue was $11.7 billion, down 2% year over year. Customers are excited about the new AirPods 4 and the latest hearing health features in AirPods Pro 2.\n\n**Kevan Parekh** (CFO)\nOn Watch, although we face a difficult compare against the Watch Ultra 2 launch last year, the Apple Watch install base reached a new all-time high, with over half of customers purchasing an Apple Watch during the quarter being new to the product. Customer satisfaction for Watch in the U.S. was reported at 94%. Our services revenue reached an all-time high of $26.3 billion, up 14% year over year. Services continues to see strong momentum, and the growth of our install base of active devices gives us great opportunities for the future. We also see increased customer engagement with our services offerings. Both transacting and paid accounts reached new all-time highs, with paid accounts growing double digits year over year. Paid subscriptions also grew double digits. We have well over a billion paid subscriptions across the services on our platform.\n\n**Kevan Parekh** (CFO)\nWe remain focused on improving the breadth and quality of our services offerings, from new games on Apple Arcade to exciting new programming on Fitness+, and the continued expansion of features like tap-to-pay, now live in 20 markets. Turning to enterprise, we have seen businesses continue to expand their deployments of our products and services. Deutsche Bank launched its Mac as Choice program for their developers and also issued the latest MacBook Air as a standard computer for their entire mortgage lending division, and we're excited to see leading enterprises such as SAP leverage Apple Intelligence in the U.S., with features like writing tools, summarize, and priority notifications to enhance both their employee and customer experiences. We also see strong demand in our emerging markets. For example, Zomato, a leading food ordering and delivery company in India, has deployed thousands of Macs across their workforce to foster innovation.\n\n**Kevan Parekh** (CFO)\nVision Pro continues to see more use cases in enterprise, with Cisco's new spatial meetings delivering a fully immersive video conferencing experience for remote collaboration and learning. Let me quickly summarize our cash position and capital return program. We ended the quarter with $141 billion in cash and marketable securities. We repaid $1 billion in maturing debt and decreased commercial paper by $8 billion, resulting in $97 billion in total debt. Therefore, net cash at the end of the quarter was $45 billion. During the quarter, we returned over $30 billion to shareholders. This included $3.9 billion in dividends and equivalents and $23.3 billion through open market repurchases of 100 million Apple shares. As usual, we will provide an update to our capital return program when we report results for the March quarter.\n\n**Kevan Parekh** (CFO)\nAs we move ahead into the March quarter, I'd like to review our outlook, which includes the types of forward-looking information that Suhasini referred to at the beginning of the call. The color we're providing today assumes that the macroeconomic outlook doesn't worsen from what we were projecting today for the current quarter. As the dollar has strengthened significantly, we expect foreign exchange to be a headwind and to have a negative impact on revenue of about 2.5 percentage points on a year-over-year basis. Despite that headwind, we expect our March quarter total company revenue to grow low to mid-single digits year over year. We expect services revenue to grow low double digits year over year. When you remove the negative impact of the foreign exchange headwinds I described earlier, the year-over-year growth rate would be comparable to that of the December quarter.\n\n**Kevan Parekh** (CFO)\nWe expect gross margin to be between 46.5% and 47.5%. We expect operating expenses to be between $15.1 billion and $15.3 billion. We expect OINE to be around negative $300 million, excluding any potential impact from the mark-to-market of minority investments, and our tax rate to be around 16%. Finally, today, our board of directors has declared a cash dividend of $0.25 per share of common stock payable on February 13, 2025, to shareholders of record as of February 10, 2025. With that, let's open the call to questions.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Kevan. We ask that you limit yourself to two questions. Operator, may we have the first question, please?\n\n**Operator**\nCertainly. We will go ahead and take our first question from Eric Woodring with Morgan Stanley. Please go ahead.\n\n**Erik Woodring** (Analyst)\nGreat, guys. Thanks so much for taking my questions.\n\n**Erik Woodring** (Analyst)\nTim, in your prepared remarks, you had noted that iPhone 16 models are selling better in markets where Apple Intelligence is available. And I'm just wondering if you could double-click on that comment a bit and share any other details you believe could better help us understand how Apple Intelligence is really impacting iPhone demand and/or what features you find that users are using most often already. And then I just have a quick follow-up. Thank you.\n\n**Tim Cook** (CEO)\nYeah, Eric. Hi, it's Tim. We did see that the markets where we had rolled out Apple Intelligence, that the year-over-year performance on the iPhone 16 family was stronger than those where Apple Intelligence was not available. In terms of the features that people are using, they're using all of the ones that I referenced in my opening comments, from writing tools to Image Playground and Genmoji to Visual Intelligence and more.\n\n**Tim Cook** (CEO)\nAnd so we see all of those being used. The Clean Up is another one that is popular, and people love seeing that one demoed in the stores as well. We only had two, two and a half weeks or so during the December quarter of the second release of 18.2, and then only had the U.K. and the other English-language countries for the two and a half weeks. And so we've got just the early indications at the moment. But we were going to.\n\n**Erik Woodring** (Analyst)\nOkay. That's really helpful.\n\n**Tim Cook** (CEO)\nYeah.\n\n**Erik Woodring** (Analyst)\nOkay. Okay. Thank you for that color, Tim. It's helpful. And then if we just touch on China, obviously, in the news fairly frequently.\n\n**Erik Woodring** (Analyst)\nIf we set aside China macro, which I understand is still challenging, can you maybe talk about the headwinds that Apple faces, whether that's shifting preferences for Western technology brands in favor of domestic vendors, or is this just a function of not necessarily having Apple Intelligence available with the iPhone 16, which is not necessarily helping replacement cycles? Just maybe double-clicking on what you think and what you're hearing in China as it relates to the iPhone. Thanks so much.\n\n**Tim Cook** (CEO)\nYeah, sure. If you look at our Greater China revenue for the quarter, we were down 11% year over year. And over half of the decline that we experienced was driven by change in channel inventory from the beginning to the end of the quarter. And of course, on the Apple Intelligence side, we have not rolled out in China.\n\n**Tim Cook** (CEO)\nAnd as we just talked about, we did see better results in the markets that we had rolled out in than markets we hadn't rolled out in. And of course, it's the most competitive market in the world. And so all of those things are true. In terms of the macro situation, there was a fiscal stimulus or subsidy announced very recently in January that did not affect the December quarter. There were some provincial subsidies in the December quarter, but the national program was announced, I believe, on January 20. And it does cover the categories that we have products in, from smartphones to tablets and PCs and smartwatches, up to a maximum price point. And so we do see fiscal stimulus occurring, and we'll be glad to talk about what that looks like on the next call.\n\n**Erik Woodring** (Analyst)\nGreat. Thanks so much, Tim. Good luck.\n\n**Tim Cook** (CEO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Eric. Operator, can we have the next question, please?\n\n**Operator**\nOur next question is from Ben Reitzes with Melius Research. Please go ahead.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nHey, guys. Thanks a lot for the question. And hey, Tim, wanted to ask you who you knew this one was coming, but there's a perception that you're a big beneficiary of lower cost of compute. And I was wondering if you could give your worldly perspective here on the DeepSeek situation and if you are going to, if anything's happened to change your views in terms of a tailwind to margins and your ability to execute even due to the potential for cost to come down due to that development and probably what was going to happen anyway. But I'd love your perspective on that and then have a quick follow-up. Thanks.\n\n**Tim Cook** (CEO)\nSure. In general, I think innovation that drives efficiency is a good thing.\n\n**Tim Cook** (CEO)\nThat's what you see in that model. Our tight integration of silicon and software, I think, will continue to serve us very well. As you know, we do things on the device, and we do things in the private cloud, which mimics from an architectural point of view what happens on device. From a CapEx point of view, we've always taken a very prudent and deliberate approach to our expenditure, and we continue to leverage a hybrid model, which I think continues to serve us well.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nOh, great. All right. Thanks, Tim.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nAnd then just with regard to the iPhone trajectory, do you feel like, I guess, you obviously don't talk about new products and stuff like that, but do you feel that there's a lot of room for form factor innovation in the future, or do you feel that the current lineup kind of shows where you're going? I guess, without pulling punches, wondering if you thought, in terms of the phone innovation, if there's a lot more to come and you could see the kind of current market changing a bit over the next two to three years. Thanks.\n\n**Tim Cook** (CEO)\nI think, Ben, I think there's a lot more to come, and I could not feel more optimistic about our product pipeline. So I think there's a lot of innovation left on the smartphone.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nThanks a lot, Tim.\n\n**Tim Cook** (CEO)\nYeah. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Ben.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nOperator, could we have the next question, please?\n\n**Operator**\nOur next question is from Michael Ng with Goldman Sachs. Please go ahead.\n\n**Michael Ng** (Analyst)\nGood afternoon. Thank you for the question. I have two as well. First, it was encouraging to hear about the record for iPhone upgraders, which I think is something you haven't said for about a year now. I was wondering if you could talk a little bit about what you would attribute this upgrade strength to. Has Apple Intelligence played a role in helping upgrades in the markets that you've launched in? Thanks.\n\n**Tim Cook** (CEO)\nYeah. Thank you for the question. If you look at iPhone, we did set an all-time record for upgraders, so we've never seen a higher level of upgraders before. The install base hit a new all-time high as well.\n\n**Tim Cook** (CEO)\nAnd if you look at the 16 compared to the 15 from launch, which occurred, as you know, in September, so this is across now two quarters, from September to the end of the December fiscal quarter, the 16 outperformed the 15. And so I think you can conclude from that that there are compelling reasons to upgrade. And in the markets where we had launched Apple Intelligence, they outperformed the markets that we did not.\n\n**Michael Ng** (Analyst)\nGreat. Thank you, Tim.\n\n**Tim Cook** (CEO)\nYeah. Lots of good color there.\n\n**Michael Ng** (Analyst)\nThat's very clear. And then I had one about the iPad Pro M4, the thinner version. I was just wondering if you could talk about that thin form factor for the iPad Pro.\n\n**Michael Ng** (Analyst)\nHow did it help iPad sales overall, and what did your kind of market and consumer research tell you about how consumers valued that thin product form factor? Thank you.\n\n**Tim Cook** (CEO)\nIt's a good question. iPad overall grew 15% for the quarter, and it was more driven by iPad Air and the entry-level iPad than it was the top-level iPad. But overall, we could not be more pleased with the iPad category growing 15%. It's a great achievement for the quarter. And probably what is most important is that over half of the sales in the December quarter went to customers who were new to the iPad. So that tells us that there's a good amount of customers there to attract.\n\n**Michael Ng** (Analyst)\nThank you very much, Tim.\n\n**Tim Cook** (CEO)\nYeah. Thank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThanks, Mike. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Amit Daryanani from Evercore ISI. Please go ahead.\n\n**Amit Daryanani** (Senior Managing Director)\nYep. Good afternoon, everyone. I'm happy as well. Maybe to start with, you folks are seeing some very robust growth trends in emerging markets right now for Apple products. Can you just, at a high level, just talk about the durability of growth that you see in emerging markets? And then do you think the summation of these emerging markets are starting to get big enough or perhaps starting to grow fast enough that they can actually offset some of the China headwinds you're going through?\n\n**Tim Cook** (CEO)\nWe have great results in a number of emerging markets. And as you know from past calls, I'm particularly keen on India. India set a December quarter record during the quarter, and we're opening more stores there. We've announced that we're going to open four new stores there. The iPhone was the top-selling model in India for the quarter.\n\n**Tim Cook** (CEO)\nIt's the second largest smartphone market in the world and the third largest for PCs and tablets. And so there's a huge market, and we have a very modest share in these markets. And so I think there's lots of upside there. And that's just one of the emerging markets.\n\n**Kevan Parekh** (CFO)\nYeah. Tim, then maybe I'll add, Amit, that in emerging markets, we're also seeing double-digit growth on the install base, both in total and for the iPhone as well. So that's also an encouraging sign.\n\n**Amit Daryanani** (Senior Managing Director)\nPerfect. Thank you. And then just a question on gross margins for the March quarter. You folks are guiding gross margins to be flatish on a sequential basis. Typically, I think it tends to be guided up a little bit, 50 basis points or sequentially. Can we just touch on what are the offsets of the puts and takes you see on gross margins?\n\n**Amit Daryanani** (Senior Managing Director)\nAnd Kevan, maybe you can just talk about its effects having an outsized impact on your margin profile as well in March.\n\n**Kevan Parekh** (CFO)\nYes. Let me take that one. As we mentioned in my remarks, we're guiding to 46.5%-47.5%. So we think we're very pleased with that level of guidance. As you mentioned, there's always puts and takes. We do think there's going to be some FX headwinds, which we talked about. That's going to affect our revenue growth as well, have an impact here on the margin, a sequential impact on margins. But we think that's going to be offset by favorable costs and the relative mix of services. We also, as you know, when we move from Q1 to Q2, especially on the product side, because Q1 is such a large quarter for our products business, we do have a loss of leverage.\n\n**Kevan Parekh** (CFO)\nSo there are some puts and takes, and I think we feel good about the range. We think it's a very, very strong guide for gross margin.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thanks, Amit. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Wamsi Mohan with Bank of America. Please go ahead.\n\n**Wamsi Mohan** (Analyst)\nYes. Thank you so much. Tim, I want to follow up on your comment about channel inventory in China. I was wondering if you could maybe address more broadly if channel inventory across your different product lines and regions, do you feel they're elevated or out of range in any other regions? And given the clearing event that kind of happened in China, I guess, in the quarter, should we think of a more normal progression quarter on quarter into the March quarter in China in particular? And I will follow.\n\n**Tim Cook** (CEO)\nYeah.\n\n**Tim Cook** (CEO)\nI don't want to project sales for the current quarter by region, but if you look at the channel inventory and look at iPhone in the aggregate, so on a worldwide basis, we're very comfortable with our channel inventory position. In China, my point was that our channel inventory reduced from the beginning of the quarter to the end of the quarter, and that was over half of the reduction in the reported results. And so if you look, part of the reason for that is that our sales were a bit higher than we forecasted them to be toward the end of the quarter. And so we ended a little leaner than we had expected to.\n\n**Wamsi Mohan** (Analyst)\nOkay. That's very clear. Thank you.\n\n**Tim Cook** (CEO)\nYeah. Thank you.\n\n**Wamsi Mohan** (Analyst)\nAnd then maybe as my follow-up, your services growth has been very strong, and I know you've kind of been navigating some pretty challenging regulatory burdens on the business globally. So how should investors think about maybe either a top-line or margin headwind that, let's say, you're currently absorbing in your results that could potentially maybe reverse in a more balanced regulatory environment? Thank you so much.\n\n**Tim Cook** (CEO)\nYeah. So I think one, I just wanted to kind of reiterate the fact that our services business set an all-time record for December quarter of 14%. And that was one strength that we saw across all geographic segments, and also it was a very broad base across all of our services. So we have, as you know, a very broad services portfolio. And so we do see good momentum across the board.\n\n**Tim Cook** (CEO)\nAnd as well, we continue to see increasing engagement across the customer base, across all of the service offerings, both transacting and paid accounts. We talked about reaching all-time highs, and we have over now a billion paid subscriptions across the services platform.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thanks, Wamsi. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Samik Chatterjee with JPMorgan. Please go ahead.\n\n**Samik Chatterjee** (Analyst)\nHi. Thanks for taking my questions. I guess for the first one, I mean, you had a great quarter on Macs and iPads both, and I'm just curious in terms of if you can help us think about the sustainability of this double-digit growth that you saw in both the product lines. And more interested are also here.\n\n**Samik Chatterjee** (Analyst)\nWe're talking about Apple Intelligence sort of influencing volumes on iPhones, but any thoughts on sort of what does that influence look like in terms of volumes for Macs, for example, where I think there's a lot of conversation on AI PCs? How are you thinking about the impact there? And I have a quick follow-up. Thank you.\n\n**Tim Cook** (CEO)\nYeah. If you look at Mac, Mac was up 16%, and on iPad, we were up 15%. The Mac was driven by a very strong uptake on our new products during the quarter and the continued success of the MacBook Air. And so, as you know, we launched an M4-based MacBook Pro, an iMac, and a Mac Mini during the quarter. We believe we've got the best AI PC out there for running workloads.\n\n**Tim Cook** (CEO)\nThe silicon in the Mac is, and it has been for several years now, designed by us and really designed for these workloads, and so I don't want to project at the category level for the future, but we're incredibly pleased with both the Mac and the iPad for the quarter.\n\n**Samik Chatterjee** (Analyst)\nOkay, and Tim, I'm going to use your earlier discussion about India as a strong emerging market to sort of ask you about the supply chain planning there in terms of how much of the supply chain planning there that you're doing is more of a reflection of the growth expectations from that market relative to in terms of more diversification of the supply chain and how should we sort of think about that strategy relative to that particular country?\n\n**Tim Cook** (CEO)\nYeah.\n\n**Tim Cook** (CEO)\nIf you look at the manufacturing we do there, we do manufacturing both for the domestic market and we export. And so our business needs a certain economies of scale for it to make sense to manufacture in-country. And so that really means that we're going to be both a use for the domestic market and an export market.\n\n**Samik Chatterjee** (Analyst)\nGreat. Thank you.\n\n**Tim Cook** (CEO)\nYeah. Thanks.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Samik. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from David Vogt with UBS. Please go ahead.\n\n**David Vogt** (Analyst)\nGreat. Thanks, guys, for taking my question. So maybe, Tim, this is for you. I'm trying to think about your commentary around Apple Intelligence being sort of a momentum driver for the iPhone business.\n\n**David Vogt** (Analyst)\nWhen I think about your kind of framework for the March quarter, if I kind of adjust for channel inventory over the last couple of years, it kind of feels like your iPhone revenue for the March quarter is going to be relatively similar to the quarter two years ago and even the quarter last year. How do we square kind of the momentum versus kind of the iPhone business effectively really kind of unchanged over the last couple of years? Second, when I think about kind of the gross margin profile of the business, obviously, you've done a great job in taking gross margins up. Where do you think we sit in terms of, on the services side at least, where margins could go?\n\n**David Vogt** (Analyst)\nIt looks like the 75% margin has been an incredibly successful quarter, but just trying to get a sense for where do you think this number could go over the intermediate term? Thank you.\n\n**Tim Cook** (CEO)\nYeah. If you look at Apple Intelligence, my point earlier was that markets where we had rolled out Apple Intelligence during the Q1 period performed better on a year-over-year basis than markets where we had not. And so that gives us a positive indicator that we were pleased with. There are many compelling reasons to upgrade. And the other thing I would say that I think I mentioned earlier is that if you look at it from a launch to the end of the December quarter, and so that goes back to September, the 16 family is outperforming the 15 family. And so I think those are two good data points.\n\n**Tim Cook** (CEO)\nOur next round of language rollouts will be in April, and so it will be in our Q3 quarter, and I'll let Kevan take the gross margin question.\n\n**Kevan Parekh** (CFO)\nYep. Great. Hi, David. How are you? So on the services gross margin, I think maybe we should step back a second. Services business in general in aggregate is accretive to the overall company margin, and one of the things, as an important reminder, is we have a very broad services portfolio. And those businesses have very different margin profiles, and so I think, one, it's because of the nature of those businesses and in part also because of the way we account for them. And so one of the big factors that drives the services gross margins are relative performance of those different businesses within the portfolio.\n\n**Kevan Parekh** (CFO)\nWe also have the dynamic of some scale businesses like payment services, iCloud that are actually growing. And there, when we add incremental users, those end up being accretive to margins as well. And so in general, what we saw in the December quarter was nice momentum across our entire services business that allows us to deliver that 75% margin at the services level. And I think our guidance takes into consideration what we think we're going to land from a company standpoint at 46.5%-47.5%, which, again, we think is a strong guide.\n\n**David Vogt** (Analyst)\nGreat. Thanks, guys.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, David. Operator, could we have the next question, please?\n\n**Operator**\nOur next question is from Krish Sankar with TD Cowen. Please go ahead.\n\n**Krish Sankar** (Analyst)\nYeah. Thanks for the invitation, Kristian. I also share two of them. One, the first one is for Tim.\n\n**Krish Sankar** (Analyst)\nYou had very strong Mac growth, 16% year-over-year last quarter. Just wondering how much of that was driven by some of the Mac silicon innovation versus a replacement cycle for Macs?\n\n**Tim Cook** (CEO)\nI don't know the answer to your question precisely, but I think it is a combination of these products are so compelling. The M4-based products are so compelling that it's driving both upgrades at the double-digit level and it's driving switchers at a double-digit level. And so we're seeing both come out, and I think it's just because of the compelling products.\n\n**Krish Sankar** (Analyst)\nGot it. Got it. Thanks, Tim. And a follow-up for Kevan on the gross margin. I want to ask you a little more on the product side. Last quarter, you had 39.3%, which is very strong, similar to a year-ago period.\n\n**Krish Sankar** (Analyst)\nI'm kind of curious how much more levels do you have on the product side to improve the gross margin, or do you think with some of the more new AI-related devices, there's more upside to gross margin from here on the product hardware side?\n\n**Kevan Parekh** (CFO)\nYeah. Thanks, Krish, for the question. So on the product side, as you mentioned, we had pretty strong sequential improvement through 100 basis points for the December quarter. That was really driven by we talked about favorable mix and leverage. As you know, in Q1, again, it's a launch quarter for many products, and so we tend to benefit from the leverage that we get from that higher volume. I would say, in general, our gross margin for products is driven by a number of factors. One of them is the various product launches that we had.\n\n**Kevan Parekh** (CFO)\nDifferent products do have different margin profiles, and so that mix does make a difference, and in particular, what we're seeing is, for example, many of our mixes across phone, for example, we're seeing customers gravitate towards our Pro products because of things like affordability that allows our customers to get into our best products, which have favorable gross margins, so we're continuing to see that trend that impacted us in the December quarter, as well, I think we're in a favorable commodity environment from a cost standpoint, and so we're benefiting from that as well in the December quarter, and then that's going to be, as we talked about, we're going to have a foreign exchange headwind heading into the March quarter, but that's contemplated in the guidance range that we gave of the 46.5%-47.5%.\n\n**Krish Sankar** (Analyst)\nThanks, Kevan. Thanks, Tim.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Krish.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nOperator, could we get the next question, please?\n\n**Operator**\nOur next question is from Richard Kramer with Arete Research. Please go ahead.\n\n**Richard Kramer** (Analyst)\nThanks very much. My first question is for Tim. I'd like to ask about what might accelerate the pace of Apple Intelligence adoption. I guess, do you see this simply as a question of time, i.e., to launch more markets and languages or increase the percentage of installed base devices that can support it? Or is it a question of money, i.e., shifting R&D or marketing spend towards AI? And based on other prior Apple services, do you expect a sort of tipping point where adoption will go mainstream? Thanks.\n\n**Tim Cook** (CEO)\nI do believe it will go mainstream. I'm getting feedback from people using different features today.\n\n**Tim Cook** (CEO)\nKeep in mind that on the iPhone side of our business, you either have to have an iPhone 15 Pro or iPhone 16 to use Apple Intelligence. So as that base grows, I think the usage will continue to grow. I know from my own personal experience, once you start using the features, you can't imagine not using them anymore. I know I get hundreds of emails a day, and the summarization function is so important. I think it's a combination of that. Of course, in April, we roll out a whole series of new languages that we had mentioned, and so the base grows further.\n\n**Richard Kramer** (Analyst)\nOkay. Thank you. Then, Kevan, one of Luca's legacies was really getting Apple to record margin levels and also maintaining very consistent pricing across the product range.\n\n**Richard Kramer** (Analyst)\nBut taking the current high levels of profitability as fairly stable, what observations might you share about price sensitivity of users and whether having a wider range of pricing across the products might unlock potentially further market share gains or boost overall product growth?\n\n**Kevan Parekh** (CFO)\nYeah. It's a good question. I think, one, I don't think we're going to really depart from what's served us pretty well to now. I mean, we always take into consideration looking at short-term comparisons between the short-term and the long-term. I think we've had a pretty disciplined pricing strategy, which would serve us pretty well. And I think we're going to continually kind of stick with that as far as I can tell.\n\n**Richard Kramer** (Analyst)\nOkay. Thanks.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nThank you, Richard. Operator, could we get the next question, please?\n\n**Operator**\nOur next question is from Atif Malik with Citi. Please go ahead.\n\n**Atif Malik** (Analyst)\nHi. Thank you for taking my question.\n\n**Atif Malik** (Analyst)\nHow do you guys see the potential tariff impact to your product for consumer demand under Trump 2.0? You guys did fine under Trump 1.0.\n\n**Tim Cook** (CEO)\nWe are monitoring the situation and don't have anything more to add than that.\n\n**Atif Malik** (Analyst)\nGreat. And Tim, as a follow-up, there is a lot of discussion on agentic AI, the use of agents. Do you guys see the upgraded Siri expected in April as something that will, let's say, be the killer application among the suite of features that you have announced in Apple Intelligence?\n\n**Tim Cook** (CEO)\nI think the killer feature is different for different people. But I think for most, they're going to find that they're going to use many of the features every day. And certainly, one of those is Siri, and that will be coming over the next several months.\n\n**Atif Malik** (Analyst)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thank you, Atif.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nOperator, could we please get the last question?\n\n**Operator**\nOur last question is from Ben Bollin from Cleveland Research Company. Please go ahead.\n\n**Ben Bollin** (Analyst)\nGood evening, everyone. Thanks for taking the question. Tim, I'm interested in your thoughts in how you would have us think about the average useful life of these devices in the wild. And in particular, curious if you look at the strength you saw in fiscal 2021 and how that might support accelerated refresh opportunity into the future.\n\n**Tim Cook** (CEO)\nYeah. Ben, I think it's different for different types of users. I mean, you have very early adopter kind of users that are very quick to jump on the latest technology that upgrade very frequently. And then you have people that are on the entire opposite side of that barbell. And most people are between those two points.\n\n**Tim Cook** (CEO)\nAnd so I do think there were lots of units that are sold during the COVID period of time, and it's a huge opportunity for us as a company for more than one of the product categories.\n\n**Ben Bollin** (Analyst)\nThat's it for me. Thanks, Tim.\n\n**Tim Cook** (CEO)\nThank you.\n\n**Suhasini Chandramouli** (Director of Investor Relations)\nAll right. Thanks, Ben. I guess that's it. A replay of today's call will be available for two weeks on Apple Podcasts or as a webcast on apple.com/investor and via telephone. The number for the telephone replay is 866-583-1035. Please enter confirmation code 7398532 followed by the pound sign. These replays will be available by approximately 5:00 P.M. Pacific Time today. Members of the press with additional questions can contact Josh Rosenstock at 408-862-1142. And financial analysts can contact me, Suhasini Chandramouli, with additional questions at 408-974-3123. Thanks again for joining us here today.",
        "fetched_at": "2026-02-04T16:09:07.432Z"
      }
    ]
  },
  "MSFT": {
    "ticker": "MSFT",
    "last_updated": "2026-02-04T16:09:43.320Z",
    "total_transcripts": 5,
    "transcripts": [
      {
        "ticker": "MSFT",
        "title": "Yahoo Finance",
        "published_date": "Jan 28, 2026, 5:30 PM EST",
        "fiscal_year": "2026",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/MSFT/earnings/MSFT-Q2-2026-earnings_call-405185.html",
        "content": "**Operator**\n...Greetings, and welcome to the Microsoft Fiscal Year 2026 second quarter earnings conference call. At this time, all participants are in a listen-only mode. A question and answer session will follow the formal presentation. If anyone should require operator assistance, please press star zero on your telephone keypad. As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Nielsen, Vice President of Investor Relations. Please go ahead.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nGood afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer, Amy Hood, Chief Financial Officer, Alice Jolla, Chief Accounting Officer, and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThey are included as additional clarifying items to aid investors in further understanding the company's second quarter performance, in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available, as a framework for assessing how our underlying businesses performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only. We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nYou can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward-looking statements, which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the Risk Factors section of our Form 10-K, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement. With that, I'll turn the call over to Satya.\n\n**Satya Nadella** (Chairman and CEO)\nThank you very much, Jonathan. This quarter, the Microsoft Cloud surpassed $50 billion in revenue for the first time, up 26% year-over-year, reflecting the strength of our platform and accelerating demand. We are in the beginning phases of AI diffusion and its broad GDP impact. Our TAM will grow substantially across every layer of the tech stack as this diffusion accelerates and spreads. In fact, even in this early innings, we have built an AI business that is larger than some of our biggest franchises that took decades to build. Today, I'll focus my remarks across the three layers of our stack: cloud and token factory, AI and platform, and high-value agentic experiences. When it comes to our cloud and token factory, the key to long-term competitiveness is shaping our infrastructure to support new high-scale workloads.\n\n**Satya Nadella** (Chairman and CEO)\nWe are building this infrastructure out for the heterogeneous and distributed nature of these workloads, ensuring the right fit with the geographic and segment-specific needs for all customers, including the long tail. The key metric we are optimizing for is tokens per watt per dollar, which comes down to increasing utilization and decreasing TCO using silicon systems and software. A good example of this is the 50% increase in throughput we were able to achieve in one of our highest volume workloads, OpenAI inferencing, powering our copilots. Another example was the unlocking of new capabilities and efficiencies for our Fairwater data centers. In this instance, we connected both Atlanta and Wisconsin site through an AI WAN to build a first-of-its-kind AI super factory. Fairwater's two-story design and liquid cooling allow us to run higher GPU densities and thereby improve both performance and latencies for high-scale training.\n\n**Satya Nadella** (Chairman and CEO)\nAll up, we added nearly 1 GW of total capacity this quarter alone. At the silicon layer, we have NVIDIA and AMD and our own Maia chips, delivering the best all-up fleet performance, cost, and supply across multiple generations of hardware. Earlier this week, we brought online our Maia 200 accelerator. Maia 200 delivers 10+ petaflops at FP4 precision with over 30% improved TCO compared to the latest generation hardware in our fleet. We will be scaling this, starting with inferencing and synthetic data gen for our super intelligence team, as well as doing inferencing for Copilot and Foundry. And given AI workloads are not just about AI accelerators, but also consume large amounts of compute, we are pleased with the progress we are making on the CPU side as well.\n\n**Satya Nadella** (Chairman and CEO)\nCobalt 200 is another big leap forward, delivering over 50% higher performance compared to our first custom-built processor for cloud-native workloads. Sovereignty is increasingly top of mind for customers, and we are expanding our solutions and global footprint to match. We announced DC investments in seven countries this quarter alone, supporting local data residency needs. We offer the most comprehensive set of sovereignty solutions across public, private, and national partner clouds, so customers can choose the right approach for each workload with the local control they require. Next, I want to talk about the agent platform. Like in every platform shift, all software is being rewritten. A new app platform is being born.\n\n**Satya Nadella** (Chairman and CEO)\nYou can think of agents as the new apps, and to build, deploy, and manage agents, customers will need a model catalog, tuning services, harness for orchestration, services for context engineering, AI safety, management, observability, and security. It starts with having broad model choice. Our customers expect to use multiple models as part of any workload that they can fine-tune and optimize based on cost, latency, and performance requirements. We offer the broadest selection of models of any hyperscaler. This quarter, we added support for GPT-5 too, as well as Claude 4.5. Already, over 1,500 customers have used both Anthropic and OpenAI models on Foundry. We are seeing increasing demand for region-specific models, including Mistral and Cohere, as more customers look for sovereign AI choices.\n\n**Satya Nadella** (Chairman and CEO)\nWe continue to invest in our first-party models, which are optimized to address the highest value customer scenarios, such as productivity, coding, and security. As part of Foundry, we also give customers the ability to customize and fine-tune models. Increasingly, customers want to be able to capture the tacit knowledge they possess inside of model weights as their core IP. This is probably the most important sovereign consideration for firms as AI diffuses more broadly across our GDP, and every firm needs to protect their enterprise value. For agents to be effective, they need to be grounded in enterprise data and knowledge. That means connecting their agents to systems of record and operational data, analytical data, as well as semi-structured and unstructured productivity and communications data. And this is what we are doing with our Unified IQ layer, spanning Fabric, Foundry, and data powering Microsoft 365.\n\n**Satya Nadella** (Chairman and CEO)\nIn the world of context engineering, Foundry Knowledge and Fabric are gaining momentum. Foundry Knowledge delivers better context with automated source routing and advanced agentic retrieval while respecting user permissions. Fabric brings together end-to-end operational, real-time, and analytical data. Two years since it became broadly available, Fabric's annual revenue run rate is now over $2 billion, with over 31,000 customers, and it continues to be the fastest-growing analytics platform on the market, with revenue up 60% year-over-year. All up, the number of customers spending $1 million plus per quarter on Foundry grew nearly 80%, driven by strong growth in every industry. Over 250 customers are on track to process over 1 trillion tokens on Foundry this year. There are many great examples of customers using all of this capability on Foundry to build their own agentic systems.\n\n**Satya Nadella** (Chairman and CEO)\nAlaska Airlines is creating natural language flight search, BMW is speeding up design cycles, Land O'Lakes is enabling precision farming for co-op members, and SymphonyAI is addressing bottlenecks in the CPG industry. And of course, Foundry remains a powerful on-ramp for the entire cloud. The vast majority of Foundry customers use additional Azure solutions like developer services, app services, databases as they scale. Beyond Fabric and Foundry, we are also addressing agent building by knowledge workers with Copilot Studio and Agent Builder. Over 80% of the Fortune 500 have active agents built using these low-code, no-code tools. As agents proliferate, every customer will need new ways to deploy, manage, and protect them. We believe this creates a major new category and significant growth opportunity for us.\n\n**Satya Nadella** (Chairman and CEO)\nThis quarter, we introduced Agent 365, which makes it easy for organizations to extend their existing governance, identity, security, and management to agents. That means the same controls they already use across Microsoft 365 and Azure now extend to agents they build and deploy on our cloud or any other cloud. And partners like Adobe, Databricks, Genspark, Glean, NVIDIA, SAP, ServiceNow, and Workday are already integrating Agent 365. We are the first provider to offer this type of agent control plane across clouds. Now, let's turn to the high-value agentic experiences we are building. AI experiences are intent-driven and are beginning to work at task scope. We are entering an age of macro delegation and micro steering across domains. Intelligence using multiple models is built into multiple form factors.\n\n**Satya Nadella** (Chairman and CEO)\nYou see this in chat, in new agent inbox apps, coworker scaffoldings, agent workflows embedded in applications and IDEs that are used every day, or even in our command line with file system access and skills. That's the approach we are taking with our first-party family of Copilot spanning key domains. In consumer, for example, Copilot experiences span chat, news, feed, search, creation, browsing, shopping, and integrations into the operating system, and it's gaining momentum. Daily users of our Copilot app increased nearly 3x year-over-year, and with Copilot Checkout, we have partnered with PayPal, Shopify, and Stripe so customers can make purchases directly within the app.... With Microsoft 365 Copilot, we are focused on organization-wide productivity. Work IQ takes the data underneath Microsoft 365 and creates the most valuable stateful agent for every organization.\n\n**Satya Nadella** (Chairman and CEO)\nIt delivers powerful reasoning capabilities over people, their roles, their artifacts, their communications, and their history and memory, all within an organization's security boundary. Microsoft 365 Copilot's accuracy and latency, powered by Work IQ, is unmatched, delivering faster and more accurate work-grounded results than competition. We have seen our biggest quarter-over-quarter improvement in response quality to date. This has driven record usage intensity, with average number of conversations per user doubling year-over-year. Microsoft 365 Copilot also is becoming true daily habit, with daily active users increasing 10x year-over-year. We are also seeing strong momentum with Researcher Agent, which supports both OpenAI and Claude, as well as agent mode in Excel, PowerPoint, and Word. All up, it was a record quarter for Microsoft 365 Copilot seat adds, up over 160% year-over-year.\n\n**Satya Nadella** (Chairman and CEO)\nWe saw accelerating seat growth quarter-over-quarter, and now have 15 million paid Microsoft 365 Copilot seats and multiples more enterprise chat users. We are seeing larger commercial deployments. The number of customers with over 35,000 seats tripled year-over-year. Fiserv, ING, NASA, University of Kentucky, University of Manchester, US Department of Interior, and Westpac all purchased over 35,000 seats. Publicis alone purchased over 95,000 seats for nearly all its employees. We are also taking share in Dynamics 365 with built-in agents across the entire suite. A great example of this is how Visa is turning customer conversations data into knowledge articles with our Customer Knowledge Management Agent in Dynamics, and how Sandvik is using our Sales Qualification Agent to automate lead qualification across tens and thousands of potential customers. In coding, we are seeing strong growth across all paid GitHub Copilot.\n\n**Satya Nadella** (Chairman and CEO)\nCopilot Pro plus subs for individual devs increased 77% quarter-over-quarter, and all up now, we have 4.7 million paid Copilot subscribers, up 75% year-over-year. Siemens, for example, is going all in on GitHub, adopting the full platform to increase developer productivity after a successful Copilot rollout to 30,000+ developers. GitHub Agent HQ is the organizing layer for all coding agents like Anthropic, OpenAI, Google, Cognition, and xAI in the context of customers' GitHub repos. With Copilot CLI and VS Code, we offer developers the full spectrum of form factors and models they need for AI-first coding workflows. And when you add Work IQ as a skill or an MCP to our developer workflow, it's a game changer, surfacing more context like emails, meetings, docs, projects, messages, and more.\n\n**Satya Nadella** (Chairman and CEO)\nYou can simply ask the agent to plan and execute changes to your code base based on an update to a spec in SharePoint or using the transcript of your last engineering and design meeting in Teams. We are going beyond that with GitHub Copilot SDK. Developers can now embed the same runtime behind Copilot CLI, multi-model, multi-step planning tools, MCP integration, auth, streaming directly into their applications. In security, we added a dozen new and updated Security Copilot agents across Defender, Entra, Intune, and Purview. For example, Icertis's SOC team used Security Copilot agent to reduce manual triage time by 75%, which is a real game changer in an industry facing a severe talent shortage.\n\n**Satya Nadella** (Chairman and CEO)\nTo make it easier for security teams to onboard, we are rolling out Security Copilot to all our E5 customers, and our security solutions are also becoming essential to manage organizations' AI deployments. 24 billion Copilot interactions were audited by Purview this quarter, up 9x year-over-year. Finally, I want to talk about two additional high-impact agentic experiences. First, in healthcare, Dragon Copilot is the leader in its category, helping over 100,000 medical providers automate their workflows. Mount Sinai Health is now moving to a system-wide Dragon Copilot deployment for providers after a successful trial with its primary care physicians. All up, we helped document 21 million patient encounters this quarter, up 3x year-over-year. And second, when it comes to science and engineering, companies like Unilever in consumer goods and Synopsys in EDA are using Microsoft Discovery to orchestrate specialized agents for R&D end-to-end.\n\n**Satya Nadella** (Chairman and CEO)\nThey're able to reason over scientific literature and internal knowledge, formulate hypotheses, spin up simulations, and continuously iterate to drive new discoveries. Beyond AI, we continue to invest in all our core franchises and meet the needs of our customers and partners, and we are seeing strong progress. For example, when it comes to cloud migrations, our new SQL Server has over 2x the IaaS adoption of the previous version. In security, we now have 1.6 million security customers, including over 1 million who use four or more of our workloads. Windows reached a big milestone, 1 billion Windows 11 users, up over 45% year-over-year. We had share gains this quarter across Windows, Edge, and Bing.\n\n**Satya Nadella** (Chairman and CEO)\nDouble-digit member growth in LinkedIn with 30% growth in paid video ads. In gaming, we are committed to delivering great games across Xbox, PC, Cloud, and every other device, and we saw record PC players and paid streaming hours on Xbox. In closing, we feel very good about how we are delivering for customers today and building the full stack to capture the opportunity ahead. With that, let me turn it over to Amy to walk through our financial results and outlook, and I look forward to rejoining for your questions.\n\n**Amy Hood** (CFO)\nThank you, Satya, and good afternoon, everyone. With growing demand for our offerings and focused execution by our sales teams, we again exceeded expectations across revenue, operating income, and earnings per share while investing to fuel long-term growth. This quarter, revenue was $81.3 billion, up 17% and 15% in constant currency. Gross margin dollars increased 16% and 14% in constant currency, while operating income increased 21% and 19% in constant currency. Earnings per share was $4.14, an increase of 24% and 21% in constant currency when adjusted for the impact from our investment in OpenAI. FX increased reported results slightly less than expected, particularly in Intelligent Cloud revenue.\n\n**Amy Hood** (CFO)\nCompany gross margin percentage was 68%, down slightly year-over-year, primarily driven by continued investments in AI infrastructure and growing AI product usage that was partially offset by ongoing efficiency gains, particularly in Azure and M365 Commercial Cloud, as well as sales mix shift to higher margin businesses. Operating expenses increased 5% and 4% in constant currency, driven by R&D investments in compute capacity and AI talent, as well as impairment charges in our gaming business. Operating margins increased year-over-year to 47% ahead of expectations. As a reminder, we still account for our investment in OpenAI under the equity method, and as a result of OpenAI's recapitalization, we now record gains or losses based on our share of the change in their net assets on their balance sheet, as opposed to our share of their operating profit or losses from their income statement.\n\n**Amy Hood** (CFO)\nTherefore, we recorded a gain which drove other income and expense to $10 billion in our GAAP results. When adjusted for the OpenAI impact, other income and expense was slightly negative and lower than expected, driven by net losses on investments. Capital expenditures were $37.5 billion, and this quarter, roughly two-thirds of our CapEx was on short-lived assets, primarily GPUs and CPUs. Our customer demand continues to exceed our supply. Therefore, we must balance the need to have our incoming supply better meet growing Azure demand with expanding first-party AI usage across services like M365 Copilot and GitHub Copilot, increasing allocations to R&D teams to accelerate product innovation, and continued replacement of end-of-life server and networking equipment. The remaining spend was for long-lived assets that will support monetization for the next 15 years and beyond.\n\n**Amy Hood** (CFO)\nThis quarter, total finance leases were $6.7 billion and were primarily for large data center sites, and cash paid for PP&E was $29.9 billion. Cash flow from operations was $35.8 billion, up 60%, driven by strong cloud billings and collections. Free cash flow was $5.9 billion and decreased sequentially, reflecting the higher cash capital expenditures from a lower mix of finance leases. Finally, we returned $12.7 billion to shareholders through dividend and share repurchases, an increase of 32% year-over-year. Now to our commercial results.\n\n**Amy Hood** (CFO)\nCommercial bookings increased 230% and 228% in constant currency, driven by the previously announced large Azure commitment from OpenAI that reflects multiyear demand needs, as well as the previously announced Anthropic commitment from November and healthy growth across our core annuity sales motions. Commercial remaining performance obligation, which continues to be reported net of reserves, increased to $625 billion and was up 110% year-over-year, with a weighted average duration of approximately 2.5 years. Roughly 25% will be recognized in revenue in the next twelve months, up 39% year-over-year. The remaining portion, recognized beyond the next twelve months, increased 156%. Approximately 45% of our commercial RPO balance is from OpenAI.\n\n**Amy Hood** (CFO)\nThe significant remaining balance grew 28% and reflects ongoing broad customer demand across the portfolio. Microsoft Cloud revenue was $51.5 billion and grew 26% and 24% in constant currency. Microsoft Cloud gross margin percentage was slightly better than expected at 67% and down year over year due to continued investments in AI that were partially offset by ongoing efficiency gains noted earlier. Now to our segment results. Revenue from Productivity and Business Processes was $34.1 billion and grew 16% and 14% in constant currency. M365 Commercial Cloud revenue increased 17% and 14% in constant currency, with consistent execution in the core business and increasing contribution from strong Copilot results.\n\n**Amy Hood** (CFO)\nARPU growth was again led by E5 and M365 Copilot, and paid M365 commercial seats grew 6% year-over-year to over 450 million, with installed base expansion across all customer segments, though primarily in our small and medium business and frontline worker offerings. M365 Commercial Products revenue increased 13% and 10% in constant currency ahead of expectations due to higher-than-expected Office 2024 transactional purchasing. M365 Consumer Cloud revenue increased 29% and 27% in constant currency, again driven by ARPU growth. M365 consumer subscriptions grew 6%. LinkedIn revenue increased 11% and 10% in constant currency, driven by marketing solutions. Dynamics 365 revenue increased 19% and 17% in constant currency, with continued growth across all workloads.\n\n**Amy Hood** (CFO)\nSegment gross margin dollars increased 17% and 15% in constant currency, and gross margin percentage increased, again, driven by efficiency gains at M365 Commercial Cloud that were partially offset by continued investments in AI, including the impact of growing Copilot usage. Operating expenses increased 6% and 5% in constant currency, and operating income increased 22% and 19% in constant currency. Operating margins increased year-over-year to 60%, driven by improved operating leverage, as well as the higher gross margins noted earlier. Next, the Intelligent Cloud segment. Revenue was $32.9 billion and grew 29% and 28% in constant currency.\n\n**Amy Hood** (CFO)\nIn Azure and other cloud services, revenue grew 39% and 38% in constant currency, slightly ahead of expectations, with ongoing efficiency gains across our fungible fleet, enabling us to reallocate some capacity to Azure that was monetized in the quarter. As mentioned earlier, we continued to see strong demand across workloads, customer segments, and geographic regions, and demand continues to exceed available supply. In our on-premises server business, revenue increased 2% and 1% in constant currency, ahead of expectations, driven by demand for our hybrid solutions, including a benefit from the launch of SQL Server 2025, as well as higher transactional purchasing ahead of memory price increases. Segment gross margin dollars increased 20% and 19% in constant currency. Gross margin percentage decreased year-over-year, driven by continued investments in AI and sales mix shift to Azure, partially offset by efficiency gains in Azure.\n\n**Amy Hood** (CFO)\nOperating expenses increased 3% and 2% in constant currency, and operating income grew 28% and 27% in constant currency. Operating margins were 42%, down slightly year-over-year, as increased investments in AI were mostly offset by improved operating leverage. Now to More Personal Computing. Revenue was $14.3 billion and declined 3%. Windows OEM and devices revenue increased 1% and was relatively unchanged in constant currency. Windows OEM grew 5% with strong execution, as well as a continued benefit from Windows 10 end of support. Results were ahead of expectations as inventory levels remained elevated, with increased purchasing ahead of memory price increases. Search and news advertising revenue, ex TAC, increased 10% and 9% in constant currency, slightly below expectations, driven by some execution challenges. As expected, the sequential growth rate moderated as the benefit from third-party partnerships normalized.\n\n**Amy Hood** (CFO)\nIn gaming, revenue decreased 9% and 10% in constant currency. Xbox content and services revenue decreased 5% and 6% in constant currency and was below expectations, driven by first-party content with impact across the platform. Segment gross margin dollars increased 2% and 1% in constant currency, and gross margin percentage increased year-over-year, driven by sales mix shift to higher margin businesses. Operating expenses increased 6% and 5% in constant currency, driven by the impairment charges in our gaming business noted earlier, as well as R&D investments in compute capacity and AI talent. Operating income decreased 3% and 4% in constant currency, and operating margins were relatively unchanged year-over-year at 27%, as higher operating expenses were mostly offset by higher gross margins. Now, moving to our Q3 outlook, which, unless specifically noted otherwise, is on a US dollar basis.\n\n**Amy Hood** (CFO)\nBased on current rates, we expect FX to increase total revenue growth by three points. Within the segments, we expect FX to increase revenue growth by four points in Productivity and Business Processes and two points in Intelligent Cloud and More Personal Computing. We expect FX to increase COGS and operating expense growth by two points. As a reminder, this impact is due to the exchange rates a year ago. Starting with the total company, we expect revenue of $80.65 billion-$81.75 billion, or growth of 15%-17%, with continued strong growth across our commercial businesses, partially offset by our consumer businesses.\n\n**Amy Hood** (CFO)\nWe expect COGS of $26.65 billion-$26.85 billion, or growth of 22%-23%, and operating expense of $17.8 billion-$17.9 billion, or growth of 10%-11%, driven by continued investment in R&D, AI compute capacity, and talent against a low prior year comparable. Operating margins should be down slightly year-over-year. Excluding any impact from our investments in OpenAI, other income and expense is expected to be roughly $700 million, driven by a fair market gain in our equity portfolio and interest income, partially offset by interest expense, which includes the interest payments related to data center finance leases. We expect our adjusted Q3 effective tax rate to be approximately 19%.\n\n**Amy Hood** (CFO)\nNext, we expect capital expenditures to decrease on a sequential basis due to the normal variability from cloud infrastructure build-outs and the timing of delivery of finance leases. As we work to close the gap between demand and supply, we expect the mix of short-lived assets to remain similar to Q2. Now, our commercial business. In commercial bookings, we expect healthy growth in the core business on a growing ex-pre base when adjusted for the OpenAI contracts in the prior year. As a reminder, the significant OpenAI contract signed in Q2 represents multiyear demand needs from them, which will result in some quarterly volatility in both bookings and RPO growth rates going forward. Microsoft Cloud gross margin percentage should be roughly 65%, down year-over-year, driven by continued investments in AI. Now to segment guidance.\n\n**Amy Hood** (CFO)\nIn Productivity and Business Processes, we expect revenue of $34.25 billion-$34.55 billion, or growth of 14%-15%. In M365 Commercial Cloud, we expect revenue growth to be between 13%-14% in constant currency, with continued stability in year-over-year growth rates on a large and expanding base. Accelerating Copilot momentum and ongoing E5 adoption will again drive ARPU growth. M365 Commercial Products revenue should decline in the low single digits, down sequentially, assuming Office 2024 transactional purchasing trends normalize. As a reminder, M365 Commercial Products include components that can be variable due to in-period revenue recognition dynamics. M365 consumer cloud revenue growth should be in the mid- to high-20% range, driven by growth at ARPU, as well as continued subscription volume.\n\n**Amy Hood** (CFO)\nFor LinkedIn, we expect revenue growth to be in the low double digits, and in Dynamics 365, we expect revenue growth to be in the high teens, with continued growth across all workloads. For Intelligent Cloud, we expect revenue of $34.1 billion-$34.4 billion, or growth of 27%-29%. In Azure, we expect Q3 revenue growth to be between 37% and 38% in constant currency against a prior year comparable that included significantly accelerating growth rates in both Q3 and Q4. As mentioned earlier, demand continues to exceed supply, and we will need to continue to balance the incoming supply we can allocate here against other priorities.\n\n**Amy Hood** (CFO)\nAs a reminder, there can be quarterly variability in year-on-year growth rates depending on the timing of capacity delivery and when it comes online, as well as from in-period revenue recognition, depending on the mix of contracts. In our on-premises server business, we expect revenue to decline in the low single digits as growth rates normalize following the launch of SQL Server 2025. Though increased memory pricing could create additional volatility in transactional purchasing. In More Personal Computing, we expect revenue to be $12.3 billion-$12.8 billion. Windows OEM and devices revenue should decline in the low teens. Growth rates will be impacted as the benefit from Windows 10 end of support normalizes and as elevated inventory levels come down through the quarter. Therefore, Windows OEM revenue should decline roughly 10%.\n\n**Amy Hood** (CFO)\nThe range of potential outcomes remains wider than normal, in part due to the potential impact on the PC market from increased memory pricing. Search and news advertising ex-TAC revenue growth should be in the high single digits. Even as we work to improve execution, we expect continued share gains across Bing and Edge, with growth driven by volume, and we expect sequential growth moderation as the contribution from third-party partnerships continues to normalize. And in Xbox content and services, we expect revenue to decline in the mid single digits against a prior year comparable that benefited from strong content performance, partially offset by growth in Xbox Game Pass, and hardware revenue should decline year-over-year. Now, some additional thoughts on the rest of the fiscal year and beyond. First, FX.\n\n**Amy Hood** (CFO)\nBased on current rates, we expect FX to increase Q4 total revenue and COGS growth by less than 1 point, with no impact to operating expense growth. Within the segments, we expect FX to increase revenue growth by roughly 1 point in Productivity and Business Processes and More Personal Computing and less than 1 point in Intelligent Cloud. With the strong work delivered in H1 to prioritize investment in key growth areas and the favorable impact from a higher mix of revenue in our Windows OEM and commercial on-prem businesses, we now expect FY 2026 operating margins to be up slightly. We mentioned the potential impact on Windows OEM and on-premises server markets from increased memory pricing earlier. In addition, rising memory prices would impact capital expenditures, though the impact on Microsoft Cloud gross margins will build more gradually as these assets depreciate over six years.\n\n**Amy Hood** (CFO)\nIn closing, we delivered strong top-line growth in H1 and are investing across every layer of the stack to continue to deliver high-value solutions and tools to our customers. With that, let's go to Q&A. Jonathan?\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Amy. We'll now move over to Q&A. Out of respect for others on the call, we request that participants please only ask one question. Operator, can you please repeat your instructions?\n\n**Operator**\nThank you. Ladies and gentlemen, if you would like to ask a question, please press star one on your telephone keypad, and a confirmation tone will indicate your line is in the question queue. You may press star two if you would like to remove your question from the queue. For participants using speaker equipment, it may be necessary to pick up your handset before pressing the star keys. Our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.\n\n**Keith Weiss** (Analyst)\nExcellent. Thank you, guys, for taking the question. I'm looking at a Microsoft print where earnings is growing 24% year-on-year, which is a spectacular result. Great execution on your part. Top line growing well, margins expanding. But I'm looking at after-hours trading, and the stock is still down. And I think one of the core issues that is weighing on investors is CapEx is growing faster than we expected, and maybe Azure is growing a little bit slower than we expected. And I think that fundamentally comes down to a concern on the ROI on this CapEx spend over time. So I was hoping you guys could help us fill in some of the blanks a little bit in terms of how should we think about capacity expansion and what that can yield in terms of Azure growth going forward?\n\n**Keith Weiss** (Analyst)\nMore to the point, how should we think about the ROI on this investment as it comes to fruition? Thanks, guys.\n\n**Amy Hood** (CFO)\n... Thanks, Keith. And let me start, and Satya can add some broader comments, I'm sure. I think the first thing, I think you really asked a very direct correlation that I do think many investors are doing, which is between the CapEx spend and seeing an Azure revenue number. And, you know, we tried last quarter, and I think again this quarter, to talk more specifically about all the places that the CapEx spend, especially the short-lived CapEx spend across CPU and GPU, and where that'll show up. Sometimes I think it's probably better to think about the Azure guidance that we give as an allocated capacity guide about what we can deliver in Azure revenue. Because as we spend the capital and put GPUs specifically, it applies to CPUs, but GPUs more specifically, we're really making long-term decisions.\n\n**Amy Hood** (CFO)\nThe first thing we're doing is solving for the increased usage in sales and the accelerating pace of M365 Copilot, as well as GitHub Copilot, our first-party apps. Then we make sure we're investing in the long-term nature of R&D and product innovation. And much of the acceleration that I think you've seen from us in products over the past bit is coming because we are allocating GPUs and capacity to many of the talented AI people we've been hiring over the past years. You end up with the remainder going towards serving the Azure capacity that continues to grow in terms of demand.\n\n**Amy Hood** (CFO)\nA way to think about it, because I think I get asked this question sometimes, is, you know, if I had taken the GPUs that just came online in Q1 and Q2, in terms of GPUs, and allocated them all to Azure, the KPI would have been over 40. And I think the most important thing to realize is that this is about investing in all the layers of the stack that benefit customers, and I think that's hopefully helpful in terms of thinking about capital growth. It shows in every piece. It shows in revenue growth across the business and shows as OpEx growth as we invest in our people.\n\n**Satya Nadella** (Chairman and CEO)\nYeah, I think you, Amy, covered it. But basically, as an investor, I think when you think about our capital, and you think about the GM profile of our portfolio, you should obviously think about Azure, but you should think about M365 Copilot, and you should think about GitHub Copilot. You should think about Dragon Copilot, Security Copilot. All of those have a GM profile and lifetime value. I mean, if you think about it, acquiring an Azure customer is super important to us, but so is acquiring an M365 or a GitHub or a Dragon Copilot, which are all, by the way, incremental businesses and TAMs for us. And so we don't want to maximize just one business of ours.\n\n**Satya Nadella** (Chairman and CEO)\nWe want to be able to allocate capacity while we're sort of supply constrained in a way that allows us to essentially build the best LTV portfolio. That's on one side, and the other one that Amy mentioned is also R&D. I mean, you got to think about compute is also R&D, and that's sort of the second element of it. And so we're using all of that, obviously, to optimize for the long term.\n\n**Keith Weiss** (Analyst)\nExcellent. Thank you.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Keith. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.\n\n**Mark Moerdler** (Analyst)\nThank you very much for taking my question, and congrats on the quarter. One of the other questions we believe investors want to understand is how to think about your line of sight from hardware CapEx investment to revenue and margins. You capitalize servers over six years, but the average duration of your RPO is 2.5 years, up from two years last quarter. How do investors get comfortable that since this is a lot of this CapEx is AI-centric, that you'll be able to capture sufficient revenue over the 6-year useful life of the hardware to deliver solid revenue and gross profit dollars growth? Hopefully, one similar to the CPU revenue. Thank you.\n\n**Amy Hood** (CFO)\nThanks, Mark. Let me start with at a high level, and Satya can add as well. I think, you know, when you think about average duration, I think what you're getting to is, and we need to remember, is that average duration is a combination of a broad set of contract arrangements that we have. A lot of them around things like M365 or our BizApp portfolio are shorter dated, right? Three-year contracts, and so they have, quite frankly, a short duration. The majority then, that's remaining are Azure contracts that are longer duration, and you saw that this quarter when we saw the extension of that duration from around 2 years to 2.5.\n\n**Amy Hood** (CFO)\nThe way to think about that is, you know, the majority of the capital that we're spending today, and a lot of the GPUs that we're buying, are already contracted for most of their useful life. So a way to think about that is, you know, much of that risk that I think you're pointing to isn't there because they're already sold for the entirety of their useful life. So part of it exists because you have this shorter dated RPO because of some of the M365 stuff. If you look at the Azure-only RPO, it's a little bit more extended. A lot of that is CPU basis. It's not just GPU.\n\n**Amy Hood** (CFO)\nOn the GPU contracts that we've talked about, including for some of our largest customers, those are sold for the entire useful life of the GPU, and so there's not the risk to which I think you may be referring. Hopefully, that's helpful.\n\n**Satya Nadella** (Chairman and CEO)\n... Yeah, and just one other thing I would add, to it is, in addition to sort of what Amy mentioned, which is it's already contracted for the useful life, is we do use software to continuously run even the latest models on, the fleet, that is aging, if you will. So that's sort of what gives us that duration. And so, at the end of the day, we want to have That's why we even think about aging the fleet constantly, right? So it's not about buying a whole lot of gear one year. It's about each year you ride the Moore's Law, you add, you use software, and then you optimize across all of it.\n\n**Amy Hood** (CFO)\nAnd Mark, maybe to state this, in case it's not obvious, is that as you go through the useful life, actually, you get more and more and more efficient at its delivery. So where you've sold the entirety of its life, the margins actually improve with time. And so I think that may be a good reminder to people as we see that, obviously, in the CPU fleet all the time.\n\n**Mark Moerdler** (Analyst)\nThat's a great answer. I really appreciate it. Thank you.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Mark. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Brent Thill with Jefferies. Please, please proceed.\n\n**Brent Thill** (Analyst)\nThanks, Amy. On 45% of the backlog being related to OpenAI, I'm just curious if you can comment. There's obviously concern about the, you know, the durability, and I know maybe there's not much you can say on this, but I think everyone's concerned about the exposure and if you could maybe talk through your perspective on what both you and Satya are seeing.\n\n**Amy Hood** (CFO)\nI think maybe I would have thought about the question quite differently, Brent. The first thing to focus on is the reason we talked about that number is because 55% or roughly $350 billion is related to the breadth of our portfolio, a breadth of customers across solutions, across Azure, across industries, across geographies. That is a significant RPO balance, larger than most peers, more diversified than most peers, and frankly, I think we have super high confidence in it. When you think about that portion alone growing 28%, it's really impressive work on the breadth as well as the adoption curve that we're seeing, which is I think what I get asked most frequently. It's grown by customer segment, by industry, and by geo, and so it's very consistent.\n\n**Amy Hood** (CFO)\nIf you're asking me about how do I feel about OpenAI and the contract and the health, listen, it's a great partnership. We continue to be their provider of scale. We're excited to do that. We sit under one of the most successful businesses built, and we continue to feel quite good about that. It's allowed us to remain a leader in terms of what we're building and being on the cutting edge of app innovation.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Brent. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Karl Keirstead with UBS. Please proceed.\n\n**Karl Keirstead** (Analyst)\nOkay, thank you very much. Satya, Amy, regardless of how you allocate the capacity between first party and third party, can you comment qualitatively on the amount of capacity that you have coming on? I think the 1 GW added in the December quarter was extraordinary and hints that the capacity adds are accelerating. But I think a lot of investors have their eyes on Fairwater, Atlanta, Fairwater, Wisconsin, and would love some comments about the magnitude of the capacity adds, regardless of how they're allocated in the coming quarters. Thank you.\n\n**Amy Hood** (CFO)\nYeah, Karl, I think we've said a couple of things. We're working as hard as we can to add capacity as quickly as we can. You've mentioned specific sites like Atlanta or Wisconsin. Those are multi-year deliveries, so I wouldn't focus necessarily on specific locations. The real thing we've got to do, and we're working incredibly hard at doing it, is adding capacity globally. A lot of that will be added in the United States, the two locations you've mentioned, but it also needs to be added across the globe to meet the customer demand that we're seeing and the increased usage. You know, we'll continue to add both long-lived assets, infrastructure.\n\n**Amy Hood** (CFO)\nThe way to think about that is we need to make sure we've got power and land and facilities available, and we'll continue to put GPUs and CPUs in them when they're done, as quickly as we can. And then finally, we'll try to make sure we can get as efficient as we possibly can on the pace at which we do that and how we operate them so that they can have the highest possible utility. And so I think, it's not really about, you know, two places, Karl. I, I would definitely abstract away from that. Those are multi-year delivery timelines, but really, we just need to get it done every location where we're currently in a build or, or starting to do that. We're working as quickly as we can.\n\n**Karl Keirstead** (Analyst)\nOkay, got it. Thank you.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Karl. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Mark Murphy with JP Morgan. Please proceed.\n\n**Mark Murphy** (Analyst)\nThank you so much. Satya, the performance achievements of the Maia 200 accelerator for inference looked quite remarkable, especially in comparison to TPUs and Trainium and Blackwell, which have just been around a lot longer. Can, can you put that accomplishment in perspective, in terms of how much of a core competency you think silicon might become for Microsoft? And Amy, are there any ramifications worth mentioning there in terms of supporting your gross margin profile for inference costs going forward?\n\n**Satya Nadella** (Chairman and CEO)\nYeah, no, thanks for the question. So a couple of things. One is we've been at this, in a variety of different forms, for a long, long time in terms of building our own silicon. And, so we're very, very thrilled about the progress with Maia 200. And, you know, especially when we think about running a GPT-5 too and the, the performance we're able to get in the GEMMs, at FP4, just proves the point that, when you have, a new workload, a new shape of a workload, you can start innovating end-to-end, between the model and, and, and the silicon. And the entire system is just not even about just the silicon, the way, the networking works at, at rack scale that's optimized, with memory for, this particular workload.\n\n**Satya Nadella** (Chairman and CEO)\nThe other thing is we are obviously round-tripping and working very closely with our own super intelligence team with all of our models. As you can imagine, whatever we build will be all optimized for Maia. We feel great about it, and I think the way to think about all up is we're in such early innings. I mean, even just look at the amount of silicon innovation and systems innovation. Even since December, I think the new thing is everybody's talking about low latency inference. Right? One of the things we want to make sure is we're not locked into any one thing. If anything, we have great partnership with NVIDIA, with AMD. They're innovating, we're innovating. We want to fleet at any given point in time to have access to the best TCO.\n\n**Satya Nadella** (Chairman and CEO)\nAnd it's not a one-generation game. I think a lot of folks just talk about who's ahead. It's just remember, you have to be ahead all thefor all time to come. And that means you really want to think about, you know, having a lot of innovation that happens out there to be in your fleet so that your fleet is fundamentally advantaged at the TCO level. So that's kind of how I look at it, which is we are excited about Maia, we're excited about Cobalt, we're excited about DPU, our next. So we have a lot of systems capability. That means we can vertically integrate, and because we can vertically integrate doesn't mean we just only vertically integrate. And so we want to be able to have the flexibility here, and that's what you see us do.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Mark. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Brad Zelnick with Deutsche Bank. Please proceed.\n\n**Brad Zelnick** (Analyst)\nGreat. Thank you very much. Satya, we heard a lot about frontier transformations from Judson at Ignite, and we've seen customers realize breakthrough benefits when they adopt the Microsoft AI stack. Can you help frame for us the momentum in enterprises embarking on these journeys, and any expectation for how much their spend with Microsoft can expand in becoming frontier firms? Thanks.\n\n**Satya Nadella** (Chairman and CEO)\nYeah, thank you for that. So I think, one of the things that we are seeing, is the adoption across the three major suites of ours, right? So if you take M365, you take, what's happening with security, and you take GitHub. In fact, it's, it's fascinating. I mean, you know, these three things had effectively compounding effects for our customers in the past, like something like Entra as an identity system or Defender as the protection system, across all three was sort of super helpful. But so what now you're seeing is something like Work IQ, right? So, I mean, just to give you a flavor for it, the most important database underneath, for any company that uses Microsoft today is the data underneath Microsoft 365, and the reason is because it has all this tacit information, right? Who are your people?\n\n**Satya Nadella** (Chairman and CEO)\nWhat are their relationships? What are the projects they're working on? What are their artifacts, their communications? So that's a super important asset for any business process, business workflow context. In fact, the scenario I even had in my transcript around, you can now take Work IQ as an MCP server and, you know, GitHub repo and say, \"Hey, please look at my design meetings for the last month in Teams and tell me if my repo reflects it.\" I mean, that's a pretty high-level way to think about how what is happening previously, perhaps with our tools business and our GitHub business, are suddenly now being transformative, right? That agentic plane is really transforming companies in some sense, right? That's, I think, the most magical thing, which is you deploy these things, and suddenly the agents are helping you coordinate, bring more leverage to your enterprise.\n\n**Satya Nadella** (Chairman and CEO)\nThen on top of it, of course, there is the transformation, which is what businesses are doing. How should we think about customer service? How should we think about marketing? How should we think about finance? How should we think about that and build our own agents? That's where all the services in Fabric and Foundry, and of course, the GitHub tooling is helping them, or even the low-code, no-code tools. I had some stats on how much that's being used. But one of the more exciting things for me is these new agents systems, M365 Copilot, GitHub Copilot, Security Copilot, all coming together to compound the benefits of all the data and all the deployment. I think is probably the most transformative effect right now.\n\n**Brad Zelnick** (Analyst)\nThank you. Very helpful.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Brad. Operator, we have time for one last question.\n\n**Operator**\nThe last question will come from the line of Raimo Lenschow with Barclays. Please proceed.\n\n**Raimo Lenschow** (Analyst)\n... Perfect. Thanks for squeezing me in. The last few quarters, we talked, besides the GPU side, we talked about CPU as well on the Azure side, and you had some operational changes at the beginning, or January last year. Can you speak what you saw there, and maybe put it more in a bigger picture in terms of clients realizing that their move to the cloud is important if they want to deliver proper AI? So, what are we seeing in terms of cloud transitions? Thank you.\n\n**Satya Nadella** (Chairman and CEO)\nI didn't quite-\n\n**Jonathan Nielsen** (VP of Investor Relations)\nSorry, Raimo, you were asking about the SMC, CPU side, or can you just repeat the question, please?\n\n**Raimo Lenschow** (Analyst)\nYeah. Yeah, yeah, yes, sorry. So I was wondering about the CPU side of Azure, because we had some operational changes there. You know, we also hear from the field a lot that people are realizing they need to be in the cloud if they want to do proper AI, and if that's kind of driving momentum. Thank you.\n\n**Satya Nadella** (Chairman and CEO)\nYeah, I think I get it. So first of all, I had mentioned in my remarks that when you think about AI workloads, you shouldn't think of AI workloads as just AI accelerator compute, right? Because in some sense, it takes any agent, the agent will then spawn through tool use maybe a container, which runs obviously on compute. In fact, we have whenever we think about even the building out of the fleet, we think of in ratios. Even for a training job, by the way, an AI training job requires a bunch of compute and a bunch of storage, very close to compute, and so therefore, and in same thing in inferencing as well. So in inferencing with agent mode, would require you to essentially provision a computer, or computing resources to the agent.\n\n**Satya Nadella** (Chairman and CEO)\nThey don't need GPUs. They're running on GPUs, but they need computers, which are compute and storage. So that's what's happening even in the new workload. The other thing you mentioned is the cloud migrations are still going on. In fact, one of the stats I had was SQL latest SQL Server growing as an IaaS service in Azure. And so that's one of the reasons why we have to think about our commercial cloud and keep it balanced with the rest of our AI cloud, because when clients bring their workloads and bring new workloads, they need all of these infrastructure elements in the region in which they're deploying.\n\n**Raimo Lenschow** (Analyst)\nYeah. Okay, perfect. Thank you.\n\n**Jonathan Nielsen** (VP of Investor Relations)\nThanks, Raimo. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with you all soon.\n\n**Satya Nadella** (Chairman and CEO)\nThank you all.\n\n**Amy Hood** (CFO)\nThank you.\n\n**Operator**\nThank you. This concludes today's conference. You may disconnect your lines at this time, and we thank you for your participation. Have a great night.",
        "fetched_at": "2026-02-04T16:09:18.517Z"
      },
      {
        "ticker": "MSFT",
        "title": "Yahoo Finance",
        "published_date": "Oct 29, 2025, 5:30 PM EDT",
        "fiscal_year": "2026",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/MSFT/earnings/MSFT-Q1-2026-earnings_call-368945.html",
        "content": "**Operator**\nGreetings and welcome to the Microsoft Fiscal Year 2026 First Quarter Earnings Conference Call. At this time, all participants are in a listen-only mode. A question and answer session will follow the formal presentation. If anyone should require operator assistance, please press *0 on your telephone keypad. As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Neilson, Vice President of Investor Relations. Please go ahead.\n\n**Jonathan Neilson** (VP of Investor Relations)\nGood afternoon and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer, Amy Hood, Chief Financial Officer, Alice Jolla, Chief Accounting Officer, and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, we will provide an earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks and provide the reconciliation of differences between GAAP and non-GAAP financial measures. More detailed Outlook slides will be available on the Microsoft Investor Relations website. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThey are included as additional clarifying items to aid investors in further understanding the company's first quarter performance, in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted. We will also provide growth rates in constant currency, when available, as a framework for assessing how our underlying business performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only. We will post our prepared remarks to our website. Today's call is being recorded. If you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording.\n\n**Jonathan Neilson** (VP of Investor Relations)\nYou can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward-looking statements, which are predictions, projections, or other statements about future events. These statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made in this conference call, and in the risk factor section of our Form 10-K, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statements. With that, I'll turn the call over to Satya.\n\n**Satya Nadella** (Chairman and CEO)\nThank you, Jonathan. It was a very strong start to our fiscal year. Microsoft Cloud revenue surpassed $49 billion, up 26% year over year, and our commercial RPO increased over 50% to nearly $400 billion with a weighted average duration of only two years. We are seeing increasing demand and diffusion of our AI platform and family of Copilots, which is fueling our investments across both capital and talent. When it comes to infrastructure, we're building a planet-scale cloud and an AI factory, maximizing tokens per dollar per watt while supporting the sovereignty needs of customers and countries. We're innovating rapidly across the family of Copilots, spanning the high-value domains of information work, coding, security, science, health, and consumer.\n\n**Satya Nadella** (Chairman and CEO)\nAs you saw yesterday, we closed a new definitive agreement with OpenAI, marking the next chapter in what is one of the most successful partnerships and investments our industry has ever seen. This is a great milestone for both companies, and we continue to benefit mutually from each other's growth across multiple dimensions. Already, we have roughly 10x our investment. OpenAI has contracted an incremental $250 billion of Azure services. Our rev share, exclusive IP rights, and API exclusivity for Azure continue until AGI or through 2030, and we have extended the model and product IP rights through 2032. We are also energized to innovate and pursue AI advancements with both talent and compute investments that have real-world impact. With that, let's turn to our momentum across our AI platform and Copilots, as well as with agents.\n\n**Satya Nadella** (Chairman and CEO)\nWe have the most expansive data center fleet for the AI era, and we are adding capacity at an unprecedented scale. We will increase our total AI capacity by over 80% this year and roughly double our total data center footprint over the next two years, reflecting the demand signals we see. Just this quarter, we announced the world's most powerful AI data center, Fairwater in Wisconsin, which will go online next year and scale to 2 gigawatts alone. We have deployed the world's first large-scale cluster of NVIDIA GB300s. We are building a fungible, global fleet that's being continuously modernized and spans all stages of the AI lifecycle, from pre-training to post-training to synthetic data generation and inference. It also goes beyond Gen AI workloads to recommendation engines, databases, and streaming. We're optimizing this fleet across silicon, systems, and software to maximize performance and efficiency.\n\n**Satya Nadella** (Chairman and CEO)\nIt's this combination of fungibility and continuous optimization that allows us to deliver the best ROI and TCO for us and our customers. For example, during the quarter, we increased the token throughput for GPT-4-1 and GPT-5, two of the most widely used models, by over 30% per GPU. We also have the most comprehensive digital sovereignty platform. Azure customers in 33 countries are now developing their own cloud and AI capabilities within their borders to meet local data residency requirements. In Germany, for example, OpenAI and SAP will rely on Azure to deliver new AI solutions to the public sector. On top of this infrastructure, we're building Azure AI Foundry to help customers build their own AI apps and agents. We have 80,000 customers, including 80% of the Fortune 500.\n\n**Satya Nadella** (Chairman and CEO)\nWe offer developers and enterprise access to over 11,000 models, more than any other vendor, including, as of this quarter, OpenAI's GPT-5, as well as xAI's Grok-4. For example, Ralph Lauren used Foundry to build a conversational shopping experience in its app, enabling customers to describe what they're looking for and get personalized recommendations. Open Evidence used Foundry to create its AI-powered clinical assistant, which surfaces relevant medical information to physicians and helps streamline charting. When it comes to our first-party models, we're excited by the performance of our new MAI models for text, voice, and image generation, which debuted among the top in the industry leaderboards. We continue to make great progress with our Phi-3 family of SLMs, which now have been downloaded over 60 million times, up 3x YoY.\n\n**Satya Nadella** (Chairman and CEO)\nBeyond models in Foundry, we are providing everything developers need to design, customize, and manage AI applications and agents at scale. Our new Microsoft Agent Framework helps developers orchestrate multi-agent systems with compliance, observability, and deep integration out of the box. For example, KPMG used the framework to modernize the audit process, connecting agents to internal data with enterprise-grade governance and observability. These kinds of real production-scale AI deployments are driving Azure's overall growth, and once again, this quarter, Azure took share. Now let's turn to applications and agents we ourselves are building on this platform. We now have 900 million monthly active users of our AI features across our products. Our first-party family of Copilots now has surpassed 150 million monthly active users across information work, coding, security, science, health, and consumer. When it comes to information work, we continue to innovate with Microsoft 365 Copilot.\n\n**Satya Nadella** (Chairman and CEO)\nCopilot is becoming the UI for the Agentic AI experience. We have integrated chat and Agentic workflows into everyday tools like Outlook, Word, Excel, PowerPoint, and Teams. Just nine months since release, tens of millions of users across the Microsoft 365 customer base are already using chat. Adoption is accelerating rapidly, growing 50% quarter over quarter, and we continue to see usage intensity increase. This quarter, we also introduced Agent Mode, which turns single prompts into expert-quality Word documents, Excel spreadsheets, PowerPoint presentations, and then iterates to deliver the final product, much like Agent Mode in coding tools today. We're thrilled by the early response, including third-party benchmarks that rank it best in class. Beyond individual productivity, Copilot is multiplayer with Teams Mode announced this week.\n\n**Satya Nadella** (Chairman and CEO)\nYou can now invite colleagues into a Copilot conversation, and our collaborative agents like Facilitator and Project Manager prep meeting agendas, take notes, capture decisions, and kick off group tasks. We are seeing a growing Copilot agent ecosystem with top ISVs like Adobe, Asana, Jira, LexisNexis, SAP, ServiceNow, Snowflake, and Workday all building their own agents that connect to Copilot. Customers are also building agents for their mission-critical business processes and workflows using tools like Copilot Studio and integrating them into Copilot. The overall number of agent users doubled quarter over quarter, and just yesterday, we announced App Builder, a new Copilot agent that lets anyone create and deploy task-specific apps and agents in minutes grounded in Microsoft 365 context. All this innovation is driving our momentum. Customers continue to adopt Microsoft 365 Copilot at a faster rate than any other new Microsoft 365 suite.\n\n**Satya Nadella** (Chairman and CEO)\nAll up, more than 90% of the Fortune 500 now use Microsoft 365 Copilot. Accenture, Bristol-Myers Squibb, EY Global, and the UK's Tax and Payment and Customs Authority all purchased over 15,000 seats this quarter. Lloyds Banking Group has deployed 30,000 seats, saving each employee an average of 46 minutes daily. A large majority of our enterprise customers continue to come back to purchase more seats. Our partner, PwC, alone added 155,000 seats this quarter and now has over 200,000 deployed across its global operations. In just six months, PwC employees interacted with Microsoft 365 Copilot over 30 million times, and they credit this agentic transformation with saving millions of hours in employee productivity. When it comes to coding, GitHub Copilot is the most popular AI pair programmer now with over 26 million users.\n\n**Satya Nadella** (Chairman and CEO)\nFor example, tens of thousands of developers at AMD use GitHub Copilot, accepting hundreds of thousands of lines of code suggestions each month and crediting it with saving months of development time. All up, GitHub is now home to over 180 million developers, and the platform is growing at the fastest rate in its history, adding a developer every second. 80% of new developers on GitHub start with Copilot within the first week. Overall, the rise of AI coding agents is driving record usage with over 500 million pull requests merged over the past year. Just yesterday at GitHub Universe, we introduced Agent HQ. GitHub Copilot and Agent HQ are the organizing layer for all coding agents, extending the GitHub primitives like PRs, issues, and actions to coding agents from OpenAI, Anthropic, Google, Cognition, xAI, as well as OSS and in-house models.\n\n**Satya Nadella** (Chairman and CEO)\nGitHub now provides a single mission control to launch, manage, and review these agents, each operating from its own branch with built-in controls, observability, and governance. We're building a similar system in security with over three dozen agents in Copilot integrated across Entra, Defender, Purview, and Intune. For example, with our phishing triage agent in Defender, studies show that analysts can be up to 6.5 times more efficient in detecting malicious mails. In health, Dragon Copilot helps providers automate critical workflows. This quarter alone, we helped document over 17 million patient encounters, up nearly 5x year over year. More than 650 healthcare organizations have purchased our ambient listening tech to date, including University of Michigan Health, where over 1,000 physicians are actively using it. Finally, when it comes to AI consumer experiences, we are excited about all the progress Copilot is making, starting with Windows.\n\n**Satya Nadella** (Chairman and CEO)\nEvery Windows 11 PC now is an AI PC. Two weeks ago, we introduced new ways to speak naturally to your computer, including a Copilot wake word. With Vision, Copilot sees what you see on your screen, and you can have a real-time conversation about it. With Action, it takes real action on your behalf, interacting with both web and desktop apps. In Edge, we are introducing first-of-its-kind AI features to automate multi-step workflows within the browser and help you pick up right where you left off. Edge now has taken share for 18 consecutive quarters. In Bing, our overview pages now include embedded conversational capabilities. We took share again in search. Daily users of our Copilot consumer app increased nearly 50% quarter over quarter. Among many updates we made last week is Groups, which turns Copilot for the first time into a shared experience.\n\n**Satya Nadella** (Chairman and CEO)\nWe also are creating a great consumer subscription offer with Microsoft 365 Premium. It brings together our Office applications and advanced Copilot features with high usage limits, giving individuals the flexibility to bring their own AI to work in a secure way. Finally, in gaming, Copilot provides a voice-first immersive experience across PC, mobile, and our new Xbox Ally. Beyond our family of Copilots and AI platform, we are seeing strong momentum across the portfolio. Cloud migrations are accelerating. In data and analytics, Fabric revenue grew 60%, which is faster than any other data and analytics platform in the industry. We now have 28,000 paid Fabric customers. In databases, SQL DB hyperscale revenue was up nearly 75%, 50% in Cosmos DB. In business applications, Dynamics 365 gained share.\n\n**Satya Nadella** (Chairman and CEO)\nIn security, our end-to-end stack is now informed by 100 trillion daily signals, 1 billion monthly active users of Entra, 16 billion Copilot interactions audited by Purview, up 72% quarter over quarter, 40,000 Sentinel customers. We took share across all categories we serve in security. In LinkedIn, nearly 1.3 billion members. In gaming, we expanded our reach across every endpoint focused on our high-margin content and services. We launched critically acclaimed games like Keeper, Ninja Gaiden 4, and Outer Worlds 2, reaching 155 million monthly active users in Minecraft, an all-time high, and set new records for overall content and services revenue for the quarter. We also saw a great response to Xbox Ally launch two weeks ago and set new records for players on PC. In closing, our planet-scale cloud and AI factory, together with Copilots across high-value domains, is driving broad diffusion and real-world impact.\n\n**Satya Nadella** (Chairman and CEO)\nWe continue to increase our investments in AI across both capital and talent to meet the massive opportunity ahead. With that, let me turn it over to Amy to walk through our financial results and outlook. I look forward to rejoining for your questions.\n\n**Amy Hood** (CFO)\nThank you, Satya, and good afternoon, everyone. First, as you heard from Satya, we were pleased to announce the next phase of our partnership with OpenAI yesterday. They continue to choose Microsoft to power their workloads, and together, we remain committed to driving innovation that meets real-world needs. Our Q1 results were not impacted by the deal signed this week. Now, on to the quarter. We delivered a strong start to our fiscal year, exceeding expectations across revenue, operating income, and earnings per share. We also saw continued share gains across many of our businesses, demonstrating our leadership position in key markets. This quarter, revenue was $77.7 billion, up 18% and 17% in constant currency. Gross margin dollars increased 18% and 16% in constant currency, while operating income increased 24% and 22% in constant currency.\n\n**Amy Hood** (CFO)\nEarnings per share was $4.13, an increase of 23% and 21% in constant currency when adjusted for the impact of our investments in OpenAI. FX impact was roughly in line with guidance. Company gross margin percentage was 69%, down slightly year over year, driven by investments in AI, including the impact of scaling our AI infrastructure and the growing usage of our AI product features. This was partially offset by ongoing efficiency gains, particularly in Azure and M365 commercial cloud. Operating expenses increased 5% and 4% in constant currency, driven by investments in cloud and AI engineering, including compute capacity and AI talent to support product development across the portfolio. Operating margins increased year over year to 49% and were ahead of expectations with stronger than anticipated results in high-margin businesses this quarter.\n\n**Amy Hood** (CFO)\nWhen adjusted for the impact from our investments in OpenAI, other income and expense was $401 million, as interest income more than offset interest expense, which includes the interest payments related to data center finance leases. Capital expenditures were $34.9 billion, driven by growing demand for our cloud and AI offerings. This quarter, roughly half of our spend was on short-lived assets, primarily GPUs and CPUs, to support increasing Azure platform demand, growing first-party apps and AI solutions, accelerating R&D by our product teams, as well as continued replacement for end-of-life server and networking equipment. The remaining spend was for long-lived assets that will support monetization for the next 15 years and beyond, including $11.1 billion of finance leases that are primarily for large data center sites. Cash paid for PP&E was $19.4 billion.\n\n**Amy Hood** (CFO)\nAs a reminder, the difference between total CapEx and cash paid for PP&E is primarily due to finance leases, as well as the normal timing of goods received but not yet paid. Cash flow from operations was $45.1 billion, up 32%, driven by strong cloud billings and collections, partially offset by higher supplier payments. Free cash flow increased 33% to $25.7 billion, with minimal impact from a sequential increase in CapEx, given the higher mix of finance leases. Finally, we returned $10.7 billion to shareholders through dividends and share repurchases. Now to our commercial results. Commercial bookings increased 112% and 111% in constant currency and were significantly ahead of expectations, driven by Azure commitments from OpenAI, as well as continued growth in the number of $100 million plus contracts for both Azure and M365.\n\n**Amy Hood** (CFO)\nThese results do not include any impact from the incremental $250 billion Azure commitments from OpenAI announced yesterday. Commercial remaining performance obligation increased to $392 billion and was up 51% year over year. The balance has nearly doubled over the past two years. Even with this growth, our weighted average duration has been relatively stable at approximately two years. Microsoft Cloud revenue was $49.1 billion ahead of expectations and grew 26% and 25% in constant currency. Microsoft Cloud gross margin percentage was slightly better than expected at 68% and down year over year due to the investments in AI that were partially offset by ongoing efficiency gains, as noted earlier. Now to segment results. Revenue from Productivity and Business Processes was $33 billion and grew 17% and 14% in constant currency.\n\n**Amy Hood** (CFO)\nM365 commercial cloud revenue increased 17% and 15% in constant currency, with one point of benefit from end-period revenue recognition. Year over year growth was driven by both ARPU and seats, with ARPU growth again led by E5 and M365 Copilot. Paid M365 commercial seats grew 6% year over year, with installed base expansion across all customer segments, though primarily in our small and medium businesses and frontline worker offerings. M365 commercial products revenue increased 17% and 14% in constant currency ahead of expectations due to higher than expected Office 2024 transactional purchasing. M365 consumer cloud revenue increased 26% and 25% in constant currency, again driven by ARPU growth. M365 consumer subscriptions grew 7% to over 90 million. LinkedIn revenue increased 10% and 9% in constant currency, driven by marketing solutions. The talent solutions business was impacted by continued weakness in the hiring market.\n\n**Amy Hood** (CFO)\nDynamics 365 revenue increased 18% and 16% in constant currency, with continued growth across all workloads. Segment gross margin dollars increased 19% and 16% in constant currency, and gross margin percentage increased, driven by efficiency gains in M365 commercial cloud that were partially offset by investments in AI, including the impact of growing usage in M365 Copilot chat. Operating expenses increased 6% and 5% in constant currency, and operating income increased 24% and 20% in constant currency. Operating margins increased three points year over year to 62%, driven by the higher gross margin noted earlier, as well as improved operating leverage. Next, the Intelligent Cloud segment. Revenue was $30.9 billion and grew 28% and 27% in constant currency. In Azure and other cloud services, where we continue to see accelerating demand, revenue grew 40% and 39% in constant currency.\n\n**Amy Hood** (CFO)\nResults were ahead of expectations, driven by better than expected growth in our core infrastructure business, primarily from our largest customers. Azure AI services revenue was generally in line with expectations, and this quarter, demand again exceeded supply across workloads, even as we brought more capacity online. In our on-premise server business, revenue increased 1% and was relatively unchanged in constant currency. Results were ahead of expectations, driven by transactional purchasing of Windows Server 2025. Segment gross margin dollars increased 20% and 19% in constant currency, and gross margin percentage decreased year over year, driven by investments in AI that were partially offset by efficiency gains in Azure. Operating expenses increased 4% and operating income grew 27%. Operating margins were 43%, down only slightly year over year, as increased investments in AI were mostly offset by improved operating leverage. Now to More Personal Computing.\n\n**Amy Hood** (CFO)\nRevenue was $13.8 billion and grew 4%. Windows OEM and devices revenue increased 6% year over year, significantly ahead of expectations, driven by strong demand ahead of Windows 10 end of support, as well as a benefit from inventory levels that remain elevated. Search and news advertising revenue ex-TAC increased 16% and 15% in constant currency, driven by growth in volume, as well as a continued benefit from third-party partnerships that was better than expected. In gaming, revenue decreased 2% and 3% in constant currency. Against a strong prior year comparable, Xbox content and services revenue increased 1% and was relatively unchanged in constant currency, driven by better than expected performance from third-party content. Segment gross margin dollars increased 11% and 10% in constant currency, and gross margin percentage increased year over year, driven by sales mix shift to higher margin businesses.\n\n**Amy Hood** (CFO)\nOperating expenses increased 4% and 3% in constant currency, and operating income increased 18% and 16% in constant currency. Operating margins increased three points year over year to 30%, driven by the higher gross margin noted earlier. Now, moving to our Q2 outlook, which, unless specifically noted otherwise, is on a U.S. dollar basis. Based on current rates, we expect FX to increase total revenue growth by two points. Within the segments, we expect FX to increase revenue growth by two points in Productivity and Business Processes and Intelligent Cloud, and one point in More Personal Computing. We expect FX to increase COGS and operating expense growth by one point. Starting with the total company, we expect revenue of $79.5 to $80.6 billion U.S. dollars, or growth of 14% to 16%. We expect COGS of $26.35 to $26.55 billion U.S.\n\n**Amy Hood** (CFO)\ndollars, or growth of 21% to 22%, and operating expense of $17.3 to $17.4 billion U.S. dollars, or growth of 7% to 8%. Operating margins should be relatively flat year over year and down sequentially, aligned with historic seasonality. Now, other income and expense. The combination of OpenAI's conversion to a public benefit corp and the ongoing nature of our partnership will result in increased volatility. Therefore, going forward, we'll provide our outlook excluding any impact from our investments in OpenAI. On that basis, in Q2, other income and expense is estimated to be roughly $100 million, as interest income will more than offset interest expense. We expect our Q2 effective tax rate to be approximately 19%. Next, capital expenditures. With accelerating demand and a growing RPO balance, we're increasing our spend on GPUs and CPUs.\n\n**Amy Hood** (CFO)\nTherefore, total spend will increase sequentially, and we now expect the FY26 growth rate to be higher than FY25. As a reminder, there can be quarterly spend variability from cloud infrastructure buildouts and the timing of delivery of finance leases. Next, our commercial business. In commercial bookings, we expect healthy growth in the core business on a low expiry base, when adjusted for the OpenAI contracts in the prior year. We expect commercial bookings will be positively impacted by the significant OpenAI commitments announced yesterday. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 66%, down year over year, driven by the continued investments in AI, as well as the mix shift to Azure. Now to segment guidance.\n\n**Amy Hood** (CFO)\nIn Productivity and Business Processes, we expect revenue of $33.3 to $33.6 billion, or growth of 13% to 14%. In M365 commercial cloud, we expect revenue growth to be between 13% and 14% in constant currency, with business trends that remain relatively stable quarter over quarter. ARPU growth will again be driven by E5 and M365 Copilot. M365 commercial products revenue growth should be in the low to mid-single digits. As a reminder, M365 commercial products include components that can be variable due to the end-period revenue recognition dynamics. M365 consumer cloud revenue growth should be in the mid-20s, driven by growth in ARPU. For LinkedIn, we expect revenue growth of approximately 10%. In Dynamics 365, we expect revenue growth to be in the mid to high teens, with continued growth across all workloads.\n\n**Amy Hood** (CFO)\nFor Intelligent Cloud, we expect revenue of $32.25 to $32.55 billion, or growth of 26% to 27%. In Azure, we expect Q2 revenue growth of approximately 37% in constant currency, as demand remains significantly ahead of the capacity we have available. While we're accelerating the amount of capacity we're bringing online, we will continue to balance Azure revenue growth with the growing needs across our first-party apps and AI solutions, our own R&D efforts, and the end-of-life server replacements. Therefore, we now expect to be capacity-constrained through at least the end of our fiscal year. As a reminder, there can be quarterly variability in the year-over-year growth rates, depending on the timing of capacity delivery and when it comes online, as well as from end-period revenue recognition, depending on the mix of contracts.\n\n**Amy Hood** (CFO)\nIn our on-premises server business, we expect revenue to decline in the low to mid-single digits, with ongoing customers' shift to cloud offerings. In More Personal Computing, we expect revenue to be in the $13.95 to $14.45 billion. Windows OEM and Devices revenue should decline in the mid-single digits. We expect continued momentum from Windows 10 end of support, although growth rates will be impacted by elevated inventory levels at the end of Q1 that we expect to come down through the quarter. Therefore, Windows OEM revenue should decline in the low to mid-single digits. The range of potential outcomes remains wider than normal. Devices revenue should decline year over year. Search and news advertising ex-TAC revenue growth should be in the low double digits, down sequentially as growth rates normalize, following the benefit from third-party partnerships noted earlier.\n\n**Amy Hood** (CFO)\nGrowth will continue to be driven by volume and revenue per search across Edge and Bing. In Xbox content and services, we expect revenue to decline in the low to mid-single digits against a prior year comparable that benefited from strong first-party performance, partially offset by growth in subscriptions. Hardware revenue should decline year over year. In closing, demand signals across bookings, RPO, and product usage are accelerating faster than we expected. We're investing in infrastructure, AI talent, and product innovation to capture that momentum and expand our leadership position. We remain focused on delivering real value to our customers that results in durable revenue growth for the long term. With that, let's go to Q&A, Jonathan.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Amy. We'll now move over to Q&A. Out of respect for others on the call, we request that participants please only ask one question. Operator, can you please repeat your instructions?\n\n**Operator**\nLadies and gentlemen, if you would like to ask a question, please press star one on your telephone keypad, and a confirmation tone will indicate your line is in the question queue. You may press star two if you would like to remove your question from the queue. For participants using speaker equipment, it may be necessary to pick up your headset before pressing the star keys. Our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.\n\n**Keith Weiss** (Managing Director)\nExcellent. Thank you guys for taking the question, and congratulations on another outstanding quarter. If I'm looking at Microsoft, this is two quarters in a row. We're really seeing results that are well ahead of anybody's expectations. When we were thinking about this company a year ago or five years ago, 111% commercial bookings growth was not on anybody's bingo card, if you will. Yet the stock is underperforming the broader market. The question I have is kind of getting at the zeitgeist that I think is weighing on the stock, and it's something about to change. I think AGI is kind of a nomenclature or a shorthand for that. It's something that's still included in your OpenAI agreement.\n\n**Keith Weiss** (Managing Director)\nSatya, when we think about AGI or we think about how application and computing architectures are changing, is there anything that you see on the horizon, whether it's AGI or something else, that could potentially change what appears to be a really strong positioning for Microsoft in the marketplace today, or that strength will perhaps weaken on a go-forward basis? Is there anything that you're worrying about in that evolution, and particularly the evolution of these generative AI models?\n\n**Satya Nadella** (Chairman and CEO)\nNo, thank you, Keith, for the question. Here's how I would say that I think there are two parts. We feel very, very good about even this, I would say, the new agreement that we now have with OpenAI, because I think even it just creates more certainty to all of the IP relationship we have as it relates to even this definition of AGI. Beyond that, I think your question touches on something that's pretty important, which is how are these AI systems going to truly be deployed in the real world and make a real difference and make a return for both the customers who are deploying them and obviously the providers of these systems?\n\n**Satya Nadella** (Chairman and CEO)\nI think the best way to characterize the situation is that even as the intelligence capability increases, let's even say exponentially, like model version over model version, the problem is it's always going to still be jagged. I think the term people use is the jagged intelligence, even it or spiky intelligence. You may even have a capability that's fantastic at a particular task, but it may not uniformly grow. What is required is, in fact, these systems, whether it is GitHub Agent HQ or the Microsoft 365 Copilot system, don't think of this as a product. Think of it as a system that in some sense smooths out those jagged edges and really helps the capability. Just to give you a flavor for it, if I am in Microsoft 365 Copilot, I can generate an Excel spreadsheet.\n\n**Satya Nadella** (Chairman and CEO)\nThe good news is now an Excel spreadsheet does understand Office JS, has the formulas in it. It feels like, wow, it is a great spreadsheet created by a good modeler. The more interesting thing is I can go into agent mode in Excel and iterate on that model, and yet it'll stay on rails. It won't go off rails. It'll be able to do the iteration. Then I can even give it to the analyst agent, and then it'll even make sense of it like a data analyst would of an Excel model. The reason I say all of that is because that's the type of construction that'll be needed, even when the model is magical, all-powerful. I think we will be in this jagged intelligence phase for a long time.\n\n**Satya Nadella** (Chairman and CEO)\nOne of the fundamental things that these, whether it's GitHub, whether it's security, whether it's Microsoft 365, the three main domains we're in, we feel very, very good about building these as organizing layers for agents to help customers. By the way, that's the same thing that we're going to put into Foundry for our third-party customers. That's kind of how people will build these multi-agent systems. I feel actually pretty good about both the progress in AI. I don't think AGI, as defined at least by us in our contract, is ever going to be achieved anytime soon. I do believe we can drive a lot of value for customers with advances in AI models by building these systems. It's kind of the real question that needs to be well understood. I feel very, very confident about our ability to make progress.\n\n**Keith Weiss** (Managing Director)\nExcellent. That's super helpful.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Keith. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Brent Thill with Jefferies. Please proceed.\n\n**Brent Thill** (Managing Director and Tech Sector Leader)\nThanks. Amy, on the bookings blowout, I guess many are somewhat concerned about concentration risk. I think you noted a number of $100 million contracts. Not to go into a lot of detail, can you just give us a sense of what you're seeing on that 51% RPO and 110%+ bookings growth that gives you confidence about what you're seeing in terms of the breadth and extent of some of these deals on a global basis? Thanks.\n\n**Amy Hood** (CFO)\nThanks, Brett. A couple of things to maybe take a step back on RPO. With a nearly $400 billion balance, we've been trying to help people understand sort of how to think about really the breadth of that. It covers numerous products. It covers customers of all sizes. That's been a balance that we've been growing, obviously, at a good clip. What people need to realize is it sits across multiple products because of the things Satya is talking about around creating systems and where we're investing. If you're going to have that type of balance, and then more importantly, have the weighted average duration be two years, it means that most of that is being consumed in relatively short order. People are not consuming, and I say this broadly, unless there's value.\n\n**Amy Hood** (CFO)\nI think this is why we keep coming back to are we creating real-world value in our AI platforms, in our AI solutions and apps and systems. I think the way to think about RPO is it's been building across a number of customers. We're thrilled to have OpenAI be a piece of that. We're learning a ton and building leading systems because of it that are being used at scale that benefits every other customer. It's why we've tried to give a little bit more color to that RPO balance, because I do understand that there have been a lot of concerns or questions about is it long-dated? Is it coming over a long period of time? Hopefully, this is helpful for people to realize that these are contracts being signed by customers who intend to use it in relatively short order.\n\n**Amy Hood** (CFO)\nAt that type of scale, I think that's a pretty remarkable execution.\n\n**Brent Thill** (Managing Director and Tech Sector Leader)\nThank you.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Brett. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.\n\n**Mark Moerdler** (SVP, Managing Director, and Senior Global Software Research Analyst)\nThank you very much for taking my question, and congratulations on the quarter. It's pretty amazing what you guys are doing. Satya and Amy, I'd like to ask you the number one question I receive, whether from investors or at AI conferences I attend. How much confidence do you have that the software and even the consumer internet business can monetize all the investments we're seeing globally, or frankly, are we in a bubble? In fact, Amy, what would be the factors you'd be watching for to assure that you're not overbuilding for current demand and that demand will sustain? Thank you.\n\n**Amy Hood** (CFO)\nMaybe I'll start, Satya, and then you could add. Let me talk a little bit about maybe connecting a couple of the dots, because with $400 billion of RPO that's sort of short-dated, as we talked about, our needs to continue to build out the infrastructure are very high. That's for booked business today. That is not any new booked business we started trying to accomplish on October 1, right? The way to think about that, and you saw it this quarter in particular, and as we talked about 2026, the remainder. Number one, we're pivoting toward increasingly, we talked about this, short-lived assets, both GPUs and CPUs. Again, we talk about all these workloads are burning both in terms of app building. Now, when that happens, short-lived assets generally are done to match sort of the duration of the contracts or the duration of your expectation of those contracts.\n\n**Amy Hood** (CFO)\nI sometimes think when people think about risk, they're not realizing that most of the lifetimes of these and the lifetimes of the contracts are very similar. When you think about having revenue and the bookings and coming on the balance sheet and the depreciation of short-lived assets, they're actually quite matched, Mark. As you know, we have spent the past few years not actually being short GPUs and CPUs per se. We were short the space or the power, is the language we use to put them in. We spent a lot of time building out that infrastructure. Now we're continuing to do that, also using leases. Those are very long-lived assets, as we've talked about, 15 to 20 years. Over that period of time, do I have confidence that we'll need to use all of that? It is very high.\n\n**Amy Hood** (CFO)\nWhen I think about sort of balancing those things, seeing the pivot to GPU, CPU short-lived, seeing the pivot in terms of how those are being utilized, we are, and I said this now, we've been short now for many quarters. I thought we were going to catch up. We are not. Demand is increasing. It is not increasing in just one place. It is increasing across many places. We're seeing usage increases in products. We are seeing new products launch that are getting increasing usage, and increasing usage very quickly. When people see real value, they actually commit real usage. I sometimes think this is where this cycle needs to be thought through completely, is that when you see these kind of demand signals and we know we're behind, we do need to spend.\n\n**Amy Hood** (CFO)\nWe're spending with a different amount of confidence in usage patterns and in bookings, and I feel very good about that. I have said we are now likely to be short capacity to serve the most important things we need to do, which is Azure, our first-party applications. We need to invest in product R&D, and we're doing end-of-life replacements in the fleet. We're going to spend to make sure that happens. It's about modernization, high quality, service delivery, and meeting demand. I feel good about doing that, and I feel good that we've been able to do it so efficiently and with a growing book of business behind it.\n\n**Satya Nadella** (Chairman and CEO)\nYeah, the only thing I would add to what Amy captured was if you sort of look out, there are two things that matter, I think, and that are critical in terms of how we think about our allocation of capital, also our R&D. One is how efficient is our planet-scale token factory? I mean, that's at the end of the day what you have to do. In order to do that, you have to start with building out a very fungible, global fleet. It's not like we're building one data center in one region in the world that's mega scale. We are building it out across the globe for inference, for pre-training, for post-training, for RL, for data synth, what have you. Therefore, the fungibility is super important. The second thing that we're also doing is continually modernizing the fleet.\n\n**Satya Nadella** (Chairman and CEO)\nIt's not like we buy one version of, say, NVIDIA and load up for all the gigawatts we have. Each year you buy, you ride the Moore's Law, you continuously modernize and depreciate it. That means you also use software to grow efficiency. I talked about, I think, 30% improvement on both serving up GPT-4.1 and 5.0. That's software. By the way, it's helpful on A100s. It's helpful on GB200s, and it'll be helpful on GB300s. That's the beauty of having the efficiency of the fleet. Keep improving utilization, keep improving the efficiency. That's what you do in the token factory. The other aspect, which Amy spoke to, is we have some of the best agent systems that matter in the high-value domains. It's in information work. That's the Copilot system. Coding.\n\n**Satya Nadella** (Chairman and CEO)\nI mean, I should also say one of the things I like about Copilot is, I mean, Copilot ARPUs compared to M365 ARPUs. It's expansive. The same thing that happened between server and cloud, like we used to always say, is it zero sum? It turned out that the cloud was so much more expansive to the server market. The same thing is happening in AI, because first, you could say, hey, our ARPUs are too low when it comes to M365, or you could say we have the opportunity with AI to be much more expansive. Same thing with tools. I mean, tools business was not like a leading business, whereas coding business is going to be one of the most expansive AI systems. We feel very good about being in that category. Same thing with security. Same thing with health.\n\n**Satya Nadella** (Chairman and CEO)\nIn consumer, one of the things is it's not just about ads. It's ads plus subscriptions. That also opens up opportunity for us. When I look at the entirety of these high-value agent systems and when we look at the efficiency and fungibility of our fleet, that's what gives us the confidence to invest both the capital and the R&D talent to go after this opportunity.\n\n**Mark Moerdler** (SVP, Managing Director, and Senior Global Software Research Analyst)\nThat was pretty amazing. I really appreciate all the detail.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Mark. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Karl Keirstead with UBS. Please proceed.\n\n**Karl Keirstead** (Managing Director of Software Equity Research)\nOK, yeah, thank you. This one is for Amy. Amy, I certainly don't want to take you down too complex an accounting path with this question, but the investment in OpenAI that sits in other income at $4.1 billion is so large that I think the audience listening in could benefit from a little bit more color about what that is. It feels like it's so much larger than you were running through other income in prior quarters that it mustn't just be your share of the OpenAI losses. Could you just describe that and what we can expect in subsequent quarters and whether this signals any kind of accounting change? Thanks so much.\n\n**Amy Hood** (CFO)\nThe Q1 number was not impacted at all by the new agreement that was put in place. Let me first say that. Secondly, that increased loss was all due to our percentage of losses in OpenAI's debt equity method. Just to be very clear, there is not anything there that is not the increased losses from OpenAI.\n\n**Karl Keirstead** (Managing Director of Software Equity Research)\nOK, understood. Thank you.\n\n**Amy Hood** (CFO)\nThanks, Karl.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Karl. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Mark Murphy with JP Morgan. Please proceed.\n\n**Mark Murphy** (Executive Director)\nThank you so much. We seem to be entering into a new era where the contractual commitments from a small number of AI natives are just incredibly large, not only in absolute terms, but sometimes relative to the size of the companies themselves. For instance, contracts worth hundreds of billions of dollars that are 20 times their current revenue scale. Philosophically, how do you evaluate the ability of those companies to follow through on these commitments? How do you think about placing guardrails on customer concentration for any single entity?\n\n**Satya Nadella** (Chairman and CEO)\nYeah, maybe I'll start, and then Amy, you can add. It goes back a little bit, Mark, to what I said about building first the asset itself such that it's most fungible. Then to recognize the strength of even sort of our portfolio. We have a third-party business. We have a first-party business. We have third-party also spread between enterprise, digital natives. I always felt that we need a balance there, because it may start with digital natives. They're always going to be the early adopters. You always have the hit app of the generation. Then essentially, it spreads throughout. The enterprise adoption cycle is just starting. Therefore, having over the arc of time, I think that third-party balance of customers will only increase.\n\n**Satya Nadella** (Chairman and CEO)\nIt's great to have the hit first-party apps in the beginning, because you can build scale that then if it's fungible, and that's where the key is. You don't want to build for a digital native as if you're just doing hosting for them. You want to build. That's where I think some of the decision-making of ours is probably getting better understood. What do we say yes to? What do we say no to? I think there was a lot of confusion. Hopefully, by now, anyone who switched on would figure this out. That's, I think, one thing we're doing on the third party. The first party is probably where a lot of our leverage comes. It's not even about one hit app on our first party even.\n\n**Satya Nadella** (Chairman and CEO)\nOur portfolio of stuff, which I just walked through in the earlier answer, gives us again the confidence that between that mix, we will be able to use our fleet to the maximum. Remember, these assets, especially the data centers and so on, are long assets. There will be many refresh cycles for any one of these when it comes to the gear. I feel that once you think about all those dimensions, the concentration risk gets mitigated by being thoughtful about how you really ensure the build is for the broad customer base.\n\n**Amy Hood** (CFO)\nMaybe just to help with another angle of that, because I think Satya's helped a lot, when you think about concentration risk or delivering to any customer, you have to remember that because we're talking about this very large flexible fleet that can be used for anyone and for any purpose, 1P, 3P, and including our commercial cloud, by the way, which I should be quite clear on, it is pretty flexible in every regard. You have to remember that the CPU and GPU and the storage gear doesn't come into play until the contracts start happening. You're right, some of these large contracts have delivery dates over time, so you get a lot of lead time in being able to say, oh, what's the status? I think we're pretty thoughtful around what's always gone in our RPO balance and been considerate of that.\n\n**Amy Hood** (CFO)\nThere's always been that taken into account when we publish that bookings number and publish the RPO balance.\n\n**Mark Murphy** (Executive Director)\nThank you very much.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Mark. Operator, next question, please.\n\n**Operator**\nThe next question comes from the line of Brad Zelnick with Deutsche Bank. Please proceed.\n\n**Brad Zelnick** (Managing Director of Software Equity Research)\nGreat. Thanks so much for taking the question. I'll echo my congrats on an amazing start to the year. Amy, is there any way to quantify or frame the revenue impact of Azure being short on capacity? I appreciate the constraints you face are broad across the industry. Is there risk of workloads going elsewhere? How do you mitigate that?\n\n**Amy Hood** (CFO)\nYeah, Brad, it's a great question. It's always hard to quantify precisely what would have been the revenue impact in quarter. I would offer a way to think about it is Azure probably does bear most of the revenue impact, because when you think about real priorities that you have to fill first, it's obviously the increasing usage and adoption and sales we've seen of Microsoft 365 Copilot and the usage of Copilot Chat, which we've seen very different patterns, which we're encouraged by. It's the adoption of security features. It's the GitHub momentum. When you're thinking about it, that is where, and it is a priority for us to allocate resourcing there first. You're all right to ask, how do I think about that?\n\n**Amy Hood** (CFO)\nWe've worked very hard to try to mitigate it as best we can, but we have been short in Azure, and we've been clear on it. I would say the other two priorities that I haven't mentioned maybe as much before is also just making sure our product teams and the AI talent that we've been able to hire into the company really over the past year and a half have access also to significant capacity, because we're seeing it make the product better in a loop that is adding great benefit today into products people are using today for real-world work. We are making that a priority to make sure our research teams have that, as well as our product engineering teams. Yes, it does impact Azure directly. That is the place where you see that prioritization.\n\n**Amy Hood** (CFO)\nI think it's probably hard for me to give an exact number, but it is safe to say that the number could be higher.\n\n**Brad Zelnick** (Managing Director of Software Equity Research)\nGreat. Thank you.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Brad. Operator, we have time for one last question.\n\n**Operator**\nThe last question will come from the line of Kash Rangan with Goldman Sachs. Please proceed.\n\n**Kash Rangan** (Managing Director)\nThank you very much. Amy, I just wanted to congratulate you. I think you said before that it is possible to accelerate Azure growth while getting efficient margins, and you've done it. Congrats on that. I have one for you, Satya. With respect to the elephant in the room, following just being a little more direct, following up on Keith Weiss's question, there's talk that another hyperscaler came in and took away the business that was rightfully Microsoft. I'm sure that there is a different point of view here. I'm wondering if you could offer some perspective on your criteria. Is it about a certain volume of business that you wish to execute on the Microsoft paper? Or is it something broader than that?\n\n**Kash Rangan** (Managing Director)\nI don't think maybe people fully appreciate the terminal value that Microsoft will have on its balance sheet at the end of these contracts, which I think is probably being underestimated as you have a full stack and you've got the multiple vectors to monetize the databases, Foundry. To your point that you are a platform company, not just a hyperscaler, maybe that's what it is all about. Or maybe there's another story about you letting the other hyperscaler company come in from nowhere and claiming a big piece of that four to five-year puzzle. Thank you so much once again. Really appreciate it. Congratulations.\n\n**Satya Nadella** (Chairman and CEO)\nThank you, Kash. For us, again, it just always goes back to, I think, the core principle, which is build a fleet that is fungible across the planet and works for third-party and first-party and research. That's essentially what we have done.\n\n**Satya Nadella** (Chairman and CEO)\nWhen some demand comes in shapes that don't fit that goal, where it's too concentrated, not just by customer, by location, by type of skewing, I think Amy mentioned some very key things. When you think about the margin profile of a hyperscaler, you've got to remember there's the AI accelerator piece, but there's compute, there's storage. If all of the demand just comes for just one meter, that's really not a long-term business we want to be in. That's even from a third party. We have to balance it with all of our first-party stuff, because that's after all a different margin stack for us. We have to fund our own R&D and model capability, because in the long run, that's what's going to differentiate us. I look at all of those.\n\n**Satya Nadella** (Chairman and CEO)\nWe sort of use all of that to make sure we are saying yes to all the demand that we want. We say no to some of the demand that may be something that we could serve, but it's not in our long-term interest. That's sort of the decision-making we've done. We feel very, very good about the decisions. In some sense, I feel even each time we say no to, the day after I feel better.\n\n**Amy Hood** (CFO)\nCash, maybe just.\n\n**Satya Nadella** (Chairman and CEO)\nYeah.\n\n**Amy Hood** (CFO)\nCash, I think this is our last call with you. I just want to say thanks and congratulations. It's been a privilege to work with you, and best of luck.\n\n**Satya Nadella** (Chairman and CEO)\nLet me add to that. Best of luck, Kash.\n\n**Kash Rangan** (Managing Director)\nThanks. Thank you so much. Very kind of you.\n\n**Jonathan Neilson** (VP of Investor Relations)\nThanks, Cash. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with all of you soon.\n\n**Satya Nadella** (Chairman and CEO)\nThank you all.\n\n**Operator**\nThank you. This concludes today's conference. You may disconnect your lines at this time. Thank you for your participation.",
        "fetched_at": "2026-02-04T16:09:23.727Z"
      },
      {
        "ticker": "MSFT",
        "title": "Yahoo Finance",
        "published_date": "Jul 30, 2025, 5:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/MSFT/earnings/MSFT-Q4-2025-earnings_call-335356.html",
        "content": "**Operator**\nGreetings, and welcome to the Microsoft Fiscal Year twenty twenty five Fourth Quarter Earnings Conference Call. At this time, all participants are in a listen only mode. A question and answer session will follow the formal presentation. As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Nielsen, Vice President of Investor Relations.\n\n**Jonathan Neilson** (VP - IR)\nGood afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer Amy Hood, Chief Financial Officer Alex Jolla, Chief Accounting Officer and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides a reconciliation of differences between GAAP and non GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non GAAP items.\n\n**Jonathan Neilson** (VP - IR)\nThe non GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company's fourth quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying businesses performed excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only.\n\n**Jonathan Neilson** (VP - IR)\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward looking statements, which are predictions, projections or other statements about future events.\n\n**Jonathan Neilson** (VP - IR)\nThese statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call and in the Risk Factors section of our Form 10 ks, Forms 10 Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward looking statement. And with that, I'll turn the call over to Satya.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThank you, Jonathan. It was a very strong close to what was a record fiscal year for us. All up Microsoft Cloud surpassed $168,000,000,000 in annual revenue, up 23%. The rate of innovation and the speed of diffusion is unlike anything we have seen. To that end, we are building the most comprehensive suite of AI products and tech stack at massive scale.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd to provide more context, I want to walk up the stack starting with Azure. Azure surpassed $75,000,000,000 in annual revenue, up 34% driven by growth across all workloads. We continue to lead the infrastructure wave and took share every quarter this year. We opened new DCs across six continents and now have over 400 data centers across 70 regions more than any other cloud provider. There is a lot of talk in the industry about building the first gigawatt and multi gigawatt data centers.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWe stood up more than two gigawatts of new capacity over the past twelve months alone and we continue to scale our capacity faster than any other competitor. Every Azure region is now AI first. All of our regions can now support liquid cooling, increasing the fungibility and the flexibility of our fleet. And we are driving and riding a set of compounding S curves across silicon systems and models to continuously improve efficiency and performance for our customers. Take for example, GBD4O family of models, which have the highest volume of inference tokens.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThrough software optimizations alone, we are delivering 90% more tokens for the same GPU compared to a year ago. Beyond the AI fleet, we continue to build our commercial cloud to address customers' unique data residency and sovereignty requirements. This quarter, we introduced the Microsoft Sovereign Cloud, the industry's most comprehensive solution spanning both public and private cloud deployments. All of this innovation is driving our strong results. We saw accelerating growth from migrations again this quarter.\n\n**Satya Nadella** (Chairman &amp; CEO)\nNestle, for example, migrated more than 200 SAP instances, 10,000 plus servers, 1.2 petabytes of data to Azure with near zero business disruption. That makes it one of the largest and most successful migrations in business history. The next big accelerator in the cloud will be quantum and I'm excited about our progress. In fact, earlier this month, we announced the world's first operational deployment of Level two quantum computer in partnership with Atom Computing. This is how we will continue to think and make investments with decade long arcs while making progress every quarter.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThe next layer is data, which is foundational to every AI application. Microsoft Fabric is becoming the complete data and analytics platform for the AI era, spanning everything from SQL to NoSQL to analytics workloads. It continues to gain momentum with revenue up 55% year over year and over 25,000 customers. It's the fastest growing database product in our history. FabricOnely expands all databases and clouds including semantic models from Power BI and therefore it is the best source of knowledge and grounding for AI applications and context engineering.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAzure Databricks and Snowflake on Azure both accelerated as well. Cosmos DB and Azure PostgreSQL are both powering mission critical workloads at scale. OpenAI for example uses Cosmos DB in the hot path of every chat GPT interactions storing chat history, user profiles and conversational state and Azure PostgreSQL stores metadata critical to the operation of ChatGPT as well as OpenAI's developer APIs. This year, we launched Azure AI Foundry to help customers design, customize and manage AI applications and agents at scale. Foundry features best in class tooling, management, observability and built in controls for trustworthy AI.\n\n**Satya Nadella** (Chairman &amp; CEO)\nCustomers increasingly want to use multiple AI models to meet their specific performance, cost and use case requirements. And with Foundry, they can provision inferencing throughput ones and apply it across more models than any other hyperscaler, including models from OpenAI, DeepSeek, Meta, xAI's Grok and very soon Black Forest Labs and Mistral AI. We sim shipped 15 models from OpenAI alone on Foundry this year, providing same day access to state of the art models deeply integrated with our infrastructure and tools. And we are seeing accelerated adoption of our new Foundry agent service, which is now being used by 14,000 customers to build agents that automate complex tasks. For example, NASDAQ is using Foundry to build agents that help customers prepare for board meetings, cutting prep time by up to 25%.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAll up 80% of Fortune five hundred already use Foundry. And when we look narrowly at just the number of tokens served by Foundry APIs, we processed over 500,000,000,000,000 this year, up over 7x. This is a good indicator of true platform diffusion beyond a few head apps and services. Talking about the app layer, these applications are becoming embedded in our daily work and life. Our family of Copilot apps has surpassed 100,000,000 monthly active users across commercial and consumer.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd when you take a broader look at the engagement of AI features across our products, we have over 800,000,000 monthly active users. Microsoft three sixty five Copilot is becoming the new way to organize work and workflow and work artifacts. We rolled out our biggest update to three sixty five Copilot to date this quarter, bringing together chat, search, create notebooks as well as agents into one intuitive scaffolding. With this innovation and continued product improvements, we are seeing real momentum. Customers continue to adopt Copilot at a faster rate than any other new Microsoft three sixty five suite with strong usage intensity as shown by our week over week retention.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd we saw the largest quarter of seat adds since launch with a record number of customers returning to buy more seats. Barclays, for example, will roll out Microsoft three sixty five Copilot to 100,000 employees globally following a successful initial deployment of 15,000. UBS is expanding its deployment to all of its employees after initially rolling it out to 55,000 of them. And Adobe, KPMG, Pfizer, Wells Fargo, purchased over 25,000 seats this quarter. Tens of thousands of organizations have already used our researcher and analyst deep reasoning agents in the first weeks of availability and we have introduced group level agents in teams like facilitator and interpreter, which generate real time translation and notes in meetings.\n\n**Satya Nadella** (Chairman &amp; CEO)\nHundreds of partners like Adobe, SAP, ServiceNow and Workday have built their own third party agents that integrate with Copilot and Teams. We are also seeing more customers use Copilot Studio to extend Microsoft three sixty five Copilot and build their own agents. This year customers created 3,000,000 agents using SharePoint and Copilot Studio. And with Copilot tuning, they can easily create agents fine tuned on their company's data, workflow and style that reflect their unique tone, language and expertise. We're also seeing great traction among specific roles and functions starting with developers.\n\n**Satya Nadella** (Chairman &amp; CEO)\nGitHub Copilot continues to have great momentum in IDE with agent mode and new form factors like coding agent, which is capable of asynchronously executing developer tasks. We have 20,000,000 GitHub Copilot users. GitHub Copilot enterprise customers increased 75% quarter over quarter as companies tailor Copilot to their own code basis and 90% of the Fortune 100 now use GitHub Copilot. More broadly, GitHub usage and repos are seeing explosive growth because of AI. AI projects on GitHub more than doubled over the last year.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThe surge in wide coding projects and AI coding agents, whether it is Cloud Code, Codex, Cursor or GitHub Copilot are generating more pull requests and more repos on GitHub. And our code review agent is being used heavily across the platform performing millions of code reviews each month. In healthcare, we had a breakout year for Dragon Co Pilot. Customers used our ambient AI solutions to document over 13,000,000 physician patient encounters this quarter, up nearly 7x year over year. For example, at Mercy Health System, more than 1,000 physicians are already using Copilot to reduce administrative burden so that they can focus on providing better care.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThey have saved more than one hundred thousand hours to date and plan to expand to all 5,000 providers. As one physician put it, the best thing to happen to my practice in ten years. And in security, we were the first in the industry to introduce agents to help defenders autonomously handle high volume security and IT tasks. More broadly, AI is driving a fundamental change in the BizApps market as customers shift from legacy systems to agentic business applications. Dynamics three sixty five took share this year and we are winning customers in every industry like Verizon with sales, Domino's Pizza Group with ERP, one-eight 100 Flowers with contact center.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWhen it comes to consumer apps, we are innovating across all surfaces. In fact, on Monday, we introduced Copilot mode in Edge. It's especially exciting to see the innovation coming back to browsers. Copilot mode brings together Copilot Composer, Chat, Discover, Search and Actions to build the next generation of browser for the AI age. Our Copilot consumer app also continued to see strong growth in engagement and successful sessions and we are bringing Copilot to every Windows 11 PC.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWith Copilot Vision, you can share your screen with Copilot and get real time insights and assistance on anything. And we are well positioned as we approach Windows 10 end of support in October, thanks to Windows 11 and Copilot plus PCs, which offer customers compelling security as well as AI value. Talking about security, it underlies our cloud and AI infrastructure as well as our Copilots and agents. We have launched over 100 new capabilities over the past year. Just last week, we added a modern data lake to our SIEM, Microsoft Sentinel, bringing together customer data across our first party tools as well as third party ecosystem over three fifty connectors.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWe're also extending the systems customers already use for governance, identity, security and management to protect every AI agent. Entra now extends identity permissions policies and access controls to agents. Defender secures nearly 2,000,000 general AI apps. Purview is used by three quarters of the Microsoft three sixty five Copilot customers to protect their data. And all up, we now have nearly 1,500,000 security customers and continue to take share across all major categories we serve.\n\n**Satya Nadella** (Chairman &amp; CEO)\nBefore I wrap, I want to talk about two consumer businesses of ours with massive end user reach, LinkedIn and Xbox. LinkedIn is home to 1,200,000,000 members with four consecutive years of double digit member growth. All up comments on LinkedIn rose over 30% and video uploads increased over 20% this year. We continue to bring AI to every part of LinkedIn experience introducing agents across hiring as well as sales. When it comes to gaming, we have 500,000,000 monthly active users across platforms and devices.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWe are now the top publisher on both Xbox and PlayStation this quarter with successful launches of Forza Horizon five and Oblivion Remastered. The Call of Duty franchise has never been stronger. 50,000,000 people have played Black Ops six, Total hours surpassed 2,000,000,000. Minecraft saw record monthly active usage and revenue this quarter, thanks in large part to the success of the Minecraft movie. And we have nearly 40 games in development, so much, much more to come.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWe surpassed over 500,000,000 of gameplay stream via the cloud this year and Game Pass annual revenue was nearly $5,000,000,000 for the first time. In closing, we are going through a generational tech shift with AI and I have never been more confident in Microsoft's opportunity to drive long term growth and define what the future looks like. With that, let me turn it over to Amy to walk through our financial results as well as the outlook.\n\n**Amy Hood** (EVP &amp; CFO)\nThank you, Satya, and good afternoon, everyone. This year, we delivered over $281,000,000,000 in revenue, up 15% year over year, which reflects the broad strength of our products and services. Operating income was over $128,000,000,000 up 17% year over year as we invested against the expansive opportunity ahead. And in our largest quarter of the year, we significantly exceeded expectations with strong execution by our sales and partner teams. As Satya shared, we're innovating faster than ever to deliver new value to our customers.\n\n**Amy Hood** (EVP &amp; CFO)\nThis quarter revenue was $76,400,000,000 up 1817% in constant currency. Gross margin dollars increased 1615% in constant currency, while operating income increased 2322% in constant currency. And earnings per share was $3.65 an increase of twenty four percent and twenty two percent in constant currency. For the first time commercial bookings were over $100,000,000,000 increasing 3730% in constant currency on a strong prior year comparable. Strong execution across our core annuity sales motions, including healthy renewals as well as an increase in the number of 10,000,000 and $100,000,000 plus contracts for both Azure and Microsoft three sixty five helped drive these results.\n\n**Amy Hood** (EVP &amp; CFO)\nCommercial remaining performance obligation increased to $368,000,000,000 up 3735% in constant currency. Roughly 35% will be recognized in revenue in the next twelve months, up 21% year over year. The remaining portion recognized beyond the next twelve months increased 49%. And this quarter our annuity mix was again 98%. FX was roughly in line with expectations on total company revenue, segment level revenue, COGS and operating expense growth.\n\n**Amy Hood** (EVP &amp; CFO)\nMicrosoft Cloud revenue was $46,700,000,000 ahead of expectations and grew 2725% in constant currency. Microsoft Cloud gross margin percentage was slightly better than expected at 68% down two points year over year from the impact of scaling our AI infrastructure partially offset by continued efficiency gains in Azure and M365 Commercial Cloud. Company gross margin percentage was 69%, down one point year over year driven by sales mix shift to Azure and the lower Microsoft Cloud gross margin noted earlier. Operating expenses increased 65% in constant currency and operating margins increased two points year over year to 45%. Better than expected revenue growth coupled with a focus on operating efficiently drove the margin expansion.\n\n**Amy Hood** (EVP &amp; CFO)\nAt a total company level, headcount at the June was relatively unchanged year over year. Now to our segment results. Revenue from Productivity and Business Processes was $33,100,000,000 and grew 1614% in constant currency better than expected driven by M365 Commercial Products and Cloud Services and M365 Consumer Products and Cloud Services. M365 Commercial Cloud revenue was ahead of expectations and increased 1816% in constant currency with two points of benefit from in period revenue recognition. Business trends remained relatively stable to the prior quarter when excluding the in period revenue recognition with ARPU growth again driven by E5 and M365 Co Pilot.\n\n**Amy Hood** (EVP &amp; CFO)\nPaid M365 commercial seats grew 6% year over year with installed base expansion across all customer segments though primarily in our small and medium business and frontline worker offerings. M365 Commercial Products revenue increased 97% in constant currency ahead of expectations due to higher than expected Office 2024 transactional purchasing. M365 consumer cloud revenue was better than expected increasing 20% driven by ARPU growth following the January price increase and subscriber growth of 8%. LinkedIn revenue increased nine percent and eight percent in constant currency with growth across all businesses. The Talent Solutions continues to be impacted by weakness in the hiring market.\n\n**Amy Hood** (EVP &amp; CFO)\nDynamics three sixty five revenue increased 2321% in constant currency with strong execution in our core annuity sales motions leading to growth across all workloads. Segment gross margin dollars increased 1615% in constant currency and gross margin percentage increased slightly driven by the efficiency gains noted earlier even as we deliver more AI features across our products and scale our AI infrastructure. Operating expenses increased 76% in constant currency and operating income increased 2119% in constant currency. Next, the Intelligent Cloud segment. Revenue was $29,900,000,000 and grew 2625% in constant currency ahead of expectations driven by Azure and our on premises server business.\n\n**Amy Hood** (EVP &amp; CFO)\nIn Azure and other cloud services revenue grew 39% significantly ahead of expectations driven by accelerated growth in our core infrastructure business primarily from our largest customers. As a reminder, new cloud and AI workloads are built and scaled using the breadth of our services. Revenue from Azure AI services was generally in line with expectations. And while we brought additional data center capacity online this quarter demand remains higher than supply. In our on premises server business revenue decreased 23% in constant currency ahead of expectations primarily driven by transactional purchasing which also has higher end period revenue recognition.\n\n**Amy Hood** (EVP &amp; CFO)\nEnterprise and Partner Services revenue increased 76% in constant currency with growth in Enterprise Support Services partially offset by a decline in Industry Solutions. Segment gross margin dollars increased 1716% in constant currency and gross margin percentage decreased four points year over year driven by scaling our AI infrastructure, partially offset by Azure efficiency gains noted earlier. Operating expenses increased 64% in constant currency and operating income grew 23%. Now to more personal computing. Revenue was $13,500,000,000 and grew 9% exceeding expectations primarily due to Windows OEM as well as Xbox content and services.\n\n**Amy Hood** (EVP &amp; CFO)\nWindows OEM and devices revenue increased 3% year over year ahead of expectations as inventory levels remained elevated. Search and news advertising revenue ex TAC increased 2120% in constant currency driven by continued growth in both volume and revenue per search as well as roughly eight points of favorable impact from third party partnerships including the benefit of a low prior year comparable. And in gaming, revenue increased 10%. Xbox content and services revenue increased 1312% in constant currency driven by better than expected performance from first party content and Xbox Game Pass. Segment gross margin dollars increased 15%.\n\n**Amy Hood** (EVP &amp; CFO)\nGross margin percentage increased three points year over year with improvement across all businesses. Operating expenses increased 43% in constant currency. Operating income increased 3433% in constant currency driven by continued prioritization of higher margin opportunities. Now back to total company results. Capital expenditures were $24,200,000,000 including $6,500,000,000 of finance leases, where we recognized the full value at the time of lease commencement.\n\n**Amy Hood** (EVP &amp; CFO)\nCash paid for PP and E was $17,100,000,000 The difference is primarily due to finance leases. More than half our spend was on long lived assets that will support monetization over the next fifteen years and beyond. The remaining spend was primarily for servers both CPUs and GPUs and driven by strong demand signals. Cash flow from operations was $42,600,000,000 up 15% driven by strong cloud billings and collections partially offset by higher supplier payments. And this quarter free cash flow was $25,600,000,000 Other income and expense was negative $1,700,000,000 primarily due to losses on investments accounted for under the equity method.\n\n**Amy Hood** (EVP &amp; CFO)\nOur effective tax rate was approximately 17%. And finally, we returned $9,400,000,000 to shareholders through dividends and share repurchases bringing our total cash return to shareholders to over $37,000,000,000 for the full fiscal year. Now moving to our outlook. My commentary for both the full year and next quarter is on a U. S.\n\n**Amy Hood** (EVP &amp; CFO)\nDollar basis unless specifically noted otherwise. Let me start with some full year commentary for FY 2026. First, FX. Assuming current rates remain stable, we expect FX to increase full year revenue growth and COGS growth by approximately two points and to increase operating expense growth by one point. Next, building on the strong momentum we saw this past year, we expect to deliver another year of double digit revenue and operating income growth in FY 2026.\n\n**Amy Hood** (EVP &amp; CFO)\nWe will continue to invest against the expansive opportunity ahead across both capital expenditures and operating expenses given our leadership position in commercial cloud, strong demand signals for our cloud and AI offerings and significant contracted backlog. Capital expenditure growth as we shared last quarter will moderate compared to FY 2025 with a greater mix of short lived assets. Due to the timing of delivery of additional capacity in H1 including large finance lease sites, we expect growth rates in H1 will be higher than in H2. We remain focused on delivering revenue growth and increasing our operational agility. And as a result, we expect operating margins to be relatively unchanged year over year.\n\n**Amy Hood** (EVP &amp; CFO)\nAnd finally, we expect our FY 2026 effective tax rate to be between 1920%. Now to our outlook for the first quarter. Based on current rates, we expect FX to increase total revenue growth by two points. Within the segments, we expect FX to increase revenue growth by roughly three points in Productivity and Business Processes and roughly one point in Intelligent Cloud and More Personal Computing. We expect FX to increase COGS and operating expense growth by roughly one point.\n\n**Amy Hood** (EVP &amp; CFO)\nIn commercial bookings, we expect healthy growth on a growing expiry base. Bookings growth will again be driven by strong execution across our core annuity sales motions and long term commitments to our platform. As a reminder, larger long term Azure contracts which are more unpredictable in their timing drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 67% down year over year driven by the impact of continuing to scale our AI infrastructure. We expect Q1 capital expenditures to be over $30,000,000,000 driven by the continued strong demand signals we see.\n\n**Amy Hood** (EVP &amp; CFO)\nAs a reminder, there can be quarterly spend variability from cloud infrastructure build outs and the timing of delivery of finance leases. Next to segment guidance. In Productivity and Business Processes, we expect revenue of 32,200,000,000.0 to $32,500,000,000 or growth of 14% to 15% with roughly three points of benefit from FX as noted earlier. In M365 Commercial Cloud, we expect revenue growth to be between 1314% in constant currency with business trends that remain relatively stable compared to the prior quarter. ARPU growth will again be driven by E5 and M365 Copilot.\n\n**Amy Hood** (EVP &amp; CFO)\nM365 Commercial Products revenue growth should be in the mid to high single digits. As a reminder, M365 commercial products includes both the Windows commercial on premises components of M365 suites and office transactional purchasing both of which can be variable due to end period revenue recognition dynamics. M365 consumer cloud revenue growth should be in the low 20s driven by the January price increase. For LinkedIn, we expect revenue growth in the high single digits. And in Dynamics three sixty five, we expect revenue growth to be in the high teens with continued growth across all workloads.\n\n**Amy Hood** (EVP &amp; CFO)\nFor Intelligent Cloud, we expect revenue of $30,100,000,000 to $30,400,000,000 or growth of 25% to 26% with roughly one point of benefit from FX as noted earlier. Revenue will continue to be driven by Azure, which can have quarterly variability in year on year growth rates depending on the timing of capacity delivery and when it comes online as well as from in period revenue recognition depending on the mix of contracts. In Azure, we expect Q1 revenue growth of approximately 37% in constant currency driven by strong demand for our portfolio of services on a significant base. Even as we continue bringing more data center capacity online, we currently expect to remain capacity constrained through the first half of our fiscal year. In our on premises server business, we expect revenue to decline in the low to mid single digits with the ongoing customer shift to cloud offerings.\n\n**Amy Hood** (EVP &amp; CFO)\nIn More Personal Computing, we expect revenue to be 12,400,000,000.0 to $12,900,000,000 Windows OEM and devices revenue should decline in the mid to high single digits. We expect the elevated inventory levels at the end of Q4 to come down through the quarter in Windows OEM, although the range of potential outcomes remains wider than normal. Devices revenue should decline. Search and news advertising ex TAC revenue growth should be in the low to mid teens, down sequentially as growth rates normalize following the benefit from third party partnerships noted earlier. Growth will continue to be driven by volume and revenue per search across Edge and Bing.\n\n**Amy Hood** (EVP &amp; CFO)\nOverall Search and News advertising revenue growth should be in the low double digits. And in gaming, we expect revenue to decline in the mid to high single digits against a strong prior year comparable. We expect Xbox content and services revenue to decline in the mid single digits. Now back to company guidance. We expect COGS of 24,300,000,000.0 to $24,500,000,000 or growth of 21% to 22% and operating expense of 15,700,000,000.0 to $15,800,000,000 or growth of 5% to 6%.\n\n**Amy Hood** (EVP &amp; CFO)\nOther income and expense is estimated to be negative $1,300,000,000 primarily due to investments accounted for under the equity method. As a reminder, we do not recognize mark to market gains or losses on equity method investments. And lastly, we expect our Q1 effective tax rate to be between 1920%. In closing, we finished the year with double digit revenue and operating income growth and exceeded the FY 2025 operating margin commitment we shared a year ago. Our focus remains on investing in security, quality and AI platform and product innovation that delivers value and opportunity to our customers.\n\n**Amy Hood** (EVP &amp; CFO)\nWe are excited for FY 2026. With that, let's go to Q and A, Jonathan.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Amy. We'll now move over to Q and A. Out of respect for others on the call, we request that participants please only ask one question. Operator, can you please repeat your instructions?\n\n**Operator**\nThank And our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.\n\n**Keith Weiss** (Equity Analyst)\nThank you guys for taking the question and congratulations on a fantastic end to FY 2025. I've been covering like this off for a while. I don't think I've ever seen a quarter where like everything came together this well. So congratulations on that.\n\n**Amy Hood** (EVP &amp; CFO)\nThank you for calling InCom Conferencing. The next available operator will be with you momentarily.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSo these are workload results that are invaluable for us to learn to build both the products as well as the platform. And then broadly they or rather over time, there will be broad diffusion. In fact, one of the things that Amy and I track is not just the head app usage, but also what's the sort of all the Tier two applications that are being built. So that sort of that speaks a little bit, Keith, to I think your question is as long as we have head apps shaping the platform and then after that we have the broad diffusion happen, which in some sense we're both of those is what we're seeing. So I feel very good about being in standing going forward.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Keith. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.\n\n**Mark Moerdler** (MD, SVP &amp; Senior Research Analyst)\nThank you. I'd also give you my congratulations. Amazing. I didn't know how you were going to beat last quarter and you did it. So congratulations.\n\n**Mark Moerdler** (MD, SVP &amp; Senior Research Analyst)\nAnd thank you for taking my question. Satya and Amy, we're now two plus years since the Gen AI revolution and adoption is still early in ramping. What do you think is the best way that software companies are going to be able to monetize AI for SaaS? Do you believe there are differences in monetization for horizontal more general apps like M365 Copilot or Dynamics CRM Copilot versus very targeted capacities on the AgenTex side? And also how should you think about the trajectory of SaaS AI margins over the long term? Thank you.\n\n**Satya Nadella** (Chairman &amp; CEO)\nYes. I'll start and Amy, you should feel free to add. I mean, if I just broaden out beyond just SaaS as a category, I think just like the server to cloud transition, was an expansion of essentially usage of servers. That is essentially what happened with the cloud, right, which is we did a bunch of servers except that the expertise required, the capital required, the time required to bring up servers, build it out, scale it was just all hard. And so therefore, the market was a certain size, whereas with the cloud, you could sort of buy it with flexibility, you could burst and you could spin up and spin down, expertise required came down.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSo it was just orders of magnitude. That's what's happening.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSo if you sort of even subscribe to this point of view that intelligence is basically log of compute, That means compute is going to grow and you've got to use it as efficiently as possible to just keep creating intelligence. Now, how does it manifest beyond just the infrastructure? I kind of to Keith's earlier question, I talked a little bit about how infrastructure is getting shaped, data layer is getting shaped, the app server is getting built. These are all classic categories of infrastructure that will continue, but they will be an order or two of magnitude more. So literally like in fact, of the other things we track is every GPU requires storage and compute.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThat ratio is another thing that is really exponential for infrastructure growth. So when you go to the app layer, the SaaS apps themselves are now building in effectively agentic and chat interfaces with intelligence and they're also building autonomous agents. Agents are kind of like applications like a database application perhaps, but they are being used increasingly inside of a user interaction. I think a good example is GitHub Copilot. It got started as an ex you know, code completions on an IDE.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThen we added the chat interface to it. Then we added the agent mode to it. And now we have an autonomous agent, which in fact works completely asynchronously. Right? So all those four things, are now part of essentially GitHub.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd by the way, it also turns out that every other tool that is also doing any form of coding is adding more and more GitHub repos. So if I had to think about GitHub monetization, we have an opportunity around just monetizing GitHub Enterprise and then we have the ability to think about GitHub Copilot and GitHub Copilot as with all these form factors. And so that's exactly the same thing that's happening with Microsoft three sixty five. That's the same thing that's happening with Dynamics three sixty five. So you have to be very open to taking your data tier, your business logic tier and your UI tier and sort of being more expansive in it.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAs long as you do that, it's just that usage goes up, and that's what I think shows up in the results.\n\n**Amy Hood** (EVP &amp; CFO)\nAnd I think, Mark, if you wanted to think about all the things and the layers Hathi talked about is really we're seeing very similar monetization tools exist in this transition, right? There's a per user logic, there's tiers of per user, sometimes those tiers relate to consumption, sometimes there's pure consumption models. I think you'll continue to see a blending of these, especially as the AI model capability grows, you'll end up with ways that teams are going to want to throttle that usage, use the best models for the best job. And I think the blending of these models will continue to be something we see on a go forward basis.\n\n**Mark Moerdler** (MD, SVP &amp; Senior Research Analyst)\nThank you. I appreciate it.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Mark. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Karl Keirstead with UBS. Please proceed.\n\n**Karl Keirstead** (Managing Director - Software Equity Research)\nOkay. Thanks. Sachin and Amy, this is the second quarter in a row of pretty material Azure upside from what sounds like an acceleration in on prem to Azure migration activity. I'm just wondering if you can comment on the plethora of customer conversations you've had whether there are a couple of two or three specific catalysts that are driving that migration and how durable a trend do you think that is? Thank you.\n\n**Satya Nadella** (Chairman &amp; CEO)\nYes. I mean just there are three things that are really happening. One is the migrations. A good example would be what I referenced in my remarks with Nestle with the SAP instances. They moved along with a lot of the data that's associated with it in a bunch of servers.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSo that's kind of a classic example. I think whether it's VMware migrations or migrations of SAP or even just our own server migrations, they're pretty healthy. And as it turns out that we're still not anywhere close to the finish line, if at best maybe in the middle innings of that. The second thing that's also happening is cloud native applications that are scaling. This is even excluding all of the AI stuff, just the classic cloud native e commerce company, let's say.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThese are scaling in a big way. And some of those customers were not on Azure previously, but now they're increasingly there because they have come for AI perhaps, but they now stay for more than AI. And so to me, that's another thing you see in overall, what's happening across the Azure number. And then of course there are the new AI workload. So those are three things that are all in some sense building on each other, but that's kind of what's driving our growth.\n\n**Karl Keirstead** (Managing Director - Software Equity Research)\nGot it. Thank you.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Karl. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Brent Thill with Jefferies. Please proceed.\n\n**Brent Thill** (MD &amp; Tech Sector Leader - Software &amp; Internet Research)\nSatya, back to the strength across the board in the quarter. Was there anything that jumped out you or surprised you that you didn't think you were going to see, but you did see in the quarter? Just the magnitude of upside, I think, had shocked many here.\n\n**Satya Nadella** (Chairman &amp; CEO)\nYes. I don't know, Brett, if anything really surprised us. But I think what, we are noticing in our own build out of these AI applications and in general is the platform is becoming more than here is a model and here is an API, make some calls, right? I mean that in some sense, was a bit of the state of the art maybe even a year ago. Whereas now you have essentially these very stateful app patterns that are emerging that require quite a bit of rethinking of even the app stack.\n\n**Satya Nadella** (Chairman &amp; CEO)\nI mean, take even the storage tier stuff, The degree of sophistication you have and hey, how much of an index do you really want to build by pre processing so that your prompt engineering or context engineering as I called can be better and higher quality. So I think all of that is emerging. So when I look at a product like Azure Search, Fabric and Cosmos DB, all of the things, the frameworks around it are just becoming robust to build serious applications. And so that's what I feel great about is the learning curve inside the company, outside the company, the diffusion of this tech, the speed with which that's emerging, that you can build applications is much faster, right? I always go back and say, hey, when a relational database came out, it took a while for people to build an ERP system, let's say.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd this thing, we're kind of building pretty sophisticated applications at a very, very fast clip based on I think the degree of maturity that's emerging.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Brent. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Raimo Lenschow with Barclays. Please proceed.\n\n**Raimo Lenschow** (Managing Director)\nPerfect. Thank you. Congrats from me as well. I had one question around Copilot, and I'm obviously a happy user here at Barclays. If you think about it, the one thing that we're all realizing is that Copilot is the AI part, but data is becoming more and more important.\n\n**Raimo Lenschow** (Managing Director)\nAnd then from there on, we can start thinking about agents. Where is the what are you seeing in your customer conversations, Satya, about like that understanding that Copilot is actually just the starting point and then from there on it's becoming like much, much broader? Thank you.\n\n**Satya Nadella** (Chairman &amp; CEO)\nYes. I think that that's right. Even inside of Copilot, I'm sure you're seeing it, right? You now have analyst and researcher to just talk about two examples and of course, people, all the third party agents. So yes, there is a lot more of this is not request response.\n\n**Satya Nadella** (Chairman &amp; CEO)\nIt's about spawning essentially applications, that then go to work and come back. But the UI still remains very important, right? Even for asynchronous work to instruct the asynchronous work, you need UI. And to monitor asynchronous work, you need UI. It may be different.\n\n**Satya Nadella** (Chairman &amp; CEO)\nIt may not be a chat interface. And of course, you need a way to then inspect what the asynchronous work is, right? So even take the example I was giving on GitHub. Even if you're not using GitHub Copilot to create the code check-in or the pull request, interestingly enough, we're seeing massive increase to GitHub Copilot code review agent, even if you used maybe Code or whatever else to write the code. So that's I think what's happening across all of these systems.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSo you're absolutely right that you need it starts with some kind of a UI that's more chat focused, but it quickly goes beyond it. And you see it in M365, you see it in Dynamics three sixty five and you see it in GitHub.\n\n**Raimo Lenschow** (Managing Director)\nThank you.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Raimo. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.\n\n**Kash Rangan** (Managing Director)\nHi, thank you very much. Amy, I want to acknowledge that, I think a few quarters ago, you said that you reach a point in time where you can accelerate Azure while slowing down CapEx. So you did it. But what is the outlook? When I look at the CapEx guidance for the upcoming quarter, certainly, I would view that as a positive indicator of the book of business you have for your cloud services.\n\n**Kash Rangan** (Managing Director)\nBut how should we think about the shape of the curve of CapEx vis a vis Azure growth rate in the years ahead, particularly as I listened to Satya's comments on the AI stack consuming more and more infrastructure? Are we at a point where we're going to have to continue to do this and we magically wait for inference and applications to kick in and therefore create a richer gross margin mix? Thank you so much for your comments and congrats on the quarter.\n\n**Amy Hood** (EVP &amp; CFO)\nThanks, Kash. Let me back up and first say, when you think about the full year comments I've made on CapEx as well as the Q1 guidance of over 30,000,000,000 you first have to ground yourself in the fact that we have $368,000,000,000 of contracted backlog we need to deliver not just across Azure, but across the breadth of the Microsoft cloud. So in terms of feeling good about the ROI and the growth rates and the correlation, I feel very good that the spend that we're making is correlated to basically contracted on the books business that we need to deliver and we need the teams to execute at their very best to get the capacity in place as quickly and effectively as they can. And so when you look, we've talked about the growth rate will decline year over year, but at its core, our investments, particularly in short lived assets like servers, GPUs, CPUs, networking storage, is just really correlated to the backlog we see and the curve of demand. And I talked about, my gosh, in January and said, I thought we'd be in better supplydemand shape by June.\n\n**Amy Hood** (EVP &amp; CFO)\nAnd now I'm saying, I hope I'm in better shape by December. And that's not because we slowed CapEx even with accelerating the spend and trying to pull leases in and get CPUs and GPUs in the system as quickly as we can. We are still seeing demand improve. And so I am not as focused, Kash, on trying to pick a date at which revenue growth and CapEx growth will meet and cross. I'm focused on building backlog, building business and delivering capacity, which we are seeing has a good ROI today in terms of our ability to get that done.\n\n**Amy Hood** (EVP &amp; CFO)\nSo I don't want people to get overly focused on a pivot point because when you're in sort of these expansive moments, picking a data point usually means you're going to pick to be too conservative in terms of market share gain and in terms of winning. And so I tend to put my energy more there. Yes.\n\n**Satya Nadella** (Chairman &amp; CEO)\nI think one of the other things, Kash, is that I think I said this in a previous earnings as well, which is the difference between a holster and a hyperscaler is software, and the same is going to be true here. That GPD four point example I gave is all software, The optimization even in the last year. So we know how to use the software skills to take any piece of hardware and make it multiple X better. And so that's kind of where the yield will come. But as Amy said, while you're really going and building out the plant, you don't want to sort of You just want to go in parallel on all of these fronts, and that's sort of what will compound over time.\n\n**Amy Hood** (EVP &amp; CFO)\nAnd I do think it's important when Plata talks about the software layer, he's talking about in his comments to connect this back to the compounding S curves. And so I would remind people that is something that we saw through the prior cloud transition. It's how we operated through that one. And the same sort of skills and logic done at an even faster pace is what will apply the same transition.\n\n**Kash Rangan** (Managing Director)\nSounds very encouraging. Thank you so much.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Kash. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Michael Turrin with Wells Fargo. Please proceed.\n\n**Michael Turrin** (MD &amp; Equity Research Analyst)\nHey, great. Thanks very much for taking the questions and congrats from me as well on the metrics working in concert here. Amy, maybe on margin impressive to hear expectations for flat operating margin in the upcoming year as you absorb some of the mix shift towards Azure and some of the more AI focused offerings. Can you speak in more detail just around your ability to manage those trade offs and offset some of the mix shift? And I'm wondering specifically just on any productivity gains you're seeing from leveraging AI internally that you'd highlight or anything else you just mentioned in underpinning the full year expectation there? Thanks,\n\n**Amy Hood** (EVP &amp; CFO)\nMichael. I think really, the area to focus on is when you think about margin. I think sometimes people get a lot of energy around cost control as a driver of margin. The other driver is to focus on making sure you deliver great product that's competitive and innovative and can take share because that drives revenue. And revenue itself and revenue growth, as you all know better, even perhaps than I do, is a durable way to see margin improvement.\n\n**Amy Hood** (EVP &amp; CFO)\nIt builds on itself. That being said, the second thing I would point to is really what I talked to Cash a little bit about before, Tati and I both mentioned it, is applying all of our skill set here to deliver efficiencies, whether that's at whatever layer of the stack that exists. The S curve is compound, and we are doing that work, and we're focused on it. At the same time, we're doing the build out. So you'll see improvements there even as we continue to invest.\n\n**Amy Hood** (EVP &amp; CFO)\nAnd then, of course, it's about continuing to have great talent here, focus on products and opportunities where we have the biggest markets and the most likelihood of success. And so when we have those three things happen and the energy is right and the focus is there, it gives me confidence in terms of margin delivery. But make no mistake, it starts and ends really with product, which is what we're really focused on here and delivering that to customers.\n\n**Michael Turrin** (MD &amp; Equity Research Analyst)\nThat all sounds pretty good. Thanks very much.\n\n**Jonathan Neilson** (VP - IR)\nThanks, Michael. That wraps up the Q and A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with you all soon.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThank you.\n\n**Amy Hood** (EVP &amp; CFO)\nThank you.\n\n**Operator**\nThis concludes today's conference. You may disconnect your lines at this time. Thank you for your participation.",
        "fetched_at": "2026-02-04T16:09:28.668Z"
      },
      {
        "ticker": "MSFT",
        "title": "Yahoo Finance",
        "published_date": "Apr 30, 2025, 5:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/MSFT/earnings/MSFT-Q3-2025-earnings_call-310655.html",
        "content": "**Operator**\nGreetings, and welcome to the Microsoft Fiscal Year twenty twenty five Third Quarter Earnings Conference Call. At this time, all participants are in a listen only mode. A question and answer session will follow the formal presentation. As a reminder, this conference is being recorded. It is now my pleasure to introduce Jonathan Nielsen, Vice President of Investor Relations. Please go ahead.\n\n**Jonathan Neilson** (VP of IR)\nGood afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer Amy Hood, Chief Financial Officer Alex Jolla, Chief Accounting Officer and Keith Dolliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non GAAP financial measures. More detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non GAAP items.\n\n**Jonathan Neilson** (VP of IR)\nThe non GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP. They are included as additional clarifying items to aid investors in further understanding the company's third quarter performance in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted. We will also provide growth rates in constant currency when available as a framework for assessing how our underlying business performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rates only.\n\n**Jonathan Neilson** (VP of IR)\nWe will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded. If you ask a question, it will be included in our live transmission, in the transcript and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we will be making forward looking statements, which are predictions, projections or other statements about future events.\n\n**Jonathan Neilson** (VP of IR)\nThese statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call and in the Risk Factors section of our Form 10 ks, Forms 10 Q and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward looking statement. And with that, I'll turn the call over to Satya.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThank you, Jonathan. It was a record quarter driven by continued strength of Microsoft Cloud, which surpassed $42,000,000,000 in revenue, up 22% in constant currency. Cloud and AI are the essential inputs for every business to expand output, reduce costs and accelerate growth. Now I'll highlight examples starting with infrastructure. We continue to expand our data center capacity.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThis quarter alone, we opened DCs in 10 countries across four continents. Model capabilities are doubling in performance every six months, thanks to multiple compounding scaling laws. We continue to optimize and drive efficiencies across every layer from DC design to hardware and silicon to system software to model optimization all towards lowering costs and increasing performance. You see this in our supply chain where we have reduced dock to lead times for new GPUs by nearly 20% across our blended fleet where we have increased AI performance by nearly 30% ISO power and our cost per token, which is more than halved. When it comes to cloud migrations, we saw accelerating demand with customers in every industry from Abercrombie and French to Coca Cola and ServiceNow, expanding their footprints on Azure.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd we remain the cloud of choice for customers' mission critical VMware, SAP and Oracle workloads with more regional availability than any other hyperscaler. We're also excited about the next frontier in cloud systems with Quantum. In addition to putting our Quantum stack on machines from our partners, we're also making real progress on a path to a utility scale quantum computer with the introduction of Majorana One. When it comes to data and analytics, we have deeply integrated our AI platform with our data stack. PostgreSQL usage accelerated for the third consecutive quarter and it is now used by nearly 60% of the Fortune 500, including companies like BMW and BNY Mellon.\n\n**Satya Nadella** (Chairman &amp; CEO)\nCosmos DB revenue growth also accelerated again this quarter and remains the go to database for globally distributed NoSQL workloads at any scale. It is used by customers in every industry like CarMax, DocuSign, NTT Data and OpenAI. This quarter, we also saw analytics consumption accelerate. Microsoft Fabric has more than 21,000 paid customers, up 80% year over year. Fabric brings together data workloads like data warehousing, data science, real time intelligence along with Power BI into one end to end solution.\n\n**Satya Nadella** (Chairman &amp; CEO)\nReal time intelligence is now the fastest growing workload in fabric with 40% of customers already using it in just five months since becoming generally available. All up more than 50% of fabric customers like AmorePacific, Louisiana State Government and Petrobras use three or more workloads. And the amount of data in our multi cloud data lake, OneLake has grown more than 6x over the past year. Now on to AI Platform and Tools. Foundry is the agent in AI app factory.\n\n**Satya Nadella** (Chairman &amp; CEO)\nIt's now used by developers at over 70,000 enterprises and digital natives from Atomic Work to Epic, Fujitsu and Gainsight to H and R Block and LG Electronics to design, customize and manage their AI apps and agents. We processed over 100,000,000,000,000 tokens this quarter, up 5x year over year, including a record 50,000,000,000,000 tokens last month alone. And four months in, over 10,000 organizations have used our new agent service to build, deploy and scale their agents. This quarter, we also made a new suite of fine tuning tools available to customers with industry leading reliability. And we brought the latest models from OpenAI along with new models from Cohere, DeepSeek, Meta, Mistral, Stability to Foundry.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd we've expanded our PHY family of SLMs with new multimodal and mini models. All up PHY has been downloaded 38,000,000 times. And our research teams are taking it one step further with BitNet B1.58, a billion parameter large language model that can run on just CPUs coming to the foundry. Now on to developer tools. We are evolving GitHub Copilot from pair to peer programmer.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWith agent mode in Versus Code, Copilot can now iterate on code, recognize errors and fix them automatically. This adds to other Copilot agents like AutoFix, which helps developers remediate vulnerabilities as well as Code Review Agent, which has already reviewed over 8,000,000 pull requests. And we are previewing a first of its kind SWE Agent capable of synchronously executing developer tasks. All up, we now have over 15,000,000 GitHub Copilot users up over 4x year over year. And both digital natives like Twilio and enterprises like Cisco, HPE, Skyscanner and Target continue to choose GitHub Copilot to equip their developers with AI throughout the entire dev life cycle. With Visual Studio and Versus Code, we have the world's most popular editor with over 50,000,000 monthly active users.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd with Power Platform, we have the leading low code platform for AI makers too. We now have 56,000,000 monthly active Power Platform users, up 27% year over year, who increasingly use our AI features to build apps and automate processes. Now on to future of work. Microsoft three sixty five Copilot is built to facilitate human agent collaboration. Hundreds of thousands of customers across geographies and industries now use Copilot, up 3x year over year.\n\n**Satya Nadella** (Chairman &amp; CEO)\nOur overall deal size continues to grow and this quarter we saw a record number of customers returning to buy more seats. And we are going further. Just last week, we announced a major update bringing together agents, notebooks, search and create into a new scaffolding for work. Our new researcher and analyst deep reasoning agents analyze vast amounts of web and enterprise data to deliver highly skilled expertise on demand directly within Copilot. Beyond horizontal knowledge work, we are introducing agents for every role and business process.\n\n**Satya Nadella** (Chairman &amp; CEO)\nOur sales agent turns contacts into qualified leads and with Sales Chat reps can quickly get up to speed on new accounts and our customer service agent is deflecting customer inquiries and helping service reps resolve issues faster. With Copilot Studio, customers can extend Copilot and build their own agents with no code, low code. More than 230,000 organizations including 90% of the Fortune 500 have already used Copilot Studio. With deep reasoning and agent flows in Copilot Studio, customers can build agents that perform more complex tasks and also handle deterministic scenarios like document processing and financial approvals. And they can now build computer use agents that take action on the UI across desktop and web apps.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd with just a click they can turn any SharePoint site into an agent too. This quarter alone customers created over 1,000,000 custom agents across SharePoint and Copilot Studio, up 130 quarter over quarter. When it comes to business applications, Dynamics three sixty five again took share as companies like Avaya, Brunswick, Softcat switched to Dynamics from legacy providers. Verizon for example chose Dynamics three sixty five sales to improve the efficiency of its sellers. In Healthcare, Dragon Co Pilot is off to a fast start.\n\n**Satya Nadella** (Chairman &amp; CEO)\nLast quarter alone we helped document nearly 9,500,000 physician patient encounters at providers like City of Hope, Ottawa Hospital, Tufts Medicine and Wellstar up over 50% quarter over quarter. In manufacturing, we introduced factory operations and safety agents at Hanover Massay and leading partners like Autodesk, PTC and Siemens have all built their own industrial AI solutions on our stack. And in retail, we have introduced agents to help customers like Bath and Body Works build more personalized shopping experience and improve store operations. When it comes to Windows Copilot plus PCs are faster and have better battery life than any other device in their category. We also continue to win new customers with best in class AI capabilities.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWe offer a growing number of AI apps from partners like Adobe, Canva and Zoom. Just last week, we rolled out exclusive AI experiences like Recall, Click to Do and Windows Search to all Copilot plus PCs. And we continue to see increased commercial traction as we approach end of support for Windows 10. Windows 11 commercial deployments increased nearly 75% year over year. Now on to security.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSecurity is our top priority and we have made significant progress against the engineering objectives we outlined a year and a half ago as part of our Secure Future initiative. We are now applying these learnings to deliver new innovation across our platform. Last month along with our partners, we introduced security copilot agents to help defenders autonomously handle high volume security and IT tasks informed by 84,000,000,000,000 daily threat signals. We also added new capabilities to Defender, Entra and Purview to help organizations secure and govern their AI deployments. All up, we now have 1,400,000 secondurity customers, over 900,000 including Global, ManpowerGroup, TriNet, Regions Bank have four or more workloads, up 21% year over year.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd in Identity, Entra now has more than 900,000,000 monthly active users. Now on to our consumer businesses, starting with LinkedIn. Over 1,000,000,000 professionals use LinkedIn to connect, learn, hire and sell and our membership continues to grow at double digits year over year. Time spent watching videos on the platform was up 36% and comments were up 32% year over year. We're also seeing more members use AI to gain new skills and find jobs.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThe number of learners who have used AI powered coaching increased over 2x quarter over quarter. And we remain the market leader in hiring as customers like Equinix and Verizon use LinkedIn hiring assistance to find qualified candidates faster. When it comes to LinkedIn Premium, we saw over 75% quarter over quarter subscriber growth to our Premium Pages offering for SMBs. And LinkedIn marketing solution continues to be the best way to reach B2B decision makers with two consecutive quarters of accelerated revenue growth. More broadly, when it comes to advertising, we are transforming how people search, browse, discover content and use AI as a personal assistant.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWith Copilot Search in Bing, we are reimagining search results with overview pages curated by AI and embedded conversational capabilities. With Copilot Vision and Edge, Copilot sees what you see and gives you real time responses while you browse. With Copilot Discover, we are personalizing experience based on user interactions and preferences. And with our updated Copilot app, we are focused on building daily engagement and successful sessions across a range of modalities, whether it is conversing, searching, shopping or travel planning. All up, we again took share across Bing and Edge and our total advertising revenue across our businesses has surpassed $20,000,000,000 over the past twelve months.\n\n**Satya Nadella** (Chairman &amp; CEO)\nNow on to Gaming. We continue to transform the business and focus on margin expansion as we bring our games to over 500,000,000 monthly active users across devices. We ended the quarter as the top publisher by pre orders and pre installs on both Xbox and PlayStation Store. PC Game Pass revenue increased over 45% year over year with Xbox Play Anywhere players now can access more than 1,000 games they can play across console and PC. And just last week, we brought cloud gaming to LG TVs.\n\n**Satya Nadella** (Chairman &amp; CEO)\nCloud gaming set a new record surpassing 150,000,000 hours played for the first time this quarter. We are also integrating AI across the Xbox. New Copilot for Gaming is a personalized gaming companion that provides in game assistant and expert coaching and our first of its kind Muse model can generate gameplay in real time. Finally, it's fantastic to see the success of the Minecraft movie, which is the top grossing film of the year. In addition to monetizing our IP in new ways, we have seen a 75% plus increase in weekly active users of the game year over year since the release.\n\n**Satya Nadella** (Chairman &amp; CEO)\nIn closing, we are rapidly innovating opportunity across both consumer and commercial businesses. In just a few weeks at our BUILD conference, we'll share how we are creating the most powerful AI platform for developers and I encourage you to tune in. With that, let me turn it over to Amy.\n\n**Amy Hood** (Executive VP &amp; CFO)\nThank you, Satya, and good afternoon, everyone. This quarter revenue was $70,100,000,000 up 1315% in constant currency. Gross margin dollars increased 1113% in constant currency, while operating income increased 1619% in constant currency. And earnings per share was $3.46 an increase of 1819% in constant currency. Results exceeded expectations driven by focused execution from our sales and partner teams.\n\n**Amy Hood** (Executive VP &amp; CFO)\nWe continue to see strong demand for our cloud and AI offerings as they help customers drive productivity, increase efficiencies and grow their businesses. And again this quarter revenue from our AI business was above expectations. Commercial bookings increased 1817% in constant currency significantly ahead of expectations again this quarter driven by an Azure commitment from OpenAI. We also saw consistent execution across our core annuity sales motions and continued long term commitments to our platform. Commercial remaining performance obligation increased to $315,000,000,000 up 3433% in constant currency.\n\n**Amy Hood** (Executive VP &amp; CFO)\nRoughly 40% will be recognized in revenue in the next twelve months up 17% year over year. The remaining portion recognized beyond the next twelve months increased 47%. And this quarter our annuity mix was 98%. FX was roughly in line with expectations on total company revenue, segment level revenue and operating expense growth. FX decreased COGS growth by only one point, one point unfavorable to expectations.\n\n**Amy Hood** (Executive VP &amp; CFO)\nMicrosoft Cloud revenue was $42,400,000,000 ahead of expectations and grew 2022% in constant currency. Microsoft Cloud gross margin percentage was 69% in line with expectations and decreased three points year over year driven by the impact of scaling our AI infrastructure. Company gross margin percentage was also 69% down one point year over year driven by scaling our AI infrastructure. Operating expenses increased 23% in constant currency lower than expected due to our focus on cost efficiencies as well as investments that shifted to Q4. Operating margins increased one point year over year to 46% better than expected as we continue to focus on building high performing teams and increasing our agility by reducing layers with fewer managers.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAt a total company level, headcount at the March was 2% higher than a year ago and was down slightly compared to last quarter. Now to our segment results. Revenue from Productivity and Business Processes was $29,900,000,000 and grew 1013% in constant currency ahead of expectations driven by LinkedIn, Microsoft three sixty five Commercial Products and Microsoft three sixty five Consumer. M365 Commercial Cloud revenue increased 1215% in constant currency in line with expectations. ARPU growth was again driven by E5 and M365 Copilot.\n\n**Amy Hood** (Executive VP &amp; CFO)\nWith M365 Copilot, we continue to see growth across customer segments and geos. Paid M365 commercial seats grew 7% year over year to over $430,000,000 While we continue to see installed base expansion across all customer segments growth was primarily driven by our small and medium business and frontline worker offerings. M365 commercial products revenue increased 58% in constant currency ahead of expectations due to higher than expected office transactional purchasing. M365 consumer cloud revenue increased 1012% in constant currency ahead of expectations driven by higher than expected subscription growth following the January price increase. M365 consumer subscriptions grew 9% to $87,700,000 LinkedIn revenue increased seven percent and eight percent in constant currency.\n\n**Amy Hood** (Executive VP &amp; CFO)\nResults were ahead of expectations due to better than expected performance across all businesses. The Talent Solutions business continues to be impacted by weakness in the hiring market. Dynamics three sixty five revenue increased 1618% in constant currency in line with expectations with continued growth across all workloads. Segment gross margin dollars increased 1013% in constant currency and gross margin percentage was relatively unchanged year over year even with the impact of scaling our AI infrastructure. Operating expenses increased 12% in constant currency and operating income increased 1518% in constant currency.\n\n**Amy Hood** (Executive VP &amp; CFO)\nNext, the Intelligent Cloud segment. Revenue was $26,800,000,000 and grew 2122% in constant currency ahead of expectations driven by Azure. In Azure and other cloud services revenue grew 3335% in constant currency including 16 points from AI services. Focused execution drove non AI services results where we saw accelerated growth in our enterprise customer segment as well as some improvement in our scale motions. And in Azure AI services we brought capacity online faster than expected.\n\n**Amy Hood** (Executive VP &amp; CFO)\nIn our on premises server business revenue decreased 64% in constant currency slightly below expectations driven by renewals with lower in period revenue recognition from the mix of contracts. The year over year decline is reflective of the continued customer shift to cloud offerings. Enterprise and Partner Services revenue increased 56% in constant currency slightly ahead of expectations due to better than expected performance in Enterprise Support Services. Segment gross margin dollars increased 1314% in constant currency and gross margin percentage decreased four points year over year driven by scaling our AI infrastructure. Operating expenses increased 67% in constant currency and operating income grew 1718% in constant currency.\n\n**Amy Hood** (Executive VP &amp; CFO)\nNow to more personal computing. Revenue was $13,400,000,000 and grew six percent and seven percent in constant currency ahead of expectations due to better than expected results across all businesses. Windows OEM and devices revenue increased 3% year over year ahead of expectations as tariff uncertainty through the quarter resulted in inventory levels that remained elevated. Search and news advertising revenue ex TAC increased 2123% in constant currency. Results were significantly ahead of expectations driven by usage from a third party partnership, better than expected rate expansion and volume growth across Edge and Bing.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd in gaming, revenue increased 56% in constant currency. Xbox content and services revenue increased 89% in constant currency ahead of expectations driven by stronger than expected performance in third party and first party content. Segment gross margin dollars increased 911% in constant currency. Gross margin percentage increased two points year over year driven by strong execution on margin improvement in Search and Gaming. Operating expenses increased 1%.\n\n**Amy Hood** (Executive VP &amp; CFO)\nOperating income increased 2123% in constant currency driven by continued prioritization of higher margin opportunities. Now back to total company results. Capital expenditures including finance leases were $21,400,000,000 slightly lower than expected due to normal variability from the timing of delivery of data center leases. Cash paid for PP and E was $16,700,000,000 roughly half of our cloud and AI related spend was on long lived assets that will support monetization over the next fifteen years and beyond. The remaining cloud and AI spend was primarily for servers both CPUs and GPUs to serve customers based on demand signals including our customer contracted backlog of $315,000,000,000 Cash flow from operations was $37,000,000,000 up 16% driven by strong cloud billings and collections partially offset by higher tax payments.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd this quarter free cash flow was $20,300,000,000 Other income and expense was negative $623,000,000 more favorable than anticipated primarily due to net gains on derivatives and investments. Our losses on investments accounted for under the equity method were slightly higher than expected. Our effective tax rate was approximately 18%. And finally, we returned $9,700,000,000 to shareholders through dividends and share repurchases, an increase of 15% year over year. Now moving to our Q4 outlook, which unless specifically noted otherwise is on a U.\n\n**Amy Hood** (Executive VP &amp; CFO)\nS. Dollar basis. First, through April demand signals across our commercial businesses as well as in LinkedIn, gaming and search have remained consistent. Our outlook assumes those trends continue in Q4. If the environment changes, our results may be impacted.\n\n**Amy Hood** (Executive VP &amp; CFO)\nIn our Windows OEM business, our outlook assumes the elevated inventory levels from Q3 will come down in Q4. We have widened our guidance range in our More Personal Computing segment to account for some of this variability. Next, FX. With the weakening of the U. S.\n\n**Amy Hood** (Executive VP &amp; CFO)\nDollar in April, we now expect FX to increase total revenue growth by one point. Within the segments, we expect FX to increase revenue growth by one point in Productivity and Business Processes and less than one point in Intelligent Cloud and More Personal Computing. We expect FX to increase COGS operating expense growth by less than one point. In Commercial Bookings, we expect solid growth on a significant prior year comparable and a growing ex pre base. Bookings growth will be driven by strong execution across our core annuity sales motions and continued long term commitments to our platform.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAs a reminder, larger longer term Azure contracts which are more unpredictable in their timing can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 67% down year over year primarily driven by the impact of scaling our AI infrastructure. And now capital expenditures. We expect Q4 capital expenditures to increase on a sequential basis. H2 CapEx in total remains unchanged from our January guidance.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAs a reminder, there can be quarterly spend variability from cloud infrastructure build outs and the timing of delivery of finance leases. Next to segment guidance. In Productivity and Business Processes, we expect revenue of US32.05 billion dollars to US32.35 billion dollars or growth of 11% to 12% in constant currency. M365 Commercial Cloud revenue growth should be approximately 14% in constant currency relatively stable compared to the prior quarter. We expect continued ARPU growth through E5 and M365 Copilot and some seat growth moderation given the size of the installed base.\n\n**Amy Hood** (Executive VP &amp; CFO)\nM365 Commercial Products revenue growth should be in the mid single digits. As a reminder, M365 Commercial Products includes both the Windows commercial on premises components of M365 suites and Office transactional purchasing both of which can be variable due to end period revenue recognition dynamics. M365 Consumer Cloud revenue growth should be in the mid teens driven by the January price increase. For LinkedIn, we expect revenue growth in the high single digits. And in Dynamics three sixty five, we expect revenue growth to be in the mid to high teens with continued growth across all workloads.\n\n**Amy Hood** (Executive VP &amp; CFO)\nFor Intelligent Cloud, we expect revenue of $28,750,000,000 to $29,050,000,000 or growth of 20 to 22% in constant currency. Revenue will continue to be driven by Azure which as a reminder can have quarterly variability primarily from in period revenue recognition depending on the mix of contracts. In Azure, we expect Q4 revenue growth to be between 3435% in constant currency driven by strong demand for our portfolio of services. In our non AI services, we expect focused execution to continue driving healthy growth. And in our AI services, while we continue to bring data center capacity online as planned, demand is growing a bit faster.\n\n**Amy Hood** (Executive VP &amp; CFO)\nTherefore, we now expect to have some AI capacity constraints beyond June. In our on premises server business, we again expect revenue to decline in the mid single digits with the ongoing customer shift to cloud offerings. And the Enterprise and Partner Services, we expect revenue growth to be in the mid to high single digits driven by Enterprise Support Services. In More Personal Computing, we expect revenue to be $12,350,000,000 to $12,850,000,000 Windows OEM and devices revenue should decline in the mid to high single digits. We expect Windows OEM revenue to decline in the low to mid single digits assuming OEM inventory levels come down through the quarter as noted earlier.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAlthough the range of potential outcomes is wider than normal. Devices revenue should decline in the high teens. Search and news advertising ex TAC revenue growth should be in the high teens even on a strong prior year comparable. We expect to see continued growth in both volume and revenue per search with share gains across Edge and Bing. Overall search and news advertising revenue growth should be in the mid teens.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd in gaming, we expect revenue growth to be in the mid single digits. We expect Xbox content and services revenue growth to be in the high single digits driven by first party content. Now back to company guidance. We expect COGS of 23,600,000,000.0 to $23,800,000,000 or growth of 19% to 20% in constant currency and operating expense of $18,000,000,000 to $18,100,000,000 or growth of approximately 5% in constant currency. Therefore, even with ongoing AI investments as we scale, we continue to expect full year FY 2025 operating margins expected to be roughly negative $1,200,000,000 primarily driven by investments accounted for under the equity method.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAs a reminder, we do not recognize mark to market gains or losses on equity method investments. And lastly, we expect our Q4 effective tax rate to be approximately 19%. Now I'd like to share some closing thoughts as we look to the next fiscal year. We remain committed to investing against the strong demand signals we see for our services. So as a reminder, our earlier comments on FY 2026 capital expenditures remain unchanged.\n\n**Amy Hood** (Executive VP &amp; CFO)\nWe expect CapEx to grow. It will grow at a lower rate than FY 2025 and will include a greater mix of short lived assets, which are more directly correlated to revenue than long lived assets. These investments along with focused execution that delivers near term value to our customers will ensure we continue to lead through the cloud and AI opportunity ahead. With that, let's go to Q and A, Jonathan.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Amy. We'll now move over to Q and A. Out of respect to others on the call, we request that participants please only ask Operator, can you please repeat your instructions?\n\n**Operator**\nAnd our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed.\n\n**Keith Weiss** (Equity Analyst)\nExcellent. Thank you guys for taking the question and congratulations on a fantastic quarter. In what all of us are looking at as a difficult environment, a lot of uncertainty out there, so really impressive to put up the results that you guys did. One of the things that we heard a lot about this quarter in the media and press reports was changing data center commitments, maybe Microsoft walking away from some of those data center commitments. But it sounds like the AI demand is very strong.\n\n**Keith Weiss** (Equity Analyst)\nYou're talking about not being able to hit all that demand with supply. So could you talk to us about what's going on with your data center strategy? Are there any shifts taking place? And maybe in particular, Satya, you could talk about some of the comments that you had made about the potential risk for oversupply in GPUs out in the future. What exactly was that risk you were talking about?\n\n**Keith Weiss** (Equity Analyst)\nAnd are you incorporating that risk into your data center strategy?\n\n**Satya Nadella** (Chairman &amp; CEO)\nYes. First of all, thanks, Keith, for the question. The reality is we've always been making adjustments to build, lease, what pace we build all through the last whatever, ten, fifteen years. It's just that you all pay a lot more attention to what we do quarter over quarter nowadays. Having said that, the key thing for us is to have our build and lease be positioned for what is the workload growth of the future.\n\n**Satya Nadella** (Chairman &amp; CEO)\nRight? So that's what you have to go and seek to. So there's a demand part to it. There is the shape of the workload part to it and there is a location part So you don't want to be upside down on having one big data center in one region when you have a global demand footprint.\n\n**Satya Nadella** (Chairman &amp; CEO)\nYou don't want to be upside down when the shape of demand changes because after all with essentially pre training plus test time compute, that's a big change in terms of how you think about even what is training, right, forget inferencing. So fundamentally given all of that and then every time that there's great Moore's Law, but remember this is a compounding sort of S curve, right, which is Moore's Law, there's system software, there's model architecture changes, there's the app server efficiency. Given all of that, we just want to make sure we're building accounting for the latest and greatest sort of information we have on all of that. And that's what you see reflected. And I feel very, very good about the pace.\n\n**Satya Nadella** (Chairman &amp; CEO)\nIn fact, Amy just mentioned, we will be short power. And so therefore but it's not power it's not a blanket statement. I need power in specific places so that we can either lease or build at the pace at which we want. And so that's the sort of plan that we're executing to. Maybe Amy, you can add to that.\n\n**Amy Hood** (Executive VP &amp; CFO)\nYes. Maybe just to add a little bit to Satya's comments. Just a reminder, these are very long lead time decisions from land to build to build outs can be lead times of five to seven years, two to three years. So we're constantly in a balancing position as we watch demand curves and many of the things Satya watched. And the second part is just to maybe remind you when Satya talks about being short power, he's really talking about data center space.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd so we've continued through the second half to put things in place. In fact, we talked a little bit about pulling even some of that space to be ready earlier and being able to deliver that earlier to customers this quarter, which is really good work by the teams as we continue to get more and more efficient at that process. And I look forward to being able to continue to do that in the future. I did talk about in my comments, we had hoped to be in balance by the end of Q4. We did see some increased demand, as you saw through the quarter.\n\n**Amy Hood** (Executive VP &amp; CFO)\nSo, we are going to be a little short, still stay a little tight as we exit the year, but are encouraged by that.\n\n**Keith Weiss** (Equity Analyst)\nExcellent. Thank you, guys.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Keith. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Brent Thill with Jefferies. Please proceed.\n\n**Brent Thill** (Tech Sector Leader, Software/Internet Research)\nThanks. Satya, on your comment about accelerating demand for cloud migrations, I'm curious if you could dig in and extrapolate a little more what you're seeing there? Thank you.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThanks, Brent. So yes, so I sort of think about three big things that are happening in the cloud all in parallel and there's also a relationship between them. One is, I'll just say the classic migration of whether it's SQL, Windows Server. And so that sort of again got good steady state progress because the reality is, I think everyone's now perhaps there's another sort of kick in the data center migrations just because of the efficiency, the cloud provides. So that's sort of one part.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThe second piece is good data growth. You saw some like Postgres on Azure. I mean, forgetting even SQL Server, Postgres on Azure is growing, Cosmos is growing. The analytics stuff I talked about with Fabric. It's even the others, whether it is Databricks or even Snowflake on Azure are growing.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSo we feel very good about Fabric, growth and our data growth. Then the cloud native growth. So this is again before we even get to AI, some of the core compute consumption of cloud native players is also pretty very healthy. It was healthy throughout the quarter. We projected to go moving forward as well.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThen the thing to notice is the ratio and I think we mentioned this multiple times before. If you look underneath even chat GPT, in fact that team does a fantastic job of thinking about not only their growth in terms of AI accelerators they need, they use Cosmos DB, they use Postgres, they use core compute and storage. And so there's even a ratio between any AI workload in terms of AI accelerator to others. So those are the four pockets, I'd say, or four different trend lines which all have a relationship with each other. And if I step back, and Amy and I talk a lot about this, this time around there's nothing certain for sure in the future except for one thing, which is our largest business is our infrastructure business.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd the good news here is the next big platform shift builds on that. So it's not a complete rebuild. Having gone through some of these platform shifts where you have to come out on the other side with a full rebuild. If there is good news here and is that we have a good business in Azure that continues to grow and the new platform depends on that. So we want to stay disciplined and execute super well on that.\n\n**Jonathan Neilson** (VP of IR)\nThank you. Thanks, Brent. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Mark Moerdler with Bernstein Research. Please proceed.\n\n**Mark Moerdler** (Managing Director, SVP and Senior Research Analyst)\nThank you very much for taking my question and I will reiterate what my peers have said. Congratulations on the great quarter. Satya and Amy, Microsoft is a very different business than it was during the last recession. Incredible job you've done. If we get into a recession, I hope we don't, how do you think about the stability, the sustainability, revenue volatility of Microsoft today if we were to get into recession?\n\n**Mark Moerdler** (Managing Director, SVP and Senior Research Analyst)\nWould the business react early to recession or late? Would a recession have a more shallow impact on revenue? Any thoughts would\n\n**Satya Nadella** (Chairman &amp; CEO)\nbe appreciated. Maybe I'll start and then Amy should add, Mark. The way at least I think we will approach it is quite frankly be very focused on how we help our customers. If there is any turbulence in the macro. Because one of the things that we feel we can't do just because of the efficiencies of the cloud And the footprint we have and the differentiated sort of layers of the stack from the SaaS application side to the infrastructure side.\n\n**Satya Nadella** (Chairman &amp; CEO)\nI think if you sort of buy into the argument that software is the most malleable resource we have to fight any type of inflationary pressure or any type of growth pressure where you need to do more with less, I think we can be super helpful in that. And so if anything, we would probably have more of that mindset is how do we make sure we are helping our customers. And then of course, we'll look to share gains.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Mark. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Karl Keirstead with UBS. Please proceed.\n\n**Karl Keirstead** (Managing Director - Software Equity Research)\nOkay. Thanks. A number of metrics to applaud, but I think the one that stands out to me is the 16 growth rate lift to Azure from AI. Sachin, Amy, I just wanted to ask if you could unpack that a little bit. Of course, you mentioned that you got a bit of a kicker from capacity coming online. But I'm a little bit more interested in where the demand came in above expectations, like what workload type. It's hard for us to see that on the outside. Was it a surge in ChatGPT inference that landed in Azure?\n\n**Karl Keirstead** (Managing Director - Software Equity Research)\nWas it an uptick in enterprise AI adoption? And Amy, do you think that 16 points could be higher in June? Thank you.\n\n**Amy Hood** (Executive VP &amp; CFO)\nThanks, Carl, for the question. Just to provide some clarity, because I think your question implies something that we didn't mean to imply on the call. First, the real outperformance in Azure this quarter was in our non AI business. So then to talk about the AI business, really what was better was precisely what we said. We talked about this.\n\n**Amy Hood** (Executive VP &amp; CFO)\nWe knew Q3 that we had really matched supply and demand pretty carefully and so didn't expect to do much better than we had guided to on the AI side. We've been quite consistent on that. So the only real upside we saw on the AI side of the business was that we were able to deliver supply early to a number of customers. And being able to do that throughout the quarter creates quite a good benefit to us. But the majority of our outperformance versus where we had expected to be was on the non AI piece of the business.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Karl. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Kash Rangan with Goldman Sachs. Please proceed.\n\n**Kash Rangan** (Managing Director)\nHi, thank you very much. One question for Amy. You've said in the past that you can attain better and better capital efficiency with the cloud business and probably cloud and AI business. Where do you stand today, Amy? Maybe, Satya, you can opine as well, that you've said before that you can slow down your CapEx growth rate while still accelerate Azure, which includes AI.\n\n**Kash Rangan** (Managing Director)\nCan we get a mark to market on that? Thank you so much.\n\n**Amy Hood** (Executive VP &amp; CFO)\nMaybe I'll I'll start, Kash, and let Satya add on. Because I really think when you go back and read some of Satya's comments on how the s curves build on themselves, that's actually the levers that go into the answer of the question that you're asking. And so the way, of course, you've seen that historically is, right, when we went through the prior cloud transitions, you see CapEx accelerate, you build out data center footprints, you slowly fill CPU capacity. And over time, you see software efficiencies and hardware efficiencies build on themselves. And you saw that process for us for, goodness, now quite a long time.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd what Tatya is talking about is how quickly that's happening on the AI side of the business and you add to that model diversity. So think about the same levers plus model efficiency, those compound. Now the one thing that's a little different this time is just the pace. And so when you're seeing that happen, pace in terms of efficiency side, but also pace in terms of the build out, So it can mask some of the progress, but we are working hard across all of the teams, hardware, software, even the build teams to get things in place as quickly as possible, dock to live times. All of that is improving and all of that actually is benefiting us.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd I'll go ahead and say, our margins on the AI side of the business are better than they were at this point by far than when we went through the same transition and the server to cloud transition.\n\n**Satya Nadella** (Chairman &amp; CEO)\nYes. I mean, I think at a macro level, think the way to think about this is you can ask the question, what's the difference between a hosting business and a hyperscale business? It's software. That's I think the gist of it. We asked for sure it's a capital intensive business, but capital efficiency comes from that system wide software optimization.\n\n**Satya Nadella** (Chairman &amp; CEO)\nAnd that's what makes the hyperscale business attractive and that's what we want to just keep executing super well on.\n\n**Kash Rangan** (Managing Director)\nSuper. Thanks so much.\n\n**Jonathan Neilson** (VP of IR)\nOperator, next question please.\n\n**Operator**\nThe next question comes from the line of Mark Murphy with JPMorgan. Please proceed.\n\n**Mark Murphy** (MD - Software Research)\nThank you so much. Satya, you had commented recently that the DeepSeek moment is a real thing. And you had said that software efficiencies mean that the fleet will be aged for a longer time. Can you comment on how those advances are affecting the pace and volume of AI experimentation and activity in the marketplace? And Amy, could we start to consider the possibility that software enhancements might extend the useful life assumption that you're using for GPUs?\n\n**Mark Murphy** (MD - Software Research)\nOr is it a little premature to be thinking that way?\n\n**Satya Nadella** (Chairman &amp; CEO)\nYeah. First of all, I think some of the work that actually OpenAI first pioneered and did with all of the reasoning models and of course DeepSeek has sort of added to it and done good work as well and others as well. The idea that you can have test time compute plus pre training and then some of the great optimization at inference time that has all happened has proven out. I mean if you look at it, I would say for every Moore's law change and movement, there's probably a 10x improvement because of software, right? That's sort of what's happening with these models.\n\n**Satya Nadella** (Chairman &amp; CEO)\nSome of it comes from model architecture, some of that comes from data efficiency, compute efficiency and what have you. So that's what we are riding and we feel that all up when you have a commodity that is getting that better then the question is how do you build out a fleet that's super balanced so that then the workloads can be built and can in fact take advantage of that efficiency at the underlying infrastructure. I mean it's kind of like virtualization. What is the difference between servers and sort of again client server with virtualization? It was efficiency.\n\n**Satya Nadella** (Chairman &amp; CEO)\nWhat is the difference between virtualization and cloud? It was efficiency. What is the difference between this generation of cloud and AI? It's efficiency. So the more you can kind of continue to think about software driving that efficiency is what drives demand ultimately.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd to your specific question, in terms of thinking about the depreciable life of an asset, we like to have a long history before we make any of those. We're focused on getting every bit of useful life we can, of course, out of assets. But to Tatya's point, that tends to be a software question more than a hardware one.\n\n**Mark Murphy** (MD - Software Research)\nThank you.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Mark. Operator, next question please.\n\n**Operator**\nThe next question comes from the line of Kirk Materne with Evercore ISI. Please proceed.\n\n**Kirk Materne** (Senior Managing Director, Equity Research)\nYes, thanks very much and congrats on a great quarter. Amy, you mentioned that the upside in Azure came from the non AI services this time around. I was wondering if you could just talk a little bit more about that. And I guess as you look forward, maybe what's different this go round versus what we saw a few years ago when obviously things like optimization weighed on the growth a little bit? It sounds like the product portfolio is much broader right now.\n\n**Kirk Materne** (Senior Managing Director, Equity Research)\nBut just wondering if you could add some color on that front. Thank you.\n\n**Amy Hood** (Executive VP &amp; CFO)\nSure. And thanks for the question, Kirk. When we go to non AI, I talked a little bit about this. In general, we saw better than expected performance across our segments, but we saw acceleration in our largest customers. We call that the enterprise segment in general.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd then in what we talked about of our scale motions where we had some challenges in Q2, things were a little better. And we still have some work to do in our scale motions, and we're encouraged by our progress. We're excited to stay focused on that as, of course, we work through the final quarter of our fiscal year. By geo, the performance was pretty consistent. Satya actually highlighted some of the workloads that came in a little better than we thought.\n\n**Amy Hood** (Executive VP &amp; CFO)\nObviously, just some good consistent work on migrations, good execution by the sales and partner teams, the data workloads he went through. And so in general, Kirk, I wouldn't say it's anything beyond that. I do think it was improved execution, And I was happy to see it, but there's still some work to do on our scale motions in particular.\n\n**Kirk Materne** (Senior Managing Director, Equity Research)\nThank you.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Kirk. Operator, we have time for one last question.\n\n**Operator**\nThe last question will come from the line of Alex Zukin with Wolfe Research. Please proceed.\n\n**Alex Zukin** (Analyst)\nHey, guys. Thanks for squeezing me in. And again, just amazing congratulations on those Azure numbers, which I think are quite honestly just inspiring. So so maybe to Amy, to to the point that you're making that the surprise factor was on the non Azure, non AI side of the house. And and it sounds like that there's confidence in that continuing, beyond.\n\n**Alex Zukin** (Analyst)\nHow much of that are you starting to see the pull pull in of the non AI driven by the AI portion of Azure? And on the AI portion specifically, as test time compute really just blows out kind of prior conceptions of scaling law challenges, how much does that change potentially the curve of the AI Azure growth as you go forward here over the next few quarters?\n\n**Amy Hood** (Executive VP &amp; CFO)\nHi, Doc. Let me, first of all, say I think we've talked about this quite a bit. It's always good to have a chance to to iterate this. It's getting harder and harder to separate what an AI workload is from a non AI workload. And we've talked about it this way, I think, in most instances, to make sure people understood that when we were accelerating all of our CapEx spend over the past two point five three years now, that people had confidence that we were turning that into revenue and product in a way that was transparent and that everyone could understand really the goals that we had set for ourselves and for our partners and customers in terms of building product that turned to Revit. But if you take a step back from that, it's that these workloads are being built, GPU, CPU, storage, network, all the same things. And so I think, really, what we're talking about is really how Satya talked about in one of the earlier questions. You know, we're seeing digital natives. Digital natives build workloads. They do AI work.\n\n**Amy Hood** (Executive VP &amp; CFO)\nThey do non AI work. Do they tend to do that work in the same cloud? Lots of times. Sometimes, it's all in the same place. Not all the time, but that relationship gets stronger and stronger as people pivot to more of AI heavy workloads.\n\n**Amy Hood** (Executive VP &amp; CFO)\nAnd so I think you're starting to see some of that relationship. I think we'll continue to see that as AI workloads continue to get built and experimented with and proof of concepts get expanded. And so I think I mostly focus on the fact that together we saw good performance in Q3 on Azure. Azure inclusive of both components in terms of our execution, in terms of the field and partner teams and backlog and conversion and interesting workloads and adding customer value and solving real problems and adding real value. And I think that's probably how I would approach that number more than trying to separate it in the way that even we have talked about it, but for very different reasons.\n\n**Jonathan Neilson** (VP of IR)\nThanks, Alex. That wraps up the Q and A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with you all soon.\n\n**Satya Nadella** (Chairman &amp; CEO)\nThank you.\n\n**Amy Hood** (Executive VP &amp; CFO)\nThank you.\n\n**Operator**\nThis concludes today's conference. You may disconnect your lines at this time. Enjoy the rest of your day.",
        "fetched_at": "2026-02-04T16:09:35.349Z"
      },
      {
        "ticker": "MSFT",
        "title": "Yahoo Finance",
        "published_date": "Jan 29, 2025, 5:30 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/MSFT/earnings/MSFT-Q2-2025-earnings_call-251674.html",
        "content": "**Operator**\nGreetings and welcome to the Microsoft Fiscal Year 2025 Second Quarter Earnings Conference Call. At this time, all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. If anyone should require operator assistance, please press star zero on your telephone keypad. As a reminder, this conference is being recorded. It is now my pleasure to introduce your host, Brett Iverson, Vice President of Investor Relations. Please go ahead.\n\n**Brett Iversen** (VP of Investor Relations)\nGood afternoon, and thank you for joining us today. On the call with me are Satya Nadella, Chairman and Chief Executive Officer, Amy Hood, Chief Financial Officer, Alice Jalla, Chief Accounting Officer, and Keith Doliver, Corporate Secretary and Deputy General Counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to supplement our prepared remarks during today's call and provides the reconciliation of differences between GAAP and non-GAAP financial measures.\n\n**Brett Iversen** (VP of Investor Relations)\nMore detailed outlook slides will be available on the Microsoft Investor Relations website when we provide outlook commentary on today's call. On this call, we will discuss certain non-GAAP items. The non-GAAP financial measures provided should not be considered as a substitute for or superior to the measures of financial performance prepared in accordance with GAAP.\n\n**Brett Iversen** (VP of Investor Relations)\nThey are included as additional clarifying items to aid investors in further understanding the company's second quarter performance, in addition to the impact these items and events have on the financial results. All growth comparisons we make on the call today relate to the corresponding period of last year, unless otherwise noted.\n\n**Brett Iversen** (VP of Investor Relations)\nWe will also provide growth rates in constant currency when available as a framework for assessing how our underlying business has performed, excluding the effect of foreign currency rate fluctuations. Where growth rates are the same in constant currency, we will refer to the growth rate only. We will post our prepared remarks to our website immediately following the call until the complete transcript is available. Today's call is being webcast live and recorded.\n\n**Brett Iversen** (VP of Investor Relations)\nIf you ask a question, it will be included in our live transmission, in the transcript, and in any future use of the recording. You can replay the call and view the transcript on the Microsoft Investor Relations website. During this call, we'll be making forward-looking statements, which are predictions, projections, or other statements about future events.\n\n**Brett Iversen** (VP of Investor Relations)\nThese statements are based on current expectations and assumptions that are subject to risks and uncertainties. Actual results could materially differ because of factors discussed in today's earnings press release, in the comments made during this conference call, and in the risk factor section of our Form 10-K, Forms 10-Q, and other reports and filings with the Securities and Exchange Commission. We do not undertake any duty to update any forward-looking statement. And with that, I'll turn the call over to Satya.\n\n**Satya Nadella** (CEO)\nThank you, Brett. This quarter, we saw continued strength in Microsoft Cloud, which surpassed $40 billion in revenue for the first time, up 21% year over year. Enterprises are beginning to move from proof of concepts to enterprise-wide deployments to unlock the full ROI of AI.\n\n**Satya Nadella** (CEO)\nAnd our AI business has now surpassed an annual revenue run rate of $13 billion, up 175% year over year. Before I get into the details of the quarter, I want to comment on the core thesis behind our approach to how we manage our fleet and how we allocate our capital to compute. AI scaling laws continue to compound across both pre-training and inference-time compute. We ourselves have been seeing significant efficiency gains in both training and inference for years now.\n\n**Satya Nadella** (CEO)\nOn inference, we have typically seen more than 2x price performance gain for every hardware generation and more than 10x for every model generation due to software optimizations. And as AI becomes more efficient and accessible, we will see exponentially more demand. Therefore, much as we have done with the commercial cloud, we are focused on continuously scaling our fleet globally and maintaining the right balance across training and inference, as well as geo-distribution.\n\n**Satya Nadella** (CEO)\nFrom now on, it's a more continuous cycle governed by both revenue growth and capability growth, thanks to the compounding effects of software-driven AI scaling laws and Moore's Law. With that, I will walk through the progress we are making across every layer of the tech stack. Azure is the infrastructure layer for AI. We continue to expand our data center capacity in line with both near-term and long-term demand signals.\n\n**Satya Nadella** (CEO)\nWe have more than doubled our overall data center capacity in the last three years, and we have added more capacity last year than any other year in our history. Our data centers, networks, racks, and silicon are all coming together as a complete system to drive new efficiencies to power both the cloud workloads of today and the next generation AI workloads.\n\n**Satya Nadella** (CEO)\nWe continue to take advantage of Moore's Law and refresh our fleet, as evidenced by our support of the latest from AMD, Intel, NVIDIA, as well as our first-party silicon innovation from Maia, Cobalt, Boost, and HSM. When it comes to cloud migrations, we continue to see customers like UBS move workloads to Azure. UBS alone migrated mainframe workloads encompassing nearly 400 billion records and two petabytes of data. And we remain the cloud of choice for customers' mission-critical Oracle, SAP, and VMware apps.\n\n**Satya Nadella** (CEO)\nAt the data layer, we are seeing Microsoft Fabric break out. We now have over 19,000 paid customers from Hitachi to Johnson Controls to Schaeffler. Fabric is now the fastest-growing analytics product in our history. Power BI is also deeply integrated with Fabric, with over 30 million monthly active users, up 40% since last year. Beyond Fabric, we are seeing new AI-driven data patterns emerge. If you look underneath ChatGPT or Copilot or enterprise AI apps, you see the growth of raw storage, database services, and app platform services as these workloads scale. The number of Azure OpenAI apps running on Azure databases and Azure app services more than doubled year over year, driving significant growth in adoption across SQL Hyperscale and Cosmos DB. Now on to AI platform and tools. As we shared last week, we are thrilled OpenAI has made a new large Azure commitment.\n\n**Satya Nadella** (CEO)\nThrough our strategic partnership, we continue to benefit mutually from each other's growth. With OpenAI's APIs exclusively running on Azure, customers can count on us to get access to the world's leading models. OpenAI has a lot more coming soon, so stay tuned.\n\n**Satya Nadella** (CEO)\nAzure AI Foundry features best-in-class tooling, runtimes to build agents, multi-agent apps, AI ops, API access to thousands of models. Two months in, we already have more than 200,000 monthly active users. We are well-positioned with our support of both OpenAI's leading models and the best selection of open-source models and SLMs. DeepSeek-R1 launched today via the model catalog on Foundry and GitHub with automated red teaming, content safety integration, and security scanning. Our Phi family of SLMs has now been downloaded over 20 million times.\n\n**Satya Nadella** (CEO)\nAnd we also have more than 30 models from partners like Bayer, Paige, Rockwell Automation, and Siemens to address industry-specific use cases. With AI, how we build, deploy, and maintain code is fundamentally changing. And GitHub Copilot is increasingly the tool of choice for both digital natives like ASOS and Spotify, as well as the world's largest enterprises like HP, HSBC, and KPMG.\n\n**Satya Nadella** (CEO)\nWe have been delighted by the early response to GitHub Copilot in VS Code with more than a million sign-ups in just the first week post-launch. All up, GitHub now is home to 150 million developers, up 50% over the past two years. Now on to the future of work. Microsoft 365 Copilot is the UI for AI. It helps supercharge employee productivity and provides access to a swarm of intelligent agents to streamline employee workflow.\n\n**Satya Nadella** (CEO)\nWe are seeing accelerated customer adoption across all deal sizes as we win new Microsoft 365 Copilot customers and see the majority of existing enterprise customers come back to purchase more seats. When you look at customers who purchased Copilot during the first quarter of availability, they have expanded their seats collectively by more than 10x over the past 18 months.\n\n**Satya Nadella** (CEO)\nTo share just one example, Novartis has added thousands of seats each quarter over the past year and now have 40,000 seats. Barclays, Carrier Group, Pearson, and University of Miami all purchased 10,000 or more seats this quarter, and overall, the number of people who use Copilot daily again more than doubled quarter over quarter. Employees are also engaging with Copilot more than ever. Usage intensity increased more than 60% quarter over quarter, and we are expanding our TAM with Copilot Chat, which was announced earlier this month.\n\n**Satya Nadella** (CEO)\nCopilot Chat, along with Copilot Studio, is now available to every employee to start using agents right in the flow of work. With Copilot Studio, we are making it as simple to build an agent as it is to create an Excel spreadsheet. More than 160,000 organizations have already used Copilot Studio, and they collectively created more than 400,000 custom agents in the last three months alone, up over 2x quarter over quarter.\n\n**Satya Nadella** (CEO)\nWe have also introduced our own first-party agents to facilitate meetings, manage projects, resolve common HR and IT queries, and access SharePoint data. We also continue to see partners like Adobe, SAP, ServiceNow, and Workday build their third-party agents and integrate with Copilot. What is driving Copilot as the UI for AI, as well as our momentum with agents, is our rich data cloud, which is the world's largest source of organizational knowledge.\n\n**Satya Nadella** (CEO)\nBillions of emails, documents, and chats, hundreds of millions of Teams meetings, and millions of SharePoint sites are added each day. This is the enterprise knowledge cloud. It is growing fast, up over 25% year over year. More broadly, what we are seeing is Copilot plus agents disrupting business applications, and we are leaning into this. With Dynamics 365, we took share as organizations like Ecolab, Lenovo, RTX, TotalEnergies, and Vaisala switched to our AI-powered apps from legacy providers.\n\n**Satya Nadella** (CEO)\nIn healthcare, DAX Copilot surpassed 2 million monthly physician-patient encounters, up 54% quarter over quarter. It is being used by top providers like Mass General Brigham, Michigan Medicine, Vanderbilt University Medical Center to increase productivity of their physicians. When it comes to Windows, we are seeing momentum build as we approach end of support for Windows 10. Customers are choosing the latest Windows 11 devices for their enhanced security and advanced AI capabilities.\n\n**Satya Nadella** (CEO)\n15% of premium-priced laptops in the U.S. this holiday were Copilot plus PCs. And we expect the majority of the PCs sold in the next several years to be Copilot plus PCs. We also see more and more developers from Adobe and CapCut to WhatsApp build apps that leverage built-in NPUs.\n\n**Satya Nadella** (CEO)\nAnd they will soon be able to run DeepSeek's R1 Distill models locally on Copilot plus PCs, as well as the vast ecosystem of GPUs available on Windows. And beyond Copilot plus PCs, the most powerful AI workstation for local development is a Windows PC running WSL2 powered by NVIDIA RTX GPUs. Now on to security.\n\n**Satya Nadella** (CEO)\nWe continue to make progress with our Secure Future initiative, and we are applying what we have learned, introducing over 80 new product capabilities over the past year. With Security Copilot, organizations across private and public sector, like City of Johannesburg, Eastman, Intesa, National Australia Bank, NTT, can resolve incidents 30% faster.\n\n**Satya Nadella** (CEO)\nData governance is increasingly critical, and customers now use Microsoft Purview to audit over two billion Copilot interactions for safe and compliant use. Now on to our consumer businesses, starting with LinkedIn. More professionals than ever are engaging in high-value conversations on LinkedIn, with comments up 37% year over year. Short-form video continues to grow on the platform, with video creation all up, growing at twice the rate of other post formats.\n\n**Satya Nadella** (CEO)\nWe're also innovating with agents to help recruiters and small businesses find qualified candidates faster, and our hiring business again took share in subscriptions. LinkedIn Premium surpassed $2 billion in annual revenue for the first time this quarter. Subscriber growth has increased nearly 50% over the past two years, and nearly 40% of subscribers have used our AI features to improve their profiles, and LinkedIn Marketing Solution remains the leader in B2B advertising.\n\n**Satya Nadella** (CEO)\nNow on to search advertising and news. We once again took share across Bing and Edge. Edge surpassed 30% market share in the US on Windows and has taken share for 15 consecutive quarters. The investments we have made in improving our ad rates are paying off, and advertisers increasingly see our network as an essential platform to optimize ROI, and our Copilot consumer app is seeing increased engagement and retention with its improved speed, unique personality, first-of-its-kind features like Copilot Vision.\n\n**Satya Nadella** (CEO)\nJust today, we made Think Deeper, powered by O1, free for all Copilot users globally. Now on to gaming. We are focused on improving the profitability of the business in order to position it for long-term growth driven by higher margin content and platform services. And we are delivering on this plan. Black Ops 6 was a top-selling game on Xbox and PlayStation this quarter and saw more players in its launch quarter than any other paid release in the franchise history.\n\n**Satya Nadella** (CEO)\nAnd we saw rave reviews of Indiana Jones and the Great Circle, which has already been played by more than 4 million people. We also continue to see strong momentum for Xbox Cloud Gaming, with a record 140 million hours streamed this quarter. All up, Game Pass set a new quarterly record for revenue and grew its PC subscriber base by over 30% as we focus on driving fully paid subscribers across endpoints. In closing, we continue to innovate across our tech stack to help our customers in this AI era. And I'm energized by the many opportunities ahead. With that, let me turn it over to Amy.\n\n**Satya Nadella** (CEO)\nThank you, Satya. And good afternoon, everyone. This quarter, revenue was $69.6 billion, up 12%. Gross margin dollars increased 13% and 12% in constant currency, while operating income increased 17% and 16% in constant currency. And earnings per share was $3.23, an increase of 10%.\n\n**Satya Nadella** (CEO)\nWe delivered another quarter of double-digit top and bottom-line growth. Results were driven by strong demand for our cloud and AI offerings, while we also improved our operating leverage with higher-than-expected operating income growth. As you heard from Satya, our AI business annual revenue run rate surpassed $13 billion and was above expectations.\n\n**Satya Nadella** (CEO)\nCommercial bookings increased 67% and 75% in constant currency and were significantly ahead of expectations driven by Azure commitments from OpenAI. Execution was strong across our core annuity sales motions, with growth in the number of $100 million-plus contracts for both Azure and Microsoft 365. Commercial remaining performance obligation increased to $298 billion, up 34% and 36% in constant currency.\n\n**Satya Nadella** (CEO)\nRoughly 40% will be recognized in revenue in the next 12 months, up 21% year over year. The remaining portion recognized beyond the next 12 months increased 45% and this quarter, our annuity mix was 97%. FX did not have a significant impact on our results and was roughly in line with expectations on total company revenue, More Personal Computing revenue, total company COGS, and operating expense. FX decreased revenue more than expected in our commercial segments.\n\n**Satya Nadella** (CEO)\nMicrosoft Cloud revenue was $40.9 billion and grew 21%. Microsoft Cloud gross margin percentage was 70%, in line with expectations, and decreased 2 points over year, driven by scaling our AI infrastructure. Company gross margin percentage increased slightly year over year to 69%, primarily driven by sales mix shift to higher margin businesses, as well as improvement in gaming and search, partially offset by the impact of scaling our AI infrastructure.\n\n**Satya Nadella** (CEO)\nOperating expenses increased 5%, lower than expected, and operating margins increased 2 points year over year to 45%. The better-than-expected margin expansion was driven by delivering efficiencies across our businesses as we invest to scale AI infrastructure and build AI applications. At a total company level, headcount at the end of December was 2% higher than a year ago and was relatively unchanged from last quarter.\n\n**Satya Nadella** (CEO)\nNow to our segment results. Revenue from productivity and business processes was $29.4 billion and grew 14% and 13% in constant currency, even with the unfavorable FX impact noted earlier. Results were ahead of expectations, driven by Microsoft 365 Commercial.\n\n**Satya Nadella** (CEO)\nMicrosoft 365 Commercial Cloud revenue increased 16% and 15% in constant currency, slightly ahead of expectations due to better-than-expected performance in E5 and Microsoft 365 Copilot. With M365 Copilot, we continued to see growth in adoption, expansion, and usage. Our growth was again driven by E5 and M365 Copilot. Paid M365 Commercial seats grew 7% year over year, with installed base expansion across all customer segments, though primarily in our small and medium business and frontline worker offerings.\n\n**Satya Nadella** (CEO)\nM365 Commercial products revenue increased 13%, significantly ahead of expectations, driven by higher-than-expected transactional purchasing with the launch of Office 2024, as well as the Windows Commercial on-premises components from the better-than-expected performance of M365 Suite noted earlier.\n\n**Satya Nadella** (CEO)\nM365 Consumer Cloud revenue increased 8%, slightly ahead of expectations. We saw continued momentum in M365 Consumer subscriptions, which grew 10% to 86.3 million, with mix shift to M365 Basic. LinkedIn revenue increased 9%, with continued growth across all lines of business. In our Talent Solutions business, results were slightly below expectations, driven by continued weakness in the hiring market in key verticals.\n\n**Satya Nadella** (CEO)\nDynamics 365 revenue increased 19% and 18% in constant currency, slightly ahead of expectations, with growth across all workloads. Segment gross margin dollars increased 13% and 12% in constant currency, and gross margin percentage decreased slightly year over year, driven by scaling our AI infrastructure. Operating expenses increased 6%, and operating income increased 16% and 15% in constant currency. Next, the Intelligent Cloud segment.\n\n**Satya Nadella** (CEO)\nRevenue was $25.5 billion and grew 19%, with more unfavorable FX impact than expected. Excluding the unfavorable FX impact, results in Azure non-AI services, on-prem server, and enterprise and partner services were slightly lower than expected, partially offset by better-than-expected results in Azure AI services.\n\n**Satya Nadella** (CEO)\nAzure and other cloud services revenue grew 31%. Azure growth included 13 points from AI services, which grew 157% year over year and was ahead of expectations, even as demand continued to be higher than our available capacity. Growth in our non-AI services was slightly lower than expected due to go-to-market execution challenges, particularly with our customers that we primarily reached through our scale motions, as we balanced driving near-term non-AI consumption with AI growth.\n\n**Satya Nadella** (CEO)\nIn our on-premises server business, revenue decreased 3%, slightly below expectations, driven by slower-than-expected purchasing around Windows Server 2025 launch. Enterprise and partner services revenue decreased 1%, below expectations, with lower-than-expected performance across enterprise support services and industry solutions.\n\n**Satya Nadella** (CEO)\nSegment gross margin dollars increased 12% and 13% in constant currency, and gross margin percentage decreased 4 points year over year, driven by scaling our AI infrastructure. Operating expenses increased 10%, and operating income grew 14%. Now to more personal computing.\n\n**Satya Nadella** (CEO)\nRevenue was $14.7 billion, relatively unchanged year over year, with better-than-expected results driven primarily by Windows OEM pre-builds, usage from a third-party partnership in search, as well as Call of Duty launch performance in gaming.\n\n**Satya Nadella** (CEO)\nWindows OEM and devices revenue increased 4% year over year, ahead of expectations, driven by commercial inventory builds in advance of Windows 10 and support, as well as uncertainty around tariffs. Search and news advertising revenue ex-TAC increased 21% and 20% in constant currency, ahead of expectations, driven by usage from a third-party partnership. Growth continues to be driven by rate expansion and healthy volume growth in both Edge and Bing.\n\n**Satya Nadella** (CEO)\nIn gaming, revenue decreased 7% and 8% in constant currency, as content and services growth continued to be offset by hardware declines. Xbox content and services revenue increased 2%, ahead of expectations, driven by stronger-than-expected performance in Blizzard and Activision content, including Call of Duty.\n\n**Satya Nadella** (CEO)\nSegment gross margin dollars increased 13% and 12% in constant currency. Gross margin percentage increased 6 points year over year, driven by sales mix shift to higher margin businesses, as well as strong execution on margin improvement in gaming and search. Operating expenses decreased 1%. Operating income increased 32% and 30% in constant currency, driven by continued prioritization of higher margin opportunities.\n\n**Satya Nadella** (CEO)\nNow back to total company results. Capital expenditures, including finance leases, were $22.6 billion, in line with expectations, and cash paid for PP&E was $15.8 billion. More than half of our cloud and AI-related spend was on long-lived assets that will support monetization over the next 15 years and beyond. The remaining cloud and AI spend was primarily for servers, both CPUs and GPUs, to serve customers based on demand signals, including our customer contracted backlog.\n\n**Satya Nadella** (CEO)\nCash flow from operations was $22.3 billion, up 18%, driven by strong cloud billings and collections, partially offset by higher supplier, employee, and tax payments. Free cash flow was $6.5 billion, down 29% year over year, reflecting the capital expenditures noted earlier. This quarter, other income and expense was negative $2.3 billion, lower than our October guidance due to the impairment charge from our cruise investment. Our effective tax rate came in slightly lower than anticipated at 18%. And finally, we returned $9.7 billion to shareholders through dividends and share repurchases.\n\n**Satya Nadella** (CEO)\nNow, moving to our Q3 outlook, which, unless specifically noted otherwise, is on a U.S. dollar basis. First, FX. With the strengthening of the U.S. dollar since October, we now expect FX to decrease total revenue growth by 2 points. Within the segments, we expect FX to decrease revenue growth by 2 points in productivity and business processes and intelligent cloud, and roughly 1 point in more personal computing.\n\n**Satya Nadella** (CEO)\nWhen compared to our October guidance assumptions on Q3 FX impact, this is a decrease to total revenue of roughly $1 billion. We expect FX to decrease COGS growth by approximately 2 points and operating expense growth by approximately 1 point.\n\n**Satya Nadella** (CEO)\nOur outlook has many of the trends we saw in Q2 continue through Q3. Demand for our differentiated cloud and AI offerings across the Microsoft Cloud should drive another quarter of strong growth. In commercial bookings, with a relatively flat expiry base and a strong prior-year comparable in terms of large Azure contracts, we expect growth to be roughly flat year over year.\n\n**Satya Nadella** (CEO)\nWe expect consistent execution across our core annuity sales motions and continued long-term commitments to our platform. As a reminder, larger long-term Azure contracts, which are more unpredictable in their timing, can drive increased quarterly volatility in our bookings growth rate. Microsoft Cloud gross margin percentage should be roughly 69%, down year over year, driven by the impact of scaling our AI infrastructure.\n\n**Satya Nadella** (CEO)\nNext, to segment guidance. In productivity and business processes, we expect revenue to grow between 11%-12% in constant currency, or $29.4-$29.7 billion USD. Microsoft 365 Commercial Cloud revenue growth should be between 14%-15% in constant currency, relatively stable compared to our better-than-expected Q2 results.\n\n**Satya Nadella** (CEO)\nWe expect continued ARPU growth through E5 and M365 Copilot, and we again expect some seat growth moderation given the size of the installed base. For M365 Commercial products, we expect revenue to be relatively unchanged year over year. As a reminder, M365 Commercial products include Windows Commercial on-premises components of M365 Suites. So our quarterly revenue growth can have variability primarily from in-period revenue recognition, depending on the mix of contracts.\n\n**Satya Nadella** (CEO)\nM365 Consumer Cloud revenue growth should be in the mid to high single digits, driven by M365 subscriptions. For LinkedIn, we expect revenue growth in the low to mid single digits. Although we expect growth across all businesses, the Q2 trends in Talent Solutions should continue in Q3 as a headwind to growth. And in Dynamics 365, we expect revenue growth to be in the mid-teens, driven by continued growth across all workloads.\n\n**Satya Nadella** (CEO)\nFor Intelligent Cloud, we expect revenue to grow between 19% and 20% in constant currency, or $25.9-$26.2 billion US dollars. Revenue will continue to be driven by Azure, which, as a reminder, can have quarterly variability primarily from in-period revenue recognition, depending on the mix of contracts. In Azure, we expect Q3 revenue growth to be between 31% and 32% in constant currency, driven by strong demand for our portfolio of services.\n\n**Satya Nadella** (CEO)\nAs we shared in October, the contribution from our AI services will grow from increased AI capacity coming online. In non-AI services, healthy growth continues, although we expect ongoing impact through H2 as we work to address the execution challenges noted earlier, and while we expect to be AI capacity constrained in Q3, by the end of FY25, we should be roughly in line with near-term demand, given our significant capital investments.\n\n**Satya Nadella** (CEO)\nIn our on-premises server business, we expect revenue to decline in the mid single digits, driven by a decrease in transactional purchasing. And in enterprise and partner services, we expect revenue growth to be in the low to mid single digits. In More Personal Computing, we expect revenue to be $12.4-$12.8 billion US dollars, with continued prioritization of higher margin opportunities.\n\n**Satya Nadella** (CEO)\nWindows OEM and devices revenue should decline in the low to mid single digits. We expect revenue from Windows OEM to be relatively flat year over year, as our outlook assumes inventory levels will normalize. Actual results may differ based on current tariff uncertainties.\n\n**Satya Nadella** (CEO)\nDevices revenue will decline. Search and news advertising ex-TAC revenue growth should be in the mid-teens, from continued growth in both volume and revenue per search, with share gains across Edge and Bing. Growth is expected to moderate from last quarter, primarily due to additional FX impact, and as the third-party partnership usage noted earlier returns to more normal levels.\n\n**Satya Nadella** (CEO)\nSearch ex-TAC growth will be higher than overall search and news advertising revenue growth, which we expect to be in the mid to high single digits. In gaming, we expect revenue growth to be in the low single digits. We expect Xbox content and services revenue growth to be in the low to mid single digits, driven by first-party content, as well as Xbox Game Pass. Hardware revenue will decline year over year.\n\n**Satya Nadella** (CEO)\nNow back to company guidance. We expect COGS to grow between 19% and 20% in constant currency, or to be between $21.65-$21.85 billion, and operating expense to grow between 5% and 6% in constant currency, or to be between $16.4-$16.5 billion.\n\n**Satya Nadella** (CEO)\nOther income and expense is expected to be roughly negative $1 billion, primarily driven by investments accounted for under the equity method. As a reminder, we do not recognize mark-to-market gains or losses on equity method investments. And lastly, we expect our Q3 effective tax rate to be approximately 18%. Now, some additional thoughts on the rest of the fiscal year and beyond.\n\n**Satya Nadella** (CEO)\nFirst, FX. With the strengthening of the U.S. dollar since October, we now expect FX to decrease Q4 revenue and COGS growth by more than one point and operating expense growth by roughly one point. Next, capital expenditures. We expect quarterly spend in Q3 and Q4 to remain at similar levels as our Q2 spend. In FY26, we expect to continue investing against strong demand signals, including customer contracted backlog we need to deliver against across the entirety of our Microsoft Cloud.\n\n**Satya Nadella** (CEO)\nHowever, the growth rate will be lower than FY25, and the mix of spend will begin to shift back to short-lived assets, which are more correlated to revenue growth. As a reminder, our long-lived infrastructure investments are fungible, enabling us to remain agile as we meet customer demand globally across our Microsoft Cloud, including AI workloads.\n\n**Satya Nadella** (CEO)\nAs always, there can be quarterly spend variability from cloud infrastructure build-outs and the timing of delivery of finance leases. For the full fiscal year, we continue to expect double-digit revenue and operating income growth as we focus on delivering efficiencies across both COGS and operating expense. And given the operating leverage that we've delivered throughout the year, inclusive of efficiency gains as we scale our AI infrastructure and utilize our own AI solutions, we now expect FY25 operating margins to be up slightly year over year.\n\n**Satya Nadella** (CEO)\nAnd finally, our FY25 full-year effective tax rate should be between 18%-19%. In closing, we are committed to delivering real-world AI solutions that help customers grow and improve their results. We are confident in our leadership position as we grow with our customers . Before turning to Q&A, I have one special thank you. Brett Iverson is moving to a new role here as the head of our Americas Sales Finance Team. On behalf of the company, thank you for your tremendous impact leading investor relations for the past four years and for the partnership with both Satya and me. And I'd like to welcome Jonathan Nielsen, the former head of finance for our security products, who is returning to investor relations to lead the team. With that, let's go to Q&A, Brett.\n\n**Satya Nadella** (CEO)\nThanks, Amy. We'll now move over to Q&A. Out of respect for others on the call, we request that participants please only ask one question. Operator, can you please repeat your instructions?\n\n**Satya Nadella** (CEO)\nThank you. Ladies and gentlemen, if you would like to ask a question, please press Star 1 on your telephone keypad, and a confirmation tool will indicate your line's in the question queue. You may press Star 2 if you would like to remove your question from the queue. For participants using speaker equipment, it may be necessary to pick up your handset before pressing the Star keys. Our first question comes from the line of Keith Weiss with Morgan Stanley. Please proceed . Excellent. Thank you, guys, for taking the question. Echoing Amy's comments, Brett, congratulations on the new role. It's been a pleasure working with you, and best of luck in that new role. Looking at the quarter, another really solid quarter when it comes to commercial bookings. But again, we were a little bit disappointed on Azure coming in at the bottom end of the guidance range.\n\n**Satya Nadella** (CEO)\nAmy, I was hoping you could dig into perhaps what some of those execution issues were, what the resolutions to those issues were, and do we still feel comfortable in the acceleration into the back half of the year that you were talking about after the June quarter and after last quarter? Thank you very much.\n\n**Satya Nadella** (CEO)\nThanks, Keith. Let me spend a little time on that, about what we saw in Q2, and give you some additional background on the near-term execution issues that we're talking about. First, let me be very specific. They are in the non-AI ACR component.\n\n**Satya Nadella** (CEO)\nOur Azure AI results were better than we thought due to very good work by the operating teams pulling in some delivery dates, even by weeks. When you're capacity constrained, weeks matter, and it was good execution by the team, and you see that in the revenue results. On the non-AI side, really the challenges were in what we call the sales motions.\n\n**Satya Nadella** (CEO)\nSo think about primarily, these are customers we reach through partners and through more indirect methods of selling. And really, the art form there is as these customers, which we reach in this way, are trying to balance how do you do an AI workload with continuing some of the work they've done on migrations and other fundamentals. We then took our sales motions in the summer and really changed to try to balance those two.\n\n**Satya Nadella** (CEO)\nAs you do that, you learn with your customers and with your partners on sort of getting that balance right between where to put our investments, where to put the marketing dollars, and importantly, where to put people in terms of coverage and being able to help customers make those transitions. And I think we are going to make some adjustments to make sure we are in balance because when you make those changes in the summer, by the time it works its way through the system, you can see the impacts and whether you have that balance right.\n\n**Satya Nadella** (CEO)\nAnd so the teams are working through that. They're already making adjustments. And I expect, well, we will see some impact through H2 just because when you work through the scale motion, it can take some time for that to adjust. I feel good that the teams understand and are working through that, so hopefully that's just helpful on that, then we've talked a little bit about Q3, and so we've talked about 31%-32% after publishing a 31% this quarter.\n\n**Satya Nadella** (CEO)\nOur AI results that we had felt good about and talked about our ability to land that revenue is the same, so again, in Q3, we are working from a pretty constrained capacity place, and that's no different than it was our expectation to be in that position last October when I talked to you all, and when I talk about being in a capacity constraint, it takes two things. You have to have space, which I generally call long-lived assets, right? That's the infrastructure and the land, and then you have to have kits.\n\n**Satya Nadella** (CEO)\nWe're continuing, and you've seen that's why our spend has pivoted this way, to be in the long-lived investment. We have been short power and space. And so as you see those investments land that we've made over the past three years, we get closer to that balance by the end of this year.\n\n**Satya Nadella** (CEO)\nAnd so the confidence on the AI side continues to be there in terms of being able to sell, utilize, and be, I think, encouraged by the signals. What we're seeing is waiting to see just how the non-AI ACR works through the scale motions in H2. But in general, the only thing that's changed is really that scale motion from my seat. Keith, hope that's helpful, Satya.\n\n**Satya Nadella** (CEO)\nYeah. I think, Amy, just one thing I'd add, Keith, to your question is, as Amy said, the AI growth rate is actually better than what we expected, and we worked through some of the supply stuff, and more importantly, some of the workloads are scaling well.\n\n**Satya Nadella** (CEO)\nAnd when you look underneath any of these AI workloads, the other thing that is good is the ratio of even what we would call just regular storage, data services, app services. So underneath a ChatGPT or a Copilot or even the emerging AI workloads in the enterprise. So that's all good. The enterprise workloads, whether it's SAP or whether it's VMware migrations, what have you, that's also in good shape. And it's just the sales pace where Amy talked about this nuance, right? How do you really tweak the incentives, go-to-market?\n\n**Satya Nadella** (CEO)\nAt a time of platform shifts, you kind of want to make sure you lean into even the new design wins, and you just don't keep doing the stuff that you did in the previous generation. That's the art form Amy was referencing to make sure you get the right balance. Let me put it this way. You would rather win the new than just protect the past. That's sort of one of the things that we definitely will lean into always.\n\n**Satya Nadella** (CEO)\nThanks, Keith. Operator, next question, please.\n\n**Satya Nadella** (CEO)\nThe next question comes from the line of Mark Moordler with Bernstein Research. Please proceed.\n\n**Satya Nadella** (CEO)\nThank you very much for taking my question. Can you give more color on what drove the far larger-than-expected Microsoft AI revenue? We talked a bit about the Azure AI component of it, but can you give more color on that? Our estimates are that the Copilot was much bigger than we expected and growing much faster. Any more details on the breakdown of what that Microsoft AI beat would be great. Thanks.\n\n**Satya Nadella** (CEO)\nThanks, Mark, for the question. Yes, that was, as we talked about, better than expected. A couple of pieces to that, which you've correctly identified. Number one is the Azure component we just talked about. And the second piece, you're right, Microsoft Copilot was better.\n\n**Satya Nadella** (CEO)\nAnd what was important about that, it was we saw strength both in seats, both new seats and expansion seats, as Satya talked about, and usage, which doesn't directly impact revenue, but of course, indirectly does as people get more and more value out of it. And also, price per seat was actually quite good, which doesn't have a good signal for value. So those are the biggest pieces, Mark, of that sort of outperformance in terms of our expectations.\n\n**Satya Nadella** (CEO)\nThank you.\n\n**Satya Nadella** (CEO)\nOperator, next question, please.\n\n**Satya Nadella** (CEO)\nThe next question comes from the line of Brent Thill with Jefferies. Please proceed.\n\n**Satya Nadella** (CEO)\nThanks. Satya, you mentioned DeepSeek a couple of times in your prepared remarks. I think everyone would love your thoughts on what you're seeing there. And are we seeing AI scale now at lower cost? Are we reaching a mark where you can see that, or do we still have some time to go? Thanks for your thoughts on this.\n\n**Satya Nadella** (CEO)\nYeah. Thanks, Brent. So yeah, in my remarks, I talked about how, in some sense, what's happening with AI is no different than what was happening with the regular compute cycle. It's always about bending the curve and then putting more points up the curve. So there's Moore's Law that's working and HyperDrive.\n\n**Satya Nadella** (CEO)\nThen on top of that, there are the AI scaling laws, both the pretraining and the inference time compute that compound. And that's all software. You should think of what I said in my remarks, which we've observed for a while, which is 10x improvements per cycle just because of all the software optimizations on inference. And so that's what you see.\n\n**Satya Nadella** (CEO)\nAnd then to that, I think DeepSeek has had some real innovations. And that is some of the things that even OpenAI found in o1. And so we are going to obviously now that's all gets commoditized and it's going to get broadly used. And the big beneficiaries of any software cycle like that is the customers, right? Because at the end of the day, if you think about it, right, what was the big lesson learned from client-server to cloud? More people bought servers, except it was called cloud. And so when token prices fall, inference computing prices fall, that means people can consume more, and there'll be more apps written.\n\n**Satya Nadella** (CEO)\nAnd it's interesting to see that when I reference these models that are pretty powerful, it's unimaginable to think that here we are in sort of beginning of 2025, where on the PC you can run a model that required pretty massive cloud infrastructure. So that type of optimizations means AI will be much more ubiquitous. And so therefore, for a hyperscaler like us, a PC platform provider like us, this is all good news as far as I'm concerned.\n\n**Satya Nadella** (CEO)\nThank you.\n\n**Satya Nadella** (CEO)\nThanks, Brett. Operator, next question, please.\n\n**Satya Nadella** (CEO)\nThe next question comes from the line of Carl Kearstedt with UBS. Please proceed.\n\n**Satya Nadella** (CEO)\nThank you. Maybe this one as well for Satya, and it's also away from the numbers. But Satya, I wanted to ask you about the Stargate news and the announced changes in the OpenAI relationship last week. It seems that most of your investors have interpreted this as Microsoft for sure remaining very committed to OpenAI's success, but electing to take more of a backseat in terms of funding OpenAI's future training CapEx needs.\n\n**Satya Nadella** (CEO)\nI was hoping you might frame your strategic decision here around Stargate and Amy, whether there's any takeaway for investors from that decision in terms of how you're thinking about CapEx needs over the next several years. Thank you.\n\n**Satya Nadella** (CEO)\nYeah. No, thanks for the question. So we remain very happy with the partnership with OpenAI. And as you saw, they've committed in a big way to Azure, and even in the bookings, what we recognized is just the first tranche of it. And so you'll see, given the role that we have, more benefits of that even into the future. And obviously, their success is our success because of even all the other commercial arrangements that we detailed out in the blog that we put out even commensurate with that announcement.\n\n**Satya Nadella** (CEO)\nBut your overall point, the thing that I would say is we are building a pretty fungible fleet, right? We're making sure that there's the right balance between training and inference. It's geo-distributed. We are working super hard on all the software optimizations, right? I mean, not just the software optimizations that come because of what DeepSeek has done, but all the work we have done to, for example, reduce the prices of GPT models over the years in partnership with OpenAI. In fact, we did a lot of the work on the inference optimizations on it, and that's been key to driving, right? One of the key things to note in AI is you just don't launch the frontier model, but if it's too expensive to serve, it's no good, right? It won't generate any demand. So you've got to have that optimization so that inferencing costs are coming down and they can be consumed broadly.\n\n**Satya Nadella** (CEO)\nAnd so that's the fleet physics we're managing. And also, remember, you don't want to buy too much of anything at one time because the Moore's Law every year is going to give you 2x. Your optimization is going to give you 10x. You want to continuously upgrade the fleet, modernize the fleet, age the fleet, and at the end of the day, have the right ratio of monetization and demand-driven monetization to what you think of as the training expense. So I feel very good about the investment we are making, and it's fungible, and it just allows us to scale more long-term business.\n\n**Satya Nadella** (CEO)\nMaybe, Carl, just to reiterate a little of the comments that I made on CapEx because I think it's helpful to ground a bit more in what Satya is saying a fungible fleet means. We have, and I think we talked about it, close to $300 billion of RPO. That is committed customer contracts that need to be delivered on. And the faster we can do that, and the more efficiently we can do that, the better off we are, not just the OpenAI partnership, which is a piece of that, but with the entire platform that we need to deliver for our customers.\n\n**Satya Nadella** (CEO)\nAnd I think the other thing that's sometimes missing is when we say fungible, we mean not just the primary use, which we've always talked about, which is inference, but there is some training, post-training, which is a key component. And then there's just running the commercial cloud, which at every layer under every modern AI app that's going to be built will be required. It'll be required to be distributed, and it'll be required to be global. And all of those things are really important because it then means you're the most efficient.\n\n**Satya Nadella** (CEO)\nAnd so the investment you see is making CapEx. You're right. The front end has been this sort of infrastructure build that lets us really catch up, not just on the AI infrastructure we needed. Think about that as the building itself, data centers, but also some of the catch-up we need to do on the commercial cloud side. And then you'll see the pivot to more CPU and GPU.\n\n**Satya Nadella** (CEO)\nAnd that pivot will more directly correlate to revenue, and it'll be contracted either with the partnership that you asked about with OpenAI or with others. And so I do think the way I want everyone to internalize it is that the CapEx growth is going through that cycle pivot, which is far more correlated to customer contract delivery, no matter who the end customer is.\n\n**Satya Nadella** (CEO)\nThank you.\n\n**Satya Nadella** (CEO)\nThanks, Carl. Operator, next question, please.\n\n**Satya Nadella** (CEO)\nAnd the next question comes from the line of Brad Zellnick with Deutsche Bank. Please proceed.\n\n**Satya Nadella** (CEO)\nThank you very much for taking my question, and I'll echo my congrats and gratitude to Brett as well. Satya, as we think about Microsoft's very rich Copilot portfolio, now having been in market for over a year with the products and precision only getting better and the cost of inference coming down, how do you think about the journey from here and perhaps the ability to package and evolve the go-to-market to address the broadest range of customers and customer requirements out there? Thanks.\n\n**Satya Nadella** (CEO)\nNo, thanks, Brad, for the question. In fact, you saw us make two announcements recently. One is on the M365 Copilot side. We now have Copilot Chat. So this is now going to be broadly deployed across the entire install base, effectively, because you can go have this now turned on by IT, and everybody can start using web-grounded chat with all the enterprise controls right away.\n\n**Satya Nadella** (CEO)\nAnd it has Copilot Studio built in, and so that means they can start building agents. So we think of that, plus the full Copilot as a good combination that I think will accelerate, quite frankly, in terms of just seat usage and agent building and what have you. So that's sort of one. And the other thing is you also see even on the consumer side, we just yesterday launched o1, the Think Harder feature on Copilot now that's powered by o1. It's available globally, right? So you can see the benefits of inference optimization and the cost coming down means you can drive more ubiquity of what were features that once were sort of premium tier. And that's all definitely something that we will do across, right? The same thing is happening in GitHub Copilot, same thing in Security Copilot. So across the length and breadth of our portfolio, you'll see that.\n\n**Satya Nadella** (CEO)\nThank you.\n\n**Satya Nadella** (CEO)\nThanks, Brad. Operator, next question, please.\n\n**Satya Nadella** (CEO)\nThe next question comes from the line of Brad Rebeck with Stifel. Please proceed.\n\n**Satya Nadella** (CEO)\nThat's great. Thank you very much. Satya, if you look at several years, any sense of what % of inference done on Azure will be done on proprietary models versus open models? And with that said, does it matter to Microsoft at the end of the day? Thanks.\n\n**Satya Nadella** (CEO)\nYeah, it's a good question because at some level, what you're seeing is effectively lots of models that get used in any application, right? When you look underneath even a Copilot or a GitHub Copilot or what have you, you already see lots of many different models.\n\n**Satya Nadella** (CEO)\nYou build models, you fine-tune models, you distill models. Some of them are models that you distill into an open-source model. So there's going to be a combination. So we've always maintained that it's always good to have frontier models. You want to always build your application with high ambition using the best model that is available and then optimize from there on. So that's also another side. There's a temporality to it, right? What you start with as a given COGS profile doesn't need to be the end because you continuously optimize for latency and COGS and putting in different models.\n\n**Satya Nadella** (CEO)\nIn fact, all that complexity, by the way, has to be managed by a new app server. So one of the things that we are investing heavily on is Foundry because from an app developer perspective, you kind of want to keep pace with these flurry of models that are coming in, and you want to have an evergreen way for your application to benefit from all that innovation, but not have all the dev cost or the dev ops cost or what people talk about AI ops cost. So we are also investing significantly in all the app server for any workload to be able to benefit from all these different models, open-source, closed-source, different weight classes. And at the same time, from an operations perspective, it's faster, easier for you . Great. Thank you.\n\n**Satya Nadella** (CEO)\nThanks, Brad. Operator, next question, please.\n\n**Satya Nadella** (CEO)\nAnd the next question comes from the line of Brad Sills with Bank of America. Please proceed.\n\n**Satya Nadella** (CEO)\nOh, wonderful. Thank you so much. Great to hear about the strength you're seeing in Copilot. Would love to get some color as to where you're seeing that strength. Is it departmental deals, customers moving from proof of concept to departmental deals, maybe multiple departmental deals in the enterprise? And you mentioned some uptick in usage trends. Would love to get some color on just the common use cases that you're seeing that give you that confidence that that will ramp into monetization later. Thank you.\n\n**Satya Nadella** (CEO)\nYeah. I mean, I think the initial sort of set of seats were for places where there's more belief in immediate productivity, a sales team, in finance or in supply chain where there is a lot of, for example, SharePoint-grounded data that you want to be able to use in conjunction with web data and have it produce results that are beneficial.\n\n**Satya Nadella** (CEO)\nBut then what's happening, very much like what we've seen in these previous generation productivity things, is that people collaborate across functions, across roles, right? For example, even in my own daily habit, I go to chat, I use work tab, I get results, and then I immediately share using pages with colleagues. I sort of call it think with AI and work with people.\n\n**Satya Nadella** (CEO)\nAnd that pattern then requires you to make it more of a standard issue across the enterprise. And so that's what we're seeing. It starts maybe at a departmental level. Quickly, the collaboration network effects will effectively demand that you spread it across. You can do it by cohort and what have you. And so what we've made it easier even is to start with Copilot Chat plus this. And so that gives the enterprise customers even more flexibility to have something that's more ubiquitous.\n\n**Satya Nadella** (CEO)\nWonderful. Thank you so much.\n\n**Satya Nadella** (CEO)\nThanks, Brad. Operator, we have time for one last question.\n\n**Satya Nadella** (CEO)\nAnd the last question will come from the line of Brent Braceland with Piper Sandler. Please proceed.\n\n**Satya Nadella** (CEO)\nThank you for the good question here. Good afternoon. I wanted to go back to commercial bookings. Commercial RPO, I think, increased $39 billion sequentially. That's the most we've ever seen on a sequential basis. Commercial bookings growth, 75% constant currency.\n\n**Satya Nadella** (CEO)\nThat's 2x higher than we've seen in the last decade.I appreciate there's some volatility with this metric, but it does feel like this quarter there was a bit of a sea change relative to momentum on backlog and bookings. Can you just talk about maybe the breadth of where that strength came from? Was it broad-based? Was there a couple of large deals? Any color there would be helpful. Thanks.\n\n**Satya Nadella** (CEO)\nThanks, Brent. It's a great question. We talked a little bit about one of the main drivers, which was one of the Azure commitments that OpenAI has made. And I do want to say, while that is obviously a big component, you'll continue to see OpenAI make commitments. So I want to separate the concept that it's one time versus an ongoing relationship that'll grow as they grow, which it absolutely will.\n\n**Satya Nadella** (CEO)\nAnd to your question on what else is participating in that number, first, we did have very good core motions. Our core motions are things like, to your point, renewals of our existing contracts, add-ons to those contracts, upsells, like for example, Copilot or GitHub Copilot or other processes. And I think that's important. We also had a good E5 quarter, which when we talk a lot about M365 Copilot, I sometimes forget to also talk about suite momentum. And we saw that as well this quarter, which we felt very good about. And then the final component is large Azure commitments. And those really did look as we expected, which is good. To your point, in that you're seeing a really broad-based growth, those Azure commitments take two forms.\n\n**Satya Nadella** (CEO)\nOne, it's existing customers who've worked through their commitments and are making larger commitments, which is a good commitment sign for the platform. And then you have new customers making commitments. And we also saw that this quarter. And so to your point, sometimes I think a big number that looks like this can make you think it's just one thing. I think you're right. Some of it was one thing, but a lot of it was good execution consistently across the workloads.\n\n**Satya Nadella** (CEO)\nCouple of color. Thank you.\n\n**Satya Nadella** (CEO)\nThanks, Brad. That wraps up the Q&A portion of today's earnings call. Thank you for joining us today, and we look forward to speaking with all of you soon. Thank you. Thank you all.\n\n**Satya Nadella** (CEO)\nThis concludes today's conference. You may disconnect your lines at this time and enjoy the rest of your day.",
        "fetched_at": "2026-02-04T16:09:40.177Z"
      }
    ]
  },
  "GOOGL": {
    "ticker": "GOOGL",
    "last_updated": "2026-02-04T16:10:32.527Z",
    "total_transcripts": 3,
    "transcripts": [
      {
        "ticker": "GOOGL",
        "title": "Yahoo Finance",
        "published_date": "Oct 29, 2025, 5:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/GOOGL/earnings/GOOGL-Q3-2025-earnings_call-366282.html",
        "content": "**Operator**\nWelcome, everyone. Thank you for standing by for the Alphabet Third Quarter 2025 Earnings Conference Call. At this time, all participants are in a listen-only mode. After the speaker presentation, there will be a question-and-answer session. To ask a question during the session, you will need to press *1 on your telephone. I would now like to hand the conference over to your speaker today, Jim Friedland, Head of Investor Relations. Please go ahead.\n\n**Jim Friedland** (Head of Investor Relations)\nThank you. Good afternoon, everyone, and welcome to Alphabet's Third Quarter 2025 Earnings Conference Call. With us today are Sundar Pichai, Philipp Schindler, and Anat Ashkenazi. Now, I'll quickly cover the safe harbor. Some of the statements that we make today regarding our business, operations, and financial performance may be considered forward-looking. Such statements are based on current expectations and assumptions that are subject to a number of risks and uncertainties. Actual results could differ materially. Please refer to our Forms 10-K and 10-Q, including the risk factors. We undertake no obligation to update any forward-looking statement. During this call, we will present both GAAP and non-GAAP financial measures. A reconciliation of non-GAAP to GAAP measures is included in today's earnings press release, which is distributed and available to the public through our Investor Relations website located at abc.xyz/investor. Our comments will be on year-over-year comparisons unless we state otherwise.\n\n**Jim Friedland** (Head of Investor Relations)\nI'll turn the call over to Sundar.\n\n**Sundar Pichai** (CEO)\nThank you, Jim. Good afternoon, everyone, and thanks for joining us. This was a terrific quarter for Alphabet, driven by double-digit growth across every major part of our business. We are seeing AI now driving real business results across the company. We delivered our first-ever $100 billion quarter. Five years ago, our quarterly revenue was at $50 billion. Our revenue number has doubled since then, and we are firmly in the generative AI era. In parallel, we have built for the long term and diversified with successful businesses in Cloud, YouTube, and subscriptions. Our momentum is strong, and we are shipping at speed. As just a few examples, our first-party models like Gemini now process 7 billion tokens per minute via direct API use by our customers. The Gemini app now has over 650 million monthly active users, and queries increased by 3x from Q2.\n\n**Sundar Pichai** (CEO)\nCloud had another great quarter of accelerating growth with AI revenue as a key driver. Cloud backlog grew 46% quarter over quarter to $155 billion. We crossed 300 million paid subscriptions led by growth in Google One and YouTube Premium. Today, I'll discuss progress in our full-stack approach to AI and then share highlights from Search, Cloud, YouTube, and Waymo. As a reminder, our full-stack approach spans AI infrastructure, world-class research, including models and tooling, and our products and platforms that bring AI to people everywhere. First up, AI infrastructure. Our extensive and reliable infrastructure, which powers all of Google's products, is the foundation of our stack and a key differentiator. We are scaling the most advanced chips in our data centers, including GPUs from our partner NVIDIA, as well as our own purpose-built TPUs. We are the only company providing a wide range of both.\n\n**Sundar Pichai** (CEO)\nAs we announced yesterday at NVIDIA GTC, we are now shipping the new A4x Max instances powered by NVIDIA GB300 to our cloud customers. Our highly sought-after TPU portfolio is led by our seventh-generation TPU, Ironwood, which will be generally available soon. We are investing in TPU capacity to meet the tremendous demand we are seeing from customers and partners, and we are excited that Anthropic recently shared plans to access up to 1 million TPUs. Next, world-class AI research, including models and tooling. Our models are world-leading. Gemini 2.5 Pro, VO Genie 3, and our viral sensation Nano Banana are among the very best in class. Over 230 million videos have been generated with VO3, and more than 13 million developers have built with our generative models. We are looking forward to the release of Gemini 3 later this year. Our research leadership is advancing next frontier technologies.\n\n**Sundar Pichai** (CEO)\nLast week, we announced that our Willow quantum chip achieved a major breakthrough, running an algorithm 13,000 times faster than one of the world's best supercomputers. The result is verifiable, paving the way to future practical applications. Speaking of quantum, let me congratulate Michel Debray, our Chief Scientist for Quantum Hardware. He received a Nobel in Physics for early research he did in the 1980s. Three Nobels awarded to current Googlers in two years. Incredible. Third, our products and platforms. We are bringing AI to more people and developers than anyone else. In July, we announced that we processed 980 trillion monthly tokens across all our surfaces. We are now processing over 1.3 quadrillion monthly tokens, more than 20x growth in a year. Phenomenal.\n\n**Sundar Pichai** (CEO)\nThis quarter, we took big steps to reimagine Chrome as a browser powered by AI through deep integrations with Gemini and AI mode in Search, with more agentic capabilities coming soon. In August, at Made by Google, we unveiled our Pixel 10 series of devices. They are the first with our most powerful chip designed to run on Gemini Tensor G5. They are our best-reviewed devices ever. Last week, we launched Android XR, our new operating system, with Samsung's Galaxy XR device. It brings new ways to use headsets and glasses with Gemini at the core. Now, turning to highlights from Search. AI is driving an expansionary moment for Search. As people learn what they can do with our new AI experiences, they are increasingly coming back to Search more. Search and its AI experiences are built to highlight the web, sending billions of clicks to sites every day.\n\n**Sundar Pichai** (CEO)\nDuring the Q2 call, we shared that overall queries and commercial queries continue to grow year over year. This growth rate increased in Q3, largely driven by our AI investments in Search, most notably AI overviews and AI mode. Let me dive into the momentum we are seeing. As we have shared before, AI overviews drive meaningful query growth. This effect was even stronger in Q3 as users continue to learn that Google can answer more of their questions. It is particularly encouraging to see the effect was more pronounced with younger people. We are also seeing that AI mode is resonating well with users. In the U.S., we have seen strong and consistent week-over-week growth in usage since launch, and queries doubled over the quarter. Over the last quarter, we rolled out AI mode globally across 40 languages in record time.\n\n**Sundar Pichai** (CEO)\nIt now has over 75 million daily active users. We shipped over 100 improvements to the product in Q3, an incredibly fast pace. Most importantly, AI mode is already driving incremental total query growth for Search. Philipp will talk more about monetization and share how AI is helping people connect with businesses and shop on Search. Next, Google Cloud. Our complete enterprise AI product portfolio is accelerating growth in revenue, operating margins, and backlog. In Q3, customer demand strengthened in three ways. One, we are signing new customers faster. The number of new GCP customers increased by nearly 34% year over year. Two, we are signing larger deals. We have signed more deals over $1 billion through Q3 this year than we did in the previous two years combined. Third, we are deepening our relationships.\n\n**Sundar Pichai** (CEO)\nOver 70% of existing Google Cloud customers use our AI products, including Banco BV, Best Buy, and Fairprice Group. As we scale, we are diversifying revenue. Today, 13 product lines are each at an annual run rate over $1 billion. We are improving operating margin with highly differentiated products built with our own technology. This deep product differentiation starts with our AI infrastructure. We have a decade of experience building AI accelerators and today offer the widest array of chips. This leadership is winning customers like Hetsia Healthcare, LG AI Research, and Macquarie Bank. It is why nine of the top 10 AI labs choose Google Cloud. We are also the only cloud provider offering our own leading generative AI models, including Gemini, Imagen, Veo, Chirp, and Lyria. Adoption is rapidly accelerating. In Q3, revenue from products built on our generative AI models grew more than 200% year over year.\n\n**Sundar Pichai** (CEO)\nOver the past 12 months, nearly 150 Google Cloud customers each processed approximately 1 trillion tokens with our models for a wide range of applications. For example, WPP is creating campaigns with up to 70% efficiency gains. Swarovski has increased email open rates by 17% and accelerated campaign localization by 10 times. Earlier this month, we launched Gemini Enterprise, the new front door for AI in the workplace, and we are seeing strong adoption for agents built on this platform. Our packaged enterprise agents in Gemini Enterprise are optimized for a variety of domains, are highly differentiated, and offer significant out-of-box value to customers. We have already crossed 2 million subscribers across 700 companies. Next, YouTube. In the living room, YouTube has remained number one in streaming watch time in the U.S. for more than two years, according to Nielsen.\n\n**Sundar Pichai** (CEO)\nLast month marked YouTube's first time as a live NFL broadcaster. This exclusive global broadcast, live from Brazil, drew more than 19 million fans and set a new record for most concurrent viewers of a live stream on YouTube. YouTube Shorts also continues to perform well. In the U.S., Shorts now earn more revenue per watch hour than traditional in-stream on YouTube. At our Made on YouTube event, we rolled out a number of AI-powered features that are helping creators supercharge creation and build their businesses. AI is now streamlining the entire content creation workflow from generative video tools and more efficient editing to AI-powered insights that help creators optimize their channels. We are also using AI to expand monetization, automatically identifying products to make their videos more shoppable. Philipp will discuss in more detail. Finally, Waymo.\n\n**Sundar Pichai** (CEO)\nNext year, Waymo aims to open service in London, and they are working to bring service to Tokyo. They have also announced expansions to Dallas, Nashville, Denver, and Seattle, and secured permission to operate fully autonomously at San Jose and San Francisco airports. Autonomous testing continues to scale in New York City. The new Waymo for Business allows enterprises to offer Waymo as a work travel option. We launched Waymo Teens accounts in Phoenix this summer. We are pleased to see usage steadily increase with positive feedback from teens and their parents alike. Waymo's growth and momentum are strong, and 2026 is shaping up to be an exciting year. Overall, a milestone quarter. The incredible work of our teams is driving momentum across the board, and our leadership in AI positions us so well for the opportunity ahead.\n\n**Sundar Pichai** (CEO)\nI want to thank all of our partners and our employees for their hard work and an excellent Q3. With that, I'll turn it over to Philipp.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nThanks, Sundar, and hello, everyone. I'll quickly cover performance for Google Services for the quarter, then structure the rest of my remarks around the great progress we're delivering across Search, Ads, YouTube, and partnerships. Google Services revenues were $87 billion for the quarter, up 14% year-on-year, driven by accelerated growth in Search and YouTube, partially offset by year-on-year decline in network revenues, adding some further color to our results. The 15% increase in Search and Other was led by growth across all major verticals, with the largest contributions from retail and financial services. YouTube saw similar performance across verticals. Its 15% growth in advertising revenues was driven by direct response, followed by brand. Starting with Search and Other revenues, which delivered over $56 billion in revenue for the quarter. As Sundar mentioned, AI is driving an expansionary moment and transforming how people use Google Search.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nOur investments in new AI experiences, such as AI overviews in AI mode, continue to drive growth in overall queries, including commercial queries, creating more opportunities for monetization. These AI experiences are enhancing how people connect with businesses and shop on Search. We recently added shopping capabilities in AI mode, which now help people shop conversationally in Search, and we expanded try-on capabilities to more clothing items, now available to anyone in the U.S. Lastly, we're making it easier for consumers to benefit from deals through new loyalty offerings, like personalized annotations on organic results and ads. Looking at monetization, businesses can now tap into our most powerful AI search experiences. Using our most advanced AI models, we can understand and predict intent like never before, unlocking entirely new commercial pathways to provide valuable new consumer connections and helping us monetize even more efficiently.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nRolled out globally in September, AI Max in Search is already used by hundreds of thousands of advertisers, currently making it the fastest-growing AI-powered Search Ads product. In Q3 alone, AI Max unlocked billions of net new queries. By delivering the most relevant ad across surfaces and matching advertisers against additional queries they weren't reaching before, AI Max helps advertisers discover new customers at the exact moment they need their product or service. Kayak, for example, looked to grow conversions while staying within their ROAS goals. After turning on AI Max in Search, they grew the conversion value by 12% in early tests. We continue to infuse generative AI capabilities at every step of the marketing process. We rolled out Imagen for AssetStudio and Product Studio, helping businesses produce more and better creatives. On the measurement front, we enriched the model supporting Meridian, our marketing mix model, with additional variables.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nMore granular reporting in Performance Max is making bidding more effective. Financial services company SoFi has been using Performance Max to meet its ambitious growth targets and helped drive a 39% improvement in its conversion volume year over year. Moving to YouTube, where we saw accelerated revenue growth, our recommendation systems are driving robust watch time growth in our key monetization areas, like Shorts and Living Room. As we leverage Gemini models, we're seeing further discovery improvement. On direct response, we're excited about the growth in revenue we're seeing, especially from small and medium advertisers adopting Demand Gen. We also improved performance on Demand Gen, with over 100 launches helping to increase conversion value by more than 40% for advertisers using target-based bidding on YouTube. The retail vertical continues to lead our growth on YouTube, with Demand Gen helping us further monetize shopping-related categories.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nLooking at the Living Room, our long-term bet, more advertisers are adopting interactive direct response ads, leading to an annual revenue run rate exceeding $1 billion globally for this format. For our viewers, we continue to give fans greater access across sports while tapping into the best of YouTube's product innovation and creator-led content. Sundar mentioned that we expanded our NFL partnership with our first-ever exclusive global broadcast of an NFL game. Brands loved the opportunity, and we sold all our ad inventory within a couple of weeks. Looking at creators, a significant force behind a thriving YouTube creator economy is the collaboration between creators and brands. Tools like direct linking to deals, websites, and Shorts, and swappable brand segments in long form will soon help creators show how they deliver great value for brands.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nThanks to a collaboration with Dude Perfect, Comcast Xfinity drove an 8% search lift, beating other Xfinity ads' recall lift on Shorts by 34%. At the same time, it decreased the cost per lifted user by 50% when compared to the next most efficient ad. We continue to invest in AI-powered features that are helping creators supercharge creation and build their businesses. With VO3 integration and speech-to-song, creators go from idea to iteration quicker, and new channel insights help them better understand performance. Ending on YouTube with our subscriptions products, we're also seeing momentum with strong growth in offerings such as YouTube Music and Premium and YouTube TV. We're also applying Gemini internally to help us serve customers with increased speed, intelligence, and efficiency. Our sales teams use Gemini enriched with ads knowledge to streamline customer interactions.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nThis increased productivity by over 10%, led to hundreds of millions in incremental revenue, and frees up sellers to engage with more customers at a deeper, more strategic level. In our Customer Support division, Gemini-powered solutions have managed over 40 million customer sessions so far this year and resolved hundreds of thousands of customer inquiries. We're just getting started. As always, I'll wrap with the progress we're seeing across partnerships, where customers tap into the strength and breadth of Google's products to accelerate their transformation. Revolut, the global financial services company, leverages Google Cloud's Vertex AI platform and Gemini models to help power its advanced customer service chatbot, develop new hyper-personalized financial products, and offer predictive insights. Revolut is also increasing its presence on YouTube, adopting VO3 for personalized creatives, making Google a key ads partner for delivering growth and launching new markets.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nIn closing, I'd like to thank Googlers everywhere for their contributions to our success, and as always, to our customers and partners for their continued trust. Of course, a huge thanks to all of you as we celebrate 25 years of Google Ads. Anat, over to you.\n\n**Anat Ashkenazi** (CFO)\nThank you, Philipp. My comments will focus on year-over-year comparisons for the third quarter, unless I state otherwise. I will start with results at the Alphabet level and will then cover our segment results. I'll end with some commentary on our outlook for the fourth quarter of 2025. We had an outstanding quarter in Q3, continuing the strong momentum we've had throughout the year, delivering double-digit revenue growth across Search and YouTube advertising, subscriptions, platforms and devices, and Google Cloud. Consolidated revenue reached $102.3 billion, a 16% year-over-year increase, or 15% in constant currency. Total cost of revenue was $41.4 billion, up 13%. Tech was $14.9 billion, up 8%. Other cost of revenues was $26.5 billion, up 16%, with the increase primarily driven by content acquisition costs, largely for YouTube, followed by depreciation and other technical infrastructure operations costs. Total operating expenses increased 28% to $29.7 billion.\n\n**Anat Ashkenazi** (CFO)\nR&D expenses increased by 22%, driven by compensation and depreciation expenses related to our AI efforts. Sales and marketing expenses were flat. G&A expenses increased meaningfully, primarily due to the $3.5 billion charge related to the European Commission fine mentioned in the earnings press release. Operating income increased 9% this quarter to $31.2 billion, and operating margin was 30.5%. Excluding the EC fine, operating income increased 22%, and operating margin was 33.9%. Operating margin benefited from strong revenue growth and continued efficiencies in our expense space, offset by the legal charge and a significant increase in depreciation expense. Other income and expenses were $12.8 billion, primarily due to unrealized gains in our non-marketable equity securities portfolio. Net income increased 33% to $35 billion, and earnings per share increased 35% to $2.87.\n\n**Anat Ashkenazi** (CFO)\nWe generated free cash flow of $24.5 billion in the third quarter and $73.6 billion for the trailing 12 months. Free cash flow in Q3 benefited from strong operating cash flow and recent tax changes regarding the timing of when research and development costs are expensed and assets are depreciated. This was partially offset by higher capex. We ended the quarter with $98.5 billion in cash and marketable securities. Turning to segment results, Google Services revenues increased 14% to $87.1 billion, reflecting strength in Google Search, YouTube advertising, and subscriptions. Google Search and other advertising revenues increased by 15% to $56.6 billion, representing another robust quarter with continued growth across all major verticals, with the largest contributions from retail and financial services. YouTube advertising revenues increased 15% to $10.3 billion, driven by direct response advertising, followed by brand. Network advertising revenues of $7.4 billion were down 3%.\n\n**Anat Ashkenazi** (CFO)\nSubscriptions, platforms, and devices revenues increased 21% this quarter to $12.9 billion, driven by very strong growth in both YouTube and Google One subscriptions. Google Services operating income increased 9% to $33.5 billion. Operating margin declined year-over-year to 38.5%, as healthy revenue growth and continued efficiencies in our expense space were offset by the impact of the European Commission fine, which was fully reflected in the Google Services segment. Turning to the Google Cloud segment, which again delivered very strong results this quarter, as Cloud continued to benefit from our enterprise AI-optimized stack, including our own custom TPUs and our industry-leading AI models. Cloud revenue increased by 34% to $15.2 billion in the third quarter, driven by strong performance in Google Cloud Platform, which continued to grow at a rate that was much higher than Cloud's overall revenue growth rate.\n\n**Anat Ashkenazi** (CFO)\nGoogle Cloud Platform's growth was driven by enterprise AI products, which are generating billions in quarterly revenue. We had strong growth in enterprise AI infrastructure and enterprise AI solutions, which benefited from demand for our industry-leading models, including Gemini 2.5. Core Google Cloud Platform was also a meaningful contributor to growth. We had double-digit growth in Workspace, which was driven by an increase in average revenues per seat and the number of seats. Cloud operating income increased by 85% to $3.6 billion, and operating margin increased from 17.1% in the third quarter last year to 23.7% this quarter. The expansion in Cloud operating margin was driven by strong revenue performance and continued efficiencies in our expense space, partially offset by higher technical infrastructure usage costs, which includes depreciation expense and other operations costs, such as energy.\n\n**Anat Ashkenazi** (CFO)\nGoogle Cloud's backlog increased 46% sequentially and 82% year-over-year, reaching $155 billion at the end of the third quarter. The increase was driven primarily by strong demand for enterprise AI. As Sundar mentioned earlier, Cloud has signed more billion-dollar deals in the first nine months of 2025 than in the past two years combined. In Other Bets, revenues were $344 million, and operating loss was $1.4 billion in the third quarter. Within Other Bets, we continue to allocate more resources to businesses like Waymo, where we see opportunities to create substantial value. With respect to CapEx, in the third quarter, our CapEx was $24 billion. The vast majority of our CapEx was invested in technical infrastructure, with approximately 60% of that investment in servers and 40% in data centers and networking equipment.\n\n**Anat Ashkenazi** (CFO)\nIn Q3, we returned capital to shareholders through repurchases of stock of $11.5 billion and dividend payments of $2.5 billion. Turning to our outlook, I would like to provide some commentary on factors that will impact our business performance in the fourth quarter of 2025, as well as an updated outlook for CapEx for the year. First, in terms of revenues, we're pleased with the overall momentum of our business. At the current spot rates, we could see an FX tailwind to our revenues in Q4. However, the volatility in exchange rates could affect the impact of FX on Q4 revenues. As for our segments, in Google Services, year-over-year comparisons in advertising will be negatively impacted by the strong spend on U.S. elections in the fourth quarter of 2024, particularly on YouTube.\n\n**Anat Ashkenazi** (CFO)\nIn Cloud, demand for our products remains high, as evidenced by the accelerating revenue growth and the $49 billion sequential increase in Cloud backlog in Q3. In GCP, we see strong demand for enterprise AI infrastructure, including TPUs and GPUs, enterprise AI solutions driven by demand for Gemini 2.5 and our other AI models, and core GCP infrastructure and other services, such as cybersecurity and data analytics. As I've mentioned on previous earnings calls, while we have been working hard to increase capacity and have improved the pace of server deployments and data center construction, we still expect to remain in a tight demand-supply environment in Q4 and 2026. Moving to investments, we're continuing to invest aggressively due to the demand we're experiencing from Cloud customers, as well as the growth opportunities we see across the company.\n\n**Anat Ashkenazi** (CFO)\nWe now expect capex to be in the range of $91 billion to $93 billion in 2025, up from our previous estimate of $85 billion, keeping in mind that the timing of cash payments can cause variability in the reported capex number. Looking out to 2026, we expect a significant increase in capex and will provide more detail on our fourth quarter earnings call. In terms of expenses, first, as I've mentioned on previous earnings calls, the significant increase in our investments in technical infrastructure will continue to put pressure on the P&L in the form of higher depreciation expenses and related data center operations costs, such as energy. In the third quarter, depreciation increased $1.6 billion year-over-year to $5.6 billion, reflecting a growth rate of 41%. Given the overall increase in capex investments, we expect the growth rate in depreciation to accelerate slightly in Q4.\n\n**Anat Ashkenazi** (CFO)\nSecond, we expect sales and marketing expenses to be more heavily weighted to the end of the year, in part to support product launches and the holiday season. Q3 was a strong quarter, and we're excited with the adoption of our AI products, helped by a rapid pace of innovation and great execution by our teams. This translated into strong momentum in Search, YouTube Ads, subscription platforms and devices, and Cloud, resulting in our first $100 billion-plus quarter. Now, Sundar, Philipp, and I will now take your questions.\n\n**Operator**\nThank you. As a reminder, to ask a question, you will need to press star one on your telephone. To prevent any background noise, we ask that you please mute your line once your question has been stated. Our first question comes from Brian Nowak with Morgan Stanley. Your line is now open.\n\n**Brian Nowak** (Managing Director)\nGreat. Thanks for taking my questions, everyone. The first one, maybe for Philipp or Sundar, it's on agentic e-commerce and agentic travel. There's a lot of external Wall Street discussion about agentic e-commerce potentially monetizing at a lower rate than Search. The question is, what factors are you most focused on to sort of ensure a smooth transition for your Search business and for your advertisers as you move over to a more agentic world? The second one, Sundar, is on Waymo. How far are we from an integration of Waymo into more of the core Gemini capabilities and the users in the platform, taking your user data of where I'm going, what hotel I'm staying at, what airport I'm staying at, and having to integrate that into Waymo so you can actually have users use their profiles to pre-schedule Waymos? How far off is that? What do we have to do?\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nHello, Brian. Great question. This is old early, but we see agentic experiences really as additive to the way people seek information. It helps us answer people's tough questions. It helps people get stuff done, and it helps businesses in the process. We're working on multiple agentic experiences across key verticals, such as travel, commerce, shopping, and so on. We're paying a lot of attention to creating a seamless user experience, but also to the fact that we need to integrate different partner ecosystems in a way that it creates value for them. By the way, we're also working closely with a lot of our partners on the other side through our Cloud services to improve their own agentic experiences. Maybe we go a little deeper on the shopping side, where we actually use AI already very actively to improve the shopping experience.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nAs you know, we launched a more visual experience on AI mode that gives people a much more intuitive conversational way to shop. You can simply describe what you're looking for now, like the way you would talk to a friend, and it will show you the visual shopping results. We think about building an agentic shopping future, and it has to be one, again, that benefits both users and merchants here. You know that at AIO, we also introduced new agentic checkout, which will let shoppers use agentic AI to buy products from merchant sites and so on. We have a partnership with PayPal to help merchants build agentic commerce experiences. We have a new open protocol for agent-to-agent transactions, and so on and so on.\n\n**Sundar Pichai** (CEO)\nBrian, on Waymo, a great question. I was reflecting, I think, on the exact same topic. I'm scheduled to meet with the team to do a review on it in a few weeks out. It is an exciting time. Waymo clearly is scaling up, particularly in 2026. I think the possibility, as you said, of Gemini, particularly with the multimodal experience, as well as services like YouTube, I think there's a real opportunity to make the in-car experience dramatically better. Definitely something we are excited about, and you'll see newer experiences in 2026, for sure.\n\n**Brian Nowak** (Managing Director)\nGreat. Thank you both.\n\n**Operator**\nOur next question comes from Doug Anmuth with JPMorgan. Your line is now open.\n\n**Doug Anmuth** (Analyst)\nThanks for taking the questions. Philipp, maybe you can just talk more about some of the drivers of the core search strength. I guess, in particular, when you think about AI overviews and AI mode, we know that query growth is accelerating, but can you help us understand from there kind of what happens in terms of clicks per query and conversion rates and pricing in these AI-driven search formats? Anat, can you talk about where you see opportunities in the core cost space as you look to make room to absorb the rapid growth in infrastructure and depreciation going forward? Thanks.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nLet me give you a bit of vertical color first. In Q3, search and other revenues, again, delivered growth across all major verticals, as we said. It was from retail and financial services. Health care was also a contributor to the growth here. Our new AI experiences, you mentioned them, AI overviews, AI mode, continue to drive growth in overall queries, including commercial queries, really creating more opportunities for monetization. AI overviews are scaling up and are working for our entire user base. We're now scaled to over 2 billion users here, and we're continuing to expand ads in AI overviews in English to more countries across desktop, mobile, and so on. As I've shared before, for AI overviews, even at our current baseline of ads, below and within the AI's response, overall, we see the monetization at approximately the same rate.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nOver time, we're excited about the opportunity of richer experiences in AI mode and AI overviews to basically open up then the opportunity for also much richer placements. I think, as I've said on a prior call, we manage the business to drive great outcomes for our users and an attractive ROI for our advertisers. We don't really manage to pay clicks and CPC targets. As you will see in the 10-Q, paid clicks were up 7% year-on-year, and CPCs were up 7% year-on-year.\n\n**Anat Ashkenazi** (CFO)\nDoug, to your question around where else can we see more opportunity for efficiency and productivity, I think you heard me say before, this is not a one-time type of effort, but rather an ongoing way in which we manage the business. The key here is that the more we drive productivity across our business, the more we can invest in the business for growth and obviously continue to drive improvement in the P&L. Some of the areas are things that you've heard us talk about in the past, such as moderating the pace of headcount growth, optimizing our real estate footprint, but also, as we invest more and more in our technical infrastructure, ensuring that we are optimizing that build-out and the overall technical infrastructure we have.\n\n**Anat Ashkenazi** (CFO)\nYou know that a lot of the data centers, for example, that we build ourselves, so they're optimized, and we make sure we do them in the most efficient way. Sundar mentioned on one of the previous calls the productivity associated with leveraging AI for Google. There's the example, the % of code, now nearly half of all code generated by AI. That's a way for us to leverage AI to drive further productivity across the business. Obviously, we always look at making sure that when we provide services or products, we get the right economics and the right value for what we provide. One good example is Shorts, which has a lower revenue share than InStream, that helps to improve some of our gross margins. This is an effort we have ongoing. I've mentioned in the past that we have headwind with depreciation, obviously increasing alongside our capex increase.\n\n**Anat Ashkenazi** (CFO)\nWe have efforts across the organization to ensure we run the business in the most disciplined and productive way while continuing to invest for future growth.\n\n**Doug Anmuth** (Analyst)\nThank you both.\n\n**Operator**\nOur next question comes from Eric Sheridan with Goldman Sachs. Your line is now open.\n\n**Eric Sheridan** (Managing Director)\nThank you so much for taking the questions. Maybe two, if I could. Sundar, when you think about your custom silicon efforts across the organization, can you reflect a little bit about the opportunity set you see with each passing generation of custom silicon, both in terms of driving operating efficiencies inside the organization and potentially increased monetization efforts around those outside of the organization? Second question would be for Philipp. Obviously, we can see the YouTube advertising revenue number in the reported results. Can you reflect a little bit about the scaling of the subscription side of YouTube offerings and how the two parts in together maybe represent an interesting framework in thinking about the monetization side of YouTube increasingly being a mix of both ads and subscription? Thank you.\n\n**Sundar Pichai** (CEO)\nEric, overall, I would say we are seeing a substantial demand for our AI infrastructure products, including TPU-based and GPU-based solutions. It is one of the key drivers of our growth over the past year. I think on a going-forward basis, we continue to see very strong demand, and we are investing to meet that. I do think a big part of what differentiates Google Cloud, effectively, we have taken a deep full-stack approach to AI, and that really plays out. We are the only hyperscaler who is really building offerings on our own models, and we are also highly differentiated on our own technology. To your question, I think that does give us the opportunity to continue driving growth in operating margins in Cloud, as we have done in the past.\n\n**Sundar Pichai** (CEO)\nI think from a revenue set, the infrastructure portion of our business will be a growth driver looking ahead as well.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nTo the second part of your question, just taking a quick step back, we often describe YouTube's business as a flywheel. Obviously, it first all starts with the creators, and we have significantly invested here to be the place that YouTube creators really call their home. That's a big piece of it, the number one piece. Viewers, of course, YouTube has billions of monthly logged-in users, and every day people watch billions of hours of video. We talked about how our recommendation systems are driving robust watch time growth, and so on. On the monetization side, YouTube's business is really powered, I would say, on it. Let's call it a twin-engine monetization strategy, combining its advertising business and its growing subscription services. Both YouTube ads and subscriptions saw strong growth this quarter.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nLooking at YouTube Music and Premium, users are on average delivering more value to creators, to music media partners, and YouTube itself than even ad-supported users do. In other words, on average, a YouTube Music and Premium subscriber generates a meaningful high gross profit than if they were simply an ad-supported user. Fans come from all over the world. You know this, and this engagement through ads and subscription generates YouTube's revenues and funds what I started with, these creators here. This then drives more viewership and engagement and so on. That's the flywheel. Our priority continues like this growth cycle. We're happy with this twin-engine monetization strategy.\n\n**Operator**\nOur next question comes from Mark Schmalich with Bernstein. Your line is now open.\n\n**Mark Shmulik** (Senior Analyst)\nYes, thanks for taking the questions. Sundar, with the strong adoption of Gemini AI mode and overviews across the user base, are there any meaningful differences to call out around the behavior and depth of engagement for those users across the entire Google ecosystem? Philip, I know we kind of ask this most quarters, but I'm curious with some of the adoption you've seen around AI overviews and mode, how you see the economics of search evolving with the higher commercial and total query volume and how it compares against the incremental cost to deliver these results. Thank you.\n\n**Sundar Pichai** (CEO)\nMark, look, I think obviously AI overviews are a natural part of a Google experience, and engagement is very, very high. I would say AI mode, you have varied cohorts. There are people who are casual users who are checking it out, but there is a core group which really likes AI mode and is passionate about it. You see the early adopters. The product is resonating very strongly, and they are seeking it out. I think that's how I would highlight the difference. With Gemini, again, a set of engaged user bases who are seeking out the product and so on.\n\n**Sundar Pichai** (CEO)\nAcross the board, I think the trajectory has been we are definitely seeing in each of those use cases a set of early adopters and then more people coming in, and the people who are using it continue to use it more over time and report high user satisfaction. I would say the underlying product metrics are pretty encouraging to see as well.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nLooking to the second part of your question, I think we covered before, Sundar covered the query development. As I've just said before, for the AI overviews, even at our current baseline of ads, whether above, below, and within the AI response, overall we see the monetization at approximately the same rate. This is a great baseline for further innovation. We talked about this. We're excited about where this can go. On the AI mode side, we're testing ads in AI mode, and we'll continue to test and learn before we expand this any further. This in combination with what we mentioned about the commercial query overall development, I think we're in a good place here.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nYou could also argue that on queries that historically have not been well monetized, we think there is a potential opportunity here where you can obviously imagine that we can build this out with smart AI integration.\n\n**Operator**\nOur next question comes from Michael Nathanson with MoffettNathanson. Your line is now open.\n\n**Michael Nathanson** (Analyst)\nThanks. I have two, one for Philipp, one for Anat. Philipp, it's clear that when people use AI mode, the query length is much longer. Can you talk about how that longer length may be impacting your abilities to drive ROAS and what you're seeing in terms of the early benefits of maybe longer query length? Anat, you came to Alphabet from a pharmaceutical company. You've been there more than a year. Can you talk a bit about how you're working to look at ROIC internally and what early signs are you seeing that give you confidence that this spending is really driving better returns longer term? Thanks.\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nLook, as Sundar shared, AI mode now has over 75 million daily active users in the U.S., and we see strong and consistent week-over-week growth in usage since launch. The queries doubled over the quarter. As I also mentioned, we're testing ads in AI mode. We'll continue to test before we expand any further. It's really too early to tell and go into any of the details of that testing.\n\n**Michael Nathanson** (Analyst)\nOK.\n\n**Anat Ashkenazi** (CFO)\nYes, and the question related to ROI and how we look at just overall our business and where do we see early signs that are encouraging. First, I would say it's not just early signs because we're seeing returns, obviously, in the Cloud business. You've heard us talk about the fact that we already are generating billions of dollars from AI in the quarter. Across the board, we have a rigorous framework and approach by which we evaluate these long-term investments that are meant to do two things. One is to ensure we build a resilient growth profile for the company, but also that we meet the demand of the customers that we have here in the more near and midterm. We look at it across the business.\n\n**Anat Ashkenazi** (CFO)\nWe evaluate the potential return for each one of them, whether it's in Cloud, and I think that's more visible, obviously, externally, given that you see the revenue generated and the fact that we're unable to meet at this point customer demand. We have more demand than we have supply. In our ads business, you see the fact that we're investing to transform search, as you heard from Philipp and Sundar with AI overviews and AI mode. We're excited to see what our investments are, how the investments are helping advertisers as well. YouTube, where it's helping power recommendations.\n\n**Anat Ashkenazi** (CFO)\nWhen we make a decision on investment in the long term, we go through a very rigorous process of assessing what the return could be and over what time frame we will see that return to give us the high level of confidence to then invest and make those investments for the long term. It's a very rigorous approach.\n\n**Michael Nathanson** (Analyst)\nThanks.\n\n**Operator**\nOur next question comes from Ross Sandler with Barclays. Your line is now open.\n\n**Ross Sandler** (Analyst)\nGreat. About 20% of Google's search queries are commercial historically. You've talked a bunch on this call about how AI overviews are kind of expanding the breadth of queries. Could you talk about how new products on the monetization side, like AI Max, are potentially increasing the % of commercial queries?\n\n**Philipp Schindler** (SVP and Chief Business Officer)\nAI Max, and I mentioned this in my call before, improves the ability for advertisers to target a wider range of queries. Separately, there is the question of whether queries actually increase with AI mode. Sundar actually talked about it and mentioned the opportunity that he sees here. I think it's important to separate those two things. I personally also see, this is what I just said in my last remark, that I think over time there's an opportunity to actually take, let's say, queries that are not fully commercial but could have an adjacent commercial relationship to basically expand this into more attractive ads offerings while really creating a really interesting user experience at the same time.\n\n**Sundar Pichai** (CEO)\nThe only thing I would add is just stepping back broadly, I think AI overviews and AI mode are dramatically improving search. We can see it in user satisfaction, user quality, all our metrics. They are universal in nature. They apply across the universality of human needs. I think we are seeing it in breadth, and naturally, over time, that'll apply to commercial categories as well.\n\n**Operator**\nOur next question comes from Ken Goralski with Wells Fargo. Your line is now open.\n\n**Ken Gawrelski** (Analyst)\nThank you very much. Two questions, please. First, it appears more and more clear that all the new modes, whether at Google with Gemini overview, AI overviews, AI mode, even ChatGPT, is growing the addressable market for engagement in search-like behavior. Could you talk about what gives you confidence that it will also grow the addressable market for marketing activity and overall revenue associated with that behavior? That's question one. Question two is just more about, as you think about AI mode, AI overviews, and traditional Google Search, how do you think, do you see a world in 12 to 24 months those all coexist? Does the user eventually pick what mode they want? Does the algorithm pick the mode? Could you talk a little bit about how you think that will progress over the next 12 to 24 months? Thank you very much.\n\n**Sundar Pichai** (CEO)\nKen, thanks. I think it's a dynamic moment, and I think we are meeting people in the moment with what they are trying to do. Obviously, search is evolving. Between AI overviews and AI mode, I think we are able to kind of give that range of experience for people in this moment. Over time, you can expect us to make the experiences simpler in a way that, just like we did universal search many years ago, we may have done text search, image search, video search, etc., and then we kind of brought it together as universal search. You will see evolutions like that. I think we want to be sensitive to making sure we are meeting the users in terms of what they are looking for. I think Gemini allows us to build a more personal, proactive, powerful AI assistant for that moment.\n\n**Sundar Pichai** (CEO)\nI think having the two surfaces, search and Gemini, allows us to really serve users across the breadth of their needs. Over time, we will thoughtfully look for opportunities to make the experience better for users. To the first part, I would broadly say, as I do think we've been consistently saying for a while now, this is an expansionary moment, and we are seeing people engage more. I think when they do that, naturally, a portion of that information for users, those journeys are commercial in nature. I would expect that to play out over time as well.\n\n**Ken Gawrelski** (Analyst)\nThank you.\n\n**Operator**\nOur last question comes from Justin Post with BAML. Your line is now open.\n\n**Justin Post** (Internet Analyst)\nGreat. Just a couple. Sundar, I think you mentioned Gemini 3 is coming. Maybe a comment on the pace of innovation in frontier models. Is there still just a tremendous amount of innovation, or is it slowing at all? You mentioned a number of large deals signed in the last nine months for Cloud, which is great. Any changes in the economics of these deals as far as long-term profitability? Anything we should be aware of? Thank you.\n\n**Sundar Pichai** (CEO)\nThanks, Justin. The first on the pace of frontier model research and development. Look, I think two things are both simultaneously true. I'm incredibly impressed by the pace at which the teams are executing and the pace at which we are improving these models. It also is true, at the same time, that each of the prior models you're trying to get better over is now getting more and more capable. I think both the pace is increasing, but sometimes we are taking the time to put out a notably improved model. I think that may take slightly longer. I do think the underlying pace is phenomenal to see. I'm excited about our Gemini 3.0 release later this year.\n\n**Sundar Pichai** (CEO)\nOn Cloud, I would point out, as a sign of the momentum, I think the number of deals greater than $1 billion that we signed in the first three quarters of this year are greater than the two years prior. We are definitely seeing strong momentum, and we are executing at pace. In terms of long-term economics, I would say that, again, us being a full-stack AI player and the fact that we are developing highly differentiated products on our own technology, I think will help us drive a good trajectory here, as you have seen over the past few years.\n\n**Justin Post** (Internet Analyst)\nGreat. Thank you.\n\n**Operator**\nThank you. That concludes our question and answer session for today. I'd like to turn the conference back over to Jim Friedland for any further remarks.\n\n**Jim Friedland** (Head of Investor Relations)\nThanks, everyone, for joining us today. We look forward to speaking with you again on our fourth quarter 2025 call. Thank you, and have a good evening.\n\n**Operator**\nThank you, everyone. This concludes today's conference call. Thank you for participating. You may now disconnect.",
        "fetched_at": "2026-02-04T16:09:48.719Z"
      },
      {
        "ticker": "GOOGL",
        "title": "Yahoo Finance",
        "published_date": "Jul 23, 2025, 4:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/GOOGL/earnings/GOOGL-Q2-2025-earnings_call-338340.html",
        "content": "**Operator**\nWelcome everyone. Thank you for standing by for the Alphabet Second Quarter twenty twenty five Earnings Conference Call. At this time, all participants are in a listen only mode. After the speaker presentation, there will be a question and answer I would now like to hand the conference over to your speaker today, Jim Friedland, Head of Investor Relations. Please go ahead.\n\n**Jim Friedland** (Senior Director - IR)\nThank you. Good afternoon, everyone, and welcome to Alphabet's second quarter twenty twenty five earnings conference call. With us today are Sundar Pichai, Philip Schindler and Anat Ashkenazi. Now, I'll quickly cover the Safe Harbor. Some of the statements that we make today regarding our business, operations, and financial performance may be considered forward looking.\n\n**Jim Friedland** (Senior Director - IR)\nSuch statements are based on current expectations and assumptions that are subject to a number of risks and uncertainties. Actual results could differ materially. Please refer to our Forms 10 ks and 10 Q, including the risk factors. We undertake no obligation to update any forward looking statement. During this call, we will present both GAAP and non GAAP financial measures.\n\n**Jim Friedland** (Senior Director - IR)\nA reconciliation of non GAAP to GAAP measures is included in today's earnings press release, which is distributed and available to the public through our Investor Relations website located at abc.xyzinvestor. Our comments will be on year over year comparisons unless we state otherwise. And now I'll turn the call over to Sundar.\n\n**Sundar Pichai** (Director &amp; CEO)\nThanks, Jim. Good afternoon, everyone. Q two was a standout quarter for us with robust growth across the company. As you saw at IO, we are leading at the frontier of AI and shipping at an incredible pace. AI is positively impacting every part of the business, driving strong momentum.\n\n**Sundar Pichai** (Director &amp; CEO)\nThis quarter, search delivered double digit revenue growth. Our new search features continue to perform well. AI mode has launched in The US and India and is going well. While AI overviews now has over 2,000,000 monthly users across more than 200 countries and territories and 40 languages. I'll give some more details on search in a moment.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe continue to see strong performance in YouTube as well as subscriptions, reflecting great momentum across these high growth businesses. In The US, Shorts now earn as much revenue per watch hour as traditional in stream on YouTube. And in some countries, it now even exceeds in stream straight. Cloud had another great quarter of strong growth in revenues, backlog, and profitability. Its annual revenue run rate is now more than $50,000,000,000.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe are seeing significant demand for our comprehensive AI product portfolio. Of course, this is all possible because of the long term investments we have made in our differentiated full stack approach to AI. This spans AI infrastructure, world class research, models and tooling, and our products and platforms that brings AI to people all over the world. I'll briefly touch on the AI stack before turning to quarterly highlights. First, AI infrastructure.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe operate the leading global network of AI optimized data centers and cloud regions. We also offer the industry's widest range of TPUs and GPUs along with storage and software built on top. That's why nearly all GenAI unicorns use Google Cloud. And it's why a growing number, including leading AI research labs like SAFE Superintelligence and Physical Intelligence use TPU specifically. Our AI infrastructure investments are crucial to meeting the growth and demand from cloud customers.\n\n**Sundar Pichai** (Director &amp; CEO)\nNext, world class AI research including models and tooling. We continue to expand our Gemini 2.5 family of hybrid reasoning models, which provide industry leading performance in nearly every major benchmark. In addition to improving our popular workhorse model Flash, we debuted an extremely fast flashlight version. We achieved gold medal level performance in the International Math Olympiad using an advanced version of Gemini with DeepTing. We can't wait to bring DeepTing to users soon.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe have some of the best models available today at every price point. Our 2.5 models have been a catalyst for growth, and 9,000,000 developers have now built with Gemini. I also want to mention v o three, our state of the art video generation model. It's been a viral hit with people sharing clips created in the Gemini app and with our new AI filmmaking tool, Flow. Since May, over 70,000,000 videos have been generated using v o three.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd we recently introduced a feature in the Gemini app to turn photos into videos, which people absolutely love. It's also rolling out to Google Photos users starting today. Third, our products and platforms. We are bringing AI to all our users and partners through surfaces like Workspace, Chrome, and more. The growth in usage has been incredible.\n\n**Sundar Pichai** (Director &amp; CEO)\nAt IO in May, we announced that we processed 480,000,000,000,000 monthly tokens across our surfaces. Since then, we have doubled that number, now processing over 980,000,000,000,000 monthly tokens, a remarkable increase. The Gemini app now has more than 450,000,000 monthly active users, and we continue to see strong growth in engagement with daily requests growing over 50% from q one. In June alone, over 50,000,000 people used AI powered meeting notes in Google Meet. And powered by v o three, our new short video product in Workspace called Google Vets reached nearly 1,000,000 monthly active users.\n\n**Sundar Pichai** (Director &amp; CEO)\nThis month at Samsung Galaxy unpacked, we announced new Android and AI features that are available on Samsung's latest devices. And we are really pleased with the growth in subscriptions, which got a boost from our Google AI Pro and Ultra plans. Now some key highlights from Search, Cloud, YouTube, and Waymo for the quarter. First up, this is an incredibly exciting moment for Search. We see AI powering an expansion in how people are searching for and accessing information, unlocking completely new kinds of questions you can ask Google.\n\n**Sundar Pichai** (Director &amp; CEO)\nOverall queries and commercial queries on search continue to grow year over year, our new AI experiences significantly contributed to this increase in usage. We are also seeing that our AI features cause users to search more as they learn that search can meet more of their needs. That's especially true for younger users. Let me go deeper on our new search experiences. We know how popular AI overviews are because they are now driving over 10% more queries globally for the types of queries that show them, and this growth continues to increase over time.\n\n**Sundar Pichai** (Director &amp; CEO)\nAI overviews are now powered by Gemini 2.5, delivering the fastest AI responses in the industry. We also saw strong growth in the use of multimodal search, particularly the combination of lens of circle to search together with AI overviews. This growth was most pronounced among younger users. Our new end to end AI search experience, AI mode, continues to receive very positive feedback, particularly for longer and more complex questions. It's still rolling out, but already has over 100,000,000 monthly active users in The US and India.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe plan to keep enhancing the AI mode experience for users by shipping great features fast. That includes our advanced research tool, deep search, and more personalized responses. Next, Google Cloud. We see strong customer demand driven by our product differentiation and our comprehensive AI product portfolio. Four stats show this.\n\n**Sundar Pichai** (Director &amp; CEO)\nOne, the number of deals over $250,000,000 doubling year over year. Two, in the first half of twenty twenty five, we signed the same number of deals over $1,000,000 that we did in all of 2024. Three, the number of new GCP customers increased by nearly 28% quarter over quarter, or more than 85,000 enterprises, including LVMH, Salesforce, and Singapore's DBS Bank now built with Gemini, driving a 35 x growth in Gemini usage year over year. Our models have served on our AI infrastructure, which offers industry leading performance and cost efficiency for both training and inference. Along with our AI accelerators, we introduced new innovations in storage, including anywhere cache, which improves inference latency by up to 70%, and rapid storage, which delivers a five x improvement in latency compared to leading hyperscalers.\n\n**Sundar Pichai** (Director &amp; CEO)\nIn addition, we have optimized AI software packages, including PyTorch and JAKs with full open source supports for various AI training and serving demands. We've also integrated AI agents deeply into each of our cloud products. Wayfair is leveraging our databases integrated with AI to streamline data pipelines and deliver more personalized customer experiences. Vatel is leveraging our Gemini powered data agents and BigQuery to review and act on product feedback more quickly. Target is using our Gemini powered threat intelligence and security operations agents to improve cybersecurity.\n\n**Sundar Pichai** (Director &amp; CEO)\nCab Gemini is utilizing our AI software engineering agents to deliver higher quality software faster by automating tasks from cogeneration to testing. And BBVA says Gemini and Google Workspace is saving employees nearly three hours per week by automating repetitive tasks. It's now rolling it out to 100,000 employees globally. We're also focused on building a flourishing AI agent ecosystem. We introduced an open source agent development kit, now has over a million downloads in less than four months.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe also introduced AgentSpace, an open and interoperable enterprise chat search and agent platform. GardenFoodservice is bringing AgentSpace to its US employees, which is enabling better, more efficient decision making. And over 1,000,000 subscriptions have been booked for agent space ahead of its general availability. Turning now to YouTube. Nielsen data shows YouTube has led US streaming watch time for over two years.\n\n**Sundar Pichai** (Director &amp; CEO)\nA generation that grew up with YouTube on their devices is now increasingly watching their favorite creators and content on their televisions. That includes millions of sports fans too. Globally, they consume more than forty million hours of sports content on YouTube annually. And in September, we'll stream the NFL's first Friday game of the season live from Brazil. From sports to shorts, we now average over 200,000,000 daily views on YouTube shorts.\n\n**Sundar Pichai** (Director &amp; CEO)\nAI is helping improve our recommendations and auto dubbing, which translates to better returns for creators and brands by dramatically increasing the potential audiences they can reach. And today, we began rolling out whole draft of new AI tools for creators on YouTube Shorts. Finally, YouTube continues to diversify its subscription options, recently expanding its premium light offerings to 15 new countries with more to come. And lastly, Waymo continues to scale and expand to safely serve more riders in more places. Last month, Waymo launched in Atlanta, more than doubled its Austin service territory, and expanded its Los Angeles and San Francisco Bay Area territories by approximately 50%.\n\n**Sundar Pichai** (Director &amp; CEO)\nWaymo also launched teen accounts starting with riders aged 14 to 17 in Phoenix. Overall, great momentum here. The Waymo Driver has now autonomously driven over 100,000,000 miles on public routes, and the team is testing across more than 10 cities this year, including New York and Philadelphia. We hope to serve riders in all 10 in the future. As I said, a standout quarter.\n\n**Sundar Pichai** (Director &amp; CEO)\nA big thank you as always to our employees and partners for an amazing q two. Caleb, over to you.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nThanks, Sundar, and hello, everyone. I'll quickly cover performance for Google services for the quarter, then structure the rest of my remarks around the great progress we're delivering across search, ads, YouTube, and partnerships. Google services revenues were 83,000,000,000 for the quarter, up 12% year on year, driven by strong growth in Search and YouTube, partially offset by year on year decline in network revenues. To add some further color to our results, the 12% increase in Search and Other revenues was led by growth across all verticals with the largest contributions from retail and financial services. YouTube saw similar performance across verticals.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nIts 13% growth in advertising revenues was driven by direct response followed by brand. Starting with search and other revenues, which delivered over 54,000,000,000 in revenue for the quarter. Shifts like AI are what propels our industry forward. Gemini's native multimodality is helping bring the offline audio and visual world back into the online world, creating a number of opportunities for search. Let me share a few examples.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nTake visual course. Google Lens searches are one of the fastest growing query types on search and grew 70% since this time last year. The majority of Lens searches are incremental, and we're seeing healthy growth for shopping queries using Lens. And you can obviously take this to the next level by moving from image to video based capabilities like Search Live. And then there's Circle to Search, which is now on over 300,000,000 Android devices.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nWe've been adding capabilities to help people explore complex topics and ask follow-up questions without switching apps. For example, gamers can now use Circle to search while playing mobile games to see an AI overview or answers. And just last week, we brought a new agentic capability directly into search for all US users with AI powered calling to local businesses. Finally, shopping. Where in Q2, we introduced a virtual tryout experience for Search Labs users in The US.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nNow people can try billions of clothing products on themselves virtually. Early results and engagement have been extremely positive, articulate with Gen Z users, and we'll be bringing this functionality to all US users imminently. All these innovations are opening up completely new ways for people to use technology, bringing the offline world into the online world in ways that simply have not been possible before. Add in our amazing AI translation capabilities and just imagine the possibilities. People can access more content in the language and businesses, large and small, international or local, can reach even more customers.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nI'm excited about how all of these elements will come together and the opportunities ahead of us in Search. Moving to ads, where our strategy to reinvent the entire marketing process with AI is delivering value for our customers and our business. Last quarter, we introduced AI Max and Search, a new suite of AI powered features in existing search campaigns. Advertisers that activate AI Max and Search campaigns typically see 14% more conversions. On media buying, smart bidding exploration, the biggest update to bidding strategy in a decade, brings better performance to advertisers by allowing them to bid on less obvious but potentially higher value queries more often.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nCampaigns using smart bidding exploration see a 19% increase in conversions on average. Demand Gen continues to drive revenue growth and deliver measurable impact for our customers. As an example, Depop, Etsy's resale clothing marketplace, used the Shorts only demand gen campaign to drive new customers to the site. Shorts drove 80% higher brand lift and double click through rates versus benchmarks. On creatives, we launched Asset Studio using our latest models to help businesses, large and small, generate creative assets.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nSmall businesses benefit from top quality assets and deployment scaling capabilities, while larger businesses can go faster from proof of concept to launch and resize at lower costs. Over 2,000,000 advertisers now use Google's AI powered asset generation tools to run ads, a 50% increase on this time last year. Turning to YouTube, where we saw continued strong revenue growth driven by direct response followed by brand. YouTube creators are connected to the global zeitgeist and trusted by their audiences like no others. As part of BrandConnect, we launched Creator Partnership Hub, which allows brands to more easily work with the right creators and tap into cultural moments.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nWe introduced VIO3 photo to video and generative effects to Shorts, making content creation easier and offering unexplored avenues for creativity. We're seeing both the volume and the price of ads in Shorts increase, particularly in developed markets. The feed based nature of the product allows for more ad opportunities on average, and this growth is further supported by ad formats native to Shorts, AI powered ad creative resizing tools, improved ad targeting, and the rise in viewer engagement. McDonald's USA harnessed the influence of YouTube creators to ignite awareness for the Minecraft movie meal. It leveraged YouTube Shorts partnership ads to increase its reach, generating a 3.3 times higher view through rate than the industry benchmark.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nFinally, on CTV where the momentum continues. According to the gauge report by Nielsen, YouTube has been number one in streaming watch time in The U. S. For more than two years, hitting a record high of 12.8% of total TV viewing in June 2025. In the past twelve months, YouTube ads viewed on CTV screens drove over 1,000,000,000 conversions.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nWe saw strong growth in retail, thanks to CTV shopping ads, which allows viewers to shop directly via QR codes, helping us leverage direct marketing opportunities. As always, I'll wrap up with the momentum we're seeing in partnerships, where our customers increasingly recognize the strength and breadth of Google's ability to help them transform their business with AI. For instance, a new partnership with PayPal will improve the digital commerce experience for their merchants and customers. PayPal will expand its Google Cloud adoption for AI driven recommendations, transaction processing, and enhanced security. The partnership also broadens the availability and functionality of PayPal's payment services and capabilities across a range of Google products.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nIn closing, I'd like to thank Googlers everywhere for their contributions and commitment to our success and to our customers and partners for their continued trust. Anat, over to you.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nThank you, Philip. My comments will focus on year over year comparisons for the second quarter, unless I state otherwise. I will start with results at the Alphabet level and will then cover our segment results. I'll end with some commentary on our outlook for the second half of twenty twenty five. We had another solid quarter in Q2.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nConsolidated revenue of $96,400,000,000 increased by 14% or 13% in constant currency. Search and YouTube advertising, subscription platforms and devices and Google Cloud each had double digit revenue growth this quarter, reflecting strong momentum across the business. Total cost of revenue was $39,000,000,000 up 10%. Tech was $14,700,000,000 up 10% and other costs of revenue was $24,300,000,000 up 10% with the increase primarily driven by content acquisition costs largely for YouTube followed by depreciation. Total operating expenses increased 20% to $26,100,000,000 The biggest driver of growth was expense for legal and other matters which reflected the impact of $1,400,000,000 charge related to a settlement in principle of certain legal matters.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nR and D investments increased by 16%, primarily driven by increases in compensation and depreciation expenses. Sales and marketing expenses increased 5%, primarily reflecting an increase in advertising and promotional expenses. Operating income increased 14% this quarter to $31,300,000,000 and operating margin was 32.4. Operating margin benefited from strong revenue growth and continued efficiencies in our expense base, partially offset by the legal charge I mentioned earlier and a significant increase in depreciation expense. Net income increased 19% to $28,200,000,000 and earnings per share increased 22% to $2.31 We generated free cash flow of $5,300,000,000 in the second quarter and $66,700,000,000 for the trailing twelve months.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nFree cash flow in the second quarter was affected by sizable sequential increase in CapEx and cash tax payments as we make federal tax payments in the second quarter for both Q1 and Q2. We ended the quarter with $95,000,000,000 in cash and marketable securities. Turning to segment results. Google services revenues increased 12% to 82,500,000,000 reflecting strength in Google Search and YouTube advertising and subscriptions. Google Search and other revenues increased by 12% to $54,200,000,000 Search and other revenues delivered growth across all verticals with the largest contributions coming from retail and financial services.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nYouTube advertising revenues increased 13% to $9,800,000,000 driven by direct response advertising followed by brand. Network advertising revenue of $7,400,000,000 were down 1%. Subscription, platforms and devices revenues increased 20% to $11,200,000,000 primarily reflecting growth in subscription revenues. This growth was driven by YouTube subscription offerings followed by Google One with growth in paid subscriptions being the biggest driver of revenue growth. Google service operating income increased 11% to $33,100,000,000 Operating margin was flat year on year at 40.1% as healthy revenue growth and continued efficiency in our expense base were partially offset by the legal charge I mentioned earlier.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nTurning to the Google Cloud segment, which delivered very strong results this quarter. Revenues increased by 32% to $13,600,000,000 in the second quarter, reflecting growth in GCP across core and AI products at the rate that was much higher than cloud's overall revenue growth and growth in Google Workspace driven by an increase in average revenue per seat and the number of seats. Google Cloud operating income increased to $2,800,000,000 and operating margin increased from 11.3% to 20.7%. The expansion in cloud operating margin was driven by strong revenue performance and continued efficiencies in our expense base, partially offset by higher technical infrastructure usage costs, which includes the associated depreciation. As we ramp our AI investments, we continue to focus on driving improvements in productivity and efficiency to offset growth in technical infrastructure related expenses, particularly from higher depreciation.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nGoogle Cloud backlog increased 18% sequentially in Q2 and 38% year over year, reaching $106,000,000,000 at the end of the quarter. This growth was driven by strong demand for our products and services from both new and existing customers. As Sundar mentioned, we have signed multiple billion dollar plus deals in the first half of the year. As for Other in the second quarter revenue were $373,000,000 and operating loss was 1,200,000,000.0 Within Other Bets, we're allocating more resources to businesses like Queimo, where we see opportunities to create additional value. With respect to CapEx, in the second quarter, our CapEx was $22,400,000,000 The vast majority of our CapEx was invested in technical infrastructure with approximately two third of investments in servers and one third in data centers and networking equipment.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nIn Q2, we returned capital to shareholders through repurchase of stock of $13,600,000,000 and dividend payments of $2,500,000,000 Turning to our outlook. I would like to provide some commentary on several factors that will impact our business performance in the 2025 as well as an updated outlook for full year CapEx. First, in terms of revenues, we're pleased with the overall momentum we're seeing across the business. At current spot rates, we could see a tailwind to our revenue in Q3. However, volatility in exchange rates could affect the impact of FX on Q3 revenue.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nAs for our segments, in Google Services, advertising revenues in the 2025 will be affected by the following: the continued lapping of the strength we experienced in financial service verticals throughout 2024 and year over year comparisons will be negatively impacted by the strong spend on U. S. Selection in the second half of twenty twenty four, particularly on YouTube. In cloud, as I mentioned, the demand for our products is high as evidenced by the continued revenue growth and the cloud backlog of $106,000,000,000 While we have been working hard to increase capacity and have improved the pace of server deployment, we expect to remain in a tight demand supply environment going into 2026. Moving to investments.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nGiven the strong demand for our cloud products and services, we now expect to invest approximately $85,000,000,000 in CapEx in 2025, up from a previous estimate of $75,000,000,000 Our updated outlook reflects additional investment in servers, the timing of delivery of servers and an acceleration in the pace of data center construction primarily to meet cloud customer demand. Looking out to 2026, we expect a further increase in CapEx due to the demand we're seeing from customers as well as growth opportunities across the company. We will provide more details on the 2026 CapEx outlook on a future earnings call. In terms of expenses, first, as I mentioned on our previous earnings call, the significant increase in our investments in CapEx over the past few years will continue to put pressure on the P and L, primarily in the form of higher depreciation. In the second quarter, depreciation increased $1,300,000,000 year over year to $5,000,000,000 reflecting a growth rate of 35%.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nGiven the recent increase in CapEx investments, we expect the growth rate in depreciation to accelerate further in Q3. Second, as we've previously said, we expect some headcount growth in 2025 in key investment areas. In the third quarter, we expect a sequential increase in total headcount additions due in part to the hiring of new graduates. And third, Q3 will reflect the expense associated with the upcoming August launch of the new Pixel family of products. In conclusion, as you heard from Sundar and Filip, we're pleased with the momentum in the business and excited about the pace of innovation.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nOur full stack approach, which combines AI infrastructure, AI research and AI products and platforms, position us well to deliver new products and services across the company. We're seeing great momentum with our AI efforts, as demonstrated by the increase cumulative token processed. Search revenues are seeing healthy growth with features like AI Overviews, AI Mode and Lens offering new ways for users to access information. Cloud has reached an annual revenue run rate of more than $50,000,000,000 and is delivering margin expansion while continuing to invest to meet customer demand. And YouTube has expanded its addressable market by building new services like Shorts, which now averages over 200,000,000,000 daily views.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nWe're excited to see the value our products and services are bringing to customers and partners around the globe. Now I'll turn the call over to the operator and Sundar and Phillip and I will take your questions.\n\n**Operator**\nThank you. Your first question comes from Eric Sheridan Your line is now open.\n\n**Eric Sheridan** (Managing Director)\nThank you so much for taking the question. Maybe one for Sundar and one for Philip. Sundar, when you think about the journey you're on with respect to the evolution of products and platforms, how do you think about some of the implications of changed consumer behavior and how investors should think about that from the volume perspective versus the monetization perspective? So I think there's a lot of long standing dynamics out there about clicks and click monetization that might be very different when you look out over the next three to five years. And Philip, you think about the evolution of YouTube, you made a number of comments there about subscription revenue.\n\n**Eric Sheridan** (Managing Director)\nI'm just curious how you think about the mix of advertising versus subscription and what some of your key learnings might have been as the subscription side of the business continues to scale? Thank you.\n\n**Sundar Pichai** (Director &amp; CEO)\nThanks, Eric. Appreciate the question. I do think look looking ahead, based on everything we are seeing, it's people are excited about AI. They are adopting it well across our products. For me, you know, just seeing multimodality, how people have modified their behavior to include images both through lens and circle to search seamlessly as part of interacting with Google.\n\n**Sundar Pichai** (Director &amp; CEO)\nYou know, are are early indications that people are gonna be adopting through these moments very, very well. I think I'm trying to understand your question in terms of about clicks and click monetization. Maybe that's something Philip can touch on. But overall, we expect as we build out our organic experiences, you know, we have a good understanding of how to continue training on monetization, so that'll work well with the organic experiences. And but we will lead with organic experience.\n\n**Sundar Pichai** (Director &amp; CEO)\nSo in terms of newer surfaces like Gemini app, etcetera, we'll focus on the organic experience for the near term. But just like we are doing with AI overviews and with AI more over time, you know, we'll we'll be able to bring very, very good commercial experiences there as well, and we think people will adapt to them as they've always done. Maybe Philip can add more. Philip?\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nYeah. So on your question on YouTube subscriptions versus ads, look, I mean, we love our ads business. We love our subscription business. YouTube subscriptions are an increasingly important for YouTube. We'll definitely continue our long term focus here.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nWe had a strong growth across YouTube subscription products, which includes, just to be clear, YouTube TV, YouTube Music and Premium. And I think one common theme for our subscription services in general is offering viewers more choice here. We also have a very deep understanding of the monetization side here, where are we monetizing more with ads, where can we potentially monetize more with subscriptions. So I think we will continue this as a double tier strategy actively going forward.\n\n**Eric Sheridan** (Managing Director)\nThank you.\n\n**Operator**\nOur next question comes from Doug Anous with JPMorgan. Your line is now open.\n\n**Douglas Anmuth** (MD &amp; Internet Analyst)\nThanks so much for taking the questions. One for Sundar and one for Philip. Sundar, can you just talk about how you're thinking about your current access to compute even as you spend $10,000,000,000 more this year in CapEx? You also said that you're still in a tight supply environment, you're just trying to marry those. And then, Philip, Philip perhaps on search growth, can you talk a little bit about paid click and pricing growth just within the 12% search growth and how we should think about volume versus monetization trends going forward? Thanks.\n\n**Sundar Pichai** (Director &amp; CEO)\nDoug, thanks. You know, on the on the CapEx stuff, you know, obviously, we are, you know, seeing strong momentum across across our portfolio and especially in cloud. You are right. It's a tight supply environment, and, you know, we are investing more to expand, but there is obviously a time delay between, you know, this additional investment will play out in future years. And so, you know, that's that's that's that's why both of them are, true at the same time.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd, but we are planning ahead, and we are investing. And, but, overall, it's exciting to see the traction, particularly in cloud. I think the the comprehensiveness of our AI portfolio, the breadth of our offerings, you know, both both providing our models on GPUs and TPUs for our customers. All of that has been really driving demand, and so we are investing to to match up to it.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nAnd on your paid click question, look, to be very clear, I think we said this before. We manage the business to drive great outcomes for our users and an attractive ROI for our advertisers. We actually don't manage to pay clicks and CPC targets. Some of the product and policy changes we make actually drive better monetization at the expense of paid clicks. You will actually see in the 10 Q, paid clicks were up 4% year on year.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nBut a number of factors affect these metrics from quarter to quarter, such as a few examples, advertiser spending, product changes, policy changes, user engagement and so on. So it's really important when it comes to pay clicks and CPCs to avoid drawing like overly broad conclusions solely based on these metrics.\n\n**Douglas Anmuth** (MD &amp; Internet Analyst)\nThank you both.\n\n**Operator**\nOur next question comes from Brian Nowak with Morgan Stanley. Your line is now open.\n\n**Brian Nowak** (Managing Director)\nThanks for taking my questions. I have two. First one, Sundar, there's a lot of discussion about agentic search for commercial activities and agents that can be broadly deployed. Maybe could you just from a technology perspective, when you sit down with the engineering teams working on some of these new agentic capabilities that could come, What are some of the predominant technological hurdles that you think need to be cleared in order to launch scalable agents for commercial queries is the first one. And the second one, I think in the past, you've updated us on stats on sources of internal efficiency you've seen from GenAI enabled capabilities.\n\n**Brian Nowak** (Managing Director)\nAny updates there? And then any sort of learnings on friction points that also need to be overcome for some of these internal tools with GenAI? Thanks.\n\n**Sundar Pichai** (Director &amp; CEO)\nThanks, Brian. On let me start with the first one on agentic capabilities. Look. Overall, we had definitely, in many ways, when we built 2.5 our series of 2.5 models, particularly with Pro, etcetera, you know, it's the direction where we are investing the most. There's definitely exciting progress, including in the models we haven't fully released yet.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd, you know, the main main gaps we are all trying to do is, you know, you're obviously chaining a sequence of events. And and so being able to do it reliably, the latency compounds, the cost compounds, And being able to do it reliably in a way for the users, all of this comes together. In each of this, we are making progress, and it all needs to kinda hang together. The good news is we are making robust progress. We think we are at the frontier there.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd, you know, in all of these areas, when you look back in a twelve month basis, you end up making the models much more efficient for any given capability. So the forward looking trajectory, I think, will really unlock these agentic experiences. We we see the potential. We're able to do them, but they're a bit slow and costly and takes time and sometimes are brittle. Right?\n\n**Sundar Pichai** (Director &amp; CEO)\nBut they're making progress on all of that. And I think that's what will really unlock, and I expect 2026, to be the year in which people kinda use agentic experiences more broadly. Right? And so it's an exciting opportunity ahead. On on the second part, I think when you say source of internalization, I presume you're talking about how we are using all of this internally.\n\n**Sundar Pichai** (Director &amp; CEO)\nYou know, again, given you've asked a question about agents, we are now beginning to roll out agentic coding journeys for our software engineers within the company. And it's been exciting to see just over the last few months, particularly over the last few weeks, people are definitely doing more agentic workflows in software engineering as well internally. And that's that's a good example of the kind of the same experiences a few months ago had a lot of friction points, but, you know, we we are overcoming it, and people are beginning to use internally on the coding side as well as in certain other areas of the company as well. So exciting progress. I expect it to be an active area where we will roll out Journeys for our users as well. So look forward to it.\n\n**Brian Nowak** (Managing Director)\nThanks, Sundar. That's great.\n\n**Operator**\nOur next question comes from Michael Nathanson with MuffettNathanson. Your line is now open.\n\n**Michael Nathanson** (Senior Research Analyst)\nThanks. Sundar, have two for you. At IO, you announced a partnership with Warby Parker to develop glasses. So I wonder if you share your view of how important a cycle of new devices will be to further scale AI? And do you envision a world in which the more functional or essential to our consumer experience?\n\n**Michael Nathanson** (Senior Research Analyst)\nThat's one. And secondly, how does Google Search with AI mode usage different different, sorry, versus Gemini standalone apps. I'm wondering, are you seeing any differences in usage or the types of consumers who go to the app versus who go to traditional search with AI? Thanks.\n\n**Sundar Pichai** (Director &amp; CEO)\nThanks, Michael. On on the first thing, look, I I think anytime IO changes, you know, you can drive new experiences, including on hardware experiences too. So I think AI will particularly enable we've long had the promise of glasses and other form factors. Right? You know, I think AI will spur a whole new wave of innovation there.\n\n**Sundar Pichai** (Director &amp; CEO)\nWe are super excited about our investment in glasses and, you know, found the experiences have taken a dramatic step up compared to the last compared to the last iteration. So I think it'll be an exciting new emerging category, but I still expect phones to be at the center of the experience, you know, for the next, two to three years at least. And and so I I I still think that's going to be phones would continue to be at the center of the consumer experience, But we are excited about the emerging categories as well. On your second question on AI mode versus Gemini standalone app, broadly, there are some use cases where you can you can get a great experience in both places. But there are use cases which are very specific.\n\n**Sundar Pichai** (Director &amp; CEO)\nI think where the queries are, you know, information oriented, but people really want to rely on the information, but have the full power of AI. I think AI mode really shines in that. You can go there and, you know, it's backed up. You know, the Gemini models are using search deeply as a tool, and so it's all grounded in that search experience. And I think I I think users are responding very positively to it.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd whereas in the Gemini standalone app, you know, you see everything from you know, people can have a long conversational chat just trying to pass time, right, in in the Gemini app. You know, you've seen early cases where people may get into it, you know, in a therapy like experience. Right? So these are all emerging experiences of what what people do. And I think this is why I'm glad we have both surfaces, and we can innovate in both of these areas.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd, of course, there'll be areas which will be commonly served by both applications. And over time, I think we can make the experience more seamless for our users.\n\n**Michael Nathanson** (Senior Research Analyst)\nThanks, Sundar.\n\n**Operator**\nOur next question comes from Mark Schmullich with Bernstein. Your line is now open.\n\n**Mark Shmulik** (MD &amp; Senior Analyst - US Internet)\nYes. Thanks for taking the question. Sundar, it seems there's almost like a daily news report about the AI talent war and high profile folks moving around, which is kind of like your perspective and how you think Google's been doing it both kind of attracting and retaining key AI talent? And along the similar lines, how do we think about AI related resourcing costs alongside kind of the step up in capital investments required to go build for AI? Thank you.\n\n**Sundar Pichai** (Director &amp; CEO)\nMark, on the, on the first question, look, I, I think, you know, we've we've gone through these moments before. We've obviously always deeply invested in, in in in talent, including an AI talent for well over a decade now. And I think we have an extraordinary both breadth and depth of the talent. In in my experience, you know, the top people look for a combination of they want to really be at the frontier driving progress and and so the mission and the and and how state of the art your workers matters. So that's super important to them.\n\n**Sundar Pichai** (Director &amp; CEO)\nAccess to compute resources and access to your peers, right, working with the best best people in the industry. And it's a combination of all of that and using it to drive impact. And I think we are pretty competitive on all those fronts. And, you know, through through this moment, we continue to I look at the both our retention metrics as well as the new talent coming in, and and both are healthy. You know, I I do know individual cases can make headlines, but when we look at look at numbers deeply, I think we are, doing very well, through this moment.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd we'll continue investing, in the people and the talent and the compute needed to make sure we are set up well for the opportunity ahead. And maybe I'll pass it on to Anant.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nYeah. And on the question on how we integrate this into our overall cost structure. And I've mentioned before, having the the benefit of having the full stack includes research, which is our people and one of our most critical resource. So, we make sure that we invest appropriately to have the best, brightest minds in the industry sitting here at Google and advancing our innovation to customers. It is part of what you're seeing now in our operating expense line across the organization, but we're also working hard to offset not just growth and investment across the business, but also to ensure that we can allocate resources appropriately.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nSo, Sundar mentioned earlier the use of AI tools within the company. So, that's another area where we can drive efficiency across the businesses to use these tools internally in terms of how we run the organizations. And then we're continuing on the same efforts that I've talked about before with regards to running the company with a high level of discipline and execution and driving efficiency across the business.\n\n**Operator**\nOur next question comes from Ross Sandler with Barclays. Your line is now open.\n\n**Ross Sandler** (Analyst)\nGreat. If I can ask two, that'd be great. So, the first one's on search click through rates as a driver of monetization. So you guys have done a great job over the past decade of driving better ad relevancy and higher click through rates in search. Just curious, as we look forward and we see lower ad impressions per SERP and all these things that are changing with AI overviews and different AI search formats, how do you feel about your ability to drive CTR going forward?\n\n**Ross Sandler** (Analyst)\nAnd then the second question is, it looks like you're now working with OpenAI for some aspect of cloud infrastructure. Just curious how that relationship might expand in the future? Thank you.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nI can take the first one. Look, referring to the area of reviews, if I understood your question correctly. Sundar mentioned it. They continue to drive higher satisfaction. They continue to drive higher search usage.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nThey're scaling up very nicely. And they're actually working for our entire user base now, scaled to over 2,000,000,000 users in over 200 countries. So very happy with this development. But when it comes specifically to the monetization of it, we talked about it before. We see monetization at approximately the same rate, which gives us actually a really strong base on which we can then innovate and and and drive actually more innovative and new and next generation ad formats.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nThat's how we look at it at this moment in time.\n\n**Sundar Pichai** (Director &amp; CEO)\nOn the second part, with respect to OpenAI, look, we are very excited to be partnering with them on Google Cloud. Google Cloud, you know, is a open platform, and, you know, we have a strong history of supporting great companies, startups, AI labs, etcetera. So super excited about our partnership there on the cloud side. And and, you know, we look forward to investing more in that relationship and growing it there.\n\n**Operator**\nOur next question comes from Mark Mahaney with Evercore. Your line is now open.\n\n**Mark Mahaney** (Senior MD)\nOkay. Two questions, please. First, can you just describe maybe Philip, you see in terms of the ad environment maybe for the back half of the year, maybe versus last year? Does it seem as certain or as uncertain as it was last year? The results seem pretty strong.\n\n**Mark Mahaney** (Senior MD)\nAre there unusual concerns you would have for the back half of the year? Then Sundar, I want to ask you again about the two surfaces approach to search. And you obviously got some you must have some internal metrics that could tell you that that's the optimal way for you to approach the market. But, you know, there's I I'm sure there's a counterargument that just having that unified search and being able to discern the intent of the search, whether it's pure information or commercial just from the query, that could give you a material advantage over other offerings in the market? Just talk a little bit about what metrics you've seen that make it that make the two surface solutions seem to be optimal. Thank you.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nSo let me start. Look, our we said our ads business performed strongly in Q2. Give you maybe some vertical color of it. In Q2, Search and Other performance was led by growth across all verticals. We mentioned the largest contributions from Retail and Financial Services, which was probably due actually to strength in Insurance.\n\n**Philipp Schindler** (Senior VP &amp; Chief Business Officer)\nWe saw Healthcare as a sizable contributor to growth as well. Look, we're only a few weeks into Q3, so I think it's really too early to comment on anything happened in the second half of the year.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd, Mark, on the second second part of the question, look, I I think, you know, the between between these two surfaces, you pretty much know, you're covering the entire breadth and depth of what, you know, humanity can possibly do. So I think there's plenty for two surfaces to tackle in this moment. Obviously, you know, you are right. You know, search is more information focused, and we think of the Gemini app as more your assistant, more personal, proactive, and powerful assistant for every aspect of your daily life. And so you can imagine wanting to call deeply or create a long video, etcetera.\n\n**Sundar Pichai** (Director &amp; CEO)\nLike, you know, those those things can be done by the Gemini app today better. Over time, like we've always done, we've gone through these evolutions before. Like, as you point out, you know, we can we can understand user intent better and abstract some of the complexity for our users. At one point, people used to go to, you know, query separately for text differently from images, differently from videos, etcetera, and we kinda made it all seamless with universal search. So we have the experience of being able to bring together experiences in a way that makes sense for users and do the heavy lifting for them.\n\n**Sundar Pichai** (Director &amp; CEO)\nBut but I think, you know, when you're in this early stage of new emerging paradigms, I think we wanna make sure, you know, we can meet them where where they're what they are expecting today. And over time, I think it'll give us an opportunity to serve them better. So I think that's how we are thinking about it.\n\n**Mark Mahaney** (Senior MD)\nOkay. Thank you.\n\n**Operator**\nOur next question comes from Ken Gorelski with Wells Fargo. Your line is now open.\n\n**Ken Gawrelski** (MD &amp; Senior Internet Analyst)\nThank you very much. Two if I may please. The first on cloud, I'm just hoping maybe you could clarify your back half outlook. Given last quarter you talked about some supply constraints that would ease towards the end of twenty twenty five, but yet you put up a really nice acceleration in 2Q. Now you're talking about some supply constraints easing into 2026.\n\n**Ken Gawrelski** (MD &amp; Senior Internet Analyst)\nIf you could just clarify a little bit on the back half outlook for cloud given the strong results in 2Q. And then the second is a bigger picture question which is an agentic experience. Does it democratize the web like search did two decades ago enabling discovery in the long tail? Or does it lead to more concentration with the smaller group of vertical winners? Would love it if you could opine on that. Thank you.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nOkay. On your first question on the cloud second half outlook and the comments I previously made on with regards to where we're going to see the capacity increase. So, obviously, we're working hard to bring more capacity online, which means data centers and servers are coming online. And we see more of an increase towards the back end of the year. But we're increasing capacity with every quarter that goes by, as you can see with the growth rates we've had both this quarter and in the previous quarter.\n\n**Anat Ashkenazi** (EVP &amp; CFO)\nAs Sundar mentioned earlier, this is not the type of investment that's a light switch. It takes time to make this investment. So, what you're seeing now is investment we made some time ago that's now translating to additional capacity coming online, but more of that towards the back end of the year. I will say it's important as you think about cloud growth not to think about this in a linear fashion, because the quarter on quarter growth rates could depend on the timing of capacity delivery and when that comes online, so that could move a little bit from quarter to quarter.\n\n**Sundar Pichai** (Director &amp; CEO)\nLook, on the agent experience, look, I think there was an earlier question on the technology aspects of it and how we are making progress. Obviously, there is the value proposition for all the players involved, and I think that's gonna be an equally important thing to create the unlock unlock here. And I do think, you know, over time, users will you know, it's clear to me as we make progress on the agentic experience, it's going to be a much better experience for users. Right? And so you'll you'll find savvier players leaning into these experiences, and that'll help them grow and meet this moment.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd I think I I I so I do think it's an opportunity for for some of the players. And so you are right. Just like the early early days of the web, there are aspects about it, which will expand access, grow grow the use cases, etcetera. And I think I think that elements are there. But I do think it's important.\n\n**Sundar Pichai** (Director &amp; CEO)\nIt's not just a technology play, but we have to solve the business models for the remaining players involved. So and I I think that's gonna be an important part of this, evolution as well.\n\n**Ken Gawrelski** (MD &amp; Senior Internet Analyst)\nThank you.\n\n**Operator**\nAnd our last question comes from Justin Post with BAML. Your line is now open.\n\n**Justin post** (Managing Director)\nGreat. Thank you. A couple for Sundar. First, looks like the subscription businesses are all tracking well and certainly Gemini 2.5 has got some much good reviews. How are you doing with Gemini subscriptions?\n\n**Justin post** (Managing Director)\nI know it's a focus area for the company and anything you can kind of do to accelerate the consumer subscriptions of Gemini within Google One? And secondly, just on the course change of CapEx, obviously a bigger increase, which appears to be because of cloud demand. But just your comments on cloud ROI and I'm sorry CapEx ROI, what gives you confidence that you're going to get good returns on that spend? Thank you.\n\n**Sundar Pichai** (Director &amp; CEO)\nGreat. Look, on the first thing on subscriptions, we've definitely Google One has been an attractive value proposition powered by storage. But now our AI plans, including both pro and ultra, and particularly with the 2.5 series of models, they've definitely seen accelerated traction. So it it was a very healthy quarter. And and and so we are definitely excited about the opportunities ahead.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd you will find, you know, through this moment, I think we'll be able to drive growth in that area based on our AI offerings. And so it's it's definitely area we are both excited by, and we are actually seeing traction, particularly in the last quarter ever since we introduced 2.5 Pro. So we are excited about about the trajectory there. On on on on the CapEx on the cloud side, look, I I I think we are definitely, investing because, we are delivering a lot of value through our cloud offerings. And I think it's important to understand, you know, as we build more and more of an installed base, with Google Cloud, you know, we have very high customer satisfaction.\n\n**Sundar Pichai** (Director &amp; CEO)\nOur churn rates are very low, and we are much more efficient in in in the investments needed to grow those lines of businesses. So you are seeing all that play out in our margin trajectory, particularly if you look at it annually, sequentially over the past few years. And so and, you know, so all that gives us confidence as we are investing in this. You know, we'll we'll be able to have a healthy ROI on our investments. And particularly in this AI moment, you know, there's definitely the value we are delivering to the customers is also growing pretty significantly on a forward looking basis.\n\n**Sundar Pichai** (Director &amp; CEO)\nAnd so I think all that, you know, will help us, you know, do well here.\n\n**Operator**\nThank you. And that concludes our question and answer session for today. I'd like to turn the conference back over to Jim Friedland for any further remarks.\n\n**Jim Friedland** (Senior Director - IR)\nThanks everyone for joining us today. We look forward to speaking with you again on our third quarter twenty twenty five call. Thank you and have a good evening.\n\n**Operator**\nThank you everyone. This concludes today's conference call. Thank you for participating. You may now disconnect.",
        "fetched_at": "2026-02-04T16:09:54.222Z"
      },
      {
        "ticker": "GOOGL",
        "title": "Yahoo Finance",
        "published_date": "Apr 24, 2025, 4:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/GOOGL/earnings/GOOGL-Q1-2025-earnings_call-312617.html",
        "content": "**Operator**\nThank you for standing by for the Alphabet First Quarter twenty twenty five Earnings Conference Call. At this time, all participants are in a listen only mode. After the speaker presentation, there will be a question and answer I would now like to hand the conference over to your speaker today, Jim Friedland, Senior Director of Investor Relations. Please go ahead.\n\n**Jim Friedland** (Senior Director - IR)\nThank you. Good afternoon, everyone, and welcome to Alphabet's first quarter twenty twenty five earnings conference call. With us today are Sundar Pichai, Philip Schindler and Anat Ashkenazi. Now, I'll quickly cover the Safe Harbor. Some of the statements that we make today regarding our business, operations and financial performance may be considered forward looking.\n\n**Jim Friedland** (Senior Director - IR)\nSuch statements are based on current expectations and assumptions that are subject to a number of risks and uncertainties. Actual results could differ materially. Please refer to our Forms 10 ks and 10 Q, including the risk factors. We undertake no obligation to update any forward looking statement. During this call, we will present both GAAP and non GAAP financial measures.\n\n**Jim Friedland** (Senior Director - IR)\nA reconciliation of non GAAP to GAAP measures is included in today's earnings press release, which is distributed and available to the public through our Investor Relations website located at abc.xyzinvestor. Our comments will be on year over year comparisons unless we state otherwise. And now, I'll turn the call over to Sundar.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nThanks, Jim. Good afternoon, everyone. We are pleased with our strong results this quarter. We continue to see healthy growth and momentum across the business, including AI powering new features. In Search, we saw continued double digit revenue growth. AI Overviews is going very well with over 1,500,000,000 users per month and we are excited by the early positive reaction to AI mode. There's a lot more to come ahead.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nIn subscriptions, we surpassed two seventy million subscriptions with YouTube and Google One as key drivers. And cloud grew rapidly with significant demand for our solutions and you saw our leadership in AI at Cloud Next across infrastructure, agents and more. Our differentiated full stack approach to AI continues to be central to our growth. This quarter was super exciting as we rolled out Gemini 2.5, our most intelligent AI model which is achieving breakthroughs in performance and it's widely recognized as the best model in the industry. That's an extraordinary foundation for our future innovation and we are focused on bringing this to people and customers everywhere.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nLooking ahead to IO, Brandcast and Google Marketing Live, I can't wait for our teams to showcase the innovations they've been working on. Turning to our AI progress this quarter, which continues to enable significant growth opportunities. The elements of the AI stack I've previously mentioned are AI infrastructure, world class research including models and tooling, and our products and platforms. Starting with AI infrastructure, our long term investments in our global network have positioned us well. Google's network is robust and resilient, supported by over 2,000,000 miles of fiber and 33 subsea cables.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nComplementing this, we offer the industry's widest range of TPUs and GPUs and continue to invest in next generation capabilities. Ironwood, our seventh generation TPU and most powerful to date, is the first designed specifically for inference at scale. It delivers more than 10x improvement in compute power over a recent high performance TPU while being nearly twice as power efficient. A strong relationship with NVIDIA continues to be a key advantage for us and our customers. We were the first cloud provider to offer NVIDIA's groundbreaking B200 and GB200 Blackwell GPUs and will be offering their next generation Vera Rubin GPUs.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nSecond, this infrastructure powers our world class research including our industry leading models. We released Gemini 2.5 Pro last month, receiving extremely positive feedback from both developers and consumers. 2.5 Pro is state of the art on a wide range of benchmarks and debuted at number one on the chatbot arena by a significant margin. 2.5 Pro achieved big leaps in reasoning, coding, science and math capabilities, opening up new possibilities for developers and customers. Active users in AI Studio and Gemini API have grown over 200 since the beginning of the year.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAnd last week, we introduced 2.5 Flash, which enables developers to optimize quality and cost. Our latest image and video generation models, Imagine three and Vio2, are rolling out broadly and are powering incredible creativity. Turning to open models. We launched Gemma three last month delivering state of the art performance for its size. Gemma models have been downloaded more than 140,000,000 times.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nLastly, we are developing AI models in new areas where there's enormous opportunity. For example, our new Gemini robotics models. And in Health, we launched AI Coscientist, a multi agent AI research system, while AlphaFold has now been used by over 2,500,000 researchers. Third, turning to products and platforms. All 15 of our products with a half a billion users now use Gemini models.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAndroid and Pixel are two examples of how we are putting the best AI in people's hands, making it super easy to use AI for a wide range of tasks just by using their camera, voice or taking a screenshot. We are upgrading Google Assistant on mobile devices to Gemini and later this year will upgrade tablets, cars and devices that connect to your phone such as headphones and watches. The Pixel 9a launched very strong reviews, providing the best of Google's AI offerings like Gemini Live and AI powered camera features. And Gemini Live camera and screen sharing is now rolling out to all Android devices, including Pixel and Samsung S25. Now moving on to key highlights from across Search, Cloud, YouTube and Waymo.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nFirst, Search. AI is one of the most revolutionary technologies for enabling and expanding our information mission. And for Search, we see it growing the number and types of questions we can answer. We are already seeing this with AI Overviews, which now has more than 1,500,000,000 users every month. Nearly a year after we launched AI Overviews in The U.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nS, we continue to see that usage growth is increasing as people learn that search is more useful for more of their queries. So we are leaning in heavily here, continuing to roll the feature out in new countries to more users and to more queries. Building on the positive feedback for AI overviews, in March we released AI Mode, an experiment in labs. It expands what AI overviews can do with more advanced reasoning, thinking and multimodal capabilities to help with questions that need further exploration and comparisons. On average AI mode queries are twice as long as traditional search queries.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nWe're getting really positive feedback from early users about its design, fast response time and ability to understand complex nuanced questions. We also continue to see significant growth in multimodal queries. Circle to Search is now available on more than two fifty million devices with usage increasing nearly 40% this quarter. And monthly visual searches with Lens have increased by 5,000,000,000 since October. Moving on to Cloud.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAt Cloud Next, we announced major innovations and over 500 companies shared the business results they are achieving by working with us. We provide leading cost, performance and reliability for AI training and inference. This enables us to deliver the best value for AI leaders like AnyScale and contextual AI as well as global brands like Verizon. And for highly sensitive data and regulatory requirements, Google Distributed Cloud and our sovereign AI make Gemini available on premises or in country. Our Vertex AI platform makes over 200 foundation models available, helping customers like Lowe's integrate AI.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nWe offer industry leading models, including Gemini 2.5 Pro, 2.5 Flash, Imagine three, Vio2, Chirp and Liria, plus open source and third party models like Lama four and Anthropic. We are the leading cloud solution for companies looking to the new era of AI agents, a big opportunity. Our Agent Development Kit is a new open source framework to simplify the process of building sophisticated AI agents and multi agent systems. And Agent Designer is a low code tool to build AI agents and automate tasks in over 100 enterprise applications and systems. We are putting AI agents in the hands of employees at major global companies like KPMG.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nWith Google Agent Space, employees can find and synthesize information from within their organization, converse with AI agents and take action with their enterprise applications. It combines enterprise search, conversational AI or chat, and access to Gemini and third party agents. We also offer prepackaged agents across customer engagement, coding, creativity and more that are helping to provide conversational customer experiences, accelerate software development and improve decision making. And of course, Google Workspace. It delivers more than 2,000,000,000 AI assists monthly, including summarizing Gmail and refining docs.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nLastly, our cybersecurity products are helping organizations detect, investigate and respond to cybersecurity threats. Our expertise, coupled with integrated Gemini AI advances, detects malware, prioritizes threats and speeds up investigative workflows. This quarter, we were excited to announce our intent to acquire Wizz, a leading cloud security platform that protects all major clouds and cloud environments. Together, we can make it easier and faster for organizations of all types and sizes to protect themselves end to end and across all major clouds. We think this will help spur more multi cloud computing, something customers want.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nNext, YouTube. Yesterday marked a historic milestone, the twentieth anniversary of the first video uploaded to YouTube. From that single nineteen second upload, the platform has grown into a global phenomenon, fundamentally changing how billions of people create, share and experience content. Through all this growth, subscriptions are now a big part of the business. We continue to diversify subscription options, recently expanding our Premium Light pilot to The U.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nS, giving users a new way to enjoy most videos on YouTube ad free. TV is the primary device for YouTube viewing in The U. S. According to Nielsen, YouTube has been number one in streaming watch time in The U. S.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nFor the last two years and YouTube now has over 1,000,000,000 monthly active podcast users. Users. YouTube Music and Premium reached over 125,000,000 subscribers, including trials globally. And finally, Waymo is now safely serving over a quarter of million paid passenger trips each week. That's up 5x from a year ago.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nThis past quarter, Waymo opened up paid service in Silicon Valley. Through our partnership with Uber, we expanded in Austin and are preparing for our public launch in Atlanta later this summer. We recently announced Washington, D. C. As a future ride hailing city going live in 2026 alongside Miami.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nWaymo continues progressing on two important capabilities for riders: airport access and freeway driving. Thanks to all of our employees for their work this quarter. It was a great start to the year and Q2 will be even more exciting. With that, Filip, over to you.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nThanks, Sundar, and hello everyone. I'll quickly cover performance for the quarter and then frame the rest of my remarks around the progress we're delivering across Search, Ads, YouTube and partnerships. Google services revenues were $77,000,000,000 for the quarter, up 10% year on year, driven by strong growth in Search and YouTube, partially offset by year on year decline in Network revenues. To add some further color to the performance, the 10% increase in Search and Other revenues was led by Financial Services, primarily due to strength in insurance followed by retail. YouTube saw a similar performance across verticals.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nIts 10% growth in advertising revenues was driven by direct response followed by brand. So let's start with Search, where we've seen robust growth in revenues. All around the world, over 2,000,000,000 people use Search every day to find information, compare products or shop and there are more than 5,000,000,000,000 searches on Google annually. We've continued our efforts to help more people ask entirely new questions, bringing more opportunities for businesses to connect with consumers and as we've mentioned before, with the launch of AI Overviews, the volume of commercial queries has increased. Q1 marked our largest expansion to date for AI overviews, both in terms of launching to new users and providing responses for more questions.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nThe feature is now available in more than 15 languages across 140 countries. For AI overviews overall, we continue to see monetization at approximately the same rate, which gives us a strong base on which we can innovate even more. Turning to visual queries. On the last earnings call, I mentioned the success we're seeing with Lens, where shoppers use their camera or images to quickly find information in ways they couldn't before. In Q1, the number of people shopping on Lens grew by over 10% and the majority of Lens queries are incremental.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nSundar mentioned the significant growth we're also seeing with Circle to Search as multimodality continues to drive queries across search. Moving to ads, more businesses big and small are adopting AI powered campaigns and the deployment of AI across our Ads business is driving results for our customers and for our business. Throughout 2024, we launched several features that leverage LLMs to enhance advertiser value and we're seeing this work pay off. The combination of these launches now allows us to match ads to more relevant search queries and this helps advertisers reach customers in searches where we would not previously have shown their ads. Focusing on our customers, we continue to solve advertisers' pain points and find opportunities to help them create, distribute and measure more performed ads, infusing AI at every step of the marketing process.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nOn audience insights, we released new asset audience recommendations, which tell businesses the themes that resonate most with their top audiences. On creatives, advertisers can now generate a broader variety of lifestyle imagery customized to their business to better engage their customers and use them across PMax, demand gen, display and app campaigns. Additionally, in PMax, advertisers can automatically source images from their landing pages and crop them, increasing the variety of their assets. On media buying, advertisers continue to see how AI powered campaigns help them find new customers. In DemandGen, advertisers can more precisely manage ad placements across YouTube, Gmail, Discover and Google Display Network globally and understand which assets work best at a channel level.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nThanks to dozens of AI part improvements launched in 2024, businesses using DemandGen now see an average 26% year on year increase in conversions per dollar spent for goals like purchases and leads. And when using DemandGen with product feed, on average, they see more than double the conversion per dollar spent year over year. As an example, Royal Cannon combined DemandGen and Pmax campaigns to find more customers for its cat and dog food products. The integration resulted in a 2.7 times higher conversion rate, a 70% lower cost per acquisition for purchases and increased the value per user by 8%. Turning to YouTube, where we saw strong growth in revenues across ads and subscriptions.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nThis week, we're celebrating YouTube's twentieth anniversary. We're proud of its leadership as a streaming destination where people come to watch everything they love, from live sports and creator produced content to shorts and podcasts. Creators are what drives viewership and on average, they upload 20,000,000 videos a day to YouTube. Our biggest creators generate a level of fandom and viewer engagement around large cultural moments on YouTube that brands can't find anywhere else. During March Madness, brands aligned not only with clips and highlights from the game, but also with the creators who drive basketball culture like Jesser and the Ringer's J.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nKyle Mann. In Q1, the growth of our reservation based ads business more than doubled year over year. Brands and creators continue to use the opportunities that collaborations and partnerships offer. Toyota worked with Zach King, the king of short magical videos with over 42,000,000 followers to take over his channel. The creator takeover and accompanying creator ad lifted Toyota's brand awareness by 25% compared to a control group and 9% compared to the Toyota brand ad.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nLooking at Shorts, engaged views grew by over 20% in the first quarter. We continue to be pleased with the progress we're making globally in Shorts monetization relative to in stream viewing and are particularly encouraged by the trend in The U. S. As always, I'll wrap up with a strong momentum we're seeing in partnerships where our customers increasingly recognize the strength and breadth of what Google has to offer. For instance, Roblox is partnering Google Ad Manager to bring immersive ads to gamers.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nGen Z gamers are Roblox biggest users and thanks to our partnership, advertisers will be able to reach this audience with ads that blend seamlessly into the gaming experience. We also launched a YouTube shorts effect to help people release iconic Roblox ads and inspire fans to create content at scale. In closing, I'd like to thank Googlers everywhere for their contributions and commitment to our success and to our customers and partners for their continued trust. Anat, over to you.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nThank you, Philip. My comments will focus on year over year comparisons for the first quarter unless they state otherwise. I will start with results at the Alphabet level and will then cover our segment results. I'll end with some commentary on our outlook for the second quarter and 2025. We had another strong quarter in Q1.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nConsolidated revenues of $90,200,000,000 increased by 12% or 14% in constant currency. Search and YouTube advertising, subscription platforms and devices and Google Cloud each had double digit revenue growth this quarter, reflecting strong momentum across the business. Total cost of revenue was $36,400,000,000 up 8%. Tech was $13,700,000,000 up 6%. We continue to see a revenue mix shift with Google Search growth at double digit levels, while network revenues, which have much higher TAC rate, declined.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nOther costs of revenue was $22,600,000,000 up 9% with the increase primarily driven by content acquisition costs largely for YouTube followed by depreciation and other technical infrastructure operations costs. Total operating expenses increased 9% to $23,300,000,000 R and D investments increased by 14%, primarily driven by increases in compensation and depreciation expenses. Sales and marketing expenses decreased 4%, primarily reflecting a decline in compensation expenses. G and A expenses increased by 17%, reflecting the impact of charges for legal and other matters. Operating income increased 20% this quarter to $31,000,000,000 and operating margin increased to 33.9%, representing 2.3 points of margin expansion.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nOperating margin benefited from healthy revenue growth, a moderated pace of compensation growth and a favorable mix shift towards lower tech advertising revenues, partially offset by a year on year increase in depreciation expenses of just over $1,000,000,000 Other income and expenses was 11,200,000,000 primarily due to unrealized gain on our non marketable equity securities related to our investment in a private company, which we noted on our 10 ks as a subsequent event. Net income increased 46% to $34,500,000,000 and earnings per share increased 49% to $2.81 We delivered free cash flow of $19,000,000,000 in the first quarter and $74,900,000,000 for the trailing twelve months. We ended the quarter with $95,000,000,000 in cash and marketable securities. Turning to segment results, Google services revenues increased 10% to $77,300,000,000 reflecting strength in Google Search and YouTube advertising as subscription. Google Search and other advertising revenues increased by 10% to $50,700,000,000 The robust performance of Search was once again broad based across verticals led by financial services due primarily to strength in insurance, followed by retail.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nYouTube advertising revenues increased 10% to $8,900,000,000 driven by direct response advertising, followed by brand. Network advertising of $7,300,000,000 were down 2%. Subscription platforms and device revenues increased 19% to $10,400,000,000 primarily reflecting growth in subscription revenues. This growth was primarily driven by YouTube subscription offerings followed by Google One with growth in the number of subscribers being the biggest driver of revenue growth. Google services operating income increased 17% to $32,700,000,000 and operating margin increased from 39.6% to 42.3%.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nTurning to the Google Cloud segment, which continued to deliver very strong results this quarter. Revenue increased by 28% to 12,300,000,000 in the first quarter, reflecting growth in GCP across core and AI products at a rate that was much higher than cloud's overall revenue growth rate. Growth in Google Workspace was primarily driven by an increase in average revenue per seat. Google Cloud operating income increased to 2,200,000,000 and operating margin increased from 9.4% to 17.8%. As we scale our fleet, we continue to focus on driving improvements in productivity, efficiency and utilization to offset the growth in expenses, particularly from higher depreciation.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nAs for Other Bets, for the first quarter, revenues were $450,000,000 and operating loss was $1,200,000,000 The year on year decline in revenue and increase in operating loss primarily reflect the milestone payment received in the first quarter of twenty twenty four for one of our other bets. With respect to CapEx, our reported CapEx in the first quarter was $17,200,000,000 primarily reflecting investment in our technical infrastructure with the largest component being investment in servers, followed by data centers to support the growth of our business across Google services, Google Cloud and Google DeepMind. In Q1, we returned value to shareholders in the form of $15,100,000,000 in share repurchases and $2,400,000,000 in dividend payments. As we announced today, our Board of Directors declared a 5% increase in our quarterly dividend and also approved a new $70,000,000,000 share repurchase authorization. Turning to our outlook, I would like to provide some commentary on several factors that will impact our business performance in the second quarter and the remainder of 2025.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nFirst, in terms of revenue, I'll highlight a couple of items that we mentioned last quarter that will have an impact on second quarter and 2025 revenue. First, in Google services, advertising revenue in 2025 will be impacted by lapping the strength we experienced in the financial service vertical throughout 2024. Second, in cloud, we're in a tight demandsupply environment And given that revenues are correlated with the timing of deployment of new capacity, we could see variability in cloud revenue growth rates depending on capacity deployment each quarter. We expect relatively higher capacity deployment towards the end of twenty twenty five. Moving to investments, starting with our expectation for CapEx for the full year 2025.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nWe still expect to invest approximately $75,000,000,000 in CapEx this year. The expected CapEx investment level may fluctuate from quarter to quarter due to the impact of changes in the timing of deliveries and construction schedules. In terms of expenses, first, as I mentioned on our previous earnings call, the significant increase in our investments in CapEx over the past few years will continue to put pressure on the P and L, primarily in the form of higher depreciation. In the first quarter, we saw 31% year on year growth in depreciation from the increase in technical infrastructure assets placed in service. Given the increase in CapEx investments over the past few years, we expect the growth rate in depreciation to accelerate throughout 2025.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nSecond, as we've previously said, we expect some headcount growth in 2025 in key investment area. As we've disclosed previously, due to a shift in the timing of our annual employee stock based compensation award beginning in 2023, our first quarter stock based comp expenses is relatively lower compared to the remaining quarters of the year. In conclusion, as you heard from Sundar and Filip, we're pleased with the progress we're making across the organization, the results for the quarter and the opportunities ahead. Our success as a company is grounded in our experience driving advancements in deep computer science that enables us to create innovative new products and services for users, businesses and partners around the world. We have a strong track record of incubating and then building these offerings into new profitable businesses for Alphabet.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nAs we announced last quarter, YouTube and Cloud exited 2024 at a combined annual run rate of $110,000,000,000 And as you heard from Sundar earlier, Waymo is continuing to progress in building on its impressive technological achievements to scale rapidly and develop a sustainable business model. Thank you. Sundar, Philip and I will now take your questions.\n\n**Operator**\nThank you. And our first question comes from Brian Nowak from Morgan Stanley. Your line is now open.\n\n**Brian Nowak** (Managing Director)\nGreat. Thanks for taking my questions. I have two. The first one is sort of the macro advertising backdrop. Maybe, Anat, I know it's April 24 and you called out some factors as you're kind of thinking about the second quarter.\n\n**Brian Nowak** (Managing Director)\nAny other factors you're seeing in advertising verticals or regions or categories that could be showing any signs of weakness quarter to date so we should think through any other changes from typical seasonality in 2Q twenty twenty five versus prior quarters? Then the second one on Philip, I think I heard you mention now the volume of commercial queries has increased. Maybe can you just walk us through which of the products are driving that increase in Commercial Queries? And as you sort of think about the pipeline of Search products, are there any others that you're particularly excited about to kind of continue to drive further Commercial Query growth throughout 2025, '20 '20 '6? Thanks.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nSo let me take the first one as well. We saw broad based strength across ad verticals in Q1 and we saw it give you a bit of vertical color here, search was led again by finance due primarily to ongoing strength in the insurance, retail, healthcare and travel were actually also sizable contributors here to growth. With regard to Q2, we're only a few weeks in, so it's really too early to comment. I mean, we're obviously not immune to the macro environment, but we wouldn't want to speculate about potential impacts beyond noting that the changes to the de minimis exemption will obviously cause a slight headwind to our ads business in 2025 primarily from APAC based retailers. And maybe to zoom out, I would say we have a lot of experience in managing through uncertain times and we focus on helping our customers by providing deep insights into changing consumer behavior that is relevant to their business.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nExamples are auction dynamics, quarry trend insights on topics like replacement purchases and so on. So we have a lot of experience in this area. On the Commercial Query side, look, AI Overviews continue to drive higher satisfaction and search usage. And as I noticed Q1 was really our largest expansion to date for AI Overviews both in terms of launching to new users and providing responses for more questions. That's really the core already of the answer.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nAI Overview sits at the center of your question here. And when it comes to other products, look, I don't want to speculate on this, but we're happy with what we're seeing here on AI overviews. And I'm confident we can expand this to more products over time.\n\n**Operator**\nThank you. Your next question is from Doug Drummond from JPMorgan. Your line is now open.\n\n**Douglas Anmuth** (Managing Director &amp; Internet Analyst)\nGreat. Thanks for taking the questions. Phil, maybe just to go back to AI overviews for a moment. Can you just tell us how we should think about the 1,500,000,000 AI overviews users just in terms of breadth of rollout? And I know you're saying monetization at approximately the same rate, but what does that mean in terms of click through rates and conversion? And then Anat, just curious if there have been any changes to Google's approach to durably reengineering the cost base since you've joined? And if macro weakens and you see more of a slowdown, would you expect to find additional opportunities to cut back more on costs? Thank you.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nYes. Look, on the ads of in AI Overviews, late last year actually we launched them within the AI Overviews on mobile in The U. S. And this builds on our previous rollout of ads above and below. So this was a change we have.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nBut as I talked about it before for AI overviews overall we see the monetization at approximately the same rate, which gives us a strong base on which we can innovate even more. So I'm very happy with this. I don't think this is the moment to go into the details of click through rates and conversion and so on. But overall, we're happy with what we're seeing.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nAnd to your question on our approach to productivity and efficiency, it hasn't really changed. I've mentioned my approach and our approach as a company on at the end of twenty twenty four. And we're still focused on driving efficiency and productivity throughout the organization, both in our operating expenses and in our CapEx. I've mentioned some of these during my prepared remarks. But certainly, this helps us as we think about the investments we need to make in innovation to drive long term sustainable growth profile for the company.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nWe're able to repurpose some of these efficiencies into these investments. As well as, as you think about the increase in CapEx we've seen over the past several years and what we're investing this year, this will put additional pressure on the income statement in the form of depreciation. So, we're working hard to try and offset some of these headwinds. As well as within the CapEx investments themselves, dollars 75,000,000,000, we're looking at how do we make sure every dollar is used efficiently. We have a highly rigorous process to determine the demand behind it and then the allocation of the compute associate with our technical infrastructure investments, ensuring that we're utilizing that appropriately and that we're highly efficient with everything we're doing.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nYou've seen some of the announcement and some of the changes, but we're focusing on continuing to moderate the pace of compensation growth, looking at our real estate footprint, and again, the build out and utilization of our technical infrastructure across the business.\n\n**Douglas Anmuth** (Managing Director &amp; Internet Analyst)\nGreat. Thank you, both.\n\n**Operator**\nThank you. Our next question comes from Eric Sheridan from Goldman Sachs. Your line is now open.\n\n**Eric Sheridan** (Managing Director)\nThank you for taking the questions. First, maybe for Sundar, when you look across the consumer AI landscape today, how are you thinking about continuing to drive differentiation for Gemini as a platform through the lens of usage, utility or putting product innovation at the forefront of driving consumer habits? And then the second one maybe for Anat. If the macro environment were to change and become more downwardly volatile, how should investors think about the investments that are must make this year almost fixed in nature versus where there might be more flexibility to alter the investment priorities of the company if the macro environment were to worsen? Thank you so much.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nThanks, Eric. Obviously, it's an exciting moment on the AI front. I think the foundation for everything is obviously the frontier model progress we are seeing. And particularly with 2.5 Pro and Flash, I think we are well positioned. We are seeing tremendous reception from developers, enterprises and consumers too.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAnd obviously, we are delivering consumer AI experiences across our product portfolio, including the primary way people experience it is obviously in Search with AI overviews and very early days with AI mode, but that will be a consumer AI forward experience. And we're already seeing very positive feedback. Queries are people are typing in roughly 2x longer queries compared to traditional search. So there's a lot of excitement there. And in the Gemini app, which you asked about, we've really seen increased momentum, particularly over the last few weeks as we've rolled out not just the newer models, but we are seeing users are really responding well to all the innovation.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nGemini Live, which is based on Project Astra, has been very well received. Deep research, I think, based on 2.5 Pro is SOTA and that's been well received. And Canvas, we've had a lot of traction as well. And so we are definitely investing more. We recently organized ourselves better to capitalize on this momentum and I'm excited about our roadmap there.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nAnd on the investments this year and overall, should there be any macroeconomic changes, you know, as I said, we're still planning to invest approximately $75,000,000,000 in CapEx this year. We do see a tremendous opportunity ahead of us across the organization, whether it's to support Google services, Google Cloud, and Google DeepMind. Recall, I've stated on the q four call that we exited the year specifically with more customer demand than we had capacity. And that was the case this quarter as well. So we want to make sure we ramp up to support customer needs and customer demands.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nHaving said that, we're investing in long term and we're investing in innovation. That's the essence of our business. And we want to do it in a responsible fashion. So you've seen us over the past couple of years, and we're continuing to do this, and you're seeing this in our results, drive efficiency and productivity throughout the business. And we've announced things such as consolidation of teams, which helps not just with cost, but with velocity and speed.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nWe're able to get things to market faster. So that's one of the areas we're focused on. You heard from Sundar the last couple of calls on just a rapid pace of innovation we're bringing to the marketplace. So the way we're doing this across the business to drive productivity and efficiency should help us have a more resilient organization irrespective of macroeconomic condition. But certainly, we don't ignore that.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nWe always look at what's happening outside the organization as well as inside, but invest appropriately to drive both the short term growth as well as the long term growth.\n\n**Eric Sheridan** (Managing Director)\nThank you.\n\n**Operator**\nThank you. Our next question comes from Ross Sandler from Barclays. Your line is now open.\n\n**Ross Sandler** (Analyst)\nGreat, thanks. One for Sundar, one for Philip. Sundar, it was disclosed this week in the trial that's going on that Gemini has 35,000,000 DAUs. And just curious, that number obviously trails ChatGPT by a pretty wide margin. Could you just talk about the strategy to get that DAU figure much higher that you guys are deploying?\n\n**Ross Sandler** (Analyst)\nAnd then Philip, just curious to hear what you're seeing on the brand advertising side at YouTube in 1Q and into early 2Q. Are brands holding up relatively well like Direct Response or are they starting to react to some of these macro jitters that we're all experiencing? Any thoughts there? Thank you very much.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nThanks, Ross. I think I touched upon this to Eric's question as well, but we are definitely I think there's been a lot of momentum in terms of product features we've been introducing and we are definitely seeing reception including increased adoption and usage based on those features. So I think we are in a good positive cycle. The recent advances on the model frontier by many metrics, think we have the best model out there now and I think that's going to drive increased adoption as well. And again, I would reiterate, people are using obviously, we have 1,500,000,000 users through AI overviews interacting with AI in a deep way, in a very engaged way.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nObviously, are innovating with AI mode. And we have a very exciting road map ahead with the Gemini app as well. So across the board, super excited about what's ahead.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nAnd on your Brand question, look Brand and by the way also Direct Response had a very solid growth in Q1. Brand advertisers really enjoyed cultural moments we had like Coachella, for example, or March Madness. We had strong contributions overall from the finance and retail verticals in Q1 on this side as well. The operating metrics for YouTube were strong in Q1. Watch time growth remains robust, particularly in key monetization opportunity areas such as shorts and living room.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nIt's also, by the way, nice to see the strong position of our creators who obviously benefit from the brand piece, which gives us a lot of confidence when we look at it more closely. And on the Q2 side, I mentioned it's too early to really comment on that.\n\n**Operator**\nThank you. Your next question is from Mark Smolik from Bernstein. Your line is now open.\n\n**Mark Shmulik** (Analyst)\nGreat. Thanks for taking my questions. Sundar, appreciate the color on Gemini deployment across kind of the 15 products with 5,000,000,000 users or more. It would be great to hear more about where you're seeing the most usage and deployment of Gen AI internally at Google. Perhaps whether the capabilities, are they in a place today in terms of either supplementing or augmenting the workforce?\n\n**Mark Shmulik** (Analyst)\nAnd then just to build on that earlier AI mode type questions, appreciate AI mode has 2x longer queries than traditional search, but any color you can share perhaps on how AI mode behavior differs from how consumers are using the Gemini app? Thank you.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nLook on internally, I mean, this has been extraordinary amount of focus and excitement both because I think we are the early use cases have been transformative in nature and I think this still feels like early days and long ways to go. Obviously, I had mentioned a few months ago in terms of how we are using AI for coding, We are continuing to make a lot of progress there in terms of people using coding suggestions. I think the last time I had said the number was like 25% of code that's checked in. It involves people accepting AI solutions. That number is well over 30% now.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nBut more importantly, we have deployed more deeper flows. And particularly with the newer models, I think we are working on early agentic workflows and how we can get those coding experiences to be much deeper. We are deploying it across all parts of the company. Our customer service teams are deeply leading the way there. We've both dramatically enhanced our user experience as well as made it much more efficient to do so.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAnd we are actually bringing all our learnings and expertise in our solutions through cloud to our other customers. But beyond that, all the way from the finance team preparing for this earnings call to everything, it's deeply embedded in everything we do, but I still see it as early days and there's going to be a lot more to do. On AI Mode, look, I think we are just leaning in on the early positive feedback well, as we scaled up AI overviews. It's been one of our most positive launches and but it's been clear people have wanted even more of it. And so with AI Mode, we are bringing the our state of the art Gemini models right into Search.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAnd I mentioned people typing in longer queries. There's a lot more complex, nuanced questions. People are following through more. People are appreciating the clean design, the fast response time and the fact that they can kind of be much more open ended, can undertake more complicated tasks, product comparisons, for example, has been a positive one, exploring how tos, planning a trip. So those are the kinds of early feedback we are seeing.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAnd I think we are obviously really focused on improving the product across all of AI, Mode, AI Overviews and the Gemini app, and we are seeing positive user traction as well.\n\n**Operator**\nThank you. Your next question is from Mark Mahaney from Evercore. Your line is now open.\n\n**Mark Mahaney** (Senior Managing Director)\nOkay. Thanks. One for Anat and one for Sundar. Anat, getting back to a question I think that Doug was asking earlier on. You just put up record high or multi year record high margins for both Google services and for Google Cloud.\n\n**Mark Mahaney** (Senior Managing Director)\nYou talked Phil about depreciation expenses accelerating rapidly throughout the year because all the investments you've already you'd warn people about. Back in the September, you seem relatively confident that you had enough levers to kind of offset kind of rising infrastructure costs. Was that still your six months later, is that still your view that you've got enough levers that even with the rising infrastructure costs you can there's enough in there to kind of counterbalance that? And then just briefly on Waymo that continues to rise aggressively the numbers Sundar. The long term business model for Waymo, is there a reason to make a decision on that soon?\n\n**Mark Mahaney** (Senior Managing Director)\nOr have you already made the decision of whether this is a long term licensing model or you really want to run this as a standalone ride sharing delivery in autonomous vehicle business? Thank you very much.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nThanks. On your first question on profitability and what levers do we have and do we still have levers to pull first, think every organization can always push a little further. I don't view productivity goals or efficiency as an episodic kind of project based effort, but rather a continuous effort that when you get to a certain place, you push a little further. Having said that, we do have significant investments we're making across the organization, and we have been making them for the past several quarters. And we've been able to do it because we were able to find efficiency to fund those investments across the organization.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nThose are for products and services that are going to drive long term growth for the company. So, while we're trying to offset as much of the headwind associated with the increase in infrastructure costs, it will become more difficult. As I said, the depreciation will accelerate. We had about a 31% year over year growth in depreciation this quarter and it will be higher as we go throughout the year. So think about that kind of as a headwind that we have to manage against.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nBut we're continuing with pushing across the organization, leveraging, Sundar mentioned, the use of AI and kind of an AI first Google across several of our functions to help us manage a larger scope of work using our AI, AI agents, and AI tools. As Sudar mentioned, we did deleverage it in preparation for the earnings call, and we're leveraging across several functions. So there are opportunities, but there are also great opportunities for investment, and we want to make sure that we make room for to make these investments to drive long term growth and ensure we have a very resilient long term growth profile for the company.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nAnd Marc, thanks. I think this is probably the first question I've got on our earnings call on Waymo, so thank you. And I think it's a sign of its progress. Look, the thing that excites me is I think we've been laser focused and we'll continue to be on building the world's best driver. And I think doing that well really gives you a variety of optionality and business models across geographies, etcetera.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nIt will also require a successful ecosystem of partners and we can't possibly do it all ourselves. And so I'm excited about the progress the teams have made through a variety of partnerships. Obviously, a highlight of it is a partnership with Uber. We are very pleased with what we are already seeing in Austin in terms of rider satisfaction. We look forward to offering the first paid rides in Atlanta via Uber later this year.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nBut we are also building up a network of partners, for example, for maintaining fleets of vehicles and doing all the operations related to that with the recently announced partnership with Moo in Phoenix and Miami, obviously partnerships with OEMs. There are future optionality around personal ownership as well. So we are widely exploring and but at the same time, staying focused and making progress both in terms of safety, the driver experience and progress on the business model and operationally scaling it up.\n\n**Mark Mahaney** (Senior Managing Director)\nOkay. Thank you very much.\n\n**Operator**\nThank you. Our next question comes from Ken Gorelsody from Wells Fargo. Your line is now open.\n\n**Ken Gawrelski** (Analyst)\nThank you. Two if I may please. First on AI powered search. You have a number of AI powered search interfaces including three most prominently AI Overviews, AI Mode and Gemini. In the future, should we think of these as distinct experiences that will be long lasting or more experimental now and Google will eventually focus on one approach going forward?\n\n**Ken Gawrelski** (Analyst)\nAnd the second one is more on the financial side. You continue to experience very healthy gross margin expansion. We see the TAC, sure, Anat, you also talked about the offsetting depreciation expense. Could you talk about beyond those two buckets where you're seeing the real savings on the COGS line and driving that gross margin expansion? And maybe even how we should be thinking about that going forward? Thank you.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nOkay. Now, maybe on AI powered Search and how do we see our consumer experiences. Look, do think Search and Gemini obviously will be two distinct efforts, right? I think there are obviously some areas of overlap, but they're also you know, like expose very, very different use cases. And so, for example, in Gemini, we see people iteratively coding and going much deeper on a coding workflow, as an example.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nSo I think both will be around. Within Search, would think of AI overviews scaling up and working for our entire user base, but an AI mode is the tip of the tree for us pushing forward on an AI forward experience. There will be things which we discover there which will make sense in the context of AI overviews, so I think will flow through to our user base. But you almost want to think of what are the most advanced 1,000,000 people using Search for, the most advanced 10,000,000 people, and then how do 1,000,000,000 people use Search for. And we want to innovate and so I think this allows us to do that.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nBut the true north through all of this is user feedback, user satisfaction, user experience. And so that will determine where this all works out in the future.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nAnd to your question on gross margin, a couple of trends to highlight there and I've mentioned this in the prepared remarks. You've seen improvement in tech that's really driven by the change in revenue mix with a continued search growth and then network revenue declines. Network revenue has a much higher tech rate. So that mix is helping us from a gross margin perspective. So think about that as well.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nNow we do have depreciation for technical infrastructure hits in two place primarily in two places in the income statement. One is in other costs of sales and the rest is in R and D. So it is in that line item that's impacting costs of sales. Now we've had some efficiencies there and I did mention the improvement in our overall cost of headcount growth and compensation kind of moderating those growth. So that helps us as well more than offset the depreciation increases in Q1.\n\n**Anat Ashkenazi** (Senior VP &amp; CFO)\nBut as I mentioned, this number will be higher in the coming quarters. Recall we have we said approximately $75,000,000,000 in CapEx, which is up from $55,000,000,000 or just over $50,000,000,000 last year. So, there is expected to be quite a significant increase in depreciation.\n\n**Operator**\nThank you. And our last question comes from Ron Josey from Citi. Your line is now open.\n\n**Ron Josey** (Managing Director)\nGreat. Thanks for taking the question. Philip, I wanted to touch a little bit more on your comments around Direct Response and YouTube. I think it's been improving and been a driver over the past couple of quarters. I'd love to hear more just about what's driving that.\n\n**Ron Josey** (Managing Director)\nIs that the demand gen and integration with Pmax? Or are users perhaps more involved on direct response now that Shorts usage is rising? Would love your thoughts there.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nYes. I think there's a lot of different factors. Mostly, we continue to help our customers really using our AI powered tools. You mentioned a few of them to drive performance. That's a very big one.\n\n**Philipp Schindler** (SVP &amp; Chief Business Officer)\nAs I mentioned before, we're also happy with the progress we're seeing on Shorts and closing the monetization gap here to the overall business, which is actually really nice to see, especially in The U. S. So we're very happy with that.\n\n**Sundar Pichai** (Director &amp; Chief Executive Officer)\nYes. And I'll just chime in to say YouTube just celebrated its twentieth birthday and we now have more than 20,000,000,000 videos on YouTube and we get 20,000,000 videos uploaded every day. So I think it's a tremendous platform and thanks to all the creators and users who have supported us there over the years.\n\n**Ron Josey** (Managing Director)\nGreat. Thank you.\n\n**Operator**\nThank you. And that concludes our question and answer session for today. I would like to turn the conference back over to Jim Freeland for any further remarks.\n\n**Jim Friedland** (Senior Director - IR)\nThanks everyone for joining us today. We look forward to speaking with you again on our second quarter twenty twenty five call. Thank you and have a good evening.\n\n**Operator**\nThank you everyone. This concludes today's conference call. Thank you for participating. You may now disconnect.",
        "fetched_at": "2026-02-04T16:10:00.116Z"
      }
    ]
  },
  "AMZN": {
    "ticker": "AMZN",
    "last_updated": "2026-02-04T16:11:22.459Z",
    "total_transcripts": 3,
    "transcripts": [
      {
        "ticker": "AMZN",
        "title": "Yahoo Finance",
        "published_date": "Oct 30, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/AMZN/earnings/AMZN-Q3-2025-earnings_call-369430.html",
        "content": "**Operator**\nThank you for standing by. Good day, everyone, and welcome to the Amazon.com Third Quarter 2025 Financial Results Teleconference. At this time, all participants are in a listen-only mode. After the presentation, we will conduct a question-and-answer session. Today's call is being recorded, and for opening remarks, I'll be turning the call over to the Vice President of Investor Relations, Mr. Dave Fildes. Thank you, sir. Please go ahead.\n\n**Dave Fildes** (VP of Investor Relations)\nHello, and welcome to our Q3 2025 Financial Results Conference call. Joining us today to answer your questions is Andy Jassy, our CEO, and Brian Olsavsky, our CFO. As you listen to today's conference call, we encourage you to have a press release in front of you, which includes our financial results, as well as metrics and commentary on the quarter. Please note, unless otherwise stated, all comparisons in this call will be against our results for the comparable period of 2024. Our comments and responses to your questions reflect management's views as of today, October 30, 2025, only, and will include forward-looking statements. Actual results may differ materially. Additional information about factors that could potentially impact our financial results is included in today's press release and our filings with the SEC, including our most recent annual report on Form 10-K and subsequent filings.\n\n**Dave Fildes** (VP of Investor Relations)\nDuring this call, we may discuss certain non-GAAP financial measures in our press release, slides accompanying this webcast, and our filings with the SEC, each of which is posted on our IR website. You will find additional disclosures regarding these non-GAAP measures, including reconciliations of these measures with comparable GAAP measures. Our guidance incorporates the order trends that we've seen to date and what we believe today to be appropriate assumptions. Our results are inherently unpredictable and may be materially affected by many factors, including fluctuations in foreign exchange rates, changes in global economic and geopolitical conditions, tariff and trade policies, and customer demand and spending, including the impact of recessionary fears, inflation, interest rates, regional labor market constraints, world events, the rate of growth of the internet, online commerce, cloud services, and new and emerging technologies, and the various factors detailed in our filings with the SEC.\n\n**Dave Fildes** (VP of Investor Relations)\nOur guidance assumes, among other things, that we don't conclude any additional business acquisitions, restructurings, or legal settlements. It's not possible to accurately predict demand for our goods and services, and therefore our actual results could differ materially from our guidance. Now I'll turn the call over to Andy.\n\n**Andy Jassy** (CEO)\nThanks, Dave. We saw strong growth across our business in Q3, and we're reporting $180.2 billion in revenue, up 12% year-over-year, excluding the impact from foreign exchange rates. Operating income was $17.4 billion, but would have been over $21 billion if not for two special Q3 expenses: $2.5 billion for an FTC settlement and $1.8 billion for estimated severance costs. Trailing 12-month free cash flow was $14.8 billion. I'll start with AWS. AWS is growing at a pace we haven't seen since 2022, re-accelerating to 20.2% year-over-year, our largest growth rate in 11 quarters. It's worth remembering that year-over-year % growth is a relative term. It's very different having 20% year-over-year growth on a $132 billion annualized run rate than to have a higher % growth rate on a meaningfully smaller annual revenue, which is the case with our competitors.\n\n**Andy Jassy** (CEO)\nBacklog grew to $200 billion by Q3 quarter end and doesn't include several unannounced new deals in October, which together are more than our total deal volume for all of Q3. AWS is gaining momentum. Customers want to be running their core and AI workloads in AWS, given its stronger functionality, security, and operational performance. The scale I see in front of us gives me significant confidence in what lies ahead. I'll share a little more detail on why. It starts with AWS having much broader infrastructure functionality. Startups, enterprises, and governments want to move their production workloads to the place that has the broadest and deepest array of capabilities. AWS has more services and deeper features within those services than anybody else and continues to innovate at a rapid clip.\n\n**Andy Jassy** (CEO)\nThese are key building blocks for anything that customers want to create, and they're a big part of why Gartner has named AWS leader in its strategic cloud platform services, Magic Quadrant, for 15 consecutive years. We're bringing the same building block approach to AI. Amazon SageMaker makes it much simpler for companies to build and deploy their own foundation models. Amazon Bedrock gives customers leading selection of foundation models and superior price performance to deploy inference into their next-generation applications. A lot of the future value companies will get from AI will be in the form of agents. AWS is heavily investing in this area and well-positioned to be a leader. Companies will both create their own agents and use agents from other companies. For those building their own, it's been harder to build than it should be.\n\n**Andy Jassy** (CEO)\nIt's why we launched Strands to make it much easier to create agents from any foundation model that builders desire. For companies who've successfully built agents, they've hesitated putting them into production because they lack secure, scalable runtime services, or memory or observability built specifically for agents. It's why we launched AgentCore, a set of infrastructure building blocks that allow builders to deploy secure, scalable agents. Ericsson used AgentCore to deliver AI agents across their workforce. Sony used it to build an agentic AI platform with enterprise-level security, observability, and scalability. Cohere Health is using AgentCore to deploy agents that will reduce medical review times by up to 30% to 40%. AgentCore's SDK has already been downloaded over a million times, and our builders are excited about it. It's an enabler.\n\n**Andy Jassy** (CEO)\nCompanies will also use others' agents, and AWS continues to build many of the agents we believe builders will use in the future. For coding, we've recently opened up our agentic coding IDE called Curo. More than 100,000 developers jumped into Curo in just the first few days of preview, and that number has more than doubled since. It's processed trillions of tokens thus far, weekly actives are growing fast, and developers love its unique spec and tool calling capabilities. For migration and transformation, we offer an agent called Transform. Year to date, customers have already used it to save 700,000 hours of manual effort, the equivalent of 335 developer years of work. For example, Thomson Reuters used it to transform 1.5 million lines of code per month, moving from Windows to open-source alternatives and completing tasks four times faster than with other migration tools.\n\n**Andy Jassy** (CEO)\nCustomers have also already used Transform to analyze nearly a billion lines of mainframe code as they move mainframe applications to the cloud. For business customers, we've recently launched QuickSleep to bring a consumer AI-like experience to work, making it easy to find insights, conduct deep research, automate tasks, visualize data, and take actions. We've already seen users turn months-long projects into days, get 80%+ time savings on complex tasks, and realize 90%+ cost savings. For contact centers, we offer Amazon Connect, which creates a more personalized and efficient experience for contact center agents, managers, and their customers. Connect has recently crested a $1 billion annualized revenue run rate, with 12 billion minutes of customer interactions being handled by AI in the last year and is being used by large enterprises like Capital One, Toyota, American Airlines, and Ryanair.\n\n**Andy Jassy** (CEO)\nThese are real, practical results for customers, and there are many more examples like them. Because of its advantaged capabilities, security, operational performance, and customer focus, AWS continues to earn most of the big enterprise and government transformations to the cloud. As a result, AWS is where the preponderance of companies' data and workloads reside and part of why most companies want to run AI in AWS. To enable customers to do so, we need to have the requisite capacity, and we've been focused on accelerating capacity the last several months, adding more than 3.8 gigawatts of power in the past 12 months, more than any other cloud provider. To put that into perspective, we're now double the power capacity that AWS was in 2022, and we're on track to double again by 2027.\n\n**Andy Jassy** (CEO)\nIn the last quarter of this year alone, we expect to add at least another 1 gigawatt of power. This capacity consists of power, data center, and chips, primarily our custom silicon Trainium and NVIDIA. We've recently brought Project Rainier online, our massive AI compute cluster spanning multiple U.S. data centers and containing nearly 500,000 of our Trainium 2 chips. Anthropic is using it now to build and deploy its industry-leading AI model, Claude, which we expect to be on more than 1 million Trainium 2 chips by year-end. Trainium 2 continues to see strong adoption, is fully subscribed, and is now a multi-billion-dollar business that grew 150% quarter over quarter. Today, Trainium is being used by a small number of very large customers, but we expect to accommodate more customers starting with Trainium 3.\n\n**Andy Jassy** (CEO)\nWe're building Amazon Bedrock to be the biggest inference engine in the world, and in the long run, believe Bedrock could be as big a business for AWS as EC2, and the majority of token usage in Amazon Bedrock is already running on Trainium. We're also continuing to work closely with chip partners like NVIDIA, with whom we continue to order very significant amounts, as well as with AMD and Intel. These are very important partners with whom we expect to keep growing our relationships over time. You're going to see us continue to be very aggressive investing in capacity because we see the demand. As fast as we're adding capacity right now, we're monetizing it. It's still quite early and represents an unusual opportunity for customers in AWS.\n\n**Andy Jassy** (CEO)\nI'll now turn to stores, where the team continues to deliver and innovate for customers across our key priorities: selection, low prices, and convenience, particularly fast delivery. We're offering 14% more selection since last quarter from popular brands like The North Face and Charlotte Tilbury, and we've added hundreds of thousands of items from popular brands this year. Everyday essentials continues to grow quickly, and year to date is growing nearly twice as fast as the rest of the business. We continue to make it easier for customers to order low-priced perishable groceries from Amazon, and customers in more than 1,000 cities and towns now can shop fresh groceries alongside millions of Amazon.com products with free same-day delivery. This is a game changer for customers who can now order milk alongside electronics, check out with one card, and have everything delivered to their doorstep within hours.\n\n**Andy Jassy** (CEO)\nThe team also invented a new add-to-delivery button that lets customers add items to previously scheduled orders, and it's been used more than 80 million times since launch, and it just launched. It's an example of one of those seemingly simple but powerful innovations that make customers' lives easier. We remain committed to staying sharp on price and meeting or beating prices of other major retailers. In July, we had our biggest Prime Day event ever, with customers saving billions of dollars across more than 35 categories. We continue to break records on speed. We're on track to deliver at our fastest speeds ever for Prime members globally once again this year, and we've started rolling out three-hour delivery in select U.S. cities. We're also continuing to invest in infrastructure to speed up rural deliveries and serve more customers in more communities.\n\n**Andy Jassy** (CEO)\nThat includes committing over $4 billion to expand our rural delivery network across the U.S. These are small towns where people want fast delivery, but where other companies have been backing out and reducing service. In contrast, we've already increased the number of rural communities with access to our same-day and next-day delivery by 60%, reaching roughly half of the total communities we plan to expand to by the end of the year. The stores team is also innovating rapidly with AI. For example, Rufus, our AI-powered shopping assistant, has had 250 million active customers this year, with monthly users up 140% year-over-year, interactions up 210% year-over-year, and customers using Rufus during a shopping trip being 60% more likely to complete a purchase. Rufus is on track to deliver over $10 billion in incremental annualized sales. Here are the highlights.\n\n**Andy Jassy** (CEO)\nOur generative AI-powered audio feature that combines product summaries and reviews to make shopping easier has expanded from hundreds of products at launch to millions of products, and millions of customers have used it, streaming almost 3 million minutes. Amazon Lens, an AI-powered visual search tool that lets customers find products with their phone's camera, a screenshot, or a barcode, now includes Lens Live, which instantly scans products and shows real-time matches in a swipeable carousel. Tens of millions of customers are using Amazon Lens each month. Moving on to Amazon Ads, we're pleased with the continued strong growth, generating $17.6 billion of revenue in the quarter and growing 22% year-over-year. We see strength across our broad portfolio of full-funnel advertising offerings that helps advertisers reach an average ad-supported audience of more than 300 million in the U.S. alone.\n\n**Andy Jassy** (CEO)\nWe also continue to be excited about our demand-side platform, Amazon DSP, which lets advertisers plan, activate, and measure full-funnel investments. Last quarter, I mentioned our partnership with Roku, and we've built on that with a partnership with Netflix, providing advertisers using Amazon DSP with direct access to Netflix's premium ad inventory. We announced integrations with Spotify and SiriusXM. With Spotify, we provide advertisers with direct programmatic access to a global audience of more than 400 million monthly ad-supported listeners. With SiriusXM, brands can reach 160 million monthly digital listeners across services like Pandora and SoundCloud. We're excited about the advertising opportunity around Prime Video Live Sports. Live Sports got a lot of interest from advertisers in upfront negotiations for 2025-2026, and we exceeded our own expectations for upfront commitments with significant growth across the board. Finally, we're continuing to innovate for advertisers with AI.\n\n**Andy Jassy** (CEO)\nFor example, in September, we announced an agentic AI tool in Creative Studio that plans and executes the entire creative process in a matter of hours instead of weeks. We're also inventing and seeing strong momentum in several other areas, and I'll mention just a few. In Prime Video Live Sports, NBA on Prime tipped off last week, and our opening night doubleheader averaged 1.25 million viewers in the U.S., a double-digit increase over last season on cable. You'll see us bring the same constant innovation here that we brought to our NFL broadcasts. We're adding golf with the Masters in 2026 and a new skins competition with the PGA Tour on Black Friday this year. We've added Peacock and Fox One to Prime Video's add-on subscription offering of over 100 channels in the U.S. We continue to be energized by the response to Alexa Plus.\n\n**Andy Jassy** (CEO)\nCompared to what we call the classic Alexa experience, Alexa Plus customers are talking to Alexa two times more, those interactions are much longer, and they're covering a broader range of topics. They're using Alexa Plus on Fire TV at 2.5 times the rate of Classic, using natural conversation to discover audio content four times more, engaging with photos four times more, and customers are completing four times more shopping conversations that end in a purchase. We've expanded the number of Project Kuiper satellites in space to more than 150 and delivered over 1 gigabit per second speeds in tests with our enterprise-grade customer terminal, the first commercial phased array we know of to clear that threshold. Finally, Zoox Robotaxis are available to riders in Las Vegas, and we've announced Washington, D.C., as the eighth testing location. We're excited for these to continue rolling out to more riders.\n\n**Andy Jassy** (CEO)\nQ4 is one of our busiest and most energizing times of the year, and we're excited about the continued demand for AWS, the innovations we'll announce to re:Invent in December, the positive customer response to our AI-powered experiences, all the gifts we'll be delivering throughout the holiday season, and a lot more. Thanks in advance to our teammates around the world who are gearing up to deliver for customers once again. With that, I'll turn it over to Brian for a financial update.\n\n**Brian Olsavsky** (CFO)\nThanks, Andy. Starting with our top-line financial results, worldwide revenue was $180.2 billion, a 12% increase year-over-year, excluding a 90 basis point favorable impact of foreign exchange. In Q3, we reported worldwide operating income of $17.4 billion. This operating income includes two special charges, which reduced operating income by $4.3 billion.\n\n**Brian Olsavsky** (CFO)\nThe first charge, of $2.5 billion, is related to a legal settlement with the Federal Trade Commission, which impacts the North America segment and is recorded in the other operating expense line. The second charge, of $1.8 billion, relates to severance costs for role eliminations and impacts all three of our segments. The severance charge is recorded primarily in the technology and infrastructure, sales and marketing, and general and administrative expense line items. Excluding these two charges, worldwide operating income would have been $21.7 billion, or $1.2 billion above the high end of our guidance range. Moving to our segment results, we remain encouraged by the innovation our teams are delivering for customers across all three segments. In the North America segment, third-quarter revenue was $106.3 billion, an increase of 11% year-over-year. International segment revenue was $40.9 billion, an increase of 10% year-over-year, excluding the impact of foreign exchange.\n\n**Brian Olsavsky** (CFO)\nWorldwide paid units grew 11% year-over-year. We continue to prioritize the inputs that matter most to our customers. In the third quarter, our sharp pricing, broad selection, and fast delivery speeds continued to resonate with customers. Customers appreciate the ability to quickly receive items essential for their daily needs, including perishable groceries, and have them delivered in the same day. Our millions of global third-party sellers continue to be important contributors to our vast selection, which helps customers find the items they need at competitive prices. We're committed to building innovative services and features for our sellers, including our ongoing advancements in generative AI. Today, more than 1.3 million sellers have used our generative AI capabilities to more quickly launch high-quality listings. Better listings translate into better traction with customers, and in Q3, worldwide third-party seller unit mix was 62%, up 200 basis points from Q3 of last year.\n\n**Brian Olsavsky** (CFO)\nShifting to profitability, North America segment operating income was $4.8 billion, with an operating margin of 4.5%. Excluding the $2.5 billion charge related to the legal settlement with the FTC, North America segment operating income would have been $7.3 billion, with an operating margin of 6.9%. North America segment operating margin also includes a portion of the severance charge. International segment operating income was $1.2 billion, with an operating margin of 2.9%. Excluding the impact of the severance charge, International segment operating margins expanded year-over-year. Globally, our progress on key inputs is delivering a better customer experience while driving a more efficient cost structure. For example, we're making notable strides in improving inventory placement to speed up delivery to customers. For the third year in a row, we are on track to deliver our fastest speeds ever for Prime members in 2025.\n\n**Brian Olsavsky** (CFO)\nWe continue to tune and improve our fulfillment operations, and our regionalized network is operating at scale. We see many benefits from our inbound process improvements, including a reduction of U.S. inbound lead time by nearly four days compared to last year. This allows us to be more efficient with our inventory purchasing, which benefits working capital. We're also placing inventory more strategically throughout the network. By leveraging our existing infrastructure, we're now offering U.S. customers the ability to order perishable groceries and receive them the same day in as little as five hours. We're seeing positive early results. Since launching in January, when customers start shopping fresh groceries on Amazon, they are visiting the site more often and returning twice as often as non-perishable shoppers. Looking ahead, we see further opportunity to improve productivity in our global fulfillment and transportation network.\n\n**Brian Olsavsky** (CFO)\nWe will continue to improve inventory placement to drive down distance traveled and touches per package. We will also build on the gains from our regionalized network through algorithmic improvements, as well as launching robotics and automation. While operating margin may fluctuate quarter to quarter, we have a deliberate approach to achieve sustained progress over the long term. Shifting to advertising. Advertising revenue was $17.7 billion, and growth accelerated for the third consecutive quarter. We continue to see strong growth on an increasingly large base as our full-funnel advertising approach of connecting brands with customers is resonating. Moving next to our AWS segment, revenue was $33 billion, up 20.2% year-over-year. This is an acceleration of 270 basis points compared to last quarter, driven by strong growth across both our AI and core services and more capacity which has come online to support customer demand.\n\n**Brian Olsavsky** (CFO)\nAWS revenue increased $2.1 billion quarter over quarter and now has an annualized revenue run rate of $132 billion. AWS operating income was $11.4 billion and reflects our continued growth coupled with our focus on driving efficiencies across the business. We are expanding our data center footprint largely to accommodate GenAI, and to the extent those assets were placed into service, the related depreciation does impact our margins. As we've long said, we expect AWS operating margins to fluctuate over time, driven in part by the level of investments we're making at any point in time. Now turning to our cash CapEx, which was $34.2 billion in Q3. We've now spent $89.9 billion so far this year.\n\n**Brian Olsavsky** (CFO)\nThis primarily relates to AWS as we invest to support demand for AI and core services and in custom silicon like Trainium, as well as tech infrastructure to support our North America and international segments. We'll continue to make significant investments, especially in AI, as we believe it to be a massive opportunity with the potential for strong returns on invested capital over the long term. Additionally, we continue to invest in our fulfillment and transportation network to support the growth of the business, improve delivery speeds, and lower our cost to serve. These investments will support growth for many years to come. Looking ahead, we expect our full-year cash CapEx to be approximately $125 billion in 2025, and we expect that amount will increase in 2026. I'll finish up my remarks with net income.\n\n**Brian Olsavsky** (CFO)\nWhile we primarily focus our comments on operating income, our third-quarter net income of $21.2 billion includes a pre-tax gain of $9.5 billion related to our investment in Anthropic. This investment activity is not related to Amazon's ongoing operations and is included in non-operating income. We're encouraged by the start of the peak season, and we are ready to serve customers in the coming months. I want to thank our teams across Amazon for their hard work as we get ready to delight customers during the holiday season. Our commitment to elevating the customer experience is the only reliable way to drive sustainable value for our shareholders. With that, let's move on to your questions.\n\n**Operator**\nThank you. At this time, we will now open the call up for questions. We ask each caller to please limit yourself to one question.\n\n**Operator**\nIf you would like to ask a question, please press star one on your keypad. We ask that when you pose your question, you pick up your handset to provide optimum sound quality. Once again, to initiate a question, please press star, then one on your touch-tone telephone at this time. Please hold while we pull for questions. Our first question comes from the line of Justin Post with Bank of America. Please proceed.\n\n**Justin Post** (Managing Director)\nGreat. Thank you. I'll ask on AWS. Can you just kind of go through how you're feeling about your capacity levels and how capacity constrained you are right now? In your prepared remarks, you mentioned Trainium 3 demand and maybe broadening out your customer base. Can you talk about the demand you're seeing outside of your major customers for Trainium? Thank you. Yeah.\n\n**Andy Jassy** (CEO)\nOn the capacity side, we brought in quite a bit of capacity, as I mentioned in my opening comments, 3.8 gigawatts of capacity in the last year, with another gigawatt plus coming in the fourth quarter. We expect to double our overall capacity by the end of 2027. We're bringing in quite a bit of capacity. Today, overall in the industry, maybe the bottleneck is power. I think at some point it may move to chips, but we're bringing in quite a bit of capacity. As fast as we're bringing it in right now, we are monetizing it. On the Trainium demand outside of our major customers, first of all, as I mentioned on Trainium 2, it's really doing well. It's fully subscribed on Trainium 2. It's a multi-billion dollar business at this point. It grew 150% quarter over quarter in revenue.\n\n**Andy Jassy** (CEO)\nYou see really big projects at scale now, like our Project Rainier that we're doing with Anthropic, where they're training their next version of Claude on top of Trainium 2 on 500,000 Trainium 2 chips, going to a million Trainium 2 chips by the end of the year. As I mentioned, today with Trainium 2, we have a small number of very large customers on it. Because Trainium is 30 to 40% more price-performant than other options out there, and because as customers start to contemplate broader scale of their production workloads, moving to being AI-focused and using inference, they badly care about price performance. We have a lot of demand for Trainium. Trainium 3 should preview at the end of this year with much fuller volumes coming in the beginning of 2026.\n\n**Andy Jassy** (CEO)\nWe have a lot of customers, both very large and I'll call it medium size, who are quite interested in Trainium 3.\n\n**Operator**\nThe next question comes from the line of Brian Nowak with Morgan Stanley.\n\n**Brian Nowak** (Managing Director)\nThanks for taking my questions. Congrats on the quarter, guys. So maybe two. One, Andy, sort of a philosophical chip question. There's a lot of questions in the market about Trainium and sort of its positioning versus other third-party chips. How do you think about the key hurdles with Trainium 3 you need to overcome to really make Trainium adoption broader, to your point on the last question, and continue to drive Trainium, as opposed to satisfying what could be broader demand with third-party chips in the near term?\n\n**Andy Jassy** (CEO)\nYeah. First of all, we're always going to have multiple chip options for our customers.\n\n**Andy Jassy** (CEO)\nIt's been true in every major technology building block or component that we've had in AWS. Really, in the history of AWS, it's never just one player that over a long period of time has the entire market segment and can satisfy everybody's needs on every dimension. We have a very deep relationship with NVIDIA. We have for a very long time, and we will for as long as I can foresee the future. We buy a lot of NVIDIA. We are not constrained in any way in buying NVIDIA. I expect that we'll continue to buy more NVIDIA, both next year and in the future. We're different from most technology companies in that we have our own very strong chip team. This is our Annapurna team.\n\n**Andy Jassy** (CEO)\nYou saw it first on the CPU side with what we built with Graviton, which is about 40% better price performance than the other x86 processors. You're seeing it again on the custom silicon on the AI side with Trainium, which is about the same amount of price performance benefit for customers relative to other GPU options. Our customers to be able to use AI as expansively as they want, and remember, it's still relatively early days at this point, they're going to need better price performance, and they care about it deeply. I mentioned earlier the momentum that Trainium 2 has. I think that for us, as we think about Trainium 3, I expect Trainium 3 will be about 40% better than Trainium 2, and Trainium 2 is already very advantaged on price performance. We have to, of course, deliver the chip.\n\n**Andy Jassy** (CEO)\nWe have to deliver it in volumes and deliver it quickly. We have to continue to work on the software ecosystem, which gets better all the time. As we have more proof points like we have with Project Rainier, with what Anthropic is doing on Trainium 2, it builds increasing credibility for Trainium. I think customers are very bullish about it, and I'm bullish about it as well.\n\n**Operator**\nOur next question comes from the line of Doug Anmuth with J.P. Morgan. Please proceed with your question.\n\n**Doug Anmuth** (Managing Director and Internet Analyst)\nThanks for taking the question. I'll stick with basically the same topic, Andy. Can you just talk a little bit about the architecture of Project Rainier and how it's differentiated, and what that means for customers and for AWS? Do you expect Rainier to expand beyond Anthropic, and how do you replicate Rainier with Trainium 3 chips? Thank you.\n\n**Andy Jassy** (CEO)\nYeah. I think what is compelling for Anthropic around Project Rainier is really the Trainium 2 chip, which we've built. First of all, we built a very large cluster that they can use in a very expansive way. It's not simple to be able to build a cluster that has 500,000-plus chips going to a million. That's an infrastructure feat that's hard to do at scale. Some piece of it is the infrastructure capabilities that we've built over a long period of time in AWS that is unusual in the industry. It's also the performance of the chip and the price performance, both of which matter. I think that Project Rainier is something that is specific for Anthropic, but we have a lot of other customers who are interested in employing large clusters of Trainium chips that we're going to hopefully give them a chance to do so with Trainium 3.\n\n**Operator**\nThe next question comes from the line of Mark Mahaney with Evercore ISI. Please proceed with your question.\n\n**Mark Mahaney** (Senior Managing Director)\nThanks. I want to ask about two topics: groceries and then how to think about headcount in the future. On groceries, the perishables, I think last quarter you talked about 70% or something of users had never purchased from perishables from Amazon before. Just talk about whether youI think you used the term game changer before. Does this mean that maybe you no longer need to do Amazon Fresh stores? You always had this DVD delivery van density advantage. Have you kind of reached a point, you think, of scale and speed that you really can change people's habit and really have them consider Amazon as one of their first grocery options? Do you really feel like you're at that point?\n\n**Mark Mahaney** (Senior Managing Director)\nSecondly, just on the headcount, given some of the recent news, just talk to us about how you think about headcount going forward. Are you seeing thatis the level of efficiencies that you're getting from AI such that. You can keep headcount relatively flattish for the foreseeable future? Just talk about the pros and cons or the wins and losses in terms of that headcount going forward. Thank you.\n\n**Andy Jassy** (CEO)\nYeah. I'll start with grocery, Mark. We have a very large grocery business. If you look at our entire grocery business, if I don't even count Whole Foods Market and Fresh, in the last 12 months, it's over $100 billion of gross merchandising sales, which would make us a top-three grocery in the U.S.\n\n**Andy Jassy** (CEO)\nA good chunk of it is a lot of the items that you'd find in the middle aisle, so consumables and canned goods and pet food and health and beauty. Very significant. That continues to grow at a very good clip. We also have Whole Foods Market, which is the pioneer in organic foods, which is also growing at a faster clip than most grocery companies and with an attractive trajectory on profitability. We'll expand our Whole Foods physical presence over the coming years here. I'm also very excited about this new concept, Daily Shop, that we have, which is a smaller version of Whole Foods in urban settings. We have three that we've launched that are off to very good starts that you should expect to see more of as well. We have always been, as you referenced, we've talked a lot about having a larger mass physical presence.\n\n**Andy Jassy** (CEO)\nWe continue to experiment with various formats. The one that we are most excited about is what you referenced, which is the ability to provide perishable groceries with same-day deliveries. If you think about how many of our customers are buying from us multiple times a week and who are buying things like shampoo or detergent or paper cups or water, where the ability to add milk and eggs and yogurt and other perishables to their order and have it live in the same shopping cart and then show up a few hours later is very compelling. We started with a few markets about a year ago, and we were really taken aback at the adoption, not just the number of people that started buying perishables from us very quickly, but how often they came back downstream to buy perishables and groceries from us in the future.\n\n**Andy Jassy** (CEO)\nWe've now expanded that to 1,000 cities around the U.S. We'll be in 2,300 by the end of the year. It's really changing the trajectory and the size of our grocery business. I also believe that this many-year tradition of the weekly stock-up, grocery stock-up is changing. I think we're a big part of that. I think there's a lot of potential there for the grocery side. It doesn't mean that we won't continue to experiment with other physical formats, but we're on to something very significant with what we're doing with perishables from our same-day facilities. On your headcount question, what I would tell you is the announcement that we made a few days ago was not really financially driven, and it's not even really AI-driven, not right now, at least. It's culture.\n\n**Andy Jassy** (CEO)\nIf you grow as fast as we did for several years, the size of businesses, the number of people, the number of locations, the types of businesses you're in, you end up with a lot more people than what you had before, and you end up with a lot more layers. When that happens, sometimes without realizing it, you can weaken the ownership of the people that you have who are doing the actual work and who own most of the two-way door decisions, the ones that should be made quickly and right at the front line. It can lead to slowing you down. As a leadership team, we are committed to operating like the world's largest startup. That means removing layers, increasing the amount of ownership that people have, and inventing and moving quickly.\n\n**Andy Jassy** (CEO)\nI don't know if there's ever been a time in the history of Amazon or maybe business in general with the technology transformation happening right now where it's important to be lean, it's important to be flat, and it's important to move fast. That's what we're going to do.\n\n**Operator**\nThe next question comes from the line of Eric Sheridan with Goldman Sachs. Please proceed with your question.\n\n**Eric Sheridan** (Managing Director)\nThanks so much for taking the question. I wanted to know, Andy, if you could reflect on the opportunity that's continuing to present itself in terms of rolling out more robotics and automation and the broader theme of physical AI across your operations and how you should be thinking about that as a driver of potential efficiencies, but also as a driver of the ability to possibly reinvest back in the business over the long term. Thanks so much.\n\n**Andy Jassy** (CEO)\nRobotics is a very substantial area of investment for us. We have over a million robots in our fulfillment network at this point. I would say that while that's significant, we have a lot of invention in flight, so I expect that we'll have more over a period of time. Robotics are very important for us and for our customers and for our teammates because they improve safety, they boost productivity, they increase speed, and they let our human teammates focus on problem-solving and what they do best. We expect that our people remain at the heart and the center of our fulfillment network as they have from when we first started working on robotics. We expect that over time, we will have a fulfillment network where robots and humans complement each other and work together. I think you're going to continue to see us invest very significantly in robotics.\n\n**Andy Jassy** (CEO)\nIt's going to help on the safety, the productivity, the speed, and ultimately some of the cost pieces, which will allow us to continue to improve the customer experience.\n\n**Operator**\nThe next question comes from the line of John Blackledge with TD Cowan. Please proceed with your question.\n\n**John Blackledge** (Senior Equity Research Analyst of Internet and New Media)\nGreat. Thank you. How does Amazon think about agentic commerce going forward? How do you think Amazon will serve customers using agents to purchase goods on Amazon in the future? Thank you.\n\n**Andy Jassy** (CEO)\nI'm very excited about, and as a business, we're very excited about, in the long term, the prospect of agentic commerce. It has a chance to be good for customers. It has a chance to be really good for e-commerce. I think if you know what you want to buy, there are a few experiences that are better than coming to Amazon.\n\n**Andy Jassy** (CEO)\nIf you don't know what you want, a physical store with a physical salesperson still has some advantages. Obviously, lots of people do it on Amazon all the time, but you very often want to ask questions and get help narrowing what you're going to look for. As you keep asking new questions, having a whole bunch of different options presented to you. I think AI and agentic commerce are going to change the experience online where that experience where you're narrowing what you want when you don't know is going to get better online than it even is in physical environments. We obviously have our own efforts here in agentic commerce. We have Rufus, which I talked about in my opening comments, which is continuing to get better and better and used more broadly.\n\n**Andy Jassy** (CEO)\nWe have features like Buy for Me where we will surface on Amazon even items that we don't stock that other merchants have. If customers want us to go and buy it for them on those merchants' websites, we will do that. Both of those have been successful for us. We're also. Having conversations with and expect over time to partner with third-party agents. I think that it reminds me in some ways of the beginning of search engines many years ago being sources of discovery for commerce. You had to kind of figure out the right way to work together. Today, search engines are a very small part of our referral traffic, and third-party agents are a very small subset of that. I do think that we will find ways to partner. We have to find a way, though, that makes the customer experience good.\n\n**Andy Jassy** (CEO)\nRight now, I would say the customer experience is not good. There's no personalization. There's no shopping history. The delivery estimates are frequently wrong. The prices are often wrong. We've got to find a way to make the customer experience better and have the right exchange of value. I do think that the exciting part of this and the promise is that AI and agentic commerce solutions are going to expand the amount of shopping that happens online. I think that's really good for customers. I think it's really good for Amazon because at the end of the day, you're going to buy from the outfit that allows you to have the broadest selection, great value, and continues to deliver for you very quickly and reliably. I think that bodes well for us.\n\n**Operator**\nOur final question comes from the line of Colin Sebastian with Baird. Please proceed with your question.\n\n**Colin Sebastian** (Managing Director and Senior Research Analyst of Internet and Digital Media)\nThanks. Good afternoon. I guess first on AWS, following up there, how much of this acceleration is driven by core infrastructure versus AI workload monetization? I think part of it is trying to understand how important numerous services like AgentCore are becoming and bringing enterprises to AWS to build agents. Secondly, regarding the acceleration in advertising, if you could potentially disaggregate the core advertising contribution versus DSP and Prime Video, that would be helpful as well. Thank you.\n\n**Andy Jassy** (CEO)\nYeah. I'll start on the AWS side. We are seeing. We're really pleased with the results from this quarter. 20% year-over-year on an annualized run rate of $132 billion is unusual. We have momentum, and you can see it. We see the growth in both our AI area where we see it in inference, we see it in training, we see it in the use of our Trainium custom silicon.\n\n**Andy Jassy** (CEO)\nBedrock continues to grow really quickly. SageMaker continues to grow quickly. I think that the number of companies who are. Working on building agents is very significant. I do believe that a lot of the value that companies will realize over time in AI will come from agents. I think that building agents today is still harder than it should be. You need tools to make it easier, which is why we built Strands, which is an open-source capability that lets people build agents from any model that they can imagine. Even more so, when you talk to enterprises or companies that care a lot about security and scale, they're starting to build agents, and they don't really feel like they've had building blocks that allow them to have the type of secure, scalable agents that they need to bet their businesses and their customer experiences and their data on.\n\n**Andy Jassy** (CEO)\nThat was really the inspiration behind AgentCore, to build another set of primitive building blocks like we built in the early days of AWS, where it was compute and storage and database. We defined a set of building blocks that you needed to be able to deploy agents securely and scalably that we provide in AgentCore. When we talk to our customers, it really resonates. There is not anything else like it. It's changing their timeframe and their receptivity to building agents, and it's very compelling for them. I do think the combination of what we're doing to enable agents to be built and run securely and scalably, as well as some of the agents that we're building ourselves that our customers are excited about, are compelling for them.\n\n**Andy Jassy** (CEO)\nI think the other place we see a lot of growth in AWS also is just the number of enterprises who have gotten back to moving from on-premises infrastructure to the cloud. We continue to earn the lion's share of those transformations. I look at the momentum we have right now, and I believe that we can continue to grow at a clip like this for a while. I think on the advertising side, that is also an area where I think collectively we feel very pleased about the progress. Every single one of our advertising offerings this quarter grew in a meaningful way. I think there's a few things going on for us. We have what I think of as a pretty unusual full funnel offering.\n\n**Andy Jassy** (CEO)\nIf you look at the top of the funnel, which typically tends to be awareness building and broad scale, to be able to use our own Prime Video and our live sports capabilities, as well as going all the way down to the bottom of the funnel at point of sale, being able to use sponsored products. Most people don't have a full funnel offering as robust as that. When you layer on top of it the combination of the audience curation and development we can do along with the advantage measurement, it just all leads to a return on advertising spend that's very unusual. I think there are multiple places where we can expect to continue to grow. One is in our stores business. I still think if you look at the worldwide market segment share of retail, still 80% to 85% of it lives in physical stores.\n\n**Andy Jassy** (CEO)\nThat equation is going to flip over time, and I think AI is going to only accelerate that. I think we have a significant opportunity still in our existing stores. I think video, we've only been at this for a little bit of time, but it's already a very large amount of advertising revenue, and we're still relatively early stage. I think that will continue to be a big area of growth. As you reference the demand-side platform, or Amazon DSP, that is growing really quickly as well. Some of it had to do with the fact that we had some features. We always had a number of the core components people wanted around some of our properties, the measurement capabilities, Amazon Marketing Cloud. We lacked some features for a while as we were building out our DSP that customers told us mattered.\n\n**Andy Jassy** (CEO)\nThe team over the last 20 months have closed those gaps in a very significant way so that now people feel like our DSP is fully featured. You look at some of the partnerships that we've done. The Roku partnership gives us the largest connected TV footprint in the U.S. You layer on top of that what we've recently done in providing our DSP customers the opportunity to integrate with the ad inventory in Netflix and Spotify and SiriusXM. It's powerful. We are growing very quickly on the demand-side platform. Very optimistic about what we're doing there. We have continued work to do, obviously, but I don't think we're close to being able to grow there.\n\n**Operator**\nThanks for joining us on the call today and for your questions. A replay will be available on our investor relations website for at least three months.\n\n**Operator**\nWe appreciate your interest in Amazon and look forward to speaking with you again next quarter.",
        "fetched_at": "2026-02-04T16:10:39.662Z"
      },
      {
        "ticker": "AMZN",
        "title": "Yahoo Finance",
        "published_date": "Jul 31, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/AMZN/earnings/AMZN-Q2-2025-earnings_call-341150.html",
        "content": "**Operator**\nThank you for standing by. Good day, everyone, and welcome to the amazon.com Second Quarter twenty twenty five Financial Results Teleconference. At this time, all participants are in a listen only mode. After the presentation, we will conduct a question and answer session. Today's call is being recorded.\n\n**Operator**\nAnd for opening remarks, I will be turning the call over to the Vice President of Investor Relations, Mr. Dave Files. Thank you, sir. Please go ahead.\n\n**Dave Fildes** (VP - IR)\nHello, and welcome to our Q2 twenty twenty five financial results conference call. Joining us today to answer your questions is Andy Jassy, our CEO and Brian Lisowski, our CFO. As you listen to today's conference call, we encourage you to have a press release in front of you, which includes our financial results as well as metrics and commentary on the quarter. Please note, unless otherwise stated, all comparisons in this call will be against our results for the comparable period of 2024. Our comments and responses to your questions reflect management's views as of today, 07/31/2025 only and will include forward looking statements.\n\n**Dave Fildes** (VP - IR)\nActual results may differ materially. Additional information about factors that could potentially impact our financial results is included in today's press release and our filings with the SEC, including our most recent annual report on Form 10 ks and subsequent filings. During this call, we may discuss certain non GAAP financial measures. In our press release, slides accompanying this webcast and our filings with the SEC, each of which is posted on our IR website. You will find additional disclosures regarding these non GAAP measures, including reconciliations of these measures with comparable GAAP measures.\n\n**Dave Fildes** (VP - IR)\nOur guidance incorporates the order trends that we've seen to date and what we believe today to be appropriate assumptions. Our results are inherently unpredictable and may be materially affected by many factors, including fluctuations in foreign exchange rates, changes in global economic and geopolitical conditions, tariff and trade policies, and customer demand and spending, including the impact of recessionary fears, inflation, interest rates, regional labor market constraints, world events, the rate of growth of the Internet, online commerce cloud services, and new and emerging technologies, and the various factors detailed in our filings with the SEC. Our guidance assumes, among other things, that we don't conclude any additional business acquisitions, restructurings or legal settlements. It's not possible to accurately predict demand for our goods and services, and therefore, our actual results could differ materially from our guidance. And now I'll turn the call over to Andy.\n\n**Andy Jassy** (President &amp; CEO)\nThanks, Dave. Today, we're reporting $167,700,000,000 in revenue, up 12% year over year, excluding the impact from foreign exchange rates. Operating income was 19,200,000,000.0 up 31% year over year and trailing twelve month free cash flow was $18,200,000,000 We saw good progress across our various customer experiences and businesses this past quarter. Starting with stores, we feel good about both the inputs and outputs of the business. At Amazon, we think of our business in terms of inputs and outputs.\n\n**Andy Jassy** (President &amp; CEO)\nOutputs are metrics like revenue or operating margin, but, of course, you can't manage at the output level. It's the inputs that drive the outputs. So we spend virtually all of our time internally talking about and going against inputs. The inputs that matter most to customers in our stores business are selection, low prices, and speed of delivery. We've taken another step forward in selection these past few months, headlined by the much requested return of Nike's products to Amazon's retail store.\n\n**Andy Jassy** (President &amp; CEO)\nWe've added premium brands like Away, Aveda, Marc Jacobs fragrances, and brands from Saks and Amazon like Dolce and Gabbana, Etro, Stella McCartney, Rosetta Getty, and La Prairie. And we started expanding our very successful perishables pilot, where we offer customers perishables at the point of purchase when they're ordering other items that will be delivered same day from our same day fulfillment nodes. We're seeing strong customer adoption as 75% of customers who've used the service this year are first time shoppers for perishables on Amazon, with 20% of customers who use the service returning multiple times within their first month. Our prices continue to be low and sharp for customers. It's one of the reasons our everyday essentials growth outpaced the rest of the business globally and represented one out of every three units sold.\n\n**Andy Jassy** (President &amp; CEO)\nIt's also why well known research firm, Perfidero, has concluded for eight years in a row that Amazon has the lowest prices of any US retailer. But perhaps the clearest outputs are the rate at which our stores business grew this past quarter and the success we saw in our recent Prime Day event. This year's Prime Day was our biggest ever with record sales, number of items sold, and number of Prime sign ups in the three weeks leading up to the Prime Day. Customers saved billions of dollars and independent sellers, most of which are small and medium sized businesses, saw their best sales performance of any Prime Day event yet. There continues to be a lot of noise about the impact that tariffs will have on retail prices and consumption.\n\n**Andy Jassy** (President &amp; CEO)\nMuch of it thus far has been wrong and misreported. As we said before, it's impossible to know what will happen. Where will tariffs finally settle, especially China? What happens when we deplete the inventory we forward bought or that our selling partners forward deployed in advance of the tariffs going into effect? If costs end up being higher, who will absorb them?\n\n**Andy Jassy** (President &amp; CEO)\nBut what we can share is what we've seen thus far, which is that through the first half of the year, we haven't yet seen diminishing demand nor prices meaningfully appreciating. We also have such diversity of sellers in our marketplace, over 2,000,000 sellers in total, with differing strategies of whether to pass on higher cost to consumers that customers are advantaged shopping at Amazon because they're more likely to find lower prices on the items they care about. Further improving delivery speed remains a key focus, and we continue to make progress. We've previously shared how we rearchitect our US inbound network into a regional structure, allowing us to place inventory and shift from locations closer to customers, improving speed and lowering costs. That work is delivering tangible results.\n\n**Andy Jassy** (President &amp; CEO)\nIn q two, we increased the share of orders moving through direct lanes where packages go straight from fulfillment delivery without extra stops by over 40% year over year. We've also reduced the average distance packages traveled by 12% and lowered handling touches per unit by nearly 15%. We've made progress on order consolidation. With more products positioned locally, we're able to pack more items into each box and send fewer packages per order. That has helped drive higher units per box and improved overall cost to serve.\n\n**Andy Jassy** (President &amp; CEO)\nTaken together, these improvements are making the network faster and structurally more efficient. We've also set another global speed record in q two, delivering to Prime members at our fastest speeds ever. In The US, we delivered 30% more items same day or next day than during the same period last year. Items customers used to pick up locally in nearby physical stores are now arriving at their door often within hours, and we're working to further improve delivery speeds no matter where customers live. We've recently announced plans to expand our same day and next day delivery to tens of millions of US customers in more than 4,000 smaller cities, towns, and rural communities by the end of the year.\n\n**Andy Jassy** (President &amp; CEO)\nToday, it's already available in more than a thousand of these communities across The US. The early response from customers in these areas have been very positive. They're shopping more frequently and purchasing household essentials at meaningfully higher rates. Automation and robotics are also important contributors to improving cost efficiencies and driving better customer experiences over time. We deployed our one millionth robot across our global fulfillment network and unveiled innovations at our last mile innovation center, such as automated package sorting and a transformative technology that brings packages directly to employees in an ergonomic height.\n\n**Andy Jassy** (President &amp; CEO)\nWe rolled out Deepfleet, our AI whose robot travel efficiency by 10%. At our scale, it's a big deal. Deepfleet acts like a traffic management system to coordinate robots' movements to find optimal paths and reduce bottlenecks. For customers, it means faster delivery times and lower costs. For our team members, our robots handle more of the physically demanding tasks, making our operations network even safer.\n\n**Andy Jassy** (President &amp; CEO)\nThis combination of robotics and generative AI is just getting started. And while we've made significant progress, it's still early with respect to what we'll roll out in the next few years. Moving on to Amazon Ads. We're pleased with the strong growth generating $15,700,000,000 of revenue in the quarter, growing 22% year over year. We continue to see strength across our broad portfolio of full funnel advertising offerings that in The US alone help advertisers reach an average ad support audience of more than 300,000,000 across our own properties.\n\n**Andy Jassy** (President &amp; CEO)\nThese are properties like our retail marketplace, Prime Video, Twitch, and Fire TV, in live sports such as NFL, NASCAR, and the NBA, as well as third party websites and apps. Another area we're excited about is our demand side platform or Amazon DSP. Our DSP enables advertisers to plan, activate, and measure full funnel investments. Our trillions of proprietary browsing, shopping, and streaming signals paired with extensive supply side relationships and our secure clean rooms provide advertisers the ability to optimize advertising, deliver greater precision, and drive efficient and effective advertising outcomes. And in June, we announced a momentous partnership with Roku, giving advertisers access to 80,000,000 connected TV households, the largest authenticated connected TV footprint in The US exclusively through Amazon DSP.\n\n**Andy Jassy** (President &amp; CEO)\nIt's a giant leap forward for advertisers bringing best in class planning, audience precision, and performance to TV advertising. We also announced an integration between Disney's real time ad exchange and Amazon DSP. This collaboration allows advertisers to gain direct access to Disney's premium inventory across platforms like Disney plus, ESPN, and Hulu, while allowing them to leverage insights from both companies. When advertisers work with Amazon, they're not just buying ad space. They're benefiting from exceptional programming, innovative technology, and unrivaled signals, measurement, and audience development that provides strong relevancy for consumers and return on investment for brands.\n\n**Andy Jassy** (President &amp; CEO)\nMoving on to AWS. In q two, AWS grew 17.5% year over year and now has over a 123,000,000,000 annualized revenue run rate. We continue to help organizations of all sizes accelerate their transition to the cloud, signing new agreements with companies including PepsiCo, Airbnb, Peloton, Nasdaq, London Stock Exchange, Nissan Motor, GitLab, SAP, Warner Brothers Discovery, Twelve Labs, FICO, Iberia Airlines, SK Telecom, and NatWest. In the rapidly evolving world of generative AI, AWS continues to build a large, fast growing, triple digit year over year percentage, multibillion dollar business with more demand than we have supplied for at the moment. A few points to make.\n\n**Andy Jassy** (President &amp; CEO)\nFirst, on the hardware side, our custom AI chip, Trainium two, is landing capacity in larger quantities and has impressively emerged as the backbone for Anthropic's newest generation cloud models and many of our most essential offerings like Amazon Bedrock. We've also launched Amazon EC two instances powered by NVIDIA Grace Blackwell Superchips, AWS' most powerful NVIDIA GPU accelerated instance. Second, in Bedrock, we've recently added Anthropix Cloud four, and it's the fastest growing model ever in Bedrock. We've also continued to see strong adoption of Amazon Nova, our own frontier model, and it's now the second most popular foundation model in Bedrock. New features in Nova allow customers to customize their Nova models in ways they can't on other foundation models, allowing organizations to infuse these models with their unique expertise while optimizing for cost and speed.\n\n**Andy Jassy** (President &amp; CEO)\nAs people have become excited about building agents, they're realizing they lack the tools to build them. In May, we released Strands, an open source way to more easily build agents that's taken off with a wide range of customers with already 2,500 stars on GitHub and over 300,000 downloads on Pipedrive. Are also struggling with deploying agents into production in a secure and scalable way. It's holding up enterprises scaling agents. To help solve that problem, Bedrock just released Agent Core.\n\n**Andy Jassy** (President &amp; CEO)\nAgent Core is a set of building blocks that gives customers the industry's first secure serverless runtime to provide both synchronous and asynchronous execution, agent identity and boundaries, a memory service, a gateway that translates services to MCP compatible interfaces, built in code execution and web browser tools, and an observability service. Customers are excited about agent core, and it frees them up to start deploying agents more expansively. Third, you're starting to see AWS release more powerful applications at the top layer of the AI stack. AWS Transform is an AWS agent that dramatically reduces mainframe modernization timelines from years to months, completes VMware to EC two conversions up to 80 times faster, and makes it simple to move from dot net Windows to dot net Linux implementations, reducing licensing costs for dot net applications by up to 40%. We've also just released Curo, our new agentic integrated development environment coding agent.\n\n**Andy Jassy** (President &amp; CEO)\nThere's a lot of buzz around Curo with several 100,000 developers using or requesting access in the first couple weeks, a 100,000 used in the first five days of the preview. What struck a chord for developers is that Cura allows them to do vibe coding where developers use natural language to chat with a coding agent to build code. But unlike other coding agents where developers don't really have any structure to build on top of, Cura allows developers to use natural language to build a spec and then automatically updates that spec as they continue to vibe code or interact with Kiro. This makes it much easier to go from prototyping to production. Customers also like Kiro's event driven agent hooks that act like an experienced developer catching things developers might miss.\n\n**Andy Jassy** (President &amp; CEO)\nWhen developers save a React component, hooks update the test file. When they modify API endpoints, hooks refresh read me files. When they're ready to commit, security hooks scan for leak credentials. It's still very early for Quiro, but it seems clear we're onto something customers love, and Quiro has a chance to transform how developers build software. I say this frequently, but remember that 85 to 90% of worldwide IT spend is still on premises versus in the cloud.\n\n**Andy Jassy** (President &amp; CEO)\nIn the next ten to fifteen years, that equation is going to flip, further accelerated by companies' excitement for leveraging AI. So AWS has significantly broader functionality, stronger security and operational performance, and much deeper experience helping enterprises modernize their infrastructure bodes well for the AWS business moving forward. We're also seeing momentum in a number of our other areas across Amazon. I'll mention just a few. We're excited about our progress with Alexa Plus, our next generation assistant powered by generative AI.\n\n**Andy Jassy** (President &amp; CEO)\nWe've been rolling out early access to US customers to start. Millions of customers have access now. We're seeing very positive feedback, and we'll continue to iterate on the experience. We've recently completed our third successful launch of Project Kuiper. We haven't launched this service commercially yet, but already have an impressive amount of enterprise and government customers who signed agreements to use Kuiper.\n\n**Andy Jassy** (President &amp; CEO)\nIn prime video live sports, our first season of NASCAR drew about 2,000,000 viewers per race and the youngest audience among NASCAR broadcasters in more than a decade. We've recently announced our stellar broadcasting crew for our upcoming first NBA season, including Iron Eagle, Stan Van Gundy, Kevin Harlan, Dwayne Wade, Taylor Rooks, Blake Griffin, Dirk Nowitzki, Steve Nash, and Candice Parker. We also announced Denis Villeneuve, an Academy Award nominee as the director for the next James Bond film. James Bond is in the hands of one of today's greatest filmmakers, and we cannot wait to get started on double o seven's next adventure. Finally, we continue to be very pleased with the growth and resonance of Amazon Pharmacy as it's grown 50% year over year, year to date on an already significant size base.\n\n**Andy Jassy** (President &amp; CEO)\nA lot of good things happening across the company. With that, I'll turn it over to Brian for a financial update.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nThanks, Andy. Let's start with our top line financial results. Worldwide revenue was a $167,700,000,000, a 12% increase year over year excluding the impact of foreign exchange. Foreign exchange had a $1,500,000,000 favorable impact to revenue in the quarter as foreign currencies generally strengthened versus the U. S.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nDollar. As a reminder, our Q2 revenue guidance had anticipated an unfavorable impact of approximately 10 basis points or $100,000,000 Although that operating income was $19,200,000,000 which is $1,700,000,000 above the high end of our guidance range. Across our segments, we continue to prioritize cost effective innovation that delivers value for our customers. In the North America segment, second quarter revenue was $100,100,000,000 an increase of 11% year over year. International segment revenue was $36,800,000,000 an increase of 11% year over year, excluding the impact of foreign exchange.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nWorldwide paid units grew 12% year over year. We remain focused on inputs that matter most to our customers. In the second quarter, we saw broad based strength across our key performance metrics. This includes sharp pricing and more in stock availability, as well as record delivery speeds for Prime members. Our millions of global sellers continue to be an important contributor to our vast selection.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nThis helps customers find the items they need and does so at a competitive price. Our investment in tools, services, and fast delivery speeds help our selling partners reach more customers and further scale their businesses. In q two, worldwide third party seller unit mix was 62%, the highest ever, up on 100 basis points from q two of last year. We're also closely monitoring the macroeconomic environment, including the impact of tariffs. As Andy mentioned, our Q2 plan factored in a range of assumptions, not all of which materialized.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nWe will continue to consider a range of assumptions going forward. Shifting to profitability, North America segment operating income was $7,500,000,000 an increase of $2,500,000,000 year on year. North America operating margin was 7.5%, up 190 basis points year over year. International segment operating income was $1,500,000,000 up $1,200,000,000 year over year. International operating margin was 4.1%, up three twenty basis points year over year.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nWe're pleased with the strong execution of our operations teams and the positive experience they delivered for customers. In q two, we saw productivity gains in our transportation network driven by improved inventory placement, strong leverage on high unit volumes, and higher levels of in demand inventory from both first party and third party selling partners. These factors contributed to faster delivery speeds and lower costs. Outbound shipping costs were up 6% year over year and continue to grow at a meaningfully slower pace than unit growth, which as I mentioned earlier was up 12% year over year. We're committed to initiatives that further improve our cost structure.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nStrategic inventory placement drives multiple benefits, including better in stock availability, shorter delivery routes, and faster customer delivery times. When we optimize inventory location, we can consolidate more items per package, reducing packaging materials and costs. To achieve this, we will continue to improve upon our inbound network, expand our US same day delivery facilities, including in rural communities, and implement robotics and automation across our facilities. While year over year improvements in operating margin may fluctuate, we have a purposeful strategy to achieve sustained progress over time. Shifting to advertising.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nAdvertising revenue grew 22% year over year, driven by sponsored products as we saw strong traffic in our stores. Advertising remains an important contributor to profitability in the North American international segments. Our full funnel advertising approach of connecting brands with customers is resonating. Moving next to our AWS segment. Revenue was $30,900,000,000 an increase of 17.5% year over year.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nAWS now has an annualized revenue run rate of more than a 123,000,000,000. During the second quarter, we continue to see growth in both our generative AI and non generative AI businesses. As companies turn their attention to newer initiatives, bring more workloads to the cloud, restart or accelerate existing migrations from on premise to the cloud, and tap into the power of generative AI. AWS operating income was $10,200,000,000. We did see AWS segment margins decline from a record high of 39.5% in q one to 32.9% in q two.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nThe largest quarter over quarter driver of the decrease for about half is due to the seasonal step up in stock based compensation expense driven by the timing of our annual compensation cycle. AWS margins also saw headwinds from higher depreciation expense as well as unfavorable impacts from year over year fluctuations in foreign exchange rates. The depreciation expense is a result of our growing investments in capital expenditures in AWS. As we've said in the past, we expect AWS operating margins to fluctuate over time, driven in part by the level of investments we are making at any point in time. We will continue to invest more capital in chips, data centers, and power to pursue this unusually large opportunity that we have in generative AI.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nNow turning to our cash CapEx, which was $31,400,000,000 in q two. We expect q two CapEx to be reasonably representative of our quarterly capital investment rate for the back half of this year. AWS continues to be the primary driver as we invest to support demand for our AI services and increasingly in custom silicon like Tranium, as well as tech infrastructure to support our North America and international segments. Additionally, we continue to invest in our fulfillment and transportation network to support growth of the business, improve delivery speeds, and lower our cost to serve by investing in same day delivery facilities as well as robotics and automation. Collectively, these investments will support growth for many years to come.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nMoving on to our third quarter financial guidance. As a reminder, our guidance considers a range of possibilities which take into consideration Q2 results, trends we see quarter to date, and expectations around the macroeconomic environment including tariffs. Q3 net sales are expected to be between $174,000,000,000 and $179,500,000,000 We estimate the year over year impact of changes in foreign exchange rates based on current rates, which we expect to be a favorable impact of approximately 130 basis points. As a reminder, global currencies can fluctuate during the quarter. Q3 operating income is expected to be between $15,500,000,000 and $20,500,000,000 In this dynamic environment, we'll focus on what matters most, delivering exceptional customer value through broad selection, competitive prices, and unmatched convenience.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nWe remain focused on driving a better customer experience and believe putting customers first is the only reliable way to create lasting value for our shareholders. With that, let's move on to your questions.\n\n**Operator**\nThank you. At this time, we will now open the call up for questions. Thank you. Our first question comes from Doug Anmuth with JPMorgan. Please proceed with your question.\n\n**Douglas Anmuth** (MD &amp; Internet Analyst)\nThanks so much for taking the questions. I have two. First, can you just help us understand with some more granularity how tariffs are being absorbed across suppliers, Amazon and consumers and whether you anticipate any change going forward? And then second on AWS, we're seeing significantly faster cloud growth among the number two and three players in the space. I totally appreciate that AWS is coming off of a bigger base. But beyond that, do you think the output gap is due more to customer demand or infrastructure supply or both? Thanks.\n\n**Andy Jassy** (President &amp; CEO)\nYes, I'll take both of those. I'll start with the tariffs. I think what we said a number of times and we still believe it is we just don't know what's going to happen moving forward. It's hard to know where the tariffs are going to settle particularly in China. It's hard to know what will happen when we deplete some of the pre buys that we did on our own first party retail and then some of the forward deploying that we saw of our third party selling partners.\n\n**Andy Jassy** (President &amp; CEO)\nAnd when, you know, if costs go up over time, it's, you know, we're unsure at this point who's gonna end up absorbing those higher costs. What we can tell you is what we've seen so far in the first half of the year. In the first half, we just haven't seen diminished demand and we haven't seen any kind of broad scale ASP increases. And, you know, so that that could change in the second half. There are a lot of things that we don't know, but that's what we've seen so far.\n\n**Andy Jassy** (President &amp; CEO)\nOn the question on AWS, you know, the first thing I'd say is, you know, it's as you said, Doug, in your question, know, year over year percentages and growth rates are always a function of the base in which you operate. And we have a, you know, a meaningfully larger business in the AWS segment than others. I think the second player is about 65% of the size of of a AWS. And we when we look at the results over the last number of quarters, there's sometimes where as far as we can tell, we're growing faster than others and sometimes others are growing faster than us. But it's still like if you if you look at second place player you're talking about, it's a pretty it's still a pretty significant segment, you know, market segment leadership position that we have.\n\n**Andy Jassy** (President &amp; CEO)\nAnd regardless, these are all really just moments in time. The last week is a moment in time too where the reality of what really matters is what customers' experiences are in operating on these platforms. And if if you look at what matters to customers, what they care they care a lot about what the operational performance is, you know, what the availability is, what the durability is, what the latency and throughput is of of the various services. And I think we have a pretty significant advantage in that area. They care a lot about security.\n\n**Andy Jassy** (President &amp; CEO)\nIf you have data that matters and for most companies, they're putting data that they really care about in the cloud. The security and the privacy of that data matters a lot, and there are very different results in security in AWS than you'll see in other players. And, yeah, you could just you just look at what's happened the last couple months. You can just see kind of adventures at some of these players almost every month. And so very big difference, I think, in security.\n\n**Andy Jassy** (President &amp; CEO)\nAnd then I I think a a really significant difference in functionality where not just in the core infrastructure do we have a lot more functionality in our services. But I think if you look at our end to end offering in AWS in in AI, it's you know, from the bottom of stack all the way to the top, it it's pretty different. So, you know, I feel good about the the the inputs and the services that we're offering to customers across AI as well as non AI. And, you know, we could we we have more demand than we have capacity right now. So we could be doing more revenue and helping customers more, and we're working very hard on on changing that outcome and how much capacity we have, but it's still like, you know, you go get the business, it's a $123,000,000,000 annual revenue run rate business, and it's still early.\n\n**Andy Jassy** (President &amp; CEO)\nI mean, how often do you have an opportunity that's a $123,000,000,000 of annual revenue run rate where you say it's still early? It's it's a very unusual opportunity that we're very bullish about.\n\n**Operator**\nThank you. Our next question comes from Mark Mahaney with Evercore. Please proceed with your question.\n\n**Mark Mahaney** (Senior MD)\nOkay. I'll stick with AWS to start it with. Could you just disclose the backlog number? And then in the past, I know you've talked about these supply constraints and hoping that they will sort of resolve themselves by the back half of the year. Is that still your intention?\n\n**Mark Mahaney** (Senior MD)\nAnything that suggests that the supply constraints are going to get resolved earlier or later? And then a long term question on Alexa Plus. And I've been experimenting with it for a while. Andy, when you think about the potential that that has in terms of increasing engagement, maybe tapping into some services revenue, advertising, maybe a little bit more retail sales per household, you're just reducing friction. Just talk about what from a financial perspective, how you think that could play out?\n\n**Mark Mahaney** (Senior MD)\nHow we would maybe see that in the numbers? Thank you very much.\n\n**Dave Fildes** (VP - IR)\nMark, this is Dave. I'll just start off to give you the backlog figure. So at the end of the quarter at June 30, that was $195,000,000,000 so that's up about 25% year over year.\n\n**Andy Jassy** (President &amp; CEO)\nOn the supply constraints as it relates to AWS and what we see there, You know, as I mentioned, well, we have more demand than we have capacity at this point. And I think that and and you see, you know, some of the constraints, and they kind of exist in multiple places. The single biggest constraint is power. But I you know, you also see constraints off and on with chips and then some of the components that, you know, once you have the chips to actually make the servers, you know, you there are you know, sometimes you have new generations of chips that are a little bit later than they're supposed to be and sometimes you get the chips and, you know, the yield you get in making servers isn't what you what you expect when you get to ramp. So there are a bunch of those pieces today that we're working on.\n\n**Andy Jassy** (President &amp; CEO)\nIt's really true across the industry today. I I don't believe that we will have fully resolved the amount of capacity we need for the amount of demand that we have in a couple quarters. I think it will take several quarters. But I do expect that it's gonna get better each quarter and I'm optimistic about that. I think on the Alexa question, you know, I I think what I'd start by saying the Alexa Plus experience is so much better than I think our prior Alexa experience.\n\n**Andy Jassy** (President &amp; CEO)\nShe's much more intelligent than her prior self. She's much more capable. And I would say unlike the the other chatbots that are out there today who are good at answering questions but really can't take any action for you, Alexa Plus can take a lot of action for you, which is very compelling. So I can ask Alexa to play music for me or play video for me or move my music from one device to another. Or if I'm listening to a a song that's on a that's in a movie, I can ask Alexa plus to actually put that movie scene on that of a song I'm playing, and it'll put it on my Prime Video on on Fire TV.\n\n**Andy Jassy** (President &amp; CEO)\nOr if I have guests coming over, I can say, you know, Alexa, draw the curtains, put the light on the porch and the driveway, increase the temperature by five degrees, and put on music that would be great for a dinner party. And and she does all that just for using natural language. So she could take a lot of actions, and it's compelling. And what we see so far, you know, we've we've been rolling out Alexa Plus starting in The US. It's it's with millions of customers now.\n\n**Andy Jassy** (President &amp; CEO)\nThe rest come the rest in The US coming in the next couple months and starting the international rollout more broadly later in the year. And customers really like the experience. They recognize how much better it is than what it was before. The ratings are very high. The usage is is much more expansive than what they were using before.\n\n**Andy Jassy** (President &amp; CEO)\nThe number calls they're making is is meaningfully higher. And I I think there are a number of different areas where we'll see benefit. I I think first, you know, if you if you build the world's best personal assistant, that has a lot of utility for customers and, therefore, it gets used a lot. So it means everything from people are excited about the devices that they can buy from us that has Alexa Plus enabled in it. People do a lot of shopping, and it's it's really it's a delightful shopping experience that will keep getting better.\n\n**Andy Jassy** (President &amp; CEO)\nI think over time, there will be opportunities, you know, as as people are engaging more multi turn conversations to have advertising play a role to help people find discovery and also as a lever to drive revenue. And I think over time, could also imagine as we keep adding functionality that there could be some sort of subscription element beyond what there is today. Today, Prime members get Alexa Plus for free and non Prime members pay $19.99 a month for Alexa Plus. So I think it's very it's still very early days, but we're very encouraged by the experience we're providing and you can bet we're gonna be iterating on it constantly.\n\n**Operator**\nThank you. And our next question comes from the line of Colin Sebastian with Baird. Please proceed with your question.\n\n**Colin Sebastian** (Senior Research Analyst)\nThanks for taking the questions. I guess first off with respect to the international segment and the progress in both revenues and margins, I was hoping you could add maybe some color on the drivers of each of those and the sustainability of the improved efficiency in those markets. And then Andy, you mentioned Kuiper. We haven't heard as much about that of late. So maybe if you could review where things stand relative to next year's launch target, timing of the service rollout and maybe any perspective you have on the longer term ambitions for the satellite network? Thank you.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nThanks, Colin. This is Brian. I'll start with the international segment question. So, yeah, very strong quarter for international segment both on revenue growth and also on operating margin. Operating margin was up three twenty basis points year over year to 4.1%.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nAnd if you look, that's the continuation of a strong progression we've seen quarter by quarter over the last ten quarters in total. We've seen an increase of close to 700 basis points during that time period. So really, it's a tale of two pieces of two segments or excuse me, sections within international. One is established countries like UK, Germany, and Japan already at similar margin profiles to The US. So we'll you know, as they continue to grow, their contribution and profit will grow over time, that's what we're seeing. In the quarter, we saw strong productivity in our transportation network in those countries, much like we saw in The US, and that's led to higher units for package and faster delivery speeds at lower cost. So again, the theme of lower cost to serve and also increased speed and, you know, better selection for customers continues, to grow in internationally as well. In our emerging countries, you know, we're pleased with the progress we're making there. We've launched eight countries, of course, in the last five years, and they're all varying degrees of upfront investment and, you know, different point times in their journey to profitability. But they're all making very nice improvements quarter over quarter in growing selection, adding prime members, and expanding our customer offerings.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nSo I think what you're saying again is sustained improvement in those areas. Feel very good about it. The established countries are continuing to grow and develop and very much look like The United States. And the emerging countries, again, all very different stages of growth right now.\n\n**Andy Jassy** (President &amp; CEO)\nOn the Project Kuiper question, so Project Kuiper is our low Earth orbit satellite constellation that we're putting up and launching. And, you know, there's 400 to 500,000,000 households worldwide who don't have broadband connectivity. And it means they can't do a lot of the things we take for granted like education online or business online or shopping or or entertainment. There is really a digital divide, and it's much needed. And it's also true for enterprises and for governments if they have assets or needs to have visibility or connectivity that they can't get today given the lack of broadband in a bunch of places around the world.\n\n**Andy Jassy** (President &amp; CEO)\nSo there's there's a high need. I would say that as we get our constellation into space, there will really be two players that have what I would consider the the modern technology in low earth orbit satellite. You know, one is is the incumbent in in the market today, and the second will be Project Kuiper. I think that we will have a a pretty meaningful differentiation here in performance. If you look at the performance of what I expect on the uplink and downlink, I think Project Kuiper will be advantaged.\n\n**Andy Jassy** (President &amp; CEO)\nI also think the pricing is gonna be very compelling for customers. And then I think if you think about the three key customer segments who want, low Earth orbit satellite, consumers, enterprises, and governments, We have very strong relationships with all three customer segments given our consumer businesses and our AWS business. And I think if you if you think about enterprises and governments, a lot of what they wanna do when they take the data down from space is they actually wanna put it into a cloud to do analysis, analytics, and and AI and and various operations on top of it. And the fact that Project Kuiper and AWS are so seamlessly connected is very attractive to enterprises and to governments. I'm kind of amazed.\n\n**Andy Jassy** (President &amp; CEO)\nWe we haven't launched Project Kuiper yet, but the number of enterprise and government agreements that have been signed already to use Project Kuiper is impressive. So we're we're working very hard to get the satellites into space. We have some delays with some of the rocket providers, but we we have most of the available rocket launches over the next couple of years. And we're very hopeful to get this service into commercial into commercial beta later this year or early next year.\n\n**Operator**\nThank you. And our next question comes from the line of Brian Novak with Morgan Stanley. Please proceed with your question.\n\n**Andy Jassy** (President &amp; CEO)\nThanks for taking my questions.\n\n**Brian Nowak** (Managing Director)\nAndy, I have two for you on AWS. They're a little tough, but I'm gonna throw them at you. So there is a Wall Street Finance person narrative right now that AWS is falling behind in GenAI with concerns about care loss to peers, etcetera. Can you just sort of address that? What what is your rebuttal to that?\n\n**Brian Nowak** (Managing Director)\nAnd talk to us about your and the team's most important focal points just to ensure that AWS stays on the knife's edge of innovation versus hyperscaler peers? And then secondly, I know AWS is a big business, but is there any reason to assume it shouldn't accelerate in the back half and into '26 given the size of the opportunity and all of the Gen AI capabilities gonna sort of come to us in the next next twelve months?\n\n**Andy Jassy** (President &amp; CEO)\nYeah. So on on the first one around AI, the first thing I would say is that I think it is so early right now in AI. If if you look at what's really happening in the space, you have it's it's very top heavy. So you have a a small number of very large frontier models that are being trained that's that spend a lot on computing. A couple of which are being trained on top of AWS and others are are being trained elsewhere.\n\n**Andy Jassy** (President &amp; CEO)\nAnd then you also have, I would say, a relatively small number of very large scale generative AI applications. You know, you know, the one category would be chatbots with the largest by a fair bit being ChatGPT, but the other category being really, I'll call it, coding agents. So these are companies like Cursor, Vercel, and Lovable, some of the companies like that. Again, several of which run significant chunks on top of AWS. And then you've got a very large number of Generve AI applications that are in pilot mode that are in pilots or that are being developed as we speak, and a very substantial number of agents that also people are starting to try to build and and figure out how to get into production in a broad way.\n\n**Andy Jassy** (President &amp; CEO)\nBut but they're all they're they're quite early. And many of them that are out there are you know, they're significant, but they're just smaller in terms of usage relative to some of those top heavy applications I mentioned earlier. We have a a very significant number of enterprises and startups who are running applications on top of AWS's AI services. And and then, you know but but they're all again, like, the the amount of usage and the expansiveness of the use cases and how much people are putting them into production and the number of agents that are gonna exist, it's still just earlier stage than it's gonna be. And so then when you think about what's gonna matter in AI, what's gonna what what are customers gonna care about when they're thinking about what what infrastructure to use, I think you kind of have to look at the different layers of the stack.\n\n**Andy Jassy** (President &amp; CEO)\nAnd, you know, I think for those that are, you know, both building models, but also just if you look at where the real costs are, they're gonna ultimately be an inference. Today, so much of the cost in training because customers are really training their models and trying to figure out how get applications into production. But in at scale, you know, 80 to 90% of the cost will be an inference because you only train periodically, but you're spitting out predictions and and inferences all the time. And so what they're gonna care a lot about is they're gonna care about the compute and the hardware they're using. And, know, you we have a very deep partnership with NVIDIA and and will for as long as I can foresee, but we we we saw this movie in the CPU space with Intel where customers are hankering for better price performance.\n\n**Andy Jassy** (President &amp; CEO)\nAnd so, you know, we built just like in in the CPU space where we built our own custom silicon and building Graviton, which is about 40% more price performance than the other leading x 86 processors. We've done the same thing on the custom silicon side in AI with Tranium. And our second version of Tranium two has really you know, it's it's become the backbone of Anthropix, you know, next cloud models they're trading on top of, and it's become the the backbone of of Bedrock and the inference that we do. So I think a lot of the inference, it's about 3040% better price performance than the other GPU providers out there right now. And we're already working on our third version of trading as well.\n\n**Andy Jassy** (President &amp; CEO)\nSo I think a lot of the you know, compute and the inference is gonna ultimately be run on top of Tranium too. And I think that that price performance is gonna matter to people as they get to scale. You know, then I would say that that middle layer of the stack are really it's it's a combination of services that customers care about to be able to build models and then to be able to leverage existing leading frontier models and then build, you know, high quality generate AI applications that do inference at scale. And, you know, we see it for people building models. They continue to use SageMaker AI very expansively.\n\n**Andy Jassy** (President &amp; CEO)\nAnd then Bedrock, you're leveraging leading frontier models, is also growing very substantially. And, you know, as I said in my opening comments, the the number of agents of scale is still really small in the scheme of what's gonna be the case. But part of the problem is it's actually hard to actually build agents, and it's it's hard to deploy these agents in a secure and scalable way. And so I think the launches we made recently in strands that make it much easier to build agents and then agent core that make it much easier to deploy at scale and in a secure way are are being very well received and customers are excited. It's gonna change what's possible on the agent side.\n\n**Andy Jassy** (President &amp; CEO)\nYeah. And then and then I think that it's you've got a very large number. I mean, remember, 85 to 90% of the global IT spend is still on premises. If you believe that equation is gonna flip, which I do and we do, you have a lot of legacy infrastructure that you've gotta move. These are mainframes.\n\n**Andy Jassy** (President &amp; CEO)\nThese are VMware's instances. And, you know, when we build agents like AWS transform to make it much easier to to move mainframes to the cloud, much easier to move VMware to the cloud, much easier to move dot net windows to dot net Linux to save money. Like, those are compelling for enterprises or things like Curo that allow customers to develop in a in a much easier way and in a much more structured way, which is why I think people are excited about. So I think I really like the inputs in the set of services that we're building in the in the AI space today. Customers really like them, and it's resonating with them.\n\n**Andy Jassy** (President &amp; CEO)\nI still think it's very early days in AI and in terms of adoption. But I the other thing I would just say is that, remember, because we're at a stage right now where so much of the activity is is training and figuring out how to get your generative AI applications into production, people aren't paying as close attention as they will in making sure that those generative AI applications are operating where the rest of their data and infrastructure is. Remember, a lot of generative AI, inference is just gonna be another building block like compute, storage, and database. And so people are gonna actually wanna run those applications close to where their other applications are running, where their data is. There's just so many more applications and data running in AWS than anywhere else.\n\n**Andy Jassy** (President &amp; CEO)\nAnd I'm very optimistic about as we get to a bigger scale, what's gonna happen for AWS on the AI side. And I think we have a set of services that is unique top to bottom in the stack. I think on the last part about what do we expect with respect to acceleration. You know, we don't we don't give guidance by segments. I'm not gonna try and give you guidance, but I I do I do believe that the combination of more enterprises who have resumed their march to modernize their infrastructure and move from on premises to the cloud, coupled with the fact that AI is going to accelerate in terms of more companies deploying more AI applications into production that start to scale, coupled with the fact that I do think that more capacity is gonna come online in the in the coming months and quarters, make me optimistic about the AWS business.\n\n**Operator**\nThank you. And the next question comes from the line of Ron Josey with Citi. Please proceed with your question.\n\n**Ron Josey** (Managing Director)\nGreat. Thanks. Thanks for that, Andy.\n\n**Ron Josey** (Managing Director)\nThat was really helpful. Maybe taking that same question, but focusing internally on Amazon. I think you penned an article or a blog post back in June just talking about the ability or potential with GenAI agents and improving efficiencies and speed to market internally. So would love to hear your thoughts as as you think about how Amazon is adopting gen.ai internally, how perhaps, you've seen improving speed to market as a result of of everything you've just talked about. Thank you.\n\n**Andy Jassy** (President &amp; CEO)\nYeah. I I think that AI is is the biggest technology transformation of our lifetime, which is saying a lot because, you know, even in in some of our relatively short lifetimes, we've we've been through, you know, the cloud, mobile, and the Internet itself. But I I think it's gonna be the biggest transformation technically in our lifetime. And I think it's gonna not not only change every customer experience that we know and enable customer experiences we really only dreamed about before, but it's also gonna change very substantially the way we work. And if you think about it, you know, the way that we do coding, the way that we do analytics, the way that we do research, the way that we do finance, you know, and and and measure fine I mean, really, the way we do business process automation, you know, the way we do customer service, every single area that I can think of in the way we work is likely gonna be impacted in some meaningful way by AI.\n\n**Andy Jassy** (President &amp; CEO)\nAnd I think when you have a big shift like that, you have two macro choices. You could you can either decide that you're gonna embrace it and you're gonna and you're gonna help shape it, and you're you're gonna figure out how to build the right tools to allow you to take advantage of the technology, or you can wish it away and have it shape you. And, you know, the the posting that you're referencing, Ron, that I that I made was just really being clear with the team that we're gonna pursue that former approach. We are going to embrace it. We're gonna try and shape it.\n\n**Andy Jassy** (President &amp; CEO)\nAnd so we have, you know, we have a number of of of tools and agents that we've built already inside the company. And, you know, these are things like if you think about Curo and and the opportunity to have coding agents do a lot of of of the coding that's that's very compelling. It's gonna allow our our teammates to be able to start from a more advanced starting spot and to be able to invent for customers much more quickly and much more expansively. If you think about services like Connect, which is our AWS service that does call center software, that has a lot of AI built into it that changes the productivity of all your customer service agents. And you can just imagine across the board the types of things we're gonna do to make it easier to get software out, to build high quality software, to to do operations, QA, to automate a lot of the business process coordination happens inside the cloud.\n\n**Andy Jassy** (President &amp; CEO)\nWe're gonna we're gonna work on a whole bunch of those areas to allow ourselves primarily to be able to invent for customers much more quickly and expansively. But, also, I think it's gonna make all of our teammates' jobs much more enjoyable because they won't have to do as many of the rote parts of the job that we all do right now. They're gonna be able to own more pieces of what they're trying to solve for customers, and and we want deep owners that wanna end own as much end to end as possible.\n\n**Operator**\nThank you. And our final question will come from the line of Justin Post with Bank of America. Please proceed with your question.\n\n**Justin post** (Managing Director)\nGreat. Thanks. I'll just ask on the revenue guidance. It looks pretty robust growth in the third quarter. I know you won't say whether AWS is expected to accelerate, but could you talk about some of the drivers and what kind of tariff and other contingencies you've put in there?\n\n**Justin post** (Managing Director)\nAnd then maybe any thoughts on how you're thinking about how the Q4 is shaping up? Thank you.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nYes. Hi, Justin. This is Brian.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nI'll take this one. Yes, we've got it to $174,000,000,000 to 175,000,000,000 and we excuse me. A 179,500,000,000.0. That's a typo. We, feel good about the growth rate, in q two that we had and the acceleration in a number of areas, including units.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nAnd, you know, we had a very successful Prime Day earlier this month. So, you know, there are is uncertainty on where tariffs will settle and maybe the ultimate impact on consumers, as Andy mentioned earlier. But, we feel really good about the key inputs we control, price selection and convenience. We've talked about delivery speeds increasing. We've talked about selection increasing, high end stock levels, well dispersed inventory close to customers.\n\n**Brian Olsavsky** (SVP &amp; CFO)\nSo we think that all works in our favor. So I would say we're cautiously optimistic. I'm not going to give any guidance for Q4 at this time, we'll talk about that next time.\n\n**Dave Fildes** (VP - IR)\nThanks for joining us on the call today and for your questions. A replay will be available on our Investor Relations website for at least three months. We appreciate your interest in Amazon and look forward to speaking with you again with you next quarter.\n\n**Operator**\nLadies and gentlemen, that does conclude today's teleconference. You may disconnect your lines at this time. Thank you for your participation.",
        "fetched_at": "2026-02-04T16:10:57.856Z"
      },
      {
        "ticker": "AMZN",
        "title": "Yahoo Finance",
        "published_date": "May 1, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/AMZN/earnings/AMZN-Q1-2025-earnings_call-313773.html",
        "content": "**Operator**\nThank you for standing by. Good day, everyone, and welcome to the Amazon.com First Quarter 2025 Financial Results Teleconference. At this time, all participants are in a listen-only mode. After the presentation, we will conduct a question-and-answer session. Today's call is being recorded, and for opening remarks, I will be turning the call over to the Vice President of Investor Relations, Mr. Dave Fildes. Thank you, sir. Please go ahead.\n\n**Dave Fildes** (VP of Investor Relations)\nHello, and welcome to our Q1 2025 Financial Results Conference call. Joining us today to answer your questions is Andy Jassy, our CEO, and Brian Olsavsky, our CFO. As you listen to today's conference call, we encourage you to have a press release in front of you, which includes our financial results, as well as metrics and commentary on the quarter. Please note, unless otherwise stated, all comparisons in this call will be against our results for the comparable period of 2024. Our comments and responses to your questions reflect management's views as of today, May 1, 2025 only, and will include forward-looking statements. Actual results may differ materially. Additional information about factors that could potentially impact our financial results is included in today's press release and our filings with the SEC, including our most recent annual report on Form 10-K and subsequent filings.\n\n**Dave Fildes** (VP of Investor Relations)\nDuring this call, we may discuss certain non-GAAP financial measures in our press release, slides accompanying this webcast, and our filings with the SEC, each of which is posted on our IR website. You will find additional disclosures regarding these non-GAAP measures, including reconciliations of these measures with comparable GAAP measures. Our guidance incorporates the order trends that we've seen to date and what we believe today to be appropriate assumptions. Our results are inherently unpredictable and may be materially affected by many factors, including fluctuations in foreign exchange rates, changes in global economic and geopolitical conditions, tariff and trade policies, and customer demand and spending, including the impact of recessionary fears, inflation, interest rates, regional labor market constraints, world events, the rate of growth of the internet, online commerce, cloud services, and new and emerging technologies, and the various factors detailed in our filings with the SEC.\n\n**Dave Fildes** (VP of Investor Relations)\nOur guidance assumes, among other things, that we do not conclude any additional business acquisitions, restructurings, or legal settlements. It is not possible to accurately predict demand for our goods and services, and therefore our actual results could differ materially from our guidance. I will now turn the call over to Andy.\n\n**Andy Jassy** (CEO)\nThanks, Dave. Today we're reporting $155.7 billion in revenue, up 10% year-over-year, excluding the impact from foreign exchange rates. Operating income is $18.4 billion, up 20% year-over-year, and trailing 12-month free cash flow is $25.9 billion. We're pleased with our continued business progress, but more importantly, with our pace of innovation and additional improvement in our customer experiences. In our stores business, we once again saw strong consumer resonance in our continued work on selection, value, and shipping speed. Our broad selection offers customers choice across their shopping journeys. We welcome well-known brands such as Oura Rings, Michael Kors, and The Ordinary, as well as a new shopping experience with Saks that offers a refined luxury assortment of fashion and beauty items from brands like Dolce & Gabbana, Balmain, Burberry, Giambattista Valli, and Jason Wu Collection.\n\n**Andy Jassy** (CEO)\nAs always, we're working to keep prices low, and with this being an uncertain moment for consumers, it's even more important than it typically is. In Q1, we held deal events worldwide to help customers save over $500 million across the Big Spring Sale in the U.S. and Canada, Spring Deal Days in Europe, and Ramadan Eid Sale events in Egypt, Saudi Arabia, Turkey, and the UAE. Prime members will have more opportunities to save throughout the year, including at our 11th Prime Day event in July. Over the past-few-years, we've made significant progress in making our fulfillment network more efficient and cost-effective. We've shared many times that an important turning point was regionalizing our national fulfillment network into regional hubs. By stocking items closer to where customers live, we're able to deliver more orders faster, often in fewer packages and at lower delivery costs.\n\n**Andy Jassy** (CEO)\nThe next challenge was getting as many items as possible into these regional nodes. Our inbound network, which is how we get items to each fulfillment center, had not been architected to leverage this new regionalization structure, so we redesigned it and just rolled out a new inbound architecture that expands the share of products that we can place in each fulfillment center, improving delivery speeds and lowering our cost to serve. In the first quarter, we once again set new delivery speed records with our fastest delivery ever for Prime members around the world, and we delivered more items in the same day or next day in Q1 than any other quarter in our history. Looking ahead, we will continue to refine our newly redesigned inbound network, build out our same-day delivery sites, and add additional robotics and automation throughout our buildings.\n\n**Andy Jassy** (CEO)\nYou'll also see us expand the number of delivery stations that we have in rural areas of the U.S. so we can get items to people who live in less densely populated areas much more quickly. I thought I'd share a few thoughts on the prospect of heightened tariffs on our stores business. Obviously, none of us knows exactly where tariffs will settle or when. We haven't seen any attenuation of demand yet. To some extent, we've seen some heightened buying in certain categories that may indicate stocking up in advance of any potential tariff impact. We also have not seen the average selling price of retail items appreciably go up yet.\n\n**Andy Jassy** (CEO)\nSome of this reflects some forward buying we did in our first-party selling, and some of that reflects some advanced inbounding our third-party sellers have done, but a fair amount of this is that most sellers just have not changed pricing yet. Again, this could change depending on where tariffs settle. Amazon is not uniquely susceptible to tariffs. As it relates to China, retailers who are not buying directly from China are typically buying from companies who themselves are buying from China, marking these items up, rebranding, and selling to U.S. consumers. These retailers are buying the product at a higher price than Chinese sellers selling directly to U.S. consumers in our marketplace, so the total tariff will be higher for these retailers than for China direct sellers. It is also sometimes easy to forget what Amazon sells. We are not mostly selling high average selling price items, though we certainly sell a bunch.\n\n**Andy Jassy** (CEO)\nIn the first quarter, our everyday essentials grew more than twice as fast as the rest of our business and represented one out of every three units sold in the U.S. on Amazon. Even if you exclude Whole Foods Market and Amazon Fresh, Amazon is one of the largest grocers in the U.S. with over $100 billion in gross sales last year. People are buying a lot of their everyday essentials at Amazon. We also have an extremely large selection, hundreds of millions of unique SKUs, which means we're often able to weather challenging conditions better than others. When there are periods of discontinuity, substantial unexpected product trends emerge. Think about the pandemic, when items like masks and hand sanitizer became big sellers.\n\n**Andy Jassy** (CEO)\nWhen you have the broadest selection like we do and 2 million plus global sellers like we do, you're better positioned to help customers find whatever items matter to them at lower price points than elsewhere. Finally, when there are uncertain environments, customers tend to choose the provider they trust most. Given our really broad selection, low pricing, and speedy delivery, we have emerged from these uncertain eras with more relative market segment share than we started and better set up for the future. I'm optimistic this could happen again. Moving to a few words on Amazon ads. We're working hard to be the best place for brands of all sizes to grow their business. We are pleased with the strong growth on a very large base, generating $13.9 billion of revenue in the quarter and growing 19% year-over-year.\n\n**Andy Jassy** (CEO)\nWe're seeing strength across our broad portfolio of full-funnel advertising offerings that help advertisers reach an average ad-supported audience of more than 275 million in the U.S. alone. This includes our top-of-funnel efforts to drive brand awareness, the bottom-of-funnel offerings where we measure outcomes at the point of conversion. Amazon ads provides brands with tools to reach targeted audiences in our own entertainment properties such as Prime Video, Twitch, and IMDb, in live sports such as NFL, NBA, and NASCAR, audio content such as Amazon Music and Wondery, and of course in our store, as well as many other external sites such as Pinterest and BuzzFeed.\n\n**Andy Jassy** (CEO)\nAll of our audience and measurement capabilities work for the ads we deliver across premium third-party publishers through Amazon DSP, and our secure clean rooms provide advertisers the ability to analyze data, produce core marketing metrics, and understand how their marketing performs across various channels. We continue to see a lot of opportunity to further expand our full-funnel capabilities for brands. AWS grew 17% year-over-year in Q1 and now sits at a $117 billion annualized revenue run rate. We continue to help organizations of all sizes accelerate their move to the cloud, helping to modernize their infrastructure, lower costs, and speed up innovation. We signed new AWS agreements with companies including Adobe, Uber, Nasdaq, Ericsson, Fujitsu, Cargill, Mitsubishi Electric Corporation, General Dynamics Information Technology, GE Vernova, Booz Allen, Hamilton, NextEra Energy, Publicis Sapient, Elastic, NetSmart, and many others.\n\n**Andy Jassy** (CEO)\nIt's useful to remember that more than 85% of the global IT spend is still on premises, so not in the cloud yet. It seems pretty straightforward to me that this equation will flip in the next 10 years-20 years. Before this generation of AI, we thought AWS had the chance to ultimately be a multi-hundred billion dollar revenue run rate business. We now think it could be even larger. If you believe your mission is to make customers' lives easier and better every day, and you believe that every customer experience will be reinvented with AI, you're going to invest very aggressively in AI, and that's what we're doing. You can see that in the thousand-plus AI applications we're building across Amazon. You can see that with our next generation of Alexa named Alexa Plus.\n\n**Andy Jassy** (CEO)\nYou can see that in how we're using AI in our fulfillment network, robotics, shopping, Prime Video, and advertising experiences. You can see that in the building blocks AWS is constructing for external and internal builders to build their own AI solutions. We're not dabbling here. We're very intentionally giving builders the broadest possible capabilities at every level of the AI stack cost-effectively to use AI expansively across their businesses. At the bottom layer for those building models, our new custom AI chip, Trainium 2, is starting to lay in capacity in larger quantities with significant appeal and demand. While we offer customers the ability to do AI in multiple chip providers and will for as long as I can foresee, customers doing AI at any significant scale realize that it can get expensive quickly.\n\n**Andy Jassy** (CEO)\nThe 30%-40% better price performance that Trainium two offers versus other GPU-based instances is compelling. For AI to be as successful as we believe it can be, the price of inference needs to come down significantly. We consider this part of our mission and responsibility to help make it so. At the middle layer for those wanting to leverage frontier models to build generative AI apps, Amazon Bedrock is our fully managed service that offers a choice of high-performing foundation models with the most compelling set of features that make it easy to build high-quality generative AI applications. We continue to iterate quickly on Bedrock, adding Anthropic's Claude 3.7 Sonnet hybrid reasoning model, their most intelligent model to date, and Meta's Llama 4 family of models.\n\n**Andy Jassy** (CEO)\nWe were also the first cloud service provider to make DeepSeek R1 and Mistral AI's Pixtral Large generally available as a fully managed model. Of course, we offer our own Amazon Nova state-of-the-art foundation models in Bedrock with the latest premier model launching yesterday. They deliver frontier intelligence and industry-leading price performance, and we have thousands of customers already using them, including Slack, Siemens, Sumo Logic, Coinbase, FanDuel, Glean, and Blue Origin. A few weeks ago, we released Amazon Nova Sonic, a new speech-to-speech foundation model that enables developers to build voice-based AI applications that are highly accurate, expressive, and human-like. Nova Sonic has lower word error rates and higher win rates over other comparable models for speech interactions. The technology world is also abuzz about the potential of agents. To date, virtually all of the agentic use cases have been of the question-answer variety.\n\n**Andy Jassy** (CEO)\nOur intention is for agents to perform wide-ranging, complex, multi-step tasks like organizing a trip or setting the lighting, temperature, and music ambience in your house for dinner guests, or handling complex IT tasks to increase business productivity. There have not been action-oriented agents like this until Alexa Plus, but the technology to build these agents is still quite primitive and accurate and requires constant human supervision. We have just released a research preview of Amazon Nova Act, a new AI model trained to perform actions within a web browser. It enables developers to break down complex workflows into reliable atomic commands like search or checkout or answer questions about the screen. It also enables them to add more detailed instructions to these commands where needed, like do not accept the insurance upsell.\n\n**Andy Jassy** (CEO)\nNova Act aims to move the current state-of-the-art accuracy on multi-step agentic actions from 30%-60% to 90 plus percent with the right set of building blocks to build these action-oriented agents. At the very top of the stack are the applications. This past quarter, Amazon Q, the most capable generative AI-powered assistant for accelerating software development and leveraging your own data, launched a lightning-fast new agentic coding experience within the command line interface that can execute complex workflows autonomously. Customers are loving this. We also made generally available GitLab Duo with Amazon Q, enabling AI agents to assist multi-step tasks such as new feature development, code-based upgrades for Java 8 and 11, while also offering code review and unit testing, all within the same familiar GitLab platform.\n\n**Andy Jassy** (CEO)\nOur AI business has a multi-billion dollar annual revenue run rate, continues to grow triple-digit year-over-year percentages, and is still in its very early days. While there is good reason for the high optimism about AI, I conclude my AWS comments with a reminder that there is still so much on-premises infrastructure yet to be moved to the cloud. Infrastructure modernization is much less sexy to talk about than AI, but fundamental to any company's technology and invention capabilities, developer productivity, speed, and cost structure. If we're companies to realize the full potential of AI, they're going to need their infrastructure and data in the cloud. I want to briefly mention a few other items.\n\n**Andy Jassy** (CEO)\nAs I've referenced a couple of times in Q1, we introduced Alexa Plus, our next-generation Alexa personal assistant who's meaningfully smarter and more capable than her prior self, can both answer virtually any question and take actions, and is free with Prime or available to non-Prime customers for $19.99 a month. We're just starting to roll this out in the U.S., and we'll be expanding to additional countries later this-year. People are really liking Alexa Plus this far. We're excited and honored to be part of the joint venture that will be creating the next generation of the esteemed James Bond film franchise. We recently named acclaimed producer Amy Pascal and David Heyman to produce the next James Bond movie.\n\n**Andy Jassy** (CEO)\nAdditionally, just a couple of days ago, Project Kuiper reached a significant milestone by launching our first satellites into orbit, with more being launched soon, and we expect to begin offering service to customers later this year. I'm proud of what our teams around the world have delivered. We're excited about what we're inventing and working on as we speak, and with that, I'll turn it over to Brian for a financial update.\n\n**Brian Olsavsky** (CFO)\nThanks, Andy. I will begin with our top-line financial results. Worldwide revenue was $155.7 billion, a 10% increase year-over-year, excluding the impact of foreign exchange. This equates to a $1.4 billion headwind from foreign exchange year-over-year in the quarter. Worldwide operating income was $18.4 billion, approximately $400 million above the high end of our guidance range.\n\n**Brian Olsavsky** (CFO)\nThese results include one-time charges that impacted North America and international operating income that I will discuss in a moment. First, let's start with the net sales results for these segments. In the North America segment, first-quarter revenue was $92.9 billion, an increase of 8% year-over-year. Our international segment revenue was $33.5 billion, also an increase of 8% year-over-year, excluding the impact of foreign exchange. Worldwide paid units grew 8% year-over-year. Our priority is to provide value to our customers across our businesses. In the first quarter, we held multiple deal events around the world, which drove strong customer engagement. We saw broad-based strengths across our key business inputs, including record delivery speeds for Prime members, enabled by improved inventory placement. Our vast selection gives customers choice across various price points, particularly in categories like grocery, which includes everyday essentials.\n\n**Brian Olsavsky** (CFO)\nThese are the items that people purchase most frequently. We partner with millions of independent sellers from around the world. These selling partners are important contributors to our broad selection, and worldwide third-party seller unit mix was 61% in Q1, consistent with Q1 of last-year. Shifting to profitability, North America segment operating income was $5.8 billion, and international segment operating income was $1 billion, with operating margins of 6.3% in North America and 3% internationally. As I mentioned earlier, during the quarter, we recorded one-time charges related to some historical customer returns that have not yet been resolved, and some costs to receive inventory that was pulled forward into Q1 ahead of anticipated tariffs. Without these charges, North America and international operating margins would have been approximately 90 basis points and 70 basis points higher, or operating margins of 7.2% for North America and 3.7% for international.\n\n**Brian Olsavsky** (CFO)\nWe are pleased with how our teams continue to execute and deliver for customers. In Q1, our newly re-architected inbound network drove productivity in our fulfillment and transportation network, leading to better inventory placement and higher units per package, and as a result, lower delivery costs. Beyond Q1, we have a number of initiatives underway to continue improving our cost structure, such as fine-tuning our inbound network, building out our same-day delivery sites, expanding our rural delivery network, and adding robotics and automation to our facilities. Better inventory placement remains a top priority. Better placement drives more in-stock selection, reduces travel distances, and speeds up delivery. Having the inventory in the right place at the right time increases the likelihood that multiple items can be combined in a package, which helps reduce packaging and costs.\n\n**Brian Olsavsky** (CFO)\nAlthough progress will not always be linear, we have a good plan to continue to drive improvement over time. Shifting to advertising. Advertising remains an important contributor to profitability in the North America and international segments. Advertising revenue grew 19% year-over-year. We are pleased with the accelerating growth on an increasingly large base. We are seeing strong adoption across our full-funnel advertising offering as brands appreciate our ability to connect them with customers. We will also continue to invest in other long-term opportunities. These efforts have the potential to be important to customers and Amazon in the future, including Kuiper, where we had our first launch of our production design satellites earlier this week, and we will be launching more satellites throughout the year. We are closely monitoring the macroeconomic environment, including the impact of tariffs. We are planning for various outcomes, and we have taken a number of actions to protect the customer experience.\n\n**Brian Olsavsky** (CFO)\nWe're doing everything we can to keep our prices low for customers and in a way that makes economic sense. Moving next to our AWS segment, revenue was $29.3 billion in Q1, an increase of 17% year-over-year. AWS now has an annualized revenue run rate of more than $117 billion. During the first quarter, we continue to see growth in both generative AI business and non-generative AI offerings. As companies turn their attention to newer initiatives, bring more workloads to the cloud, restart or accelerate existing migrations from on-premises to the cloud, and tap into the power of generative AI. AWS operating income was $11.5 billion and reflects our continued growth, coupled with our focus on driving efficiencies across the business.\n\n**Brian Olsavsky** (CFO)\nAs we've said before, we expect AWS operating margins to fluctuate over time, driven in part by the level of investments we're making at any point in time. We plan to bring on an increasing amount of capacity in the back half of the year. Now turning to our cash CapEx, which was $24.3 billion in Q1. The majority of this spend is to support the growing need for technology infrastructure. It primarily relates to AWS as we invest to support demand for our AI services and increasingly in custom silicon like Trainium, as well as tech infrastructure to support our North America and international segments. We're also investing in our fulfillment and transportation network to support future growth and improve delivery speeds and our cost structure. This investment will support growth for many-years to come.\n\n**Brian Olsavsky** (CFO)\nWhile we primarily focus our comments on operating income, I'd like to point out that our first-quarter net income of $17.1 billion includes a pre-tax gain of $3.3 billion included in non-operating income, and it relates to our investment in Anthropic. This activity is not related to Amazon's ongoing operations, but rather the result of the conversion of a portion of our convertible notes to non-voting preferred stock. Turning to Q2 guidance. As a reminder, our guidance considers a range of possibilities and takes into account Q1 results, trends in quarter-day results, and expectations around the macroeconomic environment. Q2 net sales are expected to be between $159 billion and $164 billion. We estimate the year-over-year impact of changes in foreign exchange rates based on current rates, which we expect to be a headwind of approximately 10 basis points in the quarter.\n\n**Brian Olsavsky** (CFO)\nAs a reminder, global currencies can fluctuate during the quarter. Q2 operating income is expected to be between $13 billion and $17.5 billion. This estimate includes the impact of our seasonal step-up in stock-based compensation expense in Q2, driven by the timing of our annual compensation cycle. The external environment remains complex, and as we have done throughout our history, we are focused on the inputs that we can control to protect the customer experience. We will work hard to remain the place customers trust for sharp prices, broad selection, and convenience. We'll remain focused on driving a better customer experience, and we still believe putting customers first is the only reliable way to create lasting value for our shareholders. With that, let's move on to your questions.\n\n**Operator**\nThank you. At this time, we will now open the call up for questions. We ask each caller to please limit yourself to one question. If you would like to ask a question, please press star one on your keypad. We ask that when you pose your question, you pick up your handsets to provide optimum sound quality. Once again, to initiate a question, please press star, then one on your touchstone telephone at this time. Please hold while we pull for questions. The first question comes from the line of Ross Sandler with Barclays. Please proceed with your question.\n\n**Ross Sandler** (Analyst)\nGreat. I think I'm going to leave the China questions to others and focus on AWS and kind of AI. Andy, it seems like you've been bringing on a lot more P5 GPU instances since February from what it looks like to kind of support all these new AI workloads. How would you characterize in the first quarter and maybe here in the second quarter the kind of supply-demand imbalance that you talked about before around AI workloads? When do you think that AWS will be in a position to kind of capture enough AI revenue to drive acceleration? Is that something that could happen this year, or do you see that more like next year given your capacity constraints? Thank you very much.\n\n**Andy Jassy** (CEO)\nThanks, Ross. You know, I would say that we've been bringing on a lot of P5s, which is a form of NVIDIA chip instances, as well as landing more and more Trainium 2 instances as fast as we can. I would tell you that, you know, our AI business right now is a multi-billion dollar annual run rate business. It's growing triple-digit percentage year-over-year.\n\n**Andy Jassy** (CEO)\nAs fast as we actually put the capacity in, it's being consumed. You know, I think we could be helping more customers and driving more revenue for the business if we had more capacity. We have a lot more Trainium 2 instances and the next generation of NVIDIA's instances landing in the coming months. I expect that, you know, there are other parts of the supply chain that are a little bit jammed up as well, you know, motherboards and some other componentry. I do thinkand some of that is just because there is so much demand right nowbut I do believe that the supply chain issues and the capacity issues will continue to get better as the year proceeds.\n\n**Operator**\nThe next question comes from the line of Eric Sheridan with Goldman Sachs. Please proceed with your question.\n\n**Eric Sheridan** (Managing Director)\nThanks so much for taking the question. Maybe I could ask a two-parter. First, in terms of strategy, you know, Andy, how do you think about positioning the company for the medium term with given all the levels of uncertainty out there about how the global trade environment might shift in the coming months? What do you see as the key strategic priorities that will allow the company to sort of be able to capitalize one way or another depending on various elements of outcome? How do you prioritize those investments in the months ahead? With respect to the one-quarter forward operating income guide, is there anything in there from a cost side that we should be thinking about as purely aligned with those types of investments against the trade landscape that might not repeat either later into this year or next year? Thanks so much.\n\n**Andy Jassy** (CEO)\nThanks, Eric. You know, it's hard to tell what's going to happen with tariffs right now. It's hard to tell where they're going to settle and when they're going to settle. A lot of what we're thinking about short and medium term actually turns out to be what we think about long term too, which is how do we actually have the broadest possible selection for customers at the lowest possible prices? There's maybe never been a more important time in recent memory than, you know, trying to keep prices low, which we're heads down, pretty maniacally focused on, and then get things to people quickly and take care of customers. That is the heart of what we're doing. You can see different initiatives that we've taken within those priorities. We've done some forward buys of inventory where we're the first-party seller.\n\n**Andy Jassy** (CEO)\nOur third-party sellers have pulled forward a number of items so that they have inventory here as well. Those are all, you know, we're encouraging that because we're trying to keep prices as low as possible for customers. I think also when you have as broad a selection as we have, and we have much broader selection than other retailers, it means that when you've got this continuity like we may potentially have, you're better able to help customers find what they want no matter what those trends are. I mentioned in my opening comments about what happened in the pandemic, and you can bet there are going to be things that we don't anticipate that customers really value and want that are different.\n\n**Andy Jassy** (CEO)\nIt could be as simple, by the way, as just favoring other brands that maybe people did not know about before, but where they have a more favorable price equation for customers. I think when you have also gotanother thing that people forget is that when you have got 2 million plus sellers, they are not all going to take the same strategy if there ends up being higher tariffs. I mean, there are going to be plenty of sellers that decide to pass on those higher costs to end consumers, but they are going toyou know, we have a lot of sellers in lots of different countries, and not all of them are going to pursue the same tack.\n\n**Andy Jassy** (CEO)\nI think when you've got larger diversity like we have, we have a better chance of some of those sellers deciding that they're going to capture share, and they're not going to pass on all or any of those tariffs to customers. I think customers are going to have a better chance of finding variety on selection and on lower prices when they come here. You know, the last thing I would say is that we have been in a number of our businesses, but just I'd say over the last six years or so, we have been diversifying where we produce things over a long period of time.\n\n**Andy Jassy** (CEO)\nWe had a, I would say, a meaningfully higher concentration of where we produced components for AWS or devices in China than we have now, where we've diversified meaningfully over that time, and we just thought that was wise to do so. Those are some of the ways that we're trying to make sure that we are protecting our customers over the short, medium, and long term. It turns out that most of those are the things that we focus most on, which is really broad selection for ultimate choice, really low prices, and very fast delivery.\n\n**Brian Olsavsky** (CFO)\nEric, I'll take your question on the guidance and especially on operating income. I think that was your question in the cost that might be in Q2. The thing I'd point to again is what I mentioned earlier.The stock-based comp always steps up generally in Q2 versus Q1 and then resets a rate that carries through for the next four quarters. You can look at historic trends to get an idea of that. Secondly, we do have some additional Kuiper launch costs in Q2. You saw a launch happen this week. A reminder that we expense those launch costs until the point of commercialization, which the plan is to have that be later in this-year.\n\n**Operator**\nThank you. The next question comes from the line of Justin Post with Bank of America. Please proceed with your question.\n\n**Justin Post** (Managing Director)\nGreat. Thanks. I'll go back to AWS. I know in the past you said revenues can be lumpy. Can you explain why they might fluctuate up and down if it's beyond just capacity? You see the competitors, you know, with some pretty good growth rates. How do you think about the difference there? Obviously, your dollar growth is very good, but how do you think about the difference there versus some of your competitors? Thank you.\n\n**Andy Jassy** (CEO)\nYou know, the first thing I would say is when we've historically said that revenue can be lumpy, this was, you know, we've been saying this well before what's happened with AI over the last couple of years. The reason for that is the sales cycle for, particularly for enterprises. It's true for startups. You know, what you really want is you want to have the type of capabilities where startups want to primarily choose to run on top of your platform. That's true. If you look in the startup space, you know, the vast majority of successful startups over the last 10 years-15 years have run on top of AWS.\n\n**Andy Jassy** (CEO)\nIt's unpredictable when those startups are going to find product-market fit and grow substantially. It's, you know, it's hard for them to predict and even harder for us to predict. The same thing goes on the enterprise side, but in a different way, when the sales cycle on the enterprise side is that you spend time trying to convince people that they should move from on-premises to the cloud, and then that you have the right solution for them, and then you pick a set of projects that you get experience on. Sometimes they use systems integrators, sometimes they use our own professional services, sometimes they're doing it themselves. There's a next tranche of migrations. Those migrations just take time. Some companies get through them really quickly, and some companies take longer to get through them.\n\n**Andy Jassy** (CEO)\nWhat happens a lot of times too is that they get excited and enthusiastic about the cost advantages and the speed of innovation advantages they get moving to the cloud. What was supposed to be a smaller next tranche turns into a much larger next tranche. All of that has been true for a long time. It's very hard for us to predict because it really is contingent on what enterprises, how they want to sequence it and resource it. You throw in AI, which has its own very fast growth cycle, particularly in certain types of use cases. Those change. I mean, I'll give you just some examples. You know, in the early days of, you know, the earliest days, I should say, of AI, what you've seen the most amount of has been initiatives that get you productivity and cost avoidance.\n\n**Andy Jassy** (CEO)\nWe've seen that from so many of our AWS customers. We're doing a lot of it ourselves inside of Amazon using AI. You've also seen, I would say, large-scale training, with a lot of those running on top of this as well. As you know, Anthropic is running their, you know, building their next few training models on top of our Trainium 2 chip on AWS. You've seen a couple really big chatbots. What you've seen just in the last few months is really kind of the explosion of coding agents. If you just look at the growth of these coding agents the last few months, these are companies like Cursor or Vercel, both of them run significantly on AWS. Just look at the growth of that over the last few months.\n\n**Andy Jassy** (CEO)\nYou just couldn't have predicted that sort of growth. That's why it's lumpy. You know, sometimes you'll have, you know, very significant increases that you didn't predict and you couldn't forecast. You know, they'll grow at a good rate, but maybe not the same rate before the next big kind of explosive growth. I would tell you that everything I just mentioned with interesting in AI is that we still haven't gotten to all the other customer experiences that are going to be reinvented and all the other agents that are going to be built. They're going to take, you know, the role of a lot of different functions today.\n\n**Andy Jassy** (CEO)\nYou know, those are, they're so, even though we have a lot of combined inference in those areas, I would say we're not even at the second strike of the first batter in the first inning. It is so early right now. I would just say on the how to think about relative growth rates, you always have to, you know, the year-over-year growth rate is really only a function of the percentage growth on the base with which you are operating from. We just have a very, you know, a meaningfully larger base on the technology infrastructure side than others. When, you know, it's still, you know, if you think about 17% year-over-year growth on a $117 billion revenue run rate, it's still pretty significant growth. As I said, I think we could be doing more if we had more capacity.\n\n**Andy Jassy** (CEO)\nI expect that to, you know, the capacity to ease in the coming months.\n\n**Operator**\nThank you. Our next question comes from the line of Doug Anmuth with JP Morgan. Please proceed with your question.\n\n**Doug Anmuth** (Managing Director)\nThanks for taking the questions. One for Brian, one for Andy. Brian, just maybe to follow up on AWS, but more on the margin side. We've seen a lot of fluctuation over the last couple of years and now hitting almost 40%. If you can just talk about what's driving the outperformance and then how we should think about normalized margins going forward. Andy, your comments on Alexa about moving to more complex tasks. Can you talk about that more? And just, you know, with Alexa, the products have been around for a long time, and they've had different use cases. How do you get users to shift their behavior more with Alexa? Thanks.\n\n**Brian Olsavsky** (CFO)\nThanks, Doug. I'll take your first question. Yeah, we did a strong quarter in AWS, as you mentioned, the margin performance. I would attribute it to the strong growth that we're seeing, coupled with, you know, the impact of some continued investment we're making in innovation and technology. Give you some examples. You know, we invest in software and process improvements, and it ends up optimizing our server capacity, which helps our infrastructure costs. Been developing more efficient network using our low-cost custom networking gear. We're working to maximize the power usage in our existing data centers, which both lowers our costs and also reclaims power for other newer workloads. We're also seeing the impact of advancing custom silicon like Graviton. It provides lower costs not only for us, but also for our customers, the better price performance for them.\n\n**Brian Olsavsky** (CFO)\nYou're right, margins are, you know, impacted by a lot of things, including our level of investment, competitive pricing, the mix of generative AI services as they're ramping up. We'll continue to evolve over the years to come. We do have a lot of investment in infrastructure going on and plan for the second half of the year. That will, you know, we'll start to see the impact of that. We're happy with the performance of the team with generating cost savings. It's a big focus as well as expanding the services and features for customers.\n\n**Andy Jassy** (CEO)\nOn the Alexa question, we're really excited about Alexa Plus. You know, as I mentioned earlier, it is, she's much more intelligent, much more capable, and able to take real action.\n\n**Andy Jassy** (CEO)\nYou know, today, most of the agents that have been out there have really just been able to answer questions, which, when it came out, was very remarkable. I think the future of agents is not just being intelligent, but also being able to take action. That actually requires a great model, but it also requires the ability to sync that model and to align that model with being able to take the right action and execute and implement the right APIs, or you can have very suboptimal results. We have worked hard on that in Alexa Plus. We have started rolling out over the last several weeks. It is now with over 100,000 users, with more rolling out in the coming months. So far, the response from our customers has been very, very positive.\n\n**Andy Jassy** (CEO)\nPeople are excited about it. I think that, you know, it does a lot more things than what Alexa did before. You know, we're very fortunate in that we have over a half billion devices out there in people's homes and offices and cars. We have a lot of distribution already. There will be, to some degree, a little bit of rewiring for people on what they can do because you get used to patterns. I mean, even the simple thing of not having to speak Alexa speak anymore, where we're all used to saying Alexa before we want every action to happen. What you find is you really only have to do it the first time. Then really the conversation is ongoing where you don't have to say Alexa anymore.\n\n**Andy Jassy** (CEO)\nI've been lucky enough to have, you know, the Alpha and the Beta that I've been playing with for several months. It took me a little bit of time to realize I didn't have to keep saying Alexa. It's very freeing when you don't have to do that. You know, I think it's just experience in trying things. You can do things like you have guests coming over on a Saturday night for dinner, and you can say, you know, Alexa, please open the shades, put the lights on in the driveway and on the porch, increase the temperature five degrees, and pick music that would be great for dinner that's mellow. She just does it. Like when you have those types of experiences, it makes you want to do more of it.\n\n**Andy Jassy** (CEO)\nYou know, when I was in New York when we were announcing it, I asked her what were the, you know, we did the event way downtown. I asked her what were great Italian restaurants or pizza restaurants. She gave me a list. She asked me if she wanted me to make a reservation. I said yes. She made the reservation and confirmed the time. Like that, when you get into those types of routines and you have those types of experience, they're very, very useful. It is really like having a great personal assistant, which most people in the world don't have. I think that the more and more that people get used to it, they will realize what she can do. We're not going to be standing still.\n\n**Andy Jassy** (CEO)\nWe have a lot more functionality that we plan to add in the coming months too.\n\n**Operator**\nThank you. Our next question comes from the line of Brian Nowak with Morgan Stanley. Please proceed with your question.\n\n**Brian Nowak** (Managing Director)\nThanks for taking my questions. Hey, Andy and Brian. I have one for each of you guys. Andy, you have a very complicated retail business with a lot of moving pieces to it. I imagine you have a lot of good data on what you expect demand to be over the course of the year and the holidays and things. As you kind of step back and analyze the business and the tariff uncertainty, can you just sort of walk us through the one or two key areas operationally that you're most focused on just to ensure that Prime Day, Thanksgiving, and the holidays go as smoothly as they possibly can?\n\n**Brian Nowak** (Managing Director)\nThen secondly, Brian, just to kind of go back to Eric's earlier question, as we think about the 2Q EBIT guide, are there any one-time costs or sort of tariff-related costs in there similar to that billion dollars that you called out in the first quarter? Thanks.\n\n**Brian Olsavsky** (CFO)\nThanks, Brian. On the retail question, I would say that the areas that maybe we're most focused on to make sure we have, you know, not just a great Prime Day, but Prime Day is just one event, as you know, and so is Peak. We're trying to be great all year long for customers. The obvious ones are making sure that we help our sellers however we can, because there's uncertainty for our sellers as well. We're trying to make sure we provide a great experience.\n\n**Brian Olsavsky** (CFO)\nWe're trying to make sure that we have the right diversity of sellers and low prices for our customers. I think all that you have to also be very thoughtful around how much inventory you bring into your fulfillment nodes at any one time. Because you can imagine scenarios where, you know, either on your own when you're the first-party seller or lots of third parties want to get as much inventory in as early as possible, you know, trying to beat a deadline on what may happen. If you end up with too much inventory in your fulfillment network, it really slows down your productivity and your ability to get things out as quickly as you want for customers at the cost structure you want. Being able to manage that thoughtfully, we've learned that over-the-years.\n\n**Brian Olsavsky** (CFO)\nI think the team is doing a really good job of balancing that right now. Brian, on your question about Q2, I guess I'll just reiterate what I had said earlier. You know, we had stock-based comp step up, which I think you can see the normal pattern for that if you look at our history. We have additional Kuiper expenses. Specifically, you asked about tariffs. We do have tariffs that we'll be paying on retail purchases based on current tariffs. It's not large in Q2. We had done a lot of pre-buying of inventory in Q1, as I mentioned earlier. You know, just generally, I think with the uncertainty, we've added a bit to the range that we've given you.\n\n**Brian Olsavsky** (CFO)\nWe generally have a wide range, but just the general uncertainty that we're seeing and uncertainty of consumer demand and all the everything else is causing us to increase the ranges a bit. We'll see. We've filled some an informed view of Q2 right now. As Andy mentioned earlier, we saw actually some strength in April based on what could end up being some pre-buys of a number of things. Advertising has been strong. We think there's a lot of positive trends, but, you know, certainly uncertainty right now for the quarter.\n\n**Operator**\nThank you. Our final question will come from the line of Brent Thill with Jefferies. Please proceed with your question.\n\n**Brent Thill** (Managing Director)\nThanks. On AWS, I'm curious if you could give us the backlog number. Andy, to your point about many of these core workloads still yet to come to cloud, can you just update us in what you're seeing? Are you seeing enterprise strength back? Are you seeing some confusion with AI clouding that transition and the timing of that? Just give us a perspective on what you're seeing on that migration. Thank you.\n\n**Dave Fildes** (VP of Investor Relations)\nHey, this is Dave. I'll just jump in on the backlog and turn it over to Andy. The backlog is $189 billion for Q1. That's up about 20% year-over-year. And the weighted average remaining life on that is 4.1 years.\n\n**Andy Jassy** (CEO)\nOn the AWS question, Brent, around what we're seeing on the workloads that haven't moved, you know, what I would say, the way I would characterize it is that we were on a very aggressive march that was methodical, but almost metronomic before the pandemic of enterprises deciding that they wanted to move off their on-premises infrastructure because of the speed of innovation, the developer productivity, and the cost advantages of the cloud. When you got into the pandemic and the economy looked uncertain in the second half of that couple of few years, you had everybody trying to cost optimize, including us, by the way. As we started to emerge from that trend, you saw generative AI explode. Everybody wanted to try to find a way to have a workload or a set of workloads there because people saw the potential.\n\n**Andy Jassy** (CEO)\nIt was also something that was generating a lot of interest publicly. What we've seen now over the last, call it 16 months-18 months or so, is that enterprises realize they need to do both. They want to do AI. They have all sorts of pilots at this point on AI, many of which will be successful, others of which will not be successful. The ones that are successful will scale. They also have a lot more initiatives that they haven't, you know, that they still haven't gotten to on the AI side, either because they're building that skill set or they're picking a first set to get experience with, or as they're waiting to see the cost of inference continue to go down, which it will.\n\n**Andy Jassy** (CEO)\nI mean, you will not get the expansiveness that we all know is coming in AI until we keep getting the cost of inference down, even though it's growing like crazy right now. At the same time, I would say that we see an increased resurgence and understanding for enterprises that they are dropping the low-hanging fruit if they don't move their infrastructure to the cloud. They just, you know, for all the reasons I mentioned earlier. You're starting to see those plans pick up again. As I mentioned earlier to one of the questions, you don't decide that you're going to transform your infrastructure from on-premises to the cloud and see it happen in three months.\n\n**Andy Jassy** (CEO)\nYou know, that is typically a multi-year process that some companies do it fast, some companies do it slower, but they do it in tranches and they do it thoughtfully because they can't afford for their applications not to work as they're making their transition. We're having meaningful success in those conversations and in companies choosing to transform their infrastructure on top of AWS. I think that, you know, you'll see that moving forward too.\n\n**Dave Fildes** (VP of Investor Relations)\nThank you for your time joining us today and for your questions. A replay will be available on our investor relations website for at least three months. We appreciate your interest in Amazon, and we look forward to talking with you again next quarter.\n\n**Operator**\nLadies and gentlemen, that does conclude today's teleconference. You may disconnect your lines at this time. Thank you for your participation.",
        "fetched_at": "2026-02-04T16:11:02.742Z"
      }
    ]
  },
  "NVDA": {
    "ticker": "NVDA",
    "last_updated": "2026-02-04T16:11:52.037Z",
    "total_transcripts": 5,
    "transcripts": [
      {
        "ticker": "NVDA",
        "title": "Yahoo Finance",
        "published_date": "Nov 19, 2025, 5:00 PM EST",
        "fiscal_year": "2026",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/NVDA/earnings/NVDA-Q3-2026-earnings_call-379484.html",
        "content": "**Operator**\nGood afternoon. My name is Sarah, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's third quarter earnings call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be a question-and-answer session. If you would like to ask a question during this time, simply press star, followed by the number one on your telephone keypad. If you would like to withdraw your question, press star one again. Thank you. Toshiya Hari, you may begin your conference.\n\n**Toshiya Hari** (VP of Investor Relations)\nThank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2026. With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer, and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter of fiscal 2026. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially.\n\n**Toshiya Hari** (VP of Investor Relations)\nFor a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, November 19, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\n\n**Colette Kress** (EVP and CFO)\nThank you, Toshiya. We delivered another outstanding quarter with revenue of $57 billion, up 62% year over year, and a record sequential revenue growth of $10 billion, or 22%. Our customers continue to lean into three platform shifts, fueling exponential growth for accelerated computing, powerful AI models, and agentic applications. Yet, we are still in the early innings of these transitions that will impact our work across every industry. We currently have visibility to $500 billion in Blackwell and Rubin revenue from the start of this year through the end of calendar year 2026. By executing our annual product cadence and extending our performance leadership through full-stack design, we believe NVIDIA will be the superior choice for the $3 trillion-$4 trillion in annual AI infrastructure build we estimate by the end of the decade. Demand for AI infrastructure continues to exceed our expectations.\n\n**Colette Kress** (EVP and CFO)\nThe clouds are sold out, and our GPU-installed base, both new and previous generations, including Blackwell, Hopper, and Ampere, is fully utilized. Record Q3 data center revenue of $51 billion increased 66% year over year, a significant feat at our scale. Compute grew 56% year over year, driven primarily by the GB300 ramp, while networking more than doubled given the onset of NVLink scale-up and robust double-digit growth across Spectrum X Ethernet and Quantum X InfiniBand. The world hyperscalers, a trillion-dollar industry, are transforming search, recommendations, and content understanding from classical machine learning to generative AI. NVIDIA CUDA excels at both and is the ideal platform for this transition, driving infrastructure investment measured in hundreds of billions of dollars. At Meta, AI recommendation systems are delivering higher quality and more relevant content, leading to more time spent on apps such as Facebook and Threads.\n\n**Colette Kress** (EVP and CFO)\nAnalyst expectations for the top CSPs and hyperscalers in 2026 aggregate CapEx have continued to increase and now sit roughly at $600 billion, more than $200 billion higher relative to the start of the year. We see the transition to accelerated computing and generative AI across current hyperscale workloads contributing toward roughly half of our long-term opportunity. Another growth pillar is the ongoing increase in compute spend driven by foundation model builders such as Anthropic, Mistral, OpenAI, Reflection, Safe Superintelligence, Thinking Machines Lab, and xAI, all scaling compute aggressively to scale intelligence. The three scaling laws, pre-training, post-training, and inference remain intact. In fact, we see a positive virtuous cycle emerging whereby the three scaling laws and access to compute are generating better intelligence and, in turn, increasing adoption and profits.\n\n**Colette Kress** (EVP and CFO)\nOpenAI recently shared that their weekly user base has grown to $800 million, enterprise customers have increased to 1 million, and that their gross margins were healthy. While Anthropic recently reported that its annualized run rate revenue has reached $7 billion as of last month, up from $1 billion at the start of the year. We are also witnessing a proliferation of agentic AI across various industries and tasks. Companies such as Cursor, Anthropic, Open Evidence, Epic, and Abridge are experiencing a surge in user growth as they supercharge the existing workforce, delivering unquestionable ROI for coders and healthcare professionals. The world's most important enterprise software platforms like ServiceNow, CrowdStrike, and SAP are integrating NVIDIA's accelerated computing and AI stack. Our new partner, Palantir, is supercharging the incredibly popular ontology platform with NVIDIA CUDA X libraries and AI models for the first time.\n\n**Colette Kress** (EVP and CFO)\nPreviously, like most enterprise software platforms, Ontology runs only on CPUs. Lowe's is leveraging the platform to build supply chain agility, reducing costs and improving customer satisfaction. Enterprises broadly are leveraging AI to boost productivity, increase efficiency, and reduce costs. RBC is leveraging agentic AI to drive significant analyst productivity, slashing report generation time from hours to minutes. AI and digital twins are helping Unilever accelerate content creation by 2x and cut costs by 50%. Salesforce's engineering team has seen at least a 30% productivity increase in new code development after adopting Cursor. This past quarter, we announced AI factory and infrastructure projects amounting to an aggregate of 5 million GPUs. This demand spans every market: CSPs, sovereigns, model builders, enterprises, and supercomputing centers, and includes multiple landmark buildouts.\n\n**Colette Kress** (EVP and CFO)\nxAI's Colossus 2, the world's first gigawatt-scale data center, Lilly's AI factory for drug discovery, the pharmaceutical industry's most powerful data center. Just today, AWS and Humane expanded their partnership, including the deployment of up to 150,000 AI accelerators, including our GB300. xAI and Humane also announced a partnership in which the two will jointly develop a network of world-class GPU data centers anchored by the flagship 500-megawatt facility. Blackwell gained further momentum in Q3 as GB300 crossed over GB200 and contributed roughly two-thirds of the total Blackwell revenue. The transition to GB300 has been seamless, with production shipments to the major cloud service providers, hyperscalers, and GPU clouds, and is already driving their growth. The Hopper platform, in its 13th quarter since inception, recorded approximately $2 billion in revenue in Q3. H20 sales were approximately $50 million.\n\n**Colette Kress** (EVP and CFO)\nSizable purchase orders never materialized in the quarter due to geopolitical issues and the increasingly competitive market in China. While we were disappointed in the current state that prevents us from shipping more competitive data center compute products to China, we are committed to continued engagement with the U.S. and China governments and will continue to advocate for America's ability to compete around the world. To establish a sustainable leadership position in AI computing, America must win the support of every developer and be the platform of choice for every commercial business, including those in China. The Rubin platform is on track to ramp in the second half of 2026. Powered by seven chips, the Vera Rubin platform will once again deliver an X-factor improvement in performance relative to Blackwell.\n\n**Colette Kress** (EVP and CFO)\nWe have received silicon back from our supply chain partners and are happy to report that NVIDIA teams across the world are executing the bring-up beautifully. Rubin is our third-generation rack-scale system, substantially redefined the manufacturability while remaining compatible with Grace Blackwell. Our supply chain data center ecosystem and cloud partners have now mastered the build-to-installation process of NVIDIA's rack architecture. Our ecosystem will be ready for a fast Rubin ramp. Our annual X-factor performance leap increases performance per dollar while driving down computing costs for our customers. The long useful life of NVIDIA's CUDA GPUs is a significant TCO advantage over accelerators. CUDA's compatibility and our massive installed base extend the life of NVIDIA systems well beyond their original estimated useful life. For more than two decades, we have optimized the CUDA ecosystem, improving existing workloads, accelerating new ones, and increasing throughput with every software release.\n\n**Colette Kress** (EVP and CFO)\nMost accelerators without CUDA and NVIDIA's time-tested and versatile architecture became obsolete within a few years as model technologies evolve. Thanks to CUDA, the A100 GPUs we shipped six years ago are still running at full utilization today, powered by vastly improved software stack. We have evolved over the past 25 years from a gaming GPU company to now an AI data center infrastructure company. Our ability to innovate across the CPU, the GPU, networking, and software, and ultimately drive down cost per token, is unmatched across the industry. Our networking business, purpose-built for AI and now the largest in the world, generated revenue of $8.2 billion, up 162% year over year, with NVLink, InfiniBand, and Spectrum X Ethernet all contributing to growth. We are winning in data center networking as the majority of AI deployments now include our switches with Ethernet GPU attach rates roughly on par with InfiniBand.\n\n**Colette Kress** (EVP and CFO)\nMeta, Microsoft, Oracle, and xAI are building gigawatt AI factories with Spectrum X Ethernet switches, and each will run its operating system of choice, highlighting the flexibility and openness of our platform. We recently introduced Spectrum XGS, a scale-across technology that enables gigascale AI factories. NVIDIA is the only company with AI scale-up, scale-out, and scale-across platforms, reinforcing our unique position in the market as the AI infrastructure provider. Customer interest in NVLink Fusion continues to grow. We announced a strategic collaboration with Fujitsu in October, where we will integrate Fujitsu's CPUs and NVIDIA GPUs via NVLink Fusion, connecting our large ecosystems. We also announced a collaboration with Intel to develop multiple generations of custom data center and PC products, connecting NVIDIA and Intel's ecosystems using NVLink.\n\n**Colette Kress** (EVP and CFO)\nThis week at Supercomputing 25, Arm announced that it will be integrating NVLink IP for customers to build CPU SoCs that connect with NVIDIA. Currently on its fifth generation, NVLink is the only proven scale-up technology available on the market today. In the latest MLPerf training results, Blackwell Ultra delivered 5x faster time to train than Hopper. NVIDIA swept every benchmark. Notably, NVIDIA is the only training platform to leverage bridge FP4 while meeting MLPerf's strict accuracy standards. In semi-analysis inference max benchmark, Blackwell achieved the highest performance and lowest total cost of ownership across every model and use case. Particularly important is Blackwell's NVLink's performance on a mixture of experts, the architecture for the world's most popular reasoning models. On DeepSeek R1, Blackwell delivered 10x higher performance per watt and 10x lower cost per token versus H200, a huge generational leap fueled by our extreme code design approach.\n\n**Colette Kress** (EVP and CFO)\nNVIDIA Dynamo, an open-source, low-latency modular inference framework, has now been adopted by every major cloud service provider. Leveraging Dynamo's enablement and disaggregated inference, the resulting increase in performance of complex AI models such as MOE models, AWS, Google Cloud, Microsoft Azure, and OCI have boosted AI inference performance for enterprise cloud customers. We are working on a strategic partnership with OpenAI focused on helping them build and deploy at least 10 gigawatts of AI data centers. In addition, we have the opportunity to invest in the company. We serve OpenAI through their cloud partners, Microsoft Azure, OCI, and CoreWeave. We will continue to do so for the foreseeable future. As they continue to scale, we are delighted to support the company to add self-build infrastructure, and we are working toward a definitive agreement and are excited to support OpenAI's growth. Yesterday, we celebrated an announcement with Anthropic.\n\n**Colette Kress** (EVP and CFO)\nFor the first time, Anthropic is adopting NVIDIA, and we are establishing a deep technology partnership to support Anthropic's fast growth. We will collaborate to optimize Anthropic models for CUDA and deliver the best possible performance, efficiency, and TCO. We will also optimize future NVIDIA architectures for Anthropic workloads. Anthropic's compute commitment is initially including up to 1 gigawatt of compute capacity with Grace Blackwell and Vera Rubin systems. Our strategic investments in Anthropic, Mistral, OpenAI, Reflection, Thinking Machines, and others represent partnerships that grow the NVIDIA CUDA AI ecosystem and enable every model to run optimally on NVIDIA's everywhere. We will continue to invest strategically while preserving our disciplined approach to cash flow management. Physical AI is already a multi-billion dollar business addressing a multi-trillion dollar opportunity and the next leg of growth for NVIDIA. Leading U.S.\n\n**Colette Kress** (EVP and CFO)\nManufacturers and robotics innovators are leveraging NVIDIA's three-computer architecture to train on NVIDIA, test on Omniverse computer, and deploy real-world AI on Jetson robotic computers. PTC and Siemens introduced new services that bring Omniverse-powered digital twin workflows to their extensive installed base of customers. Companies including Belden, Caterpillar, Foxconn, Lucid Motors, Toyota, TSMC, and Wistron are building Omniverse digital twin factories to accelerate AI-driven manufacturing and automation. Agility Robotics, Amazon Robotics, Figure, and Skilled at AI are building our platform, tapping offerings such as NVIDIA Cosmos World Foundation models for development, Omniverse for simulation and validation, and Jetson to power next-generation intelligent robots. We remain focused on building resiliency and redundancy in our global supply chain. Last month, in partnership with TSMC, we celebrated the first Blackwell wafer produced on U.S. soil.\n\n**Colette Kress** (EVP and CFO)\nWe will continue to work with Foxconn, Wistron, Amcor, Spill, and others to grow our presence in the U.S. over the next four years. Gaming revenue was $4.3 billion, up 30% year-on-year, driven by strong demand as Blackwell momentum continued. End-market sell-through remains robust, and channel inventories are at normal levels heading into the holiday season. Steam recently broke its concurrent user record with 42 million gamers, while thousands of fans packed the GeForce Gamer Festival in South Korea to celebrate 25 years of GeForce. NVIDIA Pro Visualization has evolved into computers for engineers and developers, whether for graphics or for AI. Professional visualization revenue was $760 million, up 56% year-over-year, was another record. Growth was driven by DGX Spark, the world's smallest AI supercomputer built on a small configuration of Grace Blackwell. Automotive revenue was $592 million, up 32% year-over-year, primarily driven by self-driving solutions.\n\n**Colette Kress** (EVP and CFO)\nWe are partnering with Uber to scale the world's largest Level 4 ready autonomous fleet, built on the new NVIDIA Hyperion L4 Robotaxi reference architecture. Moving to the rest of the P&L, GAAP gross margins were 73.4%, and non-GAAP gross margins were 73.6%, exceeding our outlook. Gross margins increased sequentially due to our data center mix, improved cycle time, and cost structure. GAAP operating expenses were up 8% sequentially and up 11% on a non-GAAP basis. The growth was driven by infrastructure compute as well as higher compensation and benefits in engineering development costs. Non-GAAP effective tax rate for the third quarter was just over 17%, higher than our guidance of 16.5% due to the strong U.S. revenue. On our balance sheet, inventory grew 32% quarter over quarter, while supply commitments increased 63% sequentially.\n\n**Colette Kress** (EVP and CFO)\nWe are preparing for significant growth ahead and feel good about our ability to execute against our opportunity set. Okay, let me turn to the outlook for the fourth quarter. Total revenue is expected to be $65 billion, plus or minus 2%. At the midpoint, our outlook implies 14% sequential growth driven by continued momentum in the Blackwell architecture. Consistent with last quarter, we are not assuming any data center compute revenue from China. GAAP and non-GAAP gross margins are expected to be 74.8% and 75% respectively, plus or minus 50 basis points. Looking ahead to fiscal year 2027, input costs are on the rise, but we are working to hold gross margins in the mid-70s. GAAP and non-GAAP operating expenses are expected to be approximately $6.7 billion and $5 billion respectively.\n\n**Colette Kress** (EVP and CFO)\nGAAP and non-GAAP other income and expenses are expected to be an income of approximately $500 million, excluding gains and losses from non-marketable and publicly held equity securities. GAAP and non-GAAP tax rates are expected to be 17%, plus or minus 1%, excluding any discrete items. At this time, let me turn the call over to Jensen for him to say a few words.\n\n**Jensen Huang** (President and CEO)\nThanks, Colette. There has been a lot of talk about an AI bubble. From our vantage point, we see something very different. As a reminder, NVIDIA is unlike any other accelerator. We excel at every phase of AI, from pre-training and post-training to inference. With our two-decade investment in CUDA X acceleration libraries, we are also exceptional at science and engineering simulations, computer graphics, structured data processing to classical machine learning.\n\n**Jensen Huang** (President and CEO)\nThe world is undergoing three massive platform shifts at once, the first time since the dawn of Moore's Law. NVIDIA is uniquely addressing each of the three transformations. The first transition is from CPU general-purpose computing to GPU accelerated computing as Moore's Law slows. The world has a massive investment in non-AI software, from data processing to science and engineering simulations, representing hundreds of billions of dollars in compute cloud computing spend each year. Many of these applications, which ran once exclusively on CPUs, are now rapidly shifting to CUDA GPUs. Accelerated computing has reached a tipping point. Secondly, AI has also reached a tipping point and is transforming existing applications while enabling entirely new ones. For existing applications, generative AI is replacing classical machine learning in search ranking, recommender systems, ad targeting, click-through prediction to content moderation, the very foundations of hyperscale infrastructure.\n\n**Jensen Huang** (President and CEO)\nMeta's Gem, a foundation model for ad recommendations trained on large-scale GPU clusters, exemplifies this shift. In Q2, Meta reported over a 5% increase in ad conversions on Instagram and 3% gain on Facebook feed, driven by generative AI-based Gem. Transitioning to generative AI represents substantial revenue gains for hyperscalers. Now, a new wave is rising: agentic AI systems capable of reasoning, planning, and using tools. From coding assistants like Cursor and Claude Code to radiology tools like iDoc, legal assistants like Harvey, and AI chauffeurs like Tesla FSD and Waymo, these systems mark the next frontier of computing. The fastest-growing companies in the world todayOpenAI, Anthropic, xAI, Google, Cursor, Lovable, Replet, Cognition AI, Open Evidence, Abridge, Teslaare pioneering agentic AI. There are three massive platform shifts. The transition to accelerated computing is foundational and necessary, essential in a post-Moore's Law era.\n\n**Jensen Huang** (President and CEO)\nThe transition to generative AI is transformational and necessary, supercharging existing applications and business models. The transition to agentic and physical AI will be revolutionary, giving rise to new applications, companies, products, and services. As you consider infrastructure investments, consider these three fundamental dynamics. Each will contribute to infrastructure growth in the coming years. NVIDIA is chosen because our singular architecture enables all three transitions, and thus so for any form and modality of AI across all industries, across every phase of AI, across all of the diverse computing needs in a cloud, and also from cloud to enterprise to robots. One architecture. Toshiya, back to you.\n\n**Toshiya Hari** (VP of Investor Relations)\nWe will now open the call for questions.\n\n**Operator**\nOperator, would you please pull for questions? Thank you. At this time, I would like to remind everyone in order to ask a question, press star, then the number one on your telephone keypad.\n\n**Operator**\nWe'll pause for just a moment to compile the Q&A roster. As a reminder, please limit yourself to one question. Thank you. Your first question comes from Joseph Moore with Morgan Stanley. Your line is open.\n\n**Joseph Moore** (Semiconductor Industry Analyst)\nGreat. Thank you. I wonder if you could update us. You talked about the $500 billion of revenue for Blackwell plus Rubin in 2025 and 2026 at GTC. At that time, you had talked about $150 billion of that already having been shipped. As the quarter's wrapped up, are those still kind of the general parameters that there's $350 billion in the next kind of 14 months or so? I would assume over that time, you haven't seen all the demand, but there is any possibility of upside to those numbers as we move forward.\n\n**Colette Kress** (EVP and CFO)\nYeah. Thanks, Joe. I'll start first with a response here on that. Yes, that's correct.\n\n**Colette Kress** (EVP and CFO)\nWe are working into our $500 billion forecast, and we are on track for that as we have finished some of the quarters. We have several quarters now in front of us to take us through the end of calendar year 2026. The number will grow, and we will achieve, I'm sure, additional needs for compute that will be shippable by fiscal year 2026. We shipped $50 billion this quarter, but we would be not finished if we did not say that we will probably be taking more orders. For example, just even today, our announcements with KSA and that agreement in itself is 400,000-600,000 more GPUs over three years. Anthropic is also not new. There is definitely an opportunity for us to have more on top of the $500 billion that we announced.\n\n**Operator**\nThe next question comes from C.J. Muse with Cantor Fitzgerald.\n\n**Operator**\nYour line is open.\n\n**CJ Muse** (Senior Managing Director)\nYeah. Good afternoon. Thank you for taking the question. There's clearly a great deal of consternation around the magnitude of AI infrastructure buildouts and the ability to fund such plans and the ROI. Yet at the same time, you're talking about being sold out. Every stood-up GPU is taken. The AI world hasn't seen the enormous benefit yet from B300, never mind Rubin. Gemini 3 just announced Grok 5 coming soon. The question is this: when you look at that as the backdrop, do you see a realistic path for supply to catch up with demand over the next 12 to 18 months, or do you think it can extend beyond that timeframe?\n\n**Jensen Huang** (President and CEO)\nAs you know, we've done a really good job planning our supply chain. NVIDIA's supply chain basically includes every technology company in the world.\n\n**Jensen Huang** (President and CEO)\nTSMC and their packaging and our memory vendors and memory partners and all of our system ODMs have done a really good job planning with us. We were planning for a big year. We've seen for some time the three transitions that I spoke about just a second ago: accelerated computing from general-purpose computing. It's really important to recognize that AI is not just agentic AI, but generative AI is transforming the way that hyperscalers did the work that they used to do on CPUs. Generative AI made it possible for them to move search and recommender systems and add recommendations and targeting. All of that has been moved to generative AI and is still transitioning.\n\n**Jensen Huang** (President and CEO)\nWhether you installed NVIDIA GPUs for data processing, or you did it for generative AI for your recommender system, or you're building it for agentic chatbots and the type of AIs that most people see when they think about AI, all of those applications are accelerated by NVIDIA. When you look at the totality of the spend, it's really important to think about each one of those layers. They're all growing. They're related, but not the same. The wonderful thing is that they all run on NVIDIA GPUs. Simultaneously, because the quality of the AI models are improving so incredibly, the adoption of it in the different use cases, whether it's in code assistance, which NVIDIA uses fairly exhaustively, and we're not the only one.\n\n**Jensen Huang** (President and CEO)\nI mean, the fastest-growing application in history, a combination of Cursor and Claude Code and OpenAI's Codex and GitHub Copilot, these applications are the fastest-growing in history. It's not just used for software engineers. It's used because of vibe coding. It's used by engineers and marketeers all over companies, supply chain planners all over companies. I think that that's just one example, and the list goes on, whether it's open evidence and the work that they do in healthcare or the work that's being done in digital video editing, runway. I mean, the number of really, really exciting startups that are taking advantage of generative AI and agentic AI is growing quite rapidly. Not to mention, we're all using it a lot more.\n\n**Jensen Huang** (President and CEO)\nAll of these exponentials, not to mention, just today, I was reading a text from Demis, and he was saying that pre-training and post-training are fully intact. Gemini 3 takes advantage of the scaling laws and got a received a huge jump in quality performance and model performance. We are seeing all of these exponentials kind of running at the same time. I just always go back to first principles and think about what's happening from each one of the dynamics that I mentioned before: general-purpose computing to accelerated computing, generative AI replacing classical machine learning, and of course, agentic AI, which is a brand new category.\n\n**Operator**\nThe next question comes from Vivek Aria with Bank of America Securities. Your line is open.\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nThanks for taking my question. I'm curious, what assumptions are you making on NVIDIA content per gigawatt in that $500 billion number?\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nBecause we have heard numbers as low as $25 billion per gigawatt of content to as high as $30 or $40 billion per gigawatt. I am curious what power and what dollar per gigawatt assumptions you are making as part of that $500 billion number. Longer-term, Jensen, the $3 to $4 trillion in data center by 2030 was mentioned. How much of that do you think will require vendor financing, and how much of that can be supported by cash flows of your large customers or governments or enterprises? Thank you.\n\n**Jensen Huang** (President and CEO)\nIn each generation, from Ampere to Hopper, from Hopper to Blackwell, Blackwell to Rubin, our part of the data center increases. Hopper generation was probably something along the lines of 20-somewhat, 20-25. Blackwell generation, Grace Blackwell particularly, is probably 30-30, say 30 plus or minus.\n\n**Jensen Huang** (President and CEO)\nRubin is probably higher than that. In each one of these generations, the speedup is X factors. Therefore, their TCO, the customer TCO, improves by X factors. The most important thing is, in the end, you still only have one gigawatt of power, one gigawatt data centers, one gigawatt of power. Therefore, performance per watt, the efficiency of your architecture, is incredibly important. The efficiency of your architecture can't be brute forced. There is no brute forcing about it. That one gigawatt translates directly, your performance per watt translates directly, absolutely directly to your revenues, which is the reason why choosing the right architecture matters so much now. The world doesn't have an excess of anything to squander.\n\n**Jensen Huang** (President and CEO)\nWe have to be really, reallywe use this concept called co-design across our entire stack, across the frameworks and models, across the entire data center, even power and cooling optimized across the entire supply chain in our ecosystem. Each generation, our economic contribution will be greater. Our value delivered will be greater. The most important thing is our energy efficiency per watt is going to be extraordinary every single generation. With respect to growing into continuing to grow, our customers' financing is up to them. We see the opportunity to grow for quite some time. Remember, today, most of the focus has been on the hyperscalers. One of the areas that is really misunderstood about the hyperscalers is that the investment on NVIDIA GPUs not only improves their scale, speed, and cost from general-purpose computingthat is number onebecause Moore's Law scaling has really slowed.\n\n**Jensen Huang** (President and CEO)\nMoore's Law is about driving cost down. It's about deflationary cost, the incredible deflationary cost of computing over time. That has slowed. Therefore, a new approach is necessary for them to keep driving the cost down. Going to NVIDIA GPU computing is really the best way to do so. The second is revenue boosting in their current business models. Recommender systems drive the world's hyperscalers every single, whether it's watching short-form videos or recommending books or recommending the next item in your basket to recommending ads to recommending news toit's all about recommenders. The internet has trillions of pieces of content. How could they possibly figure out what to put in front of you and your little tiny screen unless they have really sophisticated recommender systems to do so? That has gone generative AI.\n\n**Jensen Huang** (President and CEO)\nThe first two things that I've just said, hundreds of billions of dollars of CapEx is going to have to be invested, is fully cash flow funded. What is above it, therefore, is agentic AI. This is net new, net new consumption, but it's also net new applications. And some of the applications I mentioned before, but these new applications are also the fastest-growing applications in history. Okay? I think that you're going to see that once people start to appreciate what is actually happening under the water, if you will, from the simplistic view of what's happening to CapEx investment, recognizing there's these three dynamics. Lastly, remember, we were just talking about the American CSPs. Each country will fund their own infrastructure. You have multiple countries. You have multiple industries.\n\n**Jensen Huang** (President and CEO)\nMost of the world's industries haven't really engaged agentic AI yet, and they're about to. All the names of companies that you know we're working with, whether it's autonomous vehicle companies or digital twins for physical AI for factories and the number of factories and warehouses being built around the world, just the number of digital biology startups that are being funded so that we could accelerate drug discovery. All of those different industries are now getting engaged, and they're going to do their own fundraising. Do not just look at the hyperscalers as a way to build out for the future. You got to look at the world. You got to look at all the different industries. Enterprise computing is going to fund their own industry.\n\n**Operator**\nThe next question comes from Ben Ritzes with Melius. Your line is open.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nHey, thanks a lot.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nJensen, I wanted to ask you about cash. Speaking of half a trillion, you may generate about half a trillion in free cash flow over the next couple of years. What are your plans for that cash? How much goes to buyback versus investing in the ecosystem? How do you look at investing in the ecosystem? I think there's just a lot of confusion out there about how these deals work and your criteria for doing those, like the Anthropic, the OpenAIs, etc. Thanks a lot.\n\n**Jensen Huang** (President and CEO)\nYeah, appreciate the question. Of course, using cash to fund our growth, no company has grown at the scale that we're talking about and have the connection and the depth and the breadth of supply chain that NVIDIA has.\n\n**Jensen Huang** (President and CEO)\nThe reason why our entire customer base can rely on us is because we've secured a really resilient supply chain, and we have the balance sheet to support them. When we make purchases, our suppliers can take it to the bank. When we make forecasts and we plan with them, they take us seriously because of our balance sheet. We're not making up the offtake. We know what our offtake is. Because they've been planning with us for so many years, our reputation and our credibility is incredible. It takes really strong balance sheet to do that, to support the level of growth and the rate of growth and the magnitude associated with that. That's number one. The second thing, of course, we're going to continue to do stock buybacks. We're going to continue to do that.\n\n**Jensen Huang** (President and CEO)\nWith respect to the investments, this is really, really important work that we do. All of the investments that we've done so far, well, all the period, is associated with expanding the reach of CUDA, expanding the ecosystem. If you look at the work, the investments that we did with OpenAI, it's, of course, that relationship we've had since 2016. I delivered the first AI supercomputer ever made to OpenAI. We have had a close and wonderful relationship with OpenAI since then. Everything that OpenAI does runs on NVIDIA today. All the clouds that they deploy in, whether it's training and inference, runs NVIDIA, and we love working with them. The partnership that we have with them is one so that we could work even deeper from a technical perspective so that we could support their accelerated growth. This is a company that's growing incredibly fast.\n\n**Jensen Huang** (President and CEO)\nDo not just look at what is said in the press. Look at all the ecosystem partners and all the developers that are connected to OpenAI. They are all driving consumption of it. The quality of the AI that is being produced is a huge step up since a year ago. The quality of response is extraordinary. We invest in OpenAI for a deep partnership in co-development to expand our ecosystem and to support their growth. Of course, rather than giving up a share of our company, we get a share of their company. We invested in them in one of the most consequential once-in-a-generation companies, once-in-a-generation company that we have a share of. I fully expect that investment to translate to extraordinary returns. Now, in the case of Anthropic, this is the first time that Anthropic will be on NVIDIA's architecture.\n\n**Jensen Huang** (President and CEO)\nThe first time Anthropic will be on NVIDIA's architecture is the second most successful AI in the world in terms of total number of users. In enterprise, they're doing incredibly well. Claude Code is doing incredibly well. Claude is doing incredibly well all over the world's enterprise. Now we have the opportunity to have a deep partnership with them and bringing Claude onto the NVIDIA platform. What do we have now? NVIDIA's architecture, taking a step back, NVIDIA's architecture, NVIDIA's platform is the singular platform in the world that runs every AI model. We run OpenAI. We run Anthropic. We run xAI because of our deep partnership with Elon and xAI. We were able to bring that opportunity to Saudi Arabia, to the KSA, so that Humane could also be hosting opportunity for xAI. We run xAI. We run Gemini. We run Thinking Machines.\n\n**Jensen Huang** (President and CEO)\nLet's see, what else do we run? We run them all. Not to mention, we run the science models, the biology models, DNA models, gene models, chemical models, and all the different fields around the world. It's not just cognitive AI that the world uses. AI is impacting every single industry. We have the ability, through the ecosystem investments that we make, to partner with, deeply partner on a technical basis with some of the best companies, most brilliant companies in the world. We are expanding the reach of our ecosystem, and we're getting a share and investment in what will be a very successful company, oftentimes once-in-a-generation company. That's our investment thesis.\n\n**Operator**\nThe next question comes from Jim Schneider with Goldman Sachs. Your line is open.\n\n**Jim Schneider** (Senior Equity Analyst)\nGood afternoon. Thanks for taking my question.\n\n**Jim Schneider** (Senior Equity Analyst)\nIn the past, you've talked about roughly 40% of your shipments tied to AI inference. I'm wondering, as you look forward into next year, where do you expect that percentage could go in, say, a year's time? Can you maybe address the Rubin CPX product you expect to introduce next year and contextualize that? How big of the overall TAM you expect that can take and maybe talk about some of the target customer applications for that specific product? Thank you.\n\n**Jensen Huang** (President and CEO)\nCPX is designed for long-context type of workload generation. Long-context, basically, before you start generating answers, you have to read a lot, basically long-context. It could be a bunch of PDFs. It could be watching a bunch of videos, studying 3D images, so on and so forth. You have to absorb the context. CPX is designed for long-context type of workloads.\n\n**Jensen Huang** (President and CEO)\nIt's perf per dollars. Its perf per dollar is excellent. Its perf per watt is excellent. Which made me forget the first part of the question. Inferencing. Oh, inference. Yeah. There are three scaling laws that are scaling at the same time. The first scaling law called pretraining continues to be very effective. And the second is post-training. Post-training basically has found incredible algorithms for improving an AI's ability to break a problem down and solve a problem step by step. And post-training is scaling exponentially. Basically, the more compute you apply to a model, the smarter it is, the more intelligent it is. And then the third is inference. Inference, because of chain of thought, because of reasoning capabilities, AIs are essentially reading, thinking before it answers. The amount of computation necessary as a result of those three things has gone completely exponential.\n\n**Jensen Huang** (President and CEO)\nI think that it's hard to know exactly what the percentage will be at any given point in time and who. Of course, our hope is that inference is a very large part of the market. If inference is large, then what it suggests is that people are using it in more applications, and they're using it more frequently. We should all hope for inference to be very large. This is where Grace Blackwell is just an order of magnitude better, more advanced than anything in the world. The second best platform is H200. It's very clear now that GB300, GB200, and GB300, because of NVLink 72, the scale-up network that we have achieved, and you saw and Colette talked about in the semi-analysis benchmark, it's the largest single inference benchmark ever done.\n\n**Jensen Huang** (President and CEO)\nGB200, NVLink 72, is 10 times, 10-15 times higher performance. That is a big step up. It is going to take a long time before somebody is able to take that on. Our leadership there is surely multi-year. Yeah. I think I am hoping that inference becomes a very big deal. Our leadership in inference is extraordinary. The next question comes from Timothy Arcury with UBS. Your line is open. Thanks a lot. Jensen, many of your customers are pursuing behind-the-meter power. What is the single biggest bottleneck that worries you that could constrain your growth? Is it power, or maybe it is financing, or maybe it is something else like memory or even foundry? Thanks a lot. These are all issues, and they are all constraints.\n\n**Jensen Huang** (President and CEO)\nThe reason for that, when you're growing at the rate that we are and the scale that we are, how could anything be easy? What NVIDIA is doing, obviously, has never been done before. We have created a whole new industry. On the one hand, we are transitioning computing from general-purpose and classical or traditional computing to accelerated computing and AI. That's on the one hand. On the other hand, we created a whole new industry called AI factories. The idea that in order for software to run, you need these factories to generate it, generate every single token instead of retrieving information that was pre-created. I think this whole transition requires extraordinary scale. All the way from the supply chain, of course, the supply chain, we have much better visibility and control over it because, obviously, we're incredibly good at managing our supply chain.\n\n**Jensen Huang** (President and CEO)\nWe have great partners that we've worked with for 33 years. The supply chain part of it, we're quite confident. Now, looking down our supply chain, we've now established partnerships with so many players in land and power and shell and, of course, financing. None of these things are easy, but they're all tractable, and they're all solvable things. The most important thing that we have to do is do a good job planning. We plan up the supply chain, down the supply chain. We have established a whole lot of partners. We have a lot of routes to market. Very importantly, our architecture has to deliver the best value to the customers that we have. At this point, I'm very confident that NVIDIA's architecture is the best performance per TCO.\n\n**Jensen Huang** (President and CEO)\nIt is the best performance per watt, and therefore, for any amount of energy that is delivered, our architecture will drive the most revenues. I think the increasing rate of our success, I think that we're more successful this year at this point than we were last year at this point. The number of customers coming to us and the number of platforms coming to us after they've explored others is increasing, not decreasing. I think all of that is just all the things that I've been telling you over the years are really coming true and are becoming evident.\n\n**Operator**\nThe next question comes from Stacey Raskin with Bernstein Research. Your line is open.\n\n**Stacy Rasgon** (Senior Analyst)\nQuestions. Colette, I have some questions on margins. You said for next year, you're working to hold them in the mid-70s. I guess, first of all, what are the biggest cost increases?\n\n**Stacy Rasgon** (Senior Analyst)\nIs it just memory, or is it something else? What are you doing to work toward that? How much is cost optimizations versus pre-buys versus pricing? Also, how should we think about OpEx growth next year, given the revenues seem likely to grow materially from where we're running right now?\n\n**Colette Kress** (EVP and CFO)\nThanks, Stacey. Let me see if I can start with remembering where we were with the current fiscal year that we're in. Remember, earlier this year, we indicated that through cost improvements and mix that we would exit the year and our gross margins in the mid-70s. We've achieved that and getting ready to also execute that in Q4. Now it's time for us to communicate where are we working right now in terms of next year. Next year, there are input prices that are well-known in the industries that we need to work through.\n\n**Colette Kress** (EVP and CFO)\nOur systems are by no means very easy to work with. There are a tremendous amount of components, many different parts of it, as we think about that. We are taking all of that into account. We do believe, as we look at working again on cost improvements, cycle time, and mix, that we will work to try and hold at our gross margins in the mid-70%. That is our overall plan for gross margin. Your second question is around OpEx. Right now, our goal in terms of OpEx is to really make sure that we are innovating with our engineering teams, with all of our business teams to create more and more systems for this market. As you know, right now, we have a new architecture coming out. That means they are quite busy in order to meet that goal.\n\n**Colette Kress** (EVP and CFO)\nWe're going to continue to see our investments on innovating more and more, both our software, both our systems, and our hardware to do so. I'll leave it turned to Jensen if he wants to add any couple more comments.\n\n**Jensen Huang** (President and CEO)\nYeah. That's spot on. I think the only thing that I would add is remember that we plan, we forecast, we plan, and we negotiate with our supply chain well in advance. Our supply chain has known for quite a long time our requirements. And they've known for quite a long time our demand. We've been working with them and negotiating with them for quite a long time. I think the recent surge, obviously, quite significant. Remember, our supply chain has been working with us for a very long time.\n\n**Jensen Huang** (President and CEO)\nIn many cases, we've secured a lot of supply for ourselves because, obviously, they're working with the largest company in the world in doing so. We've also been working closely with them on the financial aspects of it and securing forecasts and plans and so on and so forth. I think all of that has worked out well for us.\n\n**Operator**\nYour final question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.\n\n**Aaron Rakers** (Wall Street Analyst)\nYeah. Thanks for taking the question. Jensen, the question for you, as you think about the Anthropic deal that was announced and just the overall breadth of your customers, I'm curious if your thoughts around the role that AI ASICs or dedicated XPUs play in these architecture buildouts has changed at all. Have you seen?\n\n**Aaron Rakers** (Wall Street Analyst)\nI think you've been fairly adamant in the past that some of these programs never really see deployments. I'm curious if we're at a point where maybe that's even changed more in favor of just GPU architecture. Thank you.\n\n**Jensen Huang** (President and CEO)\nThank you very much. I really appreciate the question. First of all, you're not competing against teams. Excuse me. Again, as a company, you're competing against teams. There just aren't that many teams in the world who are extraordinary at building these incredibly complicated things. Back in the Hopper day and the Ampere days, we would build one GPU. That's the definition of an accelerated AI system. Today, we've got to build entire racks, entire three different types of switches: a scale-up, a scale-out, and a scale-across switch. It takes a lot more than one chip to build a compute node anymore.\n\n**Jensen Huang** (President and CEO)\nEverything about that computing system, because AI needs to have memory, AI didn't used to have memory at all. Now it has to remember things. The amount of memory and context it has is gigantic. The memory architecture implication is incredible. The diversity of models from a mixture of experts to dense models to diffusion models to autoregressive, not to mention biological models that obey the laws of physics. The list of different types of models has exploded in the last several years. The challenge is the complexity of the problem is much higher. The diversity of AI models is incredibly large. This is where, if I will say, the five things that make us special, if you will. The first thing I would say that makes us special is that we accelerate every phase of that transition. That's the first phase.\n\n**Jensen Huang** (President and CEO)\nThat CUDA allows us to have CUDA X for transitioning from general-purpose to accelerated computing. We are incredibly good at generative AI. We're incredibly good at agentic AI. Every single phase of that, every single layer of that transition, we are excellent at. You can invest in one architecture, use it across the board. You can use one architecture and not worry about the changes in the workload across those three phases. That's number one. Number two, we're excellent at every phase of AI. Everybody's always known that we're incredibly good at pretraining. We're obviously very good at post-training. And we're incredibly good, as it turns out, at inference because inference is really, really hard. How could thinking be easy? People think that inference is one shot, and therefore, it's easy. Anybody could approach the market that way.\n\n**Jensen Huang** (President and CEO)\nBut it turns out to be the hardest of all because thinking, as it turns out, is quite hard. We're great at every phase of AI, the second thing. The third thing is we're now the only architecture in the world that runs every AI model, every frontier AI model. We run open-source AI models incredibly well. We run science models, biology models, robotics models. We run every single model. We're the only architecture in the world that can claim that. It doesn't matter whether you're autoregressive or diffusion-based. We run everything. We run it for every major platform, as I just mentioned. We run every model. The fourth thing I would say is that we're in every cloud. The reason why developers love us is because we're literally everywhere. We're in every cloud.\n\n**Jensen Huang** (President and CEO)\nWe're in everywe could even make you a little tiny cloud called DGX Spark. We're in every computer. We're everywhere, from cloud to on-prem to robotic systems, edge devices, PCs, you name it. One architecture, things just work. It's incredible. The last thing, and this is probably the most important thing, the fifth thing, is if you are a cloud service provider, if you're a new company like Humane, if you're a new company like CoreWeave or NSCALE or Nevius, or OCI for that matter, the reason why NVIDIA is the best platform for you is because our offtake is so diverse. We can help you with offtake. It's not about just putting a random ASIC into a data center. Where's the offtake coming from? Where's the diversity coming from? Where's the resilience coming from?\n\n**Jensen Huang** (President and CEO)\nThe versatility of the architecture coming from, the diversity of capability coming from. NVIDIA has such incredibly good offtake because our ecosystem is so large. So these five things, every phase of acceleration and transition, every phase of AI, every model, every cloud to on-prem, and of course, finally, it all leads to offtake.\n\n**Operator**\nThank you. I will now turn the call to Toshiya Hari for closing remarks.\n\n**Toshiya Hari** (VP of Investor Relations)\nIn closing, please note we will be at the UBS Global Technology and AI Conference on December 2nd. And our earnings call to discuss the results of our fourth quarter of fiscal 2026 is scheduled for February 25th. Thank you for joining us today. Operator, please go ahead and close the call.\n\n**Operator**\nThank you. This concludes today's conference call. You may now disconnect.",
        "fetched_at": "2026-02-04T16:11:27.932Z"
      },
      {
        "ticker": "NVDA",
        "title": "Yahoo Finance",
        "published_date": "Aug 27, 2025, 5:00 PM EDT",
        "fiscal_year": "2026",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/NVDA/earnings/NVDA-Q2-2026-earnings_call-351238.html",
        "content": "**Operator**\nGood afternoon. My name is Sarah, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's Second Quarter Fiscal twenty twenty six Financial Results Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there will be a question and answer session. You. Toshiya Hari, you may begin your conference.\n\n**Toshiya Hari** (VP - IR &amp; Strategic Finance)\nThank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the 2026. With me today from NVIDIA are Jensen Huang, president and chief executive officer, and Colette Kress, executive vice president and chief financial officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the 2026.\n\n**Toshiya Hari** (VP - IR &amp; Strategic Finance)\nThe content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10 k and 10 Q, and the reports that we may file on Form eight ks with the Securities and Exchange Commission.\n\n**Toshiya Hari** (VP - IR &amp; Strategic Finance)\nAll our statements are made as of today, 08/27/2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non GAAP financial measures. You can find a reconciliation of these non GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\n\n**Colette Kress** (EVP &amp; CFO)\nThank you, Toshiya. We delivered another record quarter while navigating what continues to be a dynamic external environment. Total revenue was 46,700,000,000.0, exceeded our outlook as we grew sequentially across all market platforms. Data center revenue grew 56% year over year. Data center revenue also grew sequentially despite the 4,000,000,000 decline in h '20 revenue.\n\n**Colette Kress** (EVP &amp; CFO)\nNVIDIA's Blackwell platform reached record levels, growing sequentially by 17%. We began production shipments of GB 300 in q two. Our full stack AI solutions for cloud service providers, neo clouds, enterprises, and sovereigns are all contributing to our growth. We are at the beginning of an industrial revolution that will transform every industry. We see 3 to $4,000,000,000,000 in AI infrastructure spend in the by the end of the decade.\n\n**Colette Kress** (EVP &amp; CFO)\nThe scale and scope of these build outs present significant long term growth opportunities for NVIDIA. The g b 200 NBL system is seeing widespread adoption with deployments at CSPs and consumer Internet companies, Lighthouse model builders, including OpenAI, Meta, and Mastral are using the g b 200 NBL 72 at data center scale for both training next generation models and serving inference models in production. The new Blackwell Ultra platform has also had a strong quarter, generating tens of billions in revenue. The transition to the g b 300 has been seamless for major cloud service providers due to its shared architecture, software, and physical footprint with the g b 200, enabling them to build and deploy g b 300 racks with ease. The transition to the new g b 300 rack based architecture has been seamless.\n\n**Colette Kress** (EVP &amp; CFO)\nFactory builds in late July and early August were successfully converted to support the g b 300 ramp. And today, full production is underway. The current run rate is back at full speed, producing approximately 1,000 racks per week. This output is expected to accelerate even further throughout the third quarter as additional capacity comes online. We expect widespread market availability in the second half of the year as CoreWeave prepares to bring their g v 300 instance to market as they are already seeing 10x more inference performance on reasoning models compared to h 100.\n\n**Colette Kress** (EVP &amp; CFO)\nCompared to the previous hopper generation, g v 300 and d l 72 AI factories promise a 10 x improvement in token per watt energy efficiency, which translates to revenues as data centers are power limited. The chips of the Rubin platform are in fab. The Vera CPU, Rubin GPU, c x nine Super NIC, NVLink one forty four scale up switch, Spectrum X scale out and scale across switch, and the silicon photonics processor. Rubin remains on schedule for volume production next year. Rubin will be our third generation NVLink RackScale AI supercomputer with a mature and full scale supply chain.\n\n**Colette Kress** (EVP &amp; CFO)\nThis keeps us on track with our pace of an annual product cadence and continuous innovation across compute, networking, systems, and software. In late July, the US government began reviewing licenses for sales of h 20 to China customers. While a select number of our China based customers have received licenses over the past few weeks, we have not shipped any h 20 based on those licenses. USG officials have expressed an expectation that the USG will receive 15% of the revenue generated from licensed h 20 sales. But to date, the USG has not published a regulation codifying such requirement.\n\n**Colette Kress** (EVP &amp; CFO)\nWe have not included h 20 in our q three outlook as we continue to work through geopolitical issues. If geopolitical issues reside, we should ship $2,000,000,000 to $5,000,000,000 in h twenty revenue in q three. And if we add more orders, we can bill more. We continue to advocate for the US government to approve Blackwell for China. Our products are designed and sold for beneficial commercial use, and every license sale we make will benefit The US economy, The US leadership.\n\n**Colette Kress** (EVP &amp; CFO)\nIn highly competitive markets, we want to win the support of every developer. America's AI technology stack can be the world's standard if we race and compete globally. Notably in the quarter was an increase in hopper January and h 200 shipments. We also sold approximately 650,000,000 of h 20 in q two to an unrestricted customer outside of China. The sequential increase in Hopper demand indicates the breadth of data center workloads that run on accelerated computing and the power of CUDA libraries and full stack optimizations, which continuously enhance the performance and economic value of platform.\n\n**Colette Kress** (EVP &amp; CFO)\nAs we continue to deliver both Hopper and Blackwell GPUs, we are focusing on meeting the soaring global demand. This growth is fueled by capital expenditures from the cloud to enterprises, which are on track to invest 600,000,000,000 in data center infrastructure and compute this calendar year alone, nearly doubling in two years. We expect annual AI infrastructure investments to continue growing driven by the several factors, reasoning agentic AI requiring orders of magnitude more training and inference compute, global build outs for sovereign AI, enterprise AI adoption, and the arrival of physical AI and robotics. Blackwell has set the benchmark as it is the new standard for AI inference performance. The market for AI inference is expanding rapidly with reasoning and agentic AI gaining traction across industries.\n\n**Colette Kress** (EVP &amp; CFO)\nBlackwell's RackScale NVLink and CUDA full stack architecture addresses this by redefining the economics of inference. New NV f p four four bit precision and NVLink 72 on the g b 300 platform delivers a 50 x increase in energy efficiency per token compared to Hopper, enabling companies to monetize their compute at unprecedented scale. For instance, a 3,000,000 investment in g v 200 infrastructure can generate 30,000,000 in token revenue, a 10 x return. NVIDIA software innovation, combined with the strength of our developer ecosystem, has already improved Blackwell's performance by more than two x since its launch. Advances in CUDA, TensorRT LLM, and Dynamo are unlocking maximum efficiency.\n\n**Colette Kress** (EVP &amp; CFO)\nCUDA library contributions from the open source community along with NVIDIA's open libraries and frameworks are now integrated into millions of workflows. This plow this powerful flywheel of collaborative innovation between NVIDIA and global community contribution strengthens NVIDIA's performance leadership. NVIDIA is a top contributor to OpenAI models, data, and software. Blackwell has introduced a groundbreaking numerical approach to large language model pretraining Using NV f p four, computations on the g b 300 can now achieve seven x faster training than the h 100, which uses f p eight. This innovation delivers the accuracy of 16 bit precision with the speed and efficiency of four bit, setting a new standard for AI factor efficiency and scalability.\n\n**Colette Kress** (EVP &amp; CFO)\nThe AI industry is quickly adopting this revolutionary technology with major players such as AWS, Google Cloud, Microsoft Azure, and OpenAI, as well as Cohere, Mistral, Kimi AI, Perplexity, Reflection, and Runway, already embracing it. NVIDIA's performance leadership was further validated in the latest ML Perth training benchmarks where the g b 200 delivered a clean sweep. Be on the lookout for the upcoming m MLPerf inference results in September, which will include benchmarks based on the Blackwell Ultra. NVIDIA RTX Pro servers are in full production for the world system makers. These are air cooled PCIe based systems integrated seamlessly into standard IT environments and run traditional enterprise IT applications as well as the most advanced agentic and physical AI applications.\n\n**Colette Kress** (EVP &amp; CFO)\nNearly 90 companies, including many global leaders, are already adopting RTX Pro servers. Hitachi uses them for real time simulation and digital twins, Lilly for drug discovery, Hyundai for factory design and AV validation, and Disney for immersive storytelling. As enterprises modernize data centers, RTX Pro servers are poised to become a multibillion dollar product line. Sovereign AI is one on the rise as the nation's ability to develop its own AI using domestic infrastructure data and talent presents a significant opportunity for NVIDIA. NVIDIA is at the forefront of landmark initiatives across The UK and Europe.\n\n**Colette Kress** (EVP &amp; CFO)\nThe European Union plans to invest 20,000,000,000 to establish 20 AI factories across France, Germany, Italy, and Spain, including five gigafactories to increase its AI compute infrastructure by tenfold. In The UK, the is Umbard AI supercomputer powered by NVIDIA was unveiled at the country's most powerful AI system, delivering 21 exaflots of AI performance to accelerate breakthroughs in fields of drug discovery and climate modeling. We are on track to achieve over 20,000,000,000 in sovereign AI revenue this year, more than double than that of last year. Networking delivered record revenue of 7,300,000,000.0, and escalating demands of AI compute clusters necessitate high efficiency and low latency networking. This represents a 46% sequential and 98% year on year increase with strong demand across Spectrum X Ethernet, InfiniBand, and NVLink.\n\n**Colette Kress** (EVP &amp; CFO)\nOur Spectrum X enhanced Ethernet solutions provide the highest throughput and lowest latency network for Ethernet AI workloads. Spectrum X Ethernet delivered double digit sequential and year over year growth with annualized revenue exceeding 10,000,000,000. At Hotchips, we introduced Spectrum XGS Ethernet, a technology designed to unify disparate data centers into gigascale AI super factories. Corweave is an initial adopter of the solution, which is project projected to double GPU to GPU communication speed. InfiniBand revenue nearly doubled sequentially, fueled by the adoption of XDR technology, which provides double the bandwidth improvement over its predecessor, especially valuable for the model builders.\n\n**Colette Kress** (EVP &amp; CFO)\nThe world's fastest switch, NVLink, with 14 x the bandwidth of PCIe Gen five delivered strong growth as customers deployed Brace Blackwell NVLink Rack Scale systems. The positive reception to NVLink Fusion, which allows semi custom AI infrastructure, has been widespread. Japan's upcoming Fugaku Next will integrate Fujitsu's CPUs with our architecture via NVLink Fusion. It will run a range of workloads, including AI, supercomputing, and quantum computing. Fugaku next joins a rapidly expanding list of leading quantum supercomputing and research centers running on NVIDIA's CUDA Q quantum platform, including ULEC, AIST, NNF, and NERSC, supported by over 300 ecosystem partners, including AWS, Google Quantum AI, Quantinuum, QEra, and SciQuantum.\n\n**Colette Kress** (EVP &amp; CFO)\nJust in THOR, our new robotics computing platform is now available. THOR delivers an order of magnitude greater AI performance and energy efficiency than NVIDIA AGX Orin. It runs the latest generative and reasoning AI models at the edge in real time, enabling state of the art robotics. Adoption of NVIDIA's robotics full stack platform is growing at rapid rate. Over 2,000,000 developers and 1,000 plus hardware software applications and sensor partners taking our platform to market.\n\n**Colette Kress** (EVP &amp; CFO)\nLeading enterprises across industries have adopted Thor, including Agility Robotics, Amazon Robotics, Boston Dynamics, Caterpillar, Figure, Hexagon, Medtronic, and Meta. Robotic applications require exponentially more compute on the device and in infrastructure representing a significant long term demand driver for our data center platform. NVIDIA Omniverse with Cosmos is our data center physical AI digital twin platform built for development of robot and robotic systems. This quarter, we announced a major expansion of our partnership with Siemens to enable AI automatic factories, leading European robotics companies, including Agile Robots, Neurorobotics, and Universal Robots, are building their latest innovations with the Omniverse platform. Transitioning to a quick summary of our revenue by geography.\n\n**Colette Kress** (EVP &amp; CFO)\nChina declined on a sequential basis to low single digits percentage of data center revenue. Note, our q three outlook does not include h 20 shipments to China customers. Singapore revenue represented 22% of second quarter's billed revenue as customers have centralized their invoicing in Singapore. Over 99% of data center compute revenue billed to Singapore was for US based customers. Our gaming revenue was a record 4,300,000,000.0, a 14% sequential increase and a 49% jump year on year.\n\n**Colette Kress** (EVP &amp; CFO)\nThis was driven by the ramp of Blackwell GeForce GPUs as strong sales continued as we increased supply availability. This quarter, we shipped GeForce RTX fifty sixty desktop GPU. It brings double the performance along with advanced ray tracing, neural rendering, and AI powered DLSS four gameplay to millions of gamers worldwide. Blackwell is coming to GeForce NOW in September. This is GeForce NOW's most significant upgrade, offering RTX fifty eighty class performance, minimal latency, and five k resolution at 120 frames per second.\n\n**Colette Kress** (EVP &amp; CFO)\nWe are also doubling the GeForce NOW catalog to over 4,500 titles, the largest library of any cloud gaming service. For AI enthusiasts, on device AI performs the best RTX GPUs. We partnered with OpenAI to optimize their open source GPT models for high quality, fast, and efficient inference on millions of RTX enabled window devices. With the RTX platform stack, Window developers can create AI applications designed to run on the world's largest AI PC user base. Professional visualization revenue reached 601,000,000, a 32% year on year increase.\n\n**Colette Kress** (EVP &amp; CFO)\nGrowth was driven by an adoption of the high end RTX workstation GPUs and AI powered workload like design, simulation, and prototyping. Key customers are leveraging our solutions to accelerate their operations. Activision Blizzard uses RTX workstations to enhance creative workflows, while robotics innovator Figure AI powers its humanoid robots with RTX embedded GPUs. Automotive revenue, which includes only in car compute revenue, was 586,000,000, up 69% year on year, primarily driven by self driving solutions. We have begun shipments of NVIDIA Thor SoC, the successor to Orin.\n\n**Colette Kress** (EVP &amp; CFO)\nThor's arrival coincides with the industry's accelerating shift to vision, language, model architecture, generative AI, and higher levels of autonomy. Thor is the most successful robotics and AV computer we've ever created. Thor willpower. Our full stack drive AV software platform is now in production, opening up billions to new revenue opportunities for NVIDIA while improving vehicle safety and autonomy. Now moving to the rest of our p and l.\n\n**Colette Kress** (EVP &amp; CFO)\nGAAP gross margin was 72.4%, and non GAAP gross margin was 72.7%. These figures include a 180,000,000 or 40 basis point benefit from relief releasing previously reserved h 20 inventory. Excluding this benefit, non GAAP gross margins would have been 72.3%, still exceeding our outlook. GAAP operating expenses rose eight percent and six percent on a non GAAP basis sequentially. This increase was driven by higher compute and infrastructure costs as well as higher compensation and benefit costs.\n\n**Colette Kress** (EVP &amp; CFO)\nTo support the ramp of Blackwell and Blackwell Ultra, inventory increased sequentially from 11,000,000,000 to 15,000,000,000 in q two. While we prioritize funding our growth and strategic initiatives, in q two, we returned 10,000,000,000 to shareholders through share repurchases and cash dividends. Our board of directors recently approved a 60,000,000,000 share repurchase authorization to add to our remaining 14,700,000,000.0 of authorization at the end of q two. Okay. Let me turn it to the outlook for the third quarter.\n\n**Colette Kress** (EVP &amp; CFO)\nTotal revenue is expected to be $54,000,000,000 plus or minus 2%. This represents over $7,000,000,000 in sequential growth. Again, we do not assume any h 20 shipments to China customers in our outlook. GAAP and non GAAP gross margins are expected to be 73.3%, 73.5%, respectively, plus or minus 50 basis points. We continue to expect to exit the year with non GAAP gross margins in the mid seventies.\n\n**Colette Kress** (EVP &amp; CFO)\nGAAP and non GAAP operating expenses are expected to be approximately 5,900,000,000.0 and 4,200,000,000.0, respectively. For the full year, we expect operating expenses to grow in the high thirties range year over year, up from our prior expectations of the mid thirties. We are accelerating investments in the business to address the magnitude of growth opportunities that lie ahead. GAAP and non GAAP other income and expenses are expected to be an income of approximately 500,000,000, excluding gains and losses from nonmarketable and public held equity securities. GAAP and non GAAP tax rates are expected to be 16.5, plus or minus 1%, excluding any discrete items.\n\n**Colette Kress** (EVP &amp; CFO)\nFurther financial data are included in the CFO commentary and other information available on our website. In closing, let me highlight upcoming events for the financial community. We will be at the Goldman Sachs Technology Conference on September 8 in San Francisco. Our annual NDR will commence the October. GTC data center begins on October 27 with Jensen's keynote scheduled for the twenty eighth.\n\n**Colette Kress** (EVP &amp; CFO)\nWe look forward to seeing you at these events. Our earnings call to discuss the results of our 2026 is scheduled for November 19. We will now open the call for questions. Operator, would you please poll for questions?\n\n**Operator**\nThank you. Your first question comes from C. J. Muse with Cantor Fitzgerald. Your line is open.\n\n**CJ Muse** (Senior Managing Director)\nYes, good afternoon. Thank you for taking the question.\n\n**CJ Muse** (Senior Managing Director)\nI guess with wafer in to rack out lead times of twelve months, you confirmed on the call today that Rubin is on track for ramp in the second half. And obviously, many of these investments are multiyear projects contingent upon power, cooling, etcetera. I was hoping perhaps you could you take a high level view and speak to, you know, your vision for growth in into 2026. And as part of that, if you could kinda comment between network and data center would be very helpful. Thank you.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nYeah. Thanks, CJ. At the highest level of growth drivers would be the evolution, the the introduction, if you will, of reasoning agentic AI. You know, where chatbots used to be one shot, you give it a prompt, and it would generate the answer. Now the AI does research.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nIt thinks and does a plan, and it might use tools. And so it's called long thinking, and the longer it thinks, oftentimes, it produces better answers. And the amount of computation necessary for one shot versus reasoning agentic AI models could be a 100 times, a thousand times, and potentially even more as the amount of research and basically reading and comprehension that it goes off to do. And so the amount of computation that has that has resulted in AgenTic AI has grown tremendously. And, of course, the effectiveness has also grown tremendously.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nBecause of Agentic AI, the amount of hallucination has dropped significantly. You can now use it you can now use tools and perform tasks. Enterprises have been opened up. As a result of agentic AI and vision language models, we now are seeing a breakthrough in physical AI, in robotics, autonomous systems. So the the last year, AI has made tremendous progress, and agentic systems, reasoning systems, is completely revolutionary.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nNow we built the Blackwell MVLink 72 system, a rack scale computing system, for this moment. We've been working on it for several years. This last year, we transitioned from MVLink eight, which is a node scale computing, each node is a computer, to now NVLink 72 where each rack is a computer. That disaggregation of NVLink 72 into a rack scale system was extremely hard to do, but the results are extraordinary. We're seeing orders of magnitude speed up and, therefore, energy efficiency and, therefore, cost effectiveness of token generation because of NVLink 72.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd so over the next over the next couple of years, you're gonna over well, you asked about longer term. Over the next five years, we're gonna scale into with Blackwell, with Rubin, and follow ons to scale into effectively a 3 to $4,000,000,000,000 AI infrastructure opportunity. The last couple of years, you have seen that CapEx has grown in just the top four CSPs by has doubled and grown to about $600,000,000,000. So we're in the beginning of this build out, and the AI technology advances has really enabled AI to be able to adopt and solve problems to many different industries.\n\n**Operator**\nYour next question comes from Vivek Arya with Bank of America Securities. Your line is open.\n\n**Vivek Arya** (Managing Director)\nThanks for taking my questions. Colette, just wanted to clarify the 2,000,000,000 to $5,000,000,000 in China. What needs to happen? And what is the sustainable pace of that China business as you get into Q4? And then Jensen, for you on the competitive landscape, several of your large customers already have or are planning many ASIC projects.\n\n**Vivek Arya** (Managing Director)\nI think one of your ASIC competitors Broadcom signaled that they could grow their AI business almost 55%, 60% next year. Any scenario in which you see the market moving more towards ASICs and away from NVIDIA GPU? Just what are you hearing from your customers? How are they managing this split between their use of merchant silicon and ASICs? Thank you.\n\n**Colette Kress** (EVP &amp; CFO)\nThanks, Vivek. So let me first answer your question regarding what will it take for the h twenties to be shipped. There is interest in our h twenties. There is the initial set of licenses that we received. And then, additionally, we do have supply that we are ready, and that's why we communicated that somewhere in the range of about 2 to 5,000,000,000 this quarter, we could potentially ship.\n\n**Colette Kress** (EVP &amp; CFO)\nWe're still waiting on several of the geopolitical issues going back and forth between the governments and the companies trying to determine their purchases and what they want to do. So it's still, open at this time, and we're not exactly sure what that full amount will be about this quarter. However, if more interest arrives, more licenses arrives, again, we can also still build additional h 20 and ship more as well.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nNVIDIA builds very different things than ASICs, let's talk about ASICs first. A lot of projects are started. Many startup companies are created. Very few products go into production, and the reason for that is it's really hard. Accelerated computing is unlike general purpose computing.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nYou don't write software and just compile it into a processor. Accelerated computing is a full stack co design problem. And AI factories, in the last several years, has become so much more complex because of the scale of the problems have grown so significantly. It is it is really the ultimate the most extreme computer science problem the world's ever seen, obviously. And so the stack is complicated.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nThe models are changing incredibly fast from generative based on autoregressive to generative based on diffusion to mixed models to multimodality, the number of different models that are coming out that are either derivatives of transformers or evolutions of transformers is just daunting. One of the advantages that we have is that NVIDIA's available in every cloud. We're available from every computer company. We're available from the cloud to on prem to edge to robotics on the same programming model. And so it's sensible that every framework in the in the world supports NVIDIA.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nWhen you're building a new model architecture, releasing it on NVIDIA is most sensible. And so the diversity of our platform, both in the ability to evolve into any architecture, the fact that we're everywhere, and, also, we accelerate the entire pipeline. You know, everything from data processing to pretraining to post training with reinforcement learning, all the way out to inference. And so when you build a data center with NVIDIA platform in it, the utility of it is best. The life lifetime usefulness is much, much longer.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd then I I would just say that that, in addition to all of that, it is just a a really extremely complex systems problem anymore. You know, people talk about the chip itself. There's one ASIC, the GPU that that many people talk about. But in order to build Blackwell, the platform, and Rubin, the platform, we had to build CPUs that connect fast memory, low low extremely energy efficient memory for large KB caching necessary for AgenTic AI to the GPU to a super NIC to a scale up switch we call NVLink, completely revolutionary when we're in our fifth generation now, to a scale out switch, whether it's quantum or spectrum x Ethernet, to now scale across switches so that we could prepare for these AI super factories with multiple gigawatts of computing all connected together. We call that Spectrum XGS.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nWe just announced that at Hotchips this week. And so the complications, the complexity of everything that we do is really quite extraordinary. It's just done in a in a really, really extreme scale now. And then lastly, if I could just say one more thing. You know, we're in every cloud for a good reason.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nNot only do are we the most energy efficient, our perf per watt is the best of any computing platform. And in a world of power limited data centers, perf per watt drives directly to revenues. And, you know, you've heard me say before that in a lot of ways, the more you buy, the more you grow. And because our perf per dollar, the performance per dollar is so incredible, you also have extremely great margins. So the the growth opportunity with NVIDIA's architecture and the gross margins opportunity with NVIDIA's architecture is absolutely the best.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd so there's a lot of reasons why NVIDIA's chosen by every cloud and every startup and every computer company. We're, you know, really a holistic full stack solution for AI factories.\n\n**Operator**\nYour next question comes from Ben Reitzes with Melius. Your line is open.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nJensen, I wanted to ask you about your 3,000,000,000,000 to $4,000,000,000,000 in data center infrastructure spend by the end of the decade. Previously, you talked about something in the $1,000,000,000 range, which I believe was just for compute by 2028. If you take past comments, 3,000,000,000,000 to $4,000,000,000,000 would imply maybe $2,000,000,000 plus in compute spend. And just wanted to know if that was right and that's what you're seeing by the end of the decade. And wondering what you think your share will be of that.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nYour share right now of total infrastructure compute wise is very high. So wanted to see. And also if there's any bottlenecks you're concerned about like power to get to the 3 to 4,000,000,000,000. Thanks a lot.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nYeah. Thanks. As you know, the CapEx of just the top four hyperscalers has doubled in two years. As the AI revolution went into full steam, as the AI race is now on, the CapEx spend has doubled to $600,000,000,000 per year. There's five years between now and the end of the decade, and six hundred billion dollars, only represents the top four hyperscalers.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nWe still have the rest of the enterprise companies building on prem. You have enter you have cloud service providers building around the world. United States represents about 60% of the world's compute. And and over time, you would think that artificial intelligence would reflect GDP scale and growth, and so and would be would be, of course, accelerating GDP growth. And so so our our contribution to that is a large part of the AI infrastructure.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nOut of out of a gigawatt AI factory, which can go anywhere from 50 to, you know, plus or minus 10%, let's say, to 60,000,000,000, we represent about 35 plus or minus of that. And 35 out of fifty fifty or so, billion dollars for a gigawatt data center. And there and, of course, what you get for that is not a GPU. I think people, you know, were famous for building the GPU and inventing the GPU. But as you know, over the last decade, we've really transitioned to become an AI infrastructure company.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nIt takes six chips just to build six different types of chips just to build an a AI an a Rubin AI supercomputer. And just to scale that out, you know, to a gigawatt, you have hundreds of thousands of of GPU compute nodes and whole bunch of racks. And so we're really we're really an AI infrastructure company, and we're we're hoping to continue to contribute to growing this industry, making AI more useful, and then very importantly, driving the performance per watt because the world, as you mentioned, limiters, it will always likely be power limitations or AI infrastructure or AI building limitations. And so we need to squeeze as much out of that factory as possible. NVIDIA's performance per unit of energy used drives the revenue growth of that factory.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nIt directly translates. If you have a 100 megawatt factory, perf per 100 megawatt drives your revenues. It's tokens per 100 megawatts of factory. In our case, also, the performance per dollar spent is so high that your gross margins are also the best. But anyhow, these are these are the the limiters going forward, and and 3 to $4,000,000,000,000 is fairly sensible for the next five years.\n\n**Operator**\nNext question comes from Joe Moore of Morgan Stanley. Your line is open.\n\n**Joseph Moore** (Managing Director)\nGreat. Thank you. Congratulations on reopening the China opportunity. Can you talk about the long term prospects there? You've talked about, I think half of AI software world being there.\n\n**Joseph Moore** (Managing Director)\nYou know, how much can NVIDIA grow in that business, and, you know, how important is it that you get the Blackbaud architecture ultimately licensed there?\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nThe China market, I've estimated to be about $50,000,000,000 of opportunity for us this year. If we were able to address it with competitive products and and if it's $50,000,000,000 this year, you would expect it to grow, say, 50% per year as as the rest of the world's AI AI market is growing as well. It is the second largest computing market in the world, and it is also the home of AI researchers. About 50% of the world's AI researchers are in China. The vast majority of the leading open source models are created in China, and so it's fairly important, I think, for the American technology companies to be able to address that market.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd open source, as you know, is created in one country, but it's used all over the world. The open source models that have come out of China are really excellent. DeepSeek, of course, gained global notoriety. Q1 is excellent. Kimi is excellent.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nThere's a there's a whole bunch of new models that are coming out. They're multimodal. They're link great language models, and it and it's it's really fueled the adoption of AI in enterprises around the world because enterprises wanna build their own custom proprietary software software stacks. And so open open source model is really important for enterprise. It's really important for SaaS who also would like to build proprietary systems.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nIt has been really incredible for robotics around the world. And so open source is really important, and it's important that the American companies are able to address it. This is it's gonna be a very large market. We're talking to we're talking to, the administration about the importance of American companies to be able to address, the Chinese market. And, as you know, h 20 has been approved, for companies that are not on the entities list, and many licenses have been approved.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd, so I think the, you know, the the opportunity for us to bring Blackwell to the China market is a real possibility. And so we just have to keep advocating the the sensibility of and the importance of American tech companies to be able to to lead and win the AI race and help make the American tech stack the global standard.\n\n**Operator**\nYour next question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nYeah. Thank you for the question. I want to go back to the Spectrum XGS announcement this week. And thinking about the Ethernet product now pushing over $10,000,000,000 of annualized revenue, just what is the opportunity set that you see for Spectrum XGS? So do we think about this as kind of the the data center interconnect layer?\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nAny thoughts on the sizing of this opportunity, you know, within that Ethernet portfolio? Thank you.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nWe now offer three networking technologies. One is for scale up, one is for scale out, and one for scale across. Scale up is so that we could build the largest possible virtual GPU, the virtual compute node. NVLink is revolutionary. NVLink 72 is what made it possible for Blackwell to deliver such an extraordinary generational jump over Hopper's NVLink eight.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAt a time when when we have long thinking thinking models, agentic AI reasoning systems, the NVLink basically amplifies the, memory bandwidth, which is really critical for, for reasoning systems. And so NVLink 72 is fantastic. We then scale out with networking, which we have two. We have InfiniBand, which is unquestionably the lowest latency, the lowest jitter, the best scale out network. It does require more expertise in managing those networks.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd, for supercomputing, for the leading model makers, InfiniBand quantum InfiniBand is the unambiguous choice. If you were to benchmark an AI factory, the ones with InfiniBand are the best performance. For those who would like to use Ethernet because their their whole data center is built with Ethernet, we have a new type of Ethernet called Spectrum Ethernet. Spectrum Ethernet is not off the shelf. It has a whole bunch of new technologies designed for low latency and low jitter and congestion control, and and it has the ability, to, come closer, much, much closer, to InfiniBand than anything that's out there.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd that's we call that Spectrum x Ethernet. And then finally, we have Spectrum xGS, a gigascale for connecting multiple data centers, multiple AI factories into a super factory, a gigantic system. And we're gonna you're gonna see that networking obviously is very important in AI factories. In fact, choosing the right networking, the performance, the throughput improvement going from, you know, 65% to 85% or 90%, that kind of that kind of step up because of their your networking capability effectively makes networking free. You know?\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nChoosing the right networking, you're basically paying you know, you're, you'll get a return on it like you can't believe because the AI factory, a gigawatt, as I mentioned before, could be $50,000,000,000. And so the ability to improve the efficiency of that factory by tens of percent is results in $1,020,000,000,000 dollars worth of effective benefit. And so, you know, this the the networking is a very important part of it. It's the reason why NVIDIA dedicates so much in networking. It's the reason why we purchased Mellanox five and a half years ago.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd Spectrum X, as we mentioned earlier, is now quite a quite a sizable business, and it's only about a year and a half old. So x Spectrum X is a home run. All all three of them are gonna be fantastic. NVLink, scale up Spectrum X and InfiniBand, scale out, and then Spectrum XGS for scale across.\n\n**Operator**\nYour next question comes from Stacy Raskin with Bernstein Research. Your line is open.\n\n**Stacy Rasgon** (MD &amp; Senior Analyst)\nHi, guys. Thanks for taking my question. I have a more tactical question for Colette. So on the guide, you're up over $7,000,000,000 The vast bulk of that is going to be from data center. How do I think about apportioning that $7,000,000,000 out across Blackwell versus Hopper versus networking?\n\n**Stacy Rasgon** (MD &amp; Senior Analyst)\nI mean it looks like Blackwell was probably $27,000,000,000 in the quarter, up from maybe 23,000,000,000 last quarter. Hopper is still 6,000,000,000 or $7,000,000,000 post the H20. Like do you think the Hopper strength continues? Just how do I think about parsing that $7,000,000,000 out across all the the three those three different components?\n\n**Colette Kress** (EVP &amp; CFO)\nThanks, Stacy, for the question. First part of it, looking at our growth between q two and q three, Blackwell is still going to be, the lion's share, of what we have in terms of data center. But keep in mind, that helps both our compute side as well as it helps our networking side because we are selling those significant systems, that are incorporating the NVLink that Jensen, just spoke about. Selling Hopper, we are still selling it. H 100, h two hundreds, we are.\n\n**Colette Kress** (EVP &amp; CFO)\nBut, again, they are HCX systems, and I still believe our Blackwell will be the lion's share of what we're doing on there. So we'll continue. We don't have any more specific details in terms of how we'll finish our quarter, but you should expect Blackwell again to be the driver of the growth.\n\n**Operator**\nYour next question comes from Jim Schneider of Goldman Sachs. Your line is open.\n\n**Jim Schneider** (Senior Equity Analyst)\nGood afternoon. Thanks for taking my question. You've been very clear about the reasoning model opportunity that you see and you've also been relatively clear about the technical specs for Rubin. But maybe you could provide a little bit of context about how you view the Rubin product transition going forward? What incremental capability does that offer to customers?\n\n**Jim Schneider** (Senior Equity Analyst)\nAnd would you say that Rubin is a bigger, smaller or similar step up in terms of performance for capability perspective relative to what we saw at Blackwell? Thank you.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nYeah. Thanks. Ruben. Ruben Ruben, we're on a we're on an annual cycle. And the reason why we're on an annual cycle is because we can do so to accelerate the cost reduction and maximize the revenue generation for our customers.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nWhen we increase the perf per watt, the token generation per amount of usage of energy, we are effectively driving the revenues of our customers. The perf per watt of Blackwell will be, for reasoning systems, an order of magnitude higher than Hopper. And so for the same amount of energy, and everybody's data center is energy limited by definition, for any data center that we using Blackwell, you'll be able to maximize your revenues compared to anything we've done in the past, compared to anything in the world today. And because the perf per dollar, the performance is so good that the perf per dollar invested in the in the capital, would also allow you to improve your gross margins. To the extent that we have great ideas for every single generation, we could improve their the revenue generation, improve the AI capability, improve the margins of our customers by releasing new architectures.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd so we advise our our partners, our customers to to pace themselves and to build these data centers on an annual rhythm. And Ruben is gonna is going to have a whole bunch of new ideas. I paused for a second because, you know, I've got plenty of time between now and a year from now to tell you about all the breakthroughs that Ruben's are gonna bring. And but we Rubens has a lot of great ideas. I'm anxious to tell you, but I can't right now.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd I'll save it for for for GTC, to tell you more more and more about it. But, nonetheless, for the next year, we're ramping really hard into now Grace Blackwell, g b 200, and then now Blackwell Ultra, b 300. We're ramping really hard into data centers. This this this year is obviously a record breaking year. I expect next year to be a record breaking year.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd while we continue to increase, the performance of, of AI capabilities as we race towards artificial superintelligence on the one hand, and continue to increase the revenue generation capabilities of our hyperscalers on the other hand.\n\n**Operator**\nYour final question comes from Timothy Arcuri with UBS. Your line is open.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Jensen, I wanted to ask you just answer the question you threw at a number, you said 50% CAGR for the AI market. So I'm wondering how much visibility that you have into next year. Is that kind of a reasonable bogey in terms of how much your data center revenue should grow next year? I would think you'll grow at least in line with that CAGR.\n\n**Timothy Arcuri** (Managing Director)\nAnd maybe are there any puts and takes to that? Thanks.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nWell, I think the the best way to look at it is is we we have we have reasonable forecasts from from our large customers for next year. A very, very significant forecast. And we still have a lot of businesses that we're still winning and a lot of start ups that are still being created. Don't forget that the number of start ups for AI native startups was a 100,000,000,000 was funded last year. This year, the year is not even over yet.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nIt's a 180,000,000,000 funded. If you look at look at AI native, the top AI native startups that are generating revenues, last year was $2,000,000,000. This year is $20,000,000,000. Next year, being 10 times higher than this year is not inconceivable. And the open source models is now opening up large enterprises, SaaS companies, industrial companies, robotics companies to now join the AI revolution, another source of growth.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nAnd, you know, whether whether it's AI natives or enterprise SaaS or industrial AI or startups, we're just seeing just enormous amount of, interest in AI and demand for AI. Right now, the buzz is, I'm sure all of you know about the buzz out there. The buzz is everything's sold out. H one Hers sold out. H two hundreds are sold out.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nLarge CSPs are coming out renting capacity from other CSPs. And so the the, AI native startups were really scrambling to get capacity so that they could train their reasoning models. And so the demand is really, really high. But the long term long term outlook between where we are today, CapEx has doubled in two years. It is now running about $600,000,000,000 a year just in the large hyperscalers.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nYou know, for us to grow into that $600,000,000,000 a year, representing a significant part of that CapEx isn't unreasonable. And so I think I think the the next several years, surely through the through the through the decade, we see just a really fast growing, really significant growth opportunities ahead. Let me conclude with this. Blackwell is the next generation AI platform the world's been waiting for. It delivers an ex exceptional generational leap.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nNVIDIA's NVLink 72 rack scale computing is revolutionary, arriving just in time as reasoning AI models drive order of magnitude increases in training and inference performance requirement. Blackwell Ultra is ramping at full speed, and the demand is extraordinary. Our next platform, Rubin, is already in fab. We have six new chips that represents the Rubin platform. They have all taped out to TSMC.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nRubin will be our third generation MB LINK RackScale AI supercomputer, and so we expect to have a much more mature and fully scaled up supply chain. Blackwell and Rubin AI factory platforms will be scaling into the 3 to $4,000,000,000,000 global AI factory build out through the end of the decade. Customers are building ever greater scale AI factories from thousands of hopper GPUs in tens of megawatt data centers to now hundreds of thousands of Blackwells in 100 megawatt facilities. And soon, we'll be building millions of g millions of Rubin GPU platforms powering multi gigawatt, multisite AI super factories. With each generation, demand only grows.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nOne shot chatbots have evolved into reasoning, agentic AI that research, plan, and use tools, driving orders of magnitude jump in compute for both training and inference. Agentic AI is reaching maturity and has opened the enterprise market to build domain and company specific AI agents for enterprise workflows, products, services. The age of physical AI has arrived, unlocking entirely new industries in robotics, industrial automation. Every industry and every industrial company will need to build two factories, one to build the machines and another to build their robotic AI. This quarter, NVIDIA reached record revenues and an extraordinary milestone in our journey.\n\n**Jensen Huang** (Founder, President, CEO &amp; Director)\nThe opportunity ahead is immense. A new industrial revolution has started. The AI race is on. Thanks for joining us today, and I look forward to addressing you next week, next earnings call. Thank you.\n\n**Operator**\nThis concludes today's conference call. You may now disconnect.",
        "fetched_at": "2026-02-04T16:11:34.389Z"
      },
      {
        "ticker": "NVDA",
        "title": "Yahoo Finance",
        "published_date": "May 28, 2025, 5:00 PM EDT",
        "fiscal_year": "2026",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/NVDA/earnings/NVDA-Q1-2026-earnings_call-319901.html",
        "content": "**Operator**\nGood afternoon. My name is Sarah, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's First Quarter Fiscal 2026 Financial Results Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers are marked, there will be a question-and-answer session. If you would like to ask a question during this time, simply press star one on your telephone keypad. If you would like to withdraw your question, please press star one again. Thank you. Toshiya Hari, you may begin your conference.\n\n**Toshiya Hari** (Head of Investor Relations)\nThank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the first quarter of fiscal 2026. With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer, and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the second quarter of fiscal 2026. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially.\n\n**Toshiya Hari** (Head of Investor Relations)\nFor a discussion of factors that could affect our future financial results in business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, May 28th, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\n\n**Colette Kress** (EVP and CFO)\nThank you, Toshiya. We delivered another strong quarter with revenue of $44 billion, up 69% year-over-year, exceeding our outlook in what proved to be a challenging operating environment. Data center revenue of $39 billion grew 73% year-on-year. AI workloads have transitioned strongly to inference, and AI factory buildouts are driving significant revenue. Our customers' commitments are firm. On April 9, the U.S. government issued new export controls on H20, our data center GPU designed specifically for the China market. We sold H20 with the approval of the previous administration. Although our H20 has been in the market for over a year and does not have a market outside of China, the new export controls on H20 did not provide a grace period to allow us to sell through our inventory.\n\n**Colette Kress** (EVP and CFO)\nIn Q1, we recognized $4.6 billion in H20 revenue, which occurred prior to April 9th, but also recognized a $4.5 billion charge as we wrote down inventory and purchase obligations tied to orders we had received prior to April 9th. We were unable to ship $2.5 billion in H20 revenue in the first quarter due to the new export controls. The $4.5 billion charge was less than what we initially anticipated as we were able to reuse certain materials. We are still evaluating our limited options to supply data center compute products compliant with the U.S. government's revised export control rules. Losing access to the China AI accelerator market, which we believe will grow to nearly $50 billion, would have a material adverse impact on our business going forward and benefit our foreign competitors in China and worldwide.\n\n**Colette Kress** (EVP and CFO)\nOur Blackwell ramp, the fastest in our company's history, drove a 73% year-on-year increase in data center revenue. Blackwell contributed nearly 70% of data center compute revenue in the quarter, with a transition from Hopper nearly complete. The introduction of GB200 NVL was a fundamental architectural change to enable data center-scale workloads and to achieve the lowest cost per inference token. While these systems are complex to build, we have seen a significant improvement in manufacturing yields, and rack shipments are moving to strong rates to end customers. GB200 NVL racks are now generally available for model builders, enterprises, and sovereign customers to develop and deploy AI. On average, major hyperscalers are each deploying nearly 1,000 NVL72 racks or 72,000 Blackwell GPUs per week and are on track to further ramp output this quarter.\n\n**Colette Kress** (EVP and CFO)\nMicrosoft, for example, has already deployed tens of thousands of Blackwell GPUs and is expected to ramp to hundreds of thousands of GB200s with OpenAI as one of its key customers. Key learnings from the GB200 ramp will allow for a smooth transition to the next phase of our product roadmap, Blackwell Ultra. Sampling of GB300 systems began earlier this month at the major CSPs, and we expect production shipments to commence later this quarter. GB300 will leverage the same architecture, same physical footprint, and the same electrical and mechanical specifications as GB200. The GB300 drop-in design will allow CSPs to seamlessly transition their systems and manufacturing used for GB200 while maintaining high yields. B300 GPUs with 50% more HBM will deliver another 50% increase in dense FP4 inference compute performance compared to the B200.\n\n**Colette Kress** (EVP and CFO)\nWe remain committed to our annual product cadence, with our roadmap extending through 2028, tightly aligned with the multiple-year planning cycles of our customers. We are witnessing a sharp jump in inference demand. OpenAI, Microsoft, and Google are seeing a step-function leap in token generation. Microsoft processed over 100 trillion tokens in Q1, a fivefold increase on a year-over-year basis. This exponential growth in Azure OpenAI is representative of strong demand for Azure AI Foundry, as well as other AI services across Microsoft's platform. Inference-serving startups are now serving models using B200, tripling their token generation rate and corresponding revenues for high-value reasoning models such as DeepSeek R1, as reported by Artificial Analysis. NVIDIA Dynamo on Blackwell NVL72 turbocharges AI inference throughput by 30x for the new reasoning models sweeping the industry.\n\n**Colette Kress** (EVP and CFO)\nDeveloper engagements increased with adoption ranging from LLM providers such as Perplexity to financial services institutions such as Capital One, who reduced agentic chatbot latency by 5x with Dynamo. In the latest MLPerf inference results, we submitted our first results using GB200 NVL72, delivering up to 30x higher inference throughput compared to our eight GPU H200 submission on the challenging Llama 3.1 benchmark. This feat was achieved through a combination of tripling the performance per GPU as well as 9x more GPUs, all connected on a single NVLink domain. While Blackwell is still early in its life cycle, software optimizations have already improved its performance by 1.5x in the last month alone. We expect to continue improving the performance of Blackwell through its operational life, as we have done with Hopper and Ampere.\n\n**Colette Kress** (EVP and CFO)\nFor example, we increased the inference performance of Hopper by four times over two years. This is the benefit of NVIDIA's programmable CUDA architecture and rich ecosystem. The pace and scale of AI factory deployments are accelerating with nearly 100 NVIDIA-powered AI factories in flight this quarter, a twofold increase year-over-year, with the average number of GPUs powering each factory also doubling in the same period. More AI factory projects are starting across industries and geographies. NVIDIA's full-stack architecture is underpinning AI factory deployments as industry leaders like AT&T, BYD, Capital One, Foxconn, MediaTek, and Telenor are strategically vital sovereign clouds like those recently announced in Saudi Arabia, Taiwan, and the UAE. We have a line of sight to projects requiring tens of GW of NVIDIA AI infrastructure in the not-too-distant future.\n\n**Colette Kress** (EVP and CFO)\nThe transition from generative to agentic AI, AI capable of perceiving, reasoning, planning, and acting, will transform every industry, every company, and country. We envision AI agents as a new digital workforce capable of handling tasks ranging from customer service to complex decision-making processes. We introduced the Llama Nemotron family of open reasoning models designed to supercharge agentic AI platforms for enterprises. Built on the Llama architecture, these models are available as NIMs or NVIDIA Inference Microservices with multiple sizes to meet diverse deployment needs. Our post-training enhancements have yielded a 20% accuracy boost and a 5x increase in inference speed. Leading platform companies, including Accenture, Cadence, Deloitte, and Microsoft, are transforming work with our reasoning models. NVIDIA NeMo Microservices are generally available across industries and are being leveraged by leading enterprises to build, optimize, and scale AI applications.\n\n**Colette Kress** (EVP and CFO)\nWith NeMo, Cisco increased model accuracy by 40% and improved response time by 10x in its code assistant. Nasdaq realized a 30% improvement in accuracy and response time in its AI platform's search capabilities. Shell's custom LLM achieved a 30% increase in accuracy when trained with NVIDIA NeMo. NeMo's parallelism techniques accelerated model training time by 20% when compared to other frameworks. We also announced a partnership with Yum Brands, the world's largest restaurant company, to bring NVIDIA AI to 500 of its restaurants this year and expanding to 61,000 restaurants over time to streamline order taking, optimize operations, and enhance service across its restaurants. For AI-powered cybersecurity, leading companies like Check Point, CrowdStrike, and Palo Alto Networks are using NVIDIA's AI security and software stack to build, optimize, and secure agentic workflows, with CrowdStrike realizing 2x faster detection triage with 50% less compute cost.\n\n**Colette Kress** (EVP and CFO)\nMoving to networking, sequential growth in networking resumed in Q1, with revenue up 64% quarter-over-quarter to $5 billion. Our customers continue to leverage our platform to efficiently scale up and scale out AI factory workloads. We created the world's fastest switch, NVLink. For scale-up, our NVLink compute fabric in its fifth generation offers 14x the bandwidth of PCIe Gen 5. NVLink 72 carries 130 TB per second of bandwidth in a single rack, equivalent to the entirety of the world's peak internet traffic. NVLink is a new growth vector and is off to a great start, with Q1 shipments exceeding $1 billion. At Computex, we announced NVLink Fusion. Hyperscale customers can now build semi-custom CCUs and accelerators that connect directly to the NVIDIA platform with NVLink.\n\n**Colette Kress** (EVP and CFO)\nWe are now enabling key partners, including ASIC providers such as MediaTek, Marvell, Alchip Technologies, and Astera Labs, as well as CPU suppliers such as Fujitsu and Qualcomm, to leverage NVLink Fusion to connect our respective ecosystems. For scale-out, our enhanced Ethernet offerings deliver the highest throughput, lowest latency networking for AI. SpectrumX posted strong sequential and year-on-year growth and is now annualizing over $8 billion in revenue. Adoption is widespread across major CSPs and consumer internet companies, including CoreWeave, Microsoft Azure, Oracle Cloud, and xAI. This quarter, we added Google Cloud and Meta to the growing list of SpectrumX customers. We introduced SpectrumX and QuantumX silicon photonics switches featuring the world's most advanced co-package optics. These platforms will enable next-level AI factory scaling to millions of GPUs through the increasingly power efficiency by 3.5x and network resiliency by 10x while accelerating customer time to market by 1.3x.\n\n**Colette Kress** (EVP and CFO)\nTransitioning to a quick summary of our revenue by geography. China, as a percentage of our data center revenue, was slightly below our expectations and down sequentially due to H20 export licensing controls. For Q2, we expect a meaningful decrease in China data center revenue. As a reminder, while Singapore represented nearly 20% of our Q1 build revenue, as many of our large customers use Singapore for centralized invoicing, our products are almost always shipped elsewhere. Note that over 99% of H100, H200, and Blackwell data center compute revenue billed to Singapore was for orders from U.S.-based customers. Moving to gaming and AI PCs. Gaming revenue was a record $3.8 billion, increasing 48% sequentially and 42% year-on-year. Strong adoption by gamers, creatives, and AI enthusiasts have made Blackwell our fastest ramp ever.\n\n**Colette Kress** (EVP and CFO)\nAgainst a backdrop of robust demand, we greatly improved our supply and availability in Q1 and expect to continue these efforts in Q2. AI is transforming PC and creator and gamers. With a 100 million user installed base, GeForce represents the largest footprint for PC developers. This quarter, we added to our AI PC laptop offerings, including models capable of running Microsoft's Copilot+. This past quarter, we brought Blackwell architecture to mainstream gaming with its launch of GeForce RTX 5060 and 5060 Ti, starting at just $299. The RTX 5060 also debuted in laptops, starting at $1,099. These systems that doubled the frame rate and slash latency. These GeForce RTX 5060 and 5060 Ti desktop GPUs and laptops are now available.\n\n**Colette Kress** (EVP and CFO)\nIn console gaming, the recently unveiled Nintendo Switch 2 leverages NVIDIA's neural rendering and AI technologies, including next-generation custom RTX GPUs with DLSS technology, to deliver a giant leap in gaming performance to millions of players worldwide. Nintendo has shipped over 150 million Switch consoles to date, making it one of the most successful gaming systems in history. Moving to probe visualization. Revenue of $509 million was flat sequentially and up 19% year-on-year. Tariff-related uncertainty temporarily impacted Q1 systems, and demand for our AI workstations is strong, and we expect sequential revenue growth to resume in Q2. NVIDIA DGX Spark and Station revolutionized personal computing by putting the power of an AI supercomputer in a desktop form factor. DGX Spark delivers up to one petaflop of AI compute, while DGX Station offers an incredible 20 petaflops and is powered by the GB300 superchip.\n\n**Colette Kress** (EVP and CFO)\nDGX Spark will be available in calendar Q3 and DGX Station later this year. We have deepened Omniverse's integration and adoption into some of the world's leading software platforms, including Databricks, SAP, and Schneider Electric. New Omniverse blueprints such as Mega for at-scale robotic fleet management are being leveraged in Kion Group, Pegatron, Accenture, and other leading companies to enhance industrial operations. At Computex, we showcased Omniverse's great traction with technology manufacturing leaders, including TSMC, Quanta, Foxconn, Pegatron. Using Omniverse, TSMC saves months in work by designing fabs virtually. Foxconn accelerates thermal simulations by 150x, and Pegatron reduced assembly line defect rates by 67%. Lastly, with our automotive group, revenue was $567 million, down 1% sequentially, but up 72% year-on-year. Year-on-year growth was driven by the ramp of self-driving across a number of customers and robust end demand for NEVs.\n\n**Colette Kress** (EVP and CFO)\nWe are partnering with GM to build the next-gen vehicles, factories, and robots using NVIDIA AI simulation and accelerated computing. We are now in production with our full-stack solution for Mercedes-Benz, starting with the new CLA, hitting roads in the next few months. We announced Isaac GR00T and won the world's first open, fully customizable foundation model for humanoid robots, enabling generalized reasoning and skill development. We also launched new open NVIDIA Cosmos World Foundation models. Leading companies include One X, Agility Robotics, Figure AI, Uber, and Wobot. We've begun integrating Cosmos into their operations for synthetic data generation, while Agility Robotics, Boston Dynamics, and XPeng Robotics are harnessing Isaac simulation to advance their humanoid efforts. GE Healthcare is using the new NVIDIA Isaac platform for healthcare simulation built on NVIDIA Omniverse and using NVIDIA Cosmos, the platform speeds development of robotic imaging and surgery systems.\n\n**Colette Kress** (EVP and CFO)\nThe era of robotics is here. Billions of robots, hundreds of millions of autonomous vehicles, and hundreds of thousands of robotic factories and warehouses will be developed. All right, moving to the rest of the P&L. GAAP gross margins and non-GAAP gross margins were 60.5% and 61%, respectively. Excluding the $4.5 billion charge, Q1 non-GAAP gross margins would have been 71.3%, slightly above our outlook at the beginning of the quarter. Sequentially, GAAP operating expenses were up 7%, and non-GAAP operating expenses were up 6%, reflecting higher compensation and employee growth. Our investments include expanding our infrastructure capabilities and AI solutions, and we plan to grow these investments throughout the fiscal year. In Q1, we returned a record $14.3 billion to shareholders in the form of share repurchases and cash dividends. Our capital return program continues to be a key element of our capital allocation strategy.\n\n**Colette Kress** (EVP and CFO)\nLet me turn to the outlook for the second quarter. Total revenue is expected to be $45 billion, + or -2%. We expect modest sequential growth across all of our platforms. In data center, we anticipate the continued ramp of Blackwell to be partially offset by a decline in China revenue. Note, our outlook reflects a loss in H20 revenue of approximately $8 billion for the second quarter. GAAP and non-GAAP gross margins are expected to be 71.8% and 72%, respectively, + or-50 basis points. We expect better Blackwell profitability to drive modest sequential improvement in gross margins. We are continuing to work towards achieving gross margins in the mid-70s range late this year.\n\n**Colette Kress** (EVP and CFO)\nGAAP and non-GAAP operating expenses are expected to be approximately $5.7 billion and $4 billion, respectively, and we continue to expect full year fiscal year 2026 operating expense growth to be in the mid-30% range. GAAP and non-GAAP other income and expenses are expected to be an income of approximately $450 million, excluding gain and losses from non-marketable and publicly held equity securities. GAAP and non-GAAP tax rates are expected to be 16.5%, + or -1%, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website, including a new Financial Information AI agent. Let me highlight upcoming events for the financial community.\n\n**Colette Kress** (EVP and CFO)\nWe will be at the B of A Global Technology Conference in San Francisco on June 4th, the Rosenblatt Virtual AI Summit and Nasdaq Investor Conference in London on June 10th, and GTC Paris at VivaTech on June 11th in Paris. We look forward to seeing you at these events. Our earnings call to discuss the results of our second quarter of fiscal 2026 is scheduled for August 27th. Now let me turn it over to Jensen to make some remarks.\n\n**Jensen Huang** (President and CEO)\nThanks, Colette. We've had a busy and productive year. Let me share my perspective on some topics we're frequently asked. On export control, China is one of the world's largest AI markets and a springboard to global success. With half of the world's AI researchers based there, the platform that wins China is positioned to lead globally.\n\n**Jensen Huang** (President and CEO)\nToday, however, the $50 billion China market is effectively closed to U.S. industry. The H20 export ban ended our Hopper data center business in China. We cannot reduce Hopper further to comply. As a result, we are taking a multi-billion dollar write-off on inventory that cannot be sold or repurposed. We are exploring limited ways to compete, but Hopper is no longer an option. China's AI moves on with or without U.S. chips. It has to compute to train and deploy advanced models. The question is not whether China will have AI. It already does. The question is whether one of the world's largest AI markets will run on American platforms. Shielding Chinese chip makers from U.S. competition only strengthens them abroad and weakens America's position. Export restrictions have spurred China's innovation and scale. The AI race is not just about chips. It's about which stack the world runs on.\n\n**Jensen Huang** (President and CEO)\nAs that stack grows to include 6G and quantum, U.S. global infrastructure leadership is at stake. The U.S. has based its policy on the assumption that China cannot make AI chips. That assumption was always questionable, and now it's clearly wrong. China has enormous manufacturing capability. In the end, the platform that wins the AI developers wins AI. Export controls should strengthen U.S. platforms, not drive half of the world's AI talent to rivals. On DeepSeek, DeepSeek and QN from China are among the best open-source AI models. Released freely, they've gained traction across the U.S., Europe, and beyond. DeepSeek R1, like ChatGPT, introduced Reasoning AI that produces better answers the longer it thinks. Reasoning AI enables step-by-step problem-solving, planning, and tool use, turning models into intelligent agents. Reasoning is compute-intensive, requires hundreds to thousands of times more tokens per task than previous one-shot inference.\n\n**Jensen Huang** (President and CEO)\nReasoning models are driving a step-function surge in inference demand. AI scaling laws remain firmly intact, not only for training, but now inference too requires massive-scale compute. DeepSeek also underscores the strategic value of open-source AI. When popular models are trained and optimized on U.S. platforms, it drives usage, feedback, and continuous improvement, reinforcing American leadership across the stack. U.S. platforms must remain the preferred platform for open-source AI. That means supporting collaboration with top developers globally, including in China. America wins when models like DeepSeek and QN run best on American infrastructure. Regarding onshore manufacturing, President Trump has outlined a bold vision to reshore advanced manufacturing, create jobs, and strengthen national security. Future plants will be highly computerized and robotics. We share this vision. TSMC is building six fabs and two advanced packaging plants in Arizona to make chips for NVIDIA.\n\n**Jensen Huang** (President and CEO)\nProcess qualification is underway, with volume production expected by year-end. Spill and Amcor are also investing in Arizona, constructing packaging, assembly, and test facilities. In Houston, we're partnering with Foxconn to construct a million-square-foot factory to build AI supercomputers. Wistron is building a similar plant in Fort Worth, Texas. To encourage and support these investments, we've made substantial long-term purchase commitments, a deep investment in America's AI manufacturing future. Our goal: from chip to supercomputer, built in America within a year. Each GB200 NVLink 72 racks contains 1.2 million components and weighs nearly 2 tons. No one has produced supercomputers on this scale. Our partners are doing an extraordinary job. On AI diffusion rule, President Trump rescinded the AI diffusion rule, calling it counterproductive, and proposed a new policy to promote U.S. AI tech with trusted partners. On his Middle East tour, he announced historic investments.\n\n**Jensen Huang** (President and CEO)\nI was honored to join him in announcing a 500 MW AI infrastructure project in Saudi Arabia and a 5 GW AI campus in the UAE. President Trump wants U.S. tech to lead. The deals he announced are wins for America: creating jobs, advancing infrastructure, generating tax revenue, and reducing the U.S. trade deficit. The U.S. will always be NVIDIA's largest market and home to the largest installed base of our infrastructure. Every nation now sees AI as core to the next industrial revolution, a new industry that produces intelligence and essential infrastructure for every economy. Countries are racing to build national AI platforms to elevate their digital capabilities. At Computex, we announced Taiwan's first AI factory in partnership with Foxconn and the Taiwan government. Last week, I was in Sweden to launch its first national AI infrastructure.\n\n**Jensen Huang** (President and CEO)\nJapan, Korea, India, Canada, France, the U.K., Germany, Italy, Spain, and more are now building national AI factories to empower startups, industries, and societies. Sovereign AI is a new growth engine for NVIDIA. Toshiya, back to you. Thank you.\n\n**Toshiya Hari** (Head of Investor Relations)\nOperator, we will now open the call for questions. Would you please pull for questions?\n\n**Operator**\nThank you. At this time, I would like to remind everyone, in order to ask a question, press star, then the number one on your telephone keypad. We'll pause for just a moment to compile the Q&A roster. Your first question comes from the line of Joe Moore with Morgan Stanley. Your line is open.\n\n**Joe Moore** (Analyst)\nGreat. Thank you. You guys have talked about this scaling up of inference around reasoning models for at least a year now, and we've really seen that come to fruition, as you talked about. We've heard it from your customers.\n\n**Joe Moore** (Analyst)\nCan you give us a sense for how much of that demand you're able to serve? Give us a sense for maybe how big the inference business is for you guys, and do we need full-on NVL72 rack scale solutions for reasoning inference going forward?\n\n**Jensen Huang** (President and CEO)\nWe would like to serve all of it, and I think we're on track to serve most of it. Grace Blackwell, NVLink 72, is the ideal engine today, the ideal computer thinking machine, if you will, for reasoning AI. There's a couple of reasons for that. The first reason is that the token generation amount, the number of tokens reasoning goes through, is 1000 times more than a one-shot chatbot. It's essentially thinking to itself, breaking down a problem step by step. It might be planning multiple paths to an answer.\n\n**Jensen Huang** (President and CEO)\nIt could be using tools, reading PDFs, reading web pages, watching videos, and then producing a result, an answer. The longer it thinks, the better the answer, the smarter the answer is. What we would like to do, and the reason why Grace Blackwell was designed to give such a giant step up in inference performance, is so that you could do all this and still get a response as quickly as possible. Compared to Hopper, Grace Blackwell is some 40 times higher speed and throughput compared. This is going to be a huge benefit in driving down the cost while improving the quality of response with excellent quality of service at the same time. That is the fundamental reason. That was the core driving reason for Grace Blackwell NVLink 72.\n\n**Jensen Huang** (President and CEO)\nOf course, in order to do that, we had to reinvent, literally redesign the entire way that these supercomputers are built. Now we're in full production. It's going to be exciting. It's going to be incredibly exciting.\n\n**Operator**\nThe next question comes from Vivek Arya with Bank of America Securities. Your line is open.\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nThanks for the question. Just a clarification for Colette first. On the China impact, I think previously it was mentioned at about $15 billion. You had the $8 billion in Q2. Is there still some left as a headwind for the remaining quarters? Colette, how to model that? Question, Jensen, for you. Back at GTC, you had outlined a path towards almost a trillion dollars of AI spending over the next few years. Where are we in that build-out?\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nDo you think it's going to be uniform that you will see every spender, whether it's ESP, sovereigns, enterprises, or build-out? Should we expect some periods of digestion in between? Just what are your customer discussions telling you about how to model growth for next year?\n\n**Colette Kress** (EVP and CFO)\nYes, Vivek, thanks so much for the question regarding H20. Yes, we recognized $4.6 billion H20 in Q1. We were unable to ship $2.5 billion. The total for Q1 should have been $7 billion. When we look at our Q2, our Q2 is going to be meaningfully down in terms of China data center revenue. We had highlighted in terms of the amount of orders that we had planned for H20 in Q2, and that was $8 billion. Now, going forward, we did have other orders going forward that we will not be able to fulfill.\n\n**Colette Kress** (EVP and CFO)\nThat is what was incorporated, therefore, in the amount that we wrote down of the $4.5 billion. That write-down was about inventory and purchase commitments. And our purchase commitments were about what we expected regarding the orders that we had received. Going forward, though, it's a bigger issue regarding the amount of the market that we will not be able to serve. We assess that TAM to be close to about $50 billion in the future as we don't have a product to enable for the China.\n\n**Jensen Huang** (President and CEO)\nVivek, probably the best way to think through it is that AI is several things. Of course, we know that AI is this incredible technology that's going to transform every industry, from, of course, the way we do software to healthcare and financial services to retail to, I guess, every industry, transportation, manufacturing. And we're at the beginning of that.\n\n**Jensen Huang** (President and CEO)\nMaybe another way to think about that is, where do we need intelligence? Where do we need digital intelligence? Every country is in every industry. We know, because of that, we recognize that AI is also an infrastructure. It is a way of delivering a technology that requires factories. These factories produce tokens. They, as I mentioned, are important to every single industry and every single country. On that basis, we are really at the very beginning of it because the adoption of this technology is really kind of in its early stages. Now, we have reached an extraordinary milestone with AIs that are reasoning, are thinking, what people call inference time scaling. Of course, it created a whole new era. We have entered an era where inference is going to be a significant part of the compute workload. Anyhow, it is going to be a new infrastructure.\n\n**Jensen Huang** (President and CEO)\nWe're building it out in the clouds. The United States is really the early starter and available in U.S. clouds. This is our largest market, our largest installed base, and we're going to continue to see that happening. Beyond that, we're going to see AI go into enterprise, which is on-prem, because so much of the data is still on-prem. Access control is really important. It's really hard to move every company's data into the cloud. We're going to move AI into the enterprise. You saw that we announced a couple of really exciting new products, our RTX Pro enterprise AI server that runs everything enterprise and AI, our DGX Spark and DGX Station, which is designed for developers who want to work on-prem. Enterprise AI is just taking off. Telcos.\n\n**Jensen Huang** (President and CEO)\nToday, a lot of the telco infrastructure will be, in the future, software-defined and built on AI. 6G is going to be built on AI. That infrastructure needs to be built out. It is at its very, very early stages. Of course, every factory today that makes things will have an AI factory that sits with it. The AI factory is going to be creating AI and operating AI for the factory itself, but also to power the products and the things that are made by the factory. It is very clear that every car company will have AI factories. Very soon, there will be robotics companies, robot companies, and those companies will be also building AIs to drive the robots. We are at the beginning of all of this build-out.\n\n**Operator**\nThe next question comes from CJ Muse with Cantor Fitzgerald.\n\n**Operator**\nYour line is open.\n\n**CJ Muse** (Senior Managing Director)\nYeah, good afternoon. Thank you for taking the question. There have been many large GPU cluster investment announcements in the last month, and you alluded to a few of them with Saudi Arabia, the UAE, and then also we've heard from Oracle and xAI, just to name a few. My question, are there others that have yet to be announced of the same kind of scale and magnitude? Perhaps more importantly, how are these orders impacting your lead times for Blackwell and your current visibility sitting here today, almost halfway through 2025?\n\n**Jensen Huang** (President and CEO)\nWe have more orders today than we did at the last time I spoke about orders at GTC. However, we're also increasing our supply chain and building out our supply chain. They're doing a fantastic job.\n\n**Jensen Huang** (President and CEO)\nWe're building it here on shore in the United States, but we're going to keep our supply chain quite busy for many more years coming. With respect to further announcements, I'm going to be on the road next week through Europe. Just about every country needs to build out AI infrastructure, and there are umpteen AI factories being planned. I think in the remarks, Colette mentioned there's 100 AI factories being built. There's a whole bunch that haven't been announced. I think the important concept here, which makes it easier to understand, is that like other technologies that impact literally every single industry, of course, electricity was one, and it became infrastructure. Of course, the information infrastructure, which we now know as the internet, affects every single industry, every country, every society. Intelligence is surely one of those things.\n\n**Jensen Huang** (President and CEO)\nI don't know any company, industry, country who thinks that intelligence is optional. It's essential infrastructure. We've now digitalized intelligence. I think we're clearly in the beginning of the build-out of this infrastructure. Every country will have it. I'm certain of that. Every industry will use it. That I'm certain of. What's unique about this infrastructure is that it needs factories. It's a little bit like the energy infrastructure, electricity. It needs factories. We need factories to produce this intelligence. The intelligence is getting more sophisticated. We were talking about earlier that we had a huge breakthrough in the last couple of years with reasoning AI. Now there are agents that reason, and there are super agents that use a whole bunch of tools. There's clusters of super agents where agents are working with agents, solving problems.\n\n**Jensen Huang** (President and CEO)\nYou could just imagine, compared to one-shot chatbots and the agents that are now using AI built on these large language models, how much more compute-intensive they really need to be and are. I think we're in the beginning of the build-out. There should be many, many more announcements in the future.\n\n**Operator**\nYour next question comes from Ben Reitzes with Melius. Your line is open.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nYeah, hi. Thanks for the question. I wanted to ask first to Colette just a little clarification around the guidance and maybe putting it in a different way. The $8 billion for H20 just seems like it's roughly $3 billion more than most people thought with regard to what you'd be foregoing in the second quarter.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nThat would mean that with regard to your guidance, the rest of the business, in order to hit 45, is doing $2 billion-$3 billion or so better. I was wondering if that math made sense to you. In terms of the guidance, that would imply the non-China business is doing a bit better than the street expected. Wondering what the primary driver was there in your view. This second part of my question, Jensen, I know you guide one quarter at a time. With regard to the AI diffusion rule being lifted and this momentum with Sovereign, there have been times in your history where you guys have sat on calls like this where you have more conviction and sequential growth throughout the year, etc.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nGiven the unleashing of demand with AI diffusion being revoked and the supply chain increasing, does the environment give you more conviction and sequential growth as we go throughout the year? First one for Colette, and then next one for Jensen. Thanks so much.\n\n**Colette Kress** (EVP and CFO)\nThanks, Ben, for the question. When we look at our Q2 guidance and our commentary that we provided that had the export controls not occurred, we would have had orders of about $8 billion for H20. That's correct. That was a possibility for what we would have had in our outlook for this quarter in Q2. What we also have talked about here is the growth that we've seen in Blackwell, Blackwell across many of our customers, as well as the growth that we continue to have in terms of supply that we need for our customers.\n\n**Colette Kress** (EVP and CFO)\nPutting those together, that's where we came through with the guidance that we provided. I'm going to turn the rest over to Jensen to see how he wants to.\n\n**Jensen Huang** (President and CEO)\nYeah, thanks. Thanks, Ben. I would say compared to the beginning of the year, compared to GTC timeframe, there are four positive surprises. The first positive surprise is the step function demand increase of reasoning AI. I think it is fairly clear now that AI is going through an exponential growth. Reasoning AI really busted through. Concerns about hallucination or its ability to really solve problems. I think a lot of people are crossing that barrier and realizing how incredibly effective agentic AI is and reasoning AI is. Number one is inference reasoning and the exponential growth there, demand growth. The second one, you mentioned AI diffusion.\n\n**Jensen Huang** (President and CEO)\nIt's really terrific to see that the AI diffusion rule was rescinded. President Trump wants America to win. He also realizes that we're not the only country in the race. He wants the United States to win and recognizes that we have to get the American stack out to the world and have the world build on top of American stacks instead of alternatives. AI diffusion happened. The rescinding of it happened at almost precisely the time that countries around the world are awakening to the importance of AI as an infrastructure, not just as a technology of great curiosity and great importance, but infrastructure for their industries and startups and society. Just as they had to build out infrastructure for electricity and internet, you got to build out infrastructure for AI. I think that that's an awakening, and that creates a lot of opportunity.\n\n**Jensen Huang** (President and CEO)\nThe third is enterprise AI. Agents work. And these agents are really quite successful. Much more than generative AI, agentic AI is game-changing. Agents can understand ambiguous and rather implicit instructions and are able to problem-solve and use tools and have memory and so on. I think this enterprise AI is ready to take off. It's taken us a few years to build a computing system that is able to integrate and run enterprise AI stacks, run enterprise IT stacks, but add AI to it. This is the RTX Pro enterprise server that we announced at Computex just last week. Just about every major IT company has joined us and are super excited about that. Computing is one part of it. Remember, enterprise IT is really three pillars. It's compute, storage, and networking.\n\n**Jensen Huang** (President and CEO)\nWe have now put all three of them together finally, and we are going to market with that. Lastly, industrial AI. Remember, one of the implications of the world reordering, if you will, is regions onshoring manufacturing and building plants everywhere. In addition to AI factories, of course, there are new electronics manufacturing, chip manufacturing being built around the world. All of these new plants and these new factories are creating exactly the right time when Omniverse and AI and all the work that we are doing with robotics is emerging. This fourth pillar is quite important. Every factory will have an AI factory associated with it. In order to create these physical AI systems, you really have to train a vast amount of data. Back to more data, more training, more AIs to be created, more computers.\n\n**Jensen Huang** (President and CEO)\nThese four drivers are really kicking into turbocharge.\n\n**Operator**\nYour next question comes from Timothy Arcuri with UBS. Your line is open.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Jensen, I wanted to ask about China. It sounds like the July guidance assumes there's no SKU replacement for the H20. If the president wants the U.S. to win, it seems like you're going to have to be allowed to ship something into China. I guess I had two points on that. First of all, have you been approved to ship a new modified version into China? You're currently building it, but you just can't ship it in fiscal Q2. You were sort of run rating $7 billion-$8 billion a quarter into China. Can we get back to those sorts of quarterly run rates once you get something that you're allowed to ship back into China?\n\n**Timothy Arcuri** (Managing Director)\nI think we're all trying to figure out how much to add back to our models and when. Whatever you can say there would be great. Thanks.\n\n**Jensen Huang** (President and CEO)\nThe president has a plan. He has a vision, and I trust him. With respect to our export controls, it's a set of limits. The new set of limits pretty much make it impossible for us to reduce Hopper any further for any productive use. The new limits, it's kind of the end of the road for Hopper. We have limited options. The key is to understand the limits. The key is to understand the limits and see if we can come up with interesting products that could continue to serve the Chinese market. We don't have anything at the moment, but we're considering it. We're thinking about it.\n\n**Jensen Huang** (President and CEO)\nObviously, the limits are quite stringent at the moment. We have nothing to announce today. When the time comes, we'll engage the administration and discuss that.\n\n**Operator**\nYour final question comes from the line of Aaron Rakers with Wells Fargo. Your line is open.\n\n**Operator**\nHi. This is Jake On for Aaron. Thanks for taking the question and congrats on the great quarter. I was wondering if you could give some additional color around the strength you saw within the networking business, particularly around the adoption of your Ethernet solutions at CSPs, as well as any change you're seeing in network attach rates.\n\n**Jensen Huang** (President and CEO)\nYeah, thank you for that. We now have three networking platforms, maybe four. The first one is the scale-up platform to turn a computer into a much larger computer. Scaling up is incredibly hard to do.\n\n**Jensen Huang** (President and CEO)\nScaling out is easier to do, but scaling up is hard to do. That platform is called NVLink. NVLink comes with chips and switches and NVLink spines. It is really complicated. Anyways, that is our new platform, scale-up platform. In addition to InfiniBand, we also have SpectrumX. We have been fairly consistent that Ethernet was designed for a lot of traffic that are independent. In the case of AI, you have a lot of computers working together. The traffic of AI is insanely bursty. Latency matters a lot because the AI is thinking, and it wants to get work done as quickly as possible. You have a whole bunch of nodes working together. We enhanced Ethernet, added capabilities like extremely low latency, congestion control, adaptive routing, the type of technologies that were available only in InfiniBand to Ethernet.\n\n**Jensen Huang** (President and CEO)\nAs a result, we improved the utilization of Ethernet in these clusters. These clusters are gigantic, from as low as 50% to as high as 85%, 90%. The difference is if you had a cluster that's $10 billion and you improved its effectiveness by 40%, that's worth $4 billion. It's incredible. SpectrumX has been really, quite frankly, a home run in this last quarter. As we said in the prepared remarks, we added two very significant CSPs to the SpectrumX adoption. The last one is BlueField, which is our control plane.\n\n**Jensen Huang** (President and CEO)\nIn those four, the control plane, the network, which is used for storage, is used for security, and for many of these clusters that want to achieve isolation among its users, multi-tenant clusters, and still be able to use and have extremely high-performance bare metal performance, BlueField is ideal for that and is used in a lot of these cases. We have these four networking platforms. They are all growing. We are doing really well. I am very proud of the team.\n\n**Jensen Huang** (President and CEO)\nJensen, over to you.\n\n**Operator**\nThat is all the time we have for questions. Jensen and I will turn the call back to you.\n\n**Toshiya Hari** (Head of Investor Relations)\nThank you. This is the start of a powerful new wave of growth. Grace Blackwell is in full production. We are off to the races. We now have multiple significant growth engines. Inference, one's the light of workload, is surging with revenue-generating AI services.\n\n**Toshiya Hari** (Head of Investor Relations)\nAI is growing faster and will be larger than any platform shifts before, including the internet, mobile, and cloud. Blackwell is built to power the full AI lifecycle from training frontier models to running complex inference and reasoning agents at scale. Training demands continue to rise with breakthroughs in post-training and reinforcement learning and synthetic data generation. Inference is exploding. Reasoning AI agents require orders of magnitude more compute. The foundations of our next growth platforms are in place and ready to scale. Sovereign AI nations are investing in AI infrastructure like they once did for electricity and internet. Enterprise AI must be deployable on-prem and integrated with existing IT. Our RTX Pro, DGX Spark, and DGX Station enterprise AI systems are ready to modernize the $500 billion IT infrastructure on-prem or in the cloud. Every major IT provider is partnering with us.\n\n**Toshiya Hari** (Head of Investor Relations)\nIndustrial AI, from training to digital twin simulation to deployment, NVIDIA Omniverse and Isaac GR00T are powering next-generation factories and humanoid robotic systems worldwide. The age of AI is here. From AI infrastructures, inference at scale, sovereign AI, enterprise AI, and industrial AI, NVIDIA is ready. Join us at GTC Paris. I'll keynote at VivaTech on June 11, talking about quantum GPU computing, robotic factories and robots, and celebrate our partnerships building AI factories across the region. The NVIDIA band will tour France, the U.K., Germany, and Belgium. Thank you for joining us at the earnings call today. See you in Paris.\n\n**Operator**\nThis concludes today's conference call. You may now disconnect.",
        "fetched_at": "2026-02-04T16:11:39.317Z"
      },
      {
        "ticker": "NVDA",
        "title": "Yahoo Finance",
        "published_date": "Feb 26, 2025, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/NVDA/earnings/NVDA-Q4-2025-earnings_call-251681.html",
        "content": "**Operator**\nGood afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's Fourth Quarter Earnings Call. All lines have been placed on mute to prevent any background noise.\n\n**Operator**\nAfter the speakers' remarks, there will be a question and answer session. Thank you. Stuart Stecker, you may begin your conference.\n\n**Stewart Stecker** (Senior Director - IR)\nThank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the fourth quarter of fiscal twenty twenty five. With me today from NVIDIA are Jensen Wong, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the first quarter of fiscal twenty twenty six.\n\n**Stewart Stecker** (Senior Director - IR)\nThe content of today's call is NVIDIA's property. It can't be reproduced or transcribed without prior written consent. During this call, we may make forward looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10 ks and 10 q, and the reports that we may file on Form eight ks with the Securities and Exchange Commission.\n\n**Stewart Stecker** (Senior Director - IR)\nAll our statements are made as of today, 02/26/2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non GAAP financial measures and find a reconciliation of these non GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\n\n**Colette Kress** (EVP &amp; CFO)\nThanks, Stuart. Q4 was another record quarter. Revenue of $39,300,000,000 was up 12% sequentially and up 78% year on year, and above our outlook of thirty seven point five billion dollars For fiscal twenty twenty five, revenue was $130,500,000,000 up 114% in the prior year. Let's start with data center. Data center revenue for fiscal twenty twenty five was $115,200,000,000 more than doubling from the prior year.\n\n**Colette Kress** (EVP &amp; CFO)\nIn the fourth quarter, data center revenue of $35,600,000,000 was a record of 16% sequentially and 93% year on year. As the Blackwell ramp commenced and Hopper 200 continued sequential growth. In Q4, Blackwell sales exceeded our expectations. We delivered $11,000,000,000 of Blackwell revenue to meet strong demand. This is the fastest product ramp in our company's history, unprecedented in its speed and scale.\n\n**Colette Kress** (EVP &amp; CFO)\nBlackwell production is in full gear across multiple configurations and we are increasing supply quickly, expanding customer adoption. Our Q4 data center compute revenue jumped 18% sequentially and over 2X year on year. Customers are racing to scale infrastructure to train the next generation of cutting edge models and unlock the next level of AI capabilities. With Blackwell, it will be common for these clusters to start with 100,000 GPUs or more. Shipments have already started for multiple infrastructures of this size.\n\n**Colette Kress** (EVP &amp; CFO)\nPost training and model customization are fueling demand for NVIDIA infrastructure and software as developers and enterprises leverage techniques such as fine tuning, reinforcement learning and distillation to tailor models for domain specific use cases. Hugging Face alone hosts over 90,000 derivatives created from the LAMA Foundation model. The scale of post training and model customization is massive and can collectively demand orders of magnitude more compute than pre training. Our inference demand is accelerating, driven by test time scaling and new reasoning models like OpenAI's O3, DeepSeq R1 and GROC3. Long thinking reasoning AI can require 100 X more compute per task compared to one shot inferences.\n\n**Colette Kress** (EVP &amp; CFO)\nBlackwell was architected for reasoning AI inference. Blackwell supercharges reasoning AI models with up to 25 X higher token throughput and 20 X lower cost versus hover 100. It is revolutionary. Transformer engine is built for LLM and mixture of experts infants. And its NVLink domain delivers 14 X the throughput of PCIe Gen five, ensuring the response time, throughput and cost efficiency needed to tackle the growing complexity of inference at scale.\n\n**Colette Kress** (EVP &amp; CFO)\nCompanies across industries are tapping into NVIDIA's full stack inference platform to boost performance and slash costs. Now tripled inference throughput and cut costs by 66% using NVIDIA TensorRT for its screenshot feature. Perplexity sees four thirty five million monthly queries and reduced its inference costs 3 X with NVIDIA Triton Inference Server and TensorRT LLM. Microsoft Bing achieved a five x speed up and major TCO savings for visual search across billions of images with NVIDIA, TensorRT and acceleration libraries. Blackwell has great demand for inference.\n\n**Colette Kress** (EVP &amp; CFO)\nMany of the early GB200 deployments are earmarked for inference, a first for a new architecture. Blackwell addresses the entire AI market from pre training, post training to inference across clouds to on premise to enterprise. CUDA's programmable architecture accelerates every AI model and over 4,400 applications, ensuring large infrastructure investments against obsolescence in rapidly evaluating markets. Our performance and pace of innovation is unmatched. We're driven to a 200X reduction in inference cost in just the last two years.\n\n**Colette Kress** (EVP &amp; CFO)\nWe delivered the lowest TCO and the highest ROI. And full stack optimizations for NVIDIA and our large ecosystem, including 5,900,000 developers continuously improve our customers' economics. In Q4, large CSPs represented about half of our data center revenue. And these sales increased nearly 2X year on year. Large CSPs were some of the first to stand up Blackwell with Azure, GCP, AWS and OCI bringing GB200 systems to cloud regions around the world to meet surging customer demand for AI.\n\n**Colette Kress** (EVP &amp; CFO)\nRegional cloud hosting NVIDIA GPUs increased as a percentage of data center revenue, reflecting continued AI factory build outs globally and rapidly rising demand for AI reasoning models and agents. Or we've launched a 100,000 GV200 cluster based instance with NVLink switch and Quantum two InfiniBand. Consumer Internet revenue grew 3X year on year, driven by an expanding set of generative AI and deep learning use cases. These include recommender systems, vision language understanding, synthetic data generation search and agentic AI. For example, XAI is adopting the GB200 to train and inference its next generation of GROG AI models. Meta's cutting edge Andromeda advertising engine runs on NVIDIA's Grace Hopper Superchip, serving vast quantities of ads across Instagram, Facebook applications. Andromeda harnesses Grace Hopper's fast interconnect and large memory to boost inference throughput by three X, enhance ad personalization and deliver meaningful jumps in monetization and ROI. Enterprise revenue increased nearly 2X year on accelerating demand for model fine tuning, RAG and agentic AI workflows and GPU accelerated data processing. We introduced NVIDIA llama Numeron model family NIMS to help developers create and deploy AI agents across a range of applications, including customer support, fraud detection and product supply chain and inventory management.\n\n**Colette Kress** (EVP &amp; CFO)\nLeading AI agent platform providers, including SAP and ServiceNow, are among the first to use new models. Healthcare leaders IQVIA, Illumina and Mayo Clinic are well, as ARC Institute, are using NVIDIA AI to speed drug discovery, enhance genomic research and pioneer advanced healthcare services with generative and agentic AI. As AI expands beyond the digital world, NVIDIA infrastructure and software platforms are increasingly being adopted to power robotics and physical AI development. One of the early and largest robotics applications and autonomous vehicles where virtually every AV company is developing on NVIDIA in the data center, the car or Bulls. NVIDIA's automotive vertical revenue is expected to grow to approximately $5,000,000,000 this fiscal year.\n\n**Colette Kress** (EVP &amp; CFO)\nAt CES, at CES, Hyundai Motor Group announced it is adopting NVIDIA technologies to accelerate AV and robotics development and smart factory initiatives. Vision transformers, self supervised learning, multimodal sensor fusion and high fidelity simulation are driving breakthroughs in AB development and will require 10X more compute. At TEDx, we announced the NVIDIA Cosmo World Foundation Model Platform. Just as language foundation models have revolutionized language AI, Cosmos is a physical AI to revolutionize robotics. The robotics and automotive companies, including ride sharing giant Uber, are among the first to adopt the platform.\n\n**Colette Kress** (EVP &amp; CFO)\nFrom a geographic perspective, sequential growth in our data center revenue was strongest in The US, driven by the initial ramp of BlackRock. Countries across the globe are building their AI ecosystems and demand for compute infrastructure is surging. France's Two Hundred Billion Euro AI investment and the EU's two hundred billion euros Invest AI initiatives offer a glimpse into the build out to set redefined global AI infrastructure in the coming years. Now, as a percentage of total data center revenue, data center sales in China remained well below levels seen on the onset of export controls. Absent any change in regulations, we believe that China shipments will remain roughly at the current percentage.\n\n**Colette Kress** (EVP &amp; CFO)\nThe market in China for data center solutions remains very competitive. We will continue to comply with export controls while serving our customers. Networking revenue declined 3% sequentially. Our networking attached to GPU compute systems is robust at over 75%. We are transitioning from small NVLink eight with InfiniBand to large NVLink 72 with SpectrumX.\n\n**Colette Kress** (EVP &amp; CFO)\nSpectrumX and NVLink switch revenue increased and represents a major new growth sector. We expect networking to return to growth in Q1. AI requires a new class of networking. NVIDIA offers NVLink switch systems for scale up compute. For scale out, we offer Quantum InfiniBand for HPC supercomputers and SpectrumX for Ethernet environments.\n\n**Colette Kress** (EVP &amp; CFO)\nSpectrumX enhances the Ethernet for AI computing and has been a huge success. Microsoft Azure, OCI, CoreWeave and others are building large AI factories with SpectrumX. The first Stargate data centers will use SpectrumX. Yesterday, Cisco announced integrating SpectrumX into their networking portfolio to help enterprises build AI infrastructure. With its large enterprise footprint and global reach, Cisco will bring NVIDIA Ethernet to every industry.\n\n**Colette Kress** (EVP &amp; CFO)\nNow, moving to gaming and AI PCs. Gaming revenue of $2,500,000,000 decreased 22% sequentially and 11% year on year. Full year revenue of $11,400,000,000 increased 9% year on year. And demand remained strong throughout the holiday. However, Q4 shipments were impacted by supply constraints.\n\n**Colette Kress** (EVP &amp; CFO)\nWe expect strong sequential growth in Q1 as supply increases. The new GeForce RTX 50 series desktop and laptop GPUs are here. Built for gamers, creators and developers, they fuse AI and graphics redefining visual computing. Powered by the Blackwell architecture, fifth generation tensor cores and fourth generation RT cores, and featuring up to 3,400 AI top. These GPUs deliver a 2x performance leap and new AI driven rendering, including neural shaders, digital human technologies, geometry and lighting.\n\n**Colette Kress** (EVP &amp; CFO)\nThe new DLSS four boosts frame rates up to 8x with AI driven frame generation, turning one rendered frame into three. It also features the industry's first real time application of transformer models, packing 2x more parameters and 4x the compute for unprecedented visual fidelity. We also announced a wave of GeForce Blackwell laptop GPUs with new NVIDIA Max Q technology that extends battery life by up to an incredible 40%. These laptops will be available starting in March from the world's top manufacturers. Moving to our professional visualization business.\n\n**Colette Kress** (EVP &amp; CFO)\nRevenue of $511,000,000 was up 5% sequentially and 10% year on year. Full year revenue of $1,900,000,000 increased 21% year on year. Key industry verticals driving demand include automotive and healthcare. NVIDIA technologies and generative AI are reshaping design, engineering and simulation workloads. Increasingly, these technologies are being leveraged in leading software platforms from ANSYS, Cadence and Siemens, fueling demand for NVIDIA RTX workstation.\n\n**Colette Kress** (EVP &amp; CFO)\nNow moving to automotive. Revenue was a record $570,000,000 up 27% sequentially and up 103% year on year. Full year revenue of 1,700,000,000 increased 55% year on year. Strong growth was driven by the continued ramp in autonomous vehicles, including cars and robotaxis. At CES, we announced Toyota, the world's largest automaker, will build its next generation vehicles on NVIDIA Orin, running the safety certified NVIDIA DRIVE OS.\n\n**Colette Kress** (EVP &amp; CFO)\nWe announced Aurora and Continental will deploy driverless trucks at scale powered by NVIDIA DRIVE four. Finally, our end to end autonomous vehicle platform NVIDIA DRIVE Hyperion has passed industry safety assessments by Toussud and Toussud Ryland, two of the industry's foremost authorities for automotive grade safety and cybersecurity. NVIDIA is the first AV platform to receive a comprehensive set of third party assessments. Okay. Moving to the rest of the P and L.\n\n**Colette Kress** (EVP &amp; CFO)\nGAAP gross margins was 73% and non GAAP gross margins were 73.5%, down sequentially as expected with our first deliveries of the Blackwell architecture. As discussed last quarter, Blackwell is a customizable AI infrastructure with several different types of NVIDIA build chips, multiple networking options and for air and liquid cooled data center. We exceeded our expectations in Q4 in ramping Blackwell, increasing system availability, providing several configurations to our customers. As Blackwell ramps, we expect gross margins to be in the low 70s. We initially, we are focused on expediting the manufacturing of Blackwell systems to meet strong customer demand as they race to build out Blackwell infrastructure.\n\n**Colette Kress** (EVP &amp; CFO)\nWhen fully ramped, we have many opportunities to improve the cost and gross margin will improve and return to the mid-70s late this fiscal year. Sequentially, GAAP operating expenses were up 9% and non GAAP operating expenses were 11%, reflecting higher engineering development costs and higher compute and infrastructure costs for new product introductions. In Q4, we returned 8,100,000,000 to shareholders in the form of share repurchases and cash dividends. Let me turn to the outlook in the first quarter. Total revenue is expected to be $43,000,000,000 plus or minus 2%.\n\n**Colette Kress** (EVP &amp; CFO)\nContinuing with its strong demand, we expect a significant ramp of Blackwell in Q1. We expect sequential growth in both data center and gaming. Within data center, we expect sequential growth from both compute and networking. GAAP and non GAAP gross margins are expected to be 70.671% respectively, plus or minus 50 basis points. GAAP and non GAAP operating expenses are expected to be approximately $5,200,000,000 and $3,600,000,000 respectively.\n\n**Colette Kress** (EVP &amp; CFO)\nWe expect full year fiscal year 2026 operating expenses to grow to be in the mid-30s. GAAP and non GAAP other income and expenses are expected to be an income of approximately $400,000,000 excluding gains and losses from non marketable and publicly held equity securities. GAAP and non GAAP tax rates are expected to be 17% plus or minus 1% excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR website, including a new financial information AI agent. In closing, let me highlight upcoming events for the financial community.\n\n**Colette Kress** (EVP &amp; CFO)\nWe will be at the TD Cowen Healthcare Conference in Boston on March 3, and at the Morgan Stanley Technology, Media and Telecom Conference in San Francisco on March 5. Please join us for our annual GTC conference starting Monday, March 17 in San Jose, California. Jensen will deliver a news packed keynote on March 18, and we will host a Q and A session for our financial analysts the next day, March 19. We look forward to seeing you at these events. Our earnings call to discuss the results for our first quarter of fiscal twenty twenty six is scheduled for 05/28/2025.\n\n**Colette Kress** (EVP &amp; CFO)\nWe are going to open up the call, operator, to questions. If you could start that, that would be great.\n\n**Operator**\nAnd your first question comes from C. J. Muse with Cantor Fitzgerald. Please go ahead.\n\n**CJ Muse** (Senior Managing Director)\nYes. Good afternoon. Thank you for taking the question. I guess, for me, Judson, as tough comp computing reinforcement learning shows such promise, we're clearly seeing increasing blurring in the lines between training and inference. What does this mean for the potential future of potentially inference dedicated clusters?\n\n**CJ Muse** (Senior Managing Director)\nAnd how do you think about the overall impact to NVIDIA and your customers? Thank you.\n\n**Jensen Huang** (President &amp; CEO)\nYes, I appreciate that, CJ. There are now multiple scaling laws. There's the pre training scaling law. And that's going to continue to scale because we have multi modality, we have, data that came from, reasoning that are now used to, do pretraining. And then the second is post training scaling law using reinforcement learning human feedback, reinforcement learning AI feedback, reinforcement learning verifiable rewards.\n\n**Jensen Huang** (President &amp; CEO)\nThe amount of computation you use for post training is actually higher than pre training. And it's kind of sensible in the sense that you could, while you're using reinforcement learning, generate an enormous amount of synthetic data or synthetically generated tokens. AI models are basically generating tokens to train AI models. And that's post training. And the third the third part, this is the part that you mentioned, is test time compute or reasoning, long thinking, inference scaling.\n\n**Jensen Huang** (President &amp; CEO)\nThey're all basically the same ideas. And there is you have chain of thought, you have search. The amount of tokens generated, the amount of inference compute needed is already a hundred times more than the one shot examples and the one shot capabilities of large language models in the beginning. And that's just the beginning. This is just the beginning.\n\n**Jensen Huang** (President &amp; CEO)\nThe idea that, the next generation could have thousands times and even hopefully, extremely thoughtful and simulation based and search based models that could be hundreds of thousands, millions of times, more compute than today, is, is, in our future. And so, so the question is how do you design such an architecture? Some of it some of the models are autoregressive, some of the models are diffusion based, Some of it some of the times you want your, data center to have disaggregated inference, sometimes it's compacted. And so, it's hard to it's hard to figure out, what is the best configuration of a data center, which is the reason why NVIDIA's architecture is so popular. We run every model.\n\n**Jensen Huang** (President &amp; CEO)\nWe are great at training. The vast majority of our compute today is actually inference. And Blackwell takes all of that to a new level. We designed Blackwell with the idea of reasoning models in mind. And when you look at training, it's many times more performant.\n\n**Jensen Huang** (President &amp; CEO)\nBut what's really amazing is for long thinking, test time scaling, reasoning AI models were tens of times faster, 25 times higher throughput. And so, Blackwell is going to be incredible across the board. And when you have a data center that allows you to, configure and use your data center, based on are you doing more pre training now, post training now, or scaling out your inference, our architecture is fungible and easy to use, in all of those different ways. And so, we're seeing in fact much, much more concentration of a unified architecture than ever before.\n\n**Operator**\nYour next question comes from the line of Joe Moore with JPMorgan. Please go ahead.\n\n**Joe Moore** (Analyst)\nGood morning, Stanley, actually. Thank you. I wonder if you could talk about GB200 at CES. You sort of talked about the complexity of the rack level systems and the challenges you have. And then as you said in the prepared remarks, we've seen a lot of general availability.\n\n**Joe Moore** (Analyst)\nWhere are you in terms of that ramp? Are there still bottlenecks to consider at a systems level above and beyond the chip level? And just have you maintained your enthusiasm for the NVL 72 platforms?\n\n**Jensen Huang** (President &amp; CEO)\nWell, I'm more enthusiastic today than I was at CES. And the reason for that is because we've shipped a lot more to CES. We have some three fifty plants, manufacturing the 1,500,000 components that go into each one of the Blackwell racks, Grace Blackwell racks. Yes, it's extremely complicated and, we successfully, and incredibly ramped up Grace Blackwell, delivering some $11,000,000,000 in revenues last quarter. We're going to have to continue to scale as demand is quite high and customers are anxious and impatient to get their Blackwell systems.\n\n**Jensen Huang** (President &amp; CEO)\nYou've probably seen on the web a fair number of celebrations about Grace Blackwell systems coming online. And we have them, of course, we have a fairly large installation of Grace Blackwell's for our own engineering and our own design teams and software teams. CoreWeave has now, been quite public about the successful bring up of theirs. Microsoft has. Of course, OpenAI has.\n\n**Jensen Huang** (President &amp; CEO)\nAnd you're starting to see many, many come online. And, so, I think the answer to your question is, nothing is easy about what we're doing, but we're doing great. And, all of our partners are doing great.\n\n**Operator**\nYour next question comes from the line of Vivek Arya with Bank of America Securities. Please go ahead.\n\n**Vivek Arya** (Managing Director)\nThank you for taking my question. Could I just you wouldn't mind confirming if Q1 is the bottom for gross margin? And then, Jensen, my question is for you. What is on your dashboard to give you the confidence that the strong demand can sustain into next year? And has DeepSeek and whatever innovations they came up with, has that changed that view in any way? Thank you.\n\n**Colette Kress** (EVP &amp; CFO)\nLet me first take the first part of the question, there regarding the gross margin. During our Blackwell ramp, our gross margins, will be in the low 70s. At this point, we are focusing on expediting our manufacturing, expediting our manufacturing to make sure that we can provide the customers as soon as possible. Our Blackwell has fully ramped, and once it does I'm sorry, once our Blackwell fully ramps, we can improve our cost and our gross margin. So we expect to probably be in the mid-70s later this year.\n\n**Colette Kress** (EVP &amp; CFO)\nYou know, walking through what you heard, Johnson speak about the systems and their complexity, they are customizable in some cases. They've got multiple networking options. They have liquid cooled and water cooled. So we know there is an opportunity for us to improve these gross margins going forward. But right now, we are going to focus on getting the manufacturing complete and to our customers as soon as possible.\n\n**Jensen Huang** (President &amp; CEO)\nWe know several things, Vivek. We have a fairly good line of sight of the amount of capital investment that data centers are building out towards. We know that going forward, the vast majority of software is going to be based on machine learning. And so accelerated computing and generative AI, reasoning AI, are going to be the type of architecture you want in your data center. We have, of course, forecasts and plans from our top partners.\n\n**Jensen Huang** (President &amp; CEO)\nAnd, we also know that there are many innovative, really exciting startups that are still coming online as new opportunities for developing the next breakthroughs in AI, whether it's agentic AIs, reasoning AIs, or physical AIs. The number of startups are still quite vibrant and each one of them need a fair amount of computing infrastructure. And so, I think the whether it's the near term signals or the midterm signals near term signals, of course, are POs and forecasts and things like that. Midterm signals would be, the level of infrastructure and CapEx scale out compared to previous years. And then the long term signals has to do with the fact that we know fundamentally software has changed from hand coding that runs on CPUs to machine learning and AI based software that runs on GPUs and accelerated computing systems.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, we have a fairly good sense that this is the future of software. And then maybe as you roll it out, another way to think about that is, we've really only tapped consumer, AI and search and some amount of consumer generative AI. Advertising, recommenders, kind of the early days of software. The next wave's coming. Agentic AI for enterprise, physical AI for robotics, and, Sovereign AI as different regions build out their AI for their own ecosystems.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, each one of these are fairly off the ground and we can see them. We can see them because, obviously, we're in the center of much of this development and we can see great activity happening in all these different places and these will happen. So near term, mid term, long term.\n\n**Operator**\nYour next question comes from the line of Harlan Sur with JPMorgan. Please go ahead.\n\n**Harlan Sur** (Executive Director - Equity Research)\nYes, good afternoon. Thanks for taking my question. Your next generation Blackwall Ultra set to launch in the second half of this year, in line with the team's annual product cadence. Jensen, can you help us understand the demand dynamics for Ultra, given that you'll still be ramping the current generation Blackwell solutions? How do your customers and the supply chain also manage the simultaneous ramps of these two products?\n\n**Harlan Sur** (Executive Director - Equity Research)\nAnd is the team still on track to execute Blackwell Ultra in the second half of this year?\n\n**Jensen Huang** (President &amp; CEO)\nYes. Blackwell Ultra is second half. As you know, the first Blackwell was, we had a hiccup that probably cost us a couple of months. We're fully recovered, of course. The team did an amazing job recovering.\n\n**Jensen Huang** (President &amp; CEO)\nAnd all of our supply chain partners and just so many people helped us recover at the speed of light. And so now we've successfully ramped production of Blackwell. But that doesn't stop the next train. The next train is on an annual rhythm and Blackwell Ultra with new networking, new memories and, of course, new processors. And all of that is coming online.\n\n**Jensen Huang** (President &amp; CEO)\nWe've been working with all of our partners and customers laying this out. They have all of the necessary information and we'll work with everybody to do the proper transition. This time between Blackwell and Blackwell Ultra, the system architecture is exactly the same. It's a lot harder going from Hopper to Blackwell because we went from an NVLink eight system to a NVLink 72 based system. So the chassis, the architecture of the system, the hardware, the power delivery, all of that had to change.\n\n**Jensen Huang** (President &amp; CEO)\nThis was quite a challenging transition. But the next transition will slot right in, right? Blackwall Ultra will slot right in. We've also already revealed and been working very closely with all of our partners on the click after that. And the click after that is called Verarubin.\n\n**Jensen Huang** (President &amp; CEO)\nAnd, all of our partners are, getting up to speed on, on the transition of that. And so preparing for that transition. And again, we're going to provide a big, big, huge step up. And so come to GCC and I'll talk to you about Blackwell Ultra, Verarubin and then show you what's the one click after that. Really exciting new products. So come to GTC, please.\n\n**Operator**\nYour next question comes from the line of Timothy Arcuri with UBS. Please go ahead.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Jensen, we hear a lot about custom ASICs. Can you kind of speak to the balance between custom ASIC and merchant GPU? We hear about some of these heterogeneous superclusters to use both GPU and ASIC. Is that something customers are planning on building or will these infrastructures remain fairly distinct? Thanks.\n\n**Jensen Huang** (President &amp; CEO)\nWell, we build very different things than ASICs, in some ways completely different in some areas we intersect. We're different in several ways. One, NVIDIA's architecture is general. Whether you're you've optimized for autoregressive models or diffusion based models or vision based models or multimodal models or text models, we're great at all of it. We're great at all of it because our software stack is so our architecture is flexible, our software stack is ecosystem is so rich that we're the initial target of most exciting innovations and algorithms.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, by definition, we're much, much more general than narrow. We're also, really good from the end to end, from data processing, the curation of the training data to, the training of the data, of course, to reinforcement learning, used in post training all the way to inference with test time scaling. So, we're general, we're end to end and we're everywhere. And because we're not in just one cloud, we're in every cloud, we could be on prem, we could be in a robot. Our architecture is much more accessible and a great target initial target for anybody who's starting up a new company.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, we're everywhere. And then the third thing I would say is that our performance and our rhythm is so incredibly fast. Remember that these data centers are always fixed in size. They're fixed in size or they're fixed in power. And if our performance per watt is anywhere from 2x to 4x to 8x, which is not unusual, it translates directly to revenues.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, if you have a 100 megawatt data center, if the performance or the throughput in that 100 megawatt or that gigawatt data center is four times or eight times higher, your revenues for that gigawatt data center is eight times higher. And the reason that is so different than data centers of the past is because AI factories are directly monetizable through its tokens generated. And so the token throughput of our architecture being so incredibly fast is just incredibly valuable to all of the companies that are building these things for revenue generation reasons and capturing the fast ROIs. And so, I think the third reason is performance. And then, the last thing that I would say is the software stack is incredibly hard.\n\n**Jensen Huang** (President &amp; CEO)\nBuilding an ASIC is no different than what we do. We have to build a new architecture. And the ecosystem that sits on top of our architecture is 10 times more complex today than it was two years ago. And that's fairly obvious because the amount of software that the world is building on top of architecture is growing exponentially and AI is advancing very quickly. So bringing that whole ecosystem on top of multiple chips is hard.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so I would say that those four reasons. And then finally, I will say this, just because the chip is designed doesn't mean it gets deployed. And you've seen this over and over again. There are a lot of chips that gets built. But when the time comes, a business decision has to be made.\n\n**Jensen Huang** (President &amp; CEO)\nAnd that business decision is about deploying a new engine, a new processor into a limited AI factory in size, in power and in time. And our technology, is not only more advanced, more performant, it has much, much better software capability. And very importantly, our ability to deploy is lightning fast. And so, these things are not for the faint of heart as everybody knows now. And so, there's a lot of different reasons why we do well, why we win.\n\n**Operator**\nYour next question comes from the line of Ben Reitz with Melius Research. Please go ahead.\n\n**Ben Reitzes** (Managing Director  Head of Technology Research)\nYes. Hi, Ben Reitz is here. Hey, thanks a lot for the question. Hey, Jensen, it's a geography related question. You did a great job explaining some of the demand underlying factors here on the strength.\n\n**Ben Reitzes** (Managing Director  Head of Technology Research)\nBut U. S. Was up about $5,000,000,000 or so sequentially. And I think there is a concern about whether U. S.\n\n**Ben Reitzes** (Managing Director  Head of Technology Research)\nCan pick up the slack if there's regulations towards other geographies. And I was just wondering as we go throughout the year, if this kind of surge in The U. S. Continues and it's going to be, whether that's okay and if that underlies your growth rate, how can you keep growing so fast with this mix shift towards The U. S?\n\n**Ben Reitzes** (Managing Director  Head of Technology Research)\nYour guidance looks like China is probably up sequentially. So just wondering if you could go through that dynamic and maybe Colette can weigh in? Thanks a lot.\n\n**Jensen Huang** (President &amp; CEO)\nChina is approximately the same percentage as Q4 and as, in previous quarters. It's about half of what it was before the export control. But it's approximately the same in percentage. With respect to geographies, the takeaway is that AI is software. It's modern software.\n\n**Jensen Huang** (President &amp; CEO)\nIt's incredible modern software, but it's modern software and AI has gone mainstream. AI is used in delivery services everywhere, shopping services everywhere. You know, if you were to buy, you know, a quarter of milk is delivered to you, AI was involved. And so, almost everything that a consumer service, provides, AI's at the core of it. Every every student will use AI as a tutor.\n\n**Jensen Huang** (President &amp; CEO)\nHealthcare services use AI. Financial services use AI. No fintech company will not use AI. Every fintech company will. Climate tech company use AI.\n\n**Jensen Huang** (President &amp; CEO)\nMineral discovery now uses AI. The number of the number of at every higher education, every university, uses AI. And so, I think it is fairly safe to say that AI has gone mainstream, that it's being integrated into every application. And our hope is that, of course, the technology continues to advance, safely and advance in a helpful way to society. And with that, we're, I do believe that we're at the beginning of this new transition.\n\n**Jensen Huang** (President &amp; CEO)\nAnd what I mean by that in the beginning is remember behind us has been decades of data centers and decades of computers that have been built. And they've been built for a world of hand coding and general purpose computing and, CPUs and so on and so forth. And going forward, I think it's fairly safe to say that that world is going to be almost all software will be infused with AI. All software and all services will be based on ultimately based on machine learning and the data flywheel is going to be part of improving software and services, and that the future computers will be accelerated. The future computers will be based on AI.\n\n**Jensen Huang** (President &amp; CEO)\nAnd we're really two years into that journey. And in modernizing computers that have taken decades to build out. And so I'm fairly sure that we're in the beginning of this new era. And then lastly, no technology has ever had the opportunity to address a larger part of the world's GDP than AI. No software tool ever has.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, this is now a software tool that can address a much larger part of the world's GDP more than any time in history. And so, the way we think about growth and the way we think about whether something is big or small has to be in the context of that. And, when you take a step back and look at it from that perspective, we're really just in the beginnings.\n\n**Operator**\nYour next question comes from the line of Aaron Rakers with Wells Fargo. Please go ahead. Aaron, your line is open. Your next question comes from Mark Lupacis with Evercore ISI. Please go ahead.\n\n**Mark Lipacis** (Senior Managing Director)\nHi, that's Mark Matapasas. Thanks for taking the question.\n\n**Mark Lipacis** (Senior Managing Director)\nI had a clarification and a question. Colette, up for the clarification. Did you say that enterprise within the data center grew 2x year on year for the January? And if so, does that would that make it faster going than the hyperscalers? And then, Jensen, for you, the question, hyperscalers are the biggest purchasers of your solutions, but they buy equipment for both internal and external workloads, external workloads being cloud services that enterprises use.\n\n**Mark Lipacis** (Senior Managing Director)\nSo, the question is, can you give us a sense of how that hyperscale expense splits between that external workload and internal? And as these new AI workloads and applications come up, would you expect enterprises to become a larger part of that consumption mix and decide to impact how you develop your, service your ecosystem? Thank you.\n\n**Colette Kress** (EVP &amp; CFO)\nSure. Thanks for the question regarding, our enterprise business. Yes, it grew 2x and very similar to what we were seeing, with our large CSPs. Keep in mind, these are both important, areas to understand. Working with the CSPs can be, working on large language models, can be working on inference in their own work.\n\n**Colette Kress** (EVP &amp; CFO)\nBut keep in mind, that is also where the enterprises are surfacing. Your enterprises are both with your CSPs as well as in terms of, building on their own. They're both growing quite, quite well.\n\n**Jensen Huang** (President &amp; CEO)\nThe CSPs are about half of our business. And, and, the CSPs have internal consumption and external consumption, as you say. And we're using of course, used for internal consumption. We we work very closely with all of them to optimize workloads that are internal to them, because they have a large infrastructure of NVIDIA gear that they could take advantage of. And the fact that we could be used for AI on the one hand, video processing on the other hand, data processing like Spark, were fungible.\n\n**Jensen Huang** (President &amp; CEO)\nAnd so, the useful life of our infrastructure is much better. If the useful life is much longer, then the TCO is also lower. And so, the second part is how do we see the growth of enterprise or not CSPs, if you will, going forward? And the answer is, I believe long term it is by far larger. And the reason for that is because if you look at the computer industry today, and what is not served by the computer industry is largely industrial.\n\n**Jensen Huang** (President &amp; CEO)\nSo, So let me give you an example. When we say enterprise, and let's say let's use a car company as an example because they make both soft things and hard things. And so in the case of a car company, the employees would be what we call enterprise. And agentic AI and software planning systems and tools and we have some really exciting things to share with you guys at GTC, those agentic systems are for employees to make employees more productive, to design, to market, to plan, to operate their company. That's agentic AIs.\n\n**Jensen Huang** (President &amp; CEO)\nOn the other hand, the cars that they manufacture also need AI. They need an AI system that trains the cars, treats this entire giant fleet of cars. And today, there's a billion cars on the road. Someday, there'd be a billion cars on the road and every single one of those cars will be robotic cars. And they'll all be collecting data and we'll be improving them, using an AI factory.\n\n**Jensen Huang** (President &amp; CEO)\nWhereas they have a car factory today, in the future they'll have a car factory and an AI factory. And then inside the car itself is a robotic system. And so, as you can see, there are three computers involved. And there's the computer that helps the people, there's the computer that builds the AI for, the machineries, it could be, of course, it could be a tractor, it could be a lawnmower, it could be a humanoid robot that's being developed today, it could be a building, it could be a warehouse. These physical systems require a new type of AI we call physical AI.\n\n**Jensen Huang** (President &amp; CEO)\nThey can't just understand the meaning of words and languages, but they have to understand the meaning of the world. Friction and inertia, object permanence and cause and effect and all of those type of things that are common sense to you and I, but, you know, AIs have to go learn those physical effects. So, we call that physical AI. That whole part of using Agentic AI to revolutionize the way we work inside companies, that's just starting. This is now the beginning of the agentic AI era and you hear a lot of people talking about it and we've got some really great things going on.\n\n**Jensen Huang** (President &amp; CEO)\nAnd then there's the physical AI after that and then there are robotic systems after that. And so, these three computers are all brand new. And my sense is that long term this will be by far a larger of them all, which kind of makes sense. The world of the world's GDP is representing represented by either heavy industries or industrials and companies that are providing for those.\n\n**Operator**\nYour next question comes from the line of Aaron Rickers with Wells Fargo. Please go ahead.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nYes. Thanks for letting me back in. Jensen, I'm curious as we now approach the two year anniversary of really the Hopper inflection that you saw in 2023 and Gen AI in general and we think about the roadmap you have in front of us, how do you think about the infrastructure that's been deployed from a replacement cycle perspective and whether if it's GB300 or if it's the Ruben cycle where we start to see maybe some refresh opportunity. I'm just curious to how you look at that.\n\n**Jensen Huang** (President &amp; CEO)\nI appreciate it. First of all, people are still using Voltas and Pascals and Amperes. And the reason for that is because there are always, things that because CUDA is so programmable, you could use it right well, one of the major use cases right now is data processing and data curation. You find a circumstance that an AI model is not very good at. You present that circumstance to a vision language model, let's say.\n\n**Jensen Huang** (President &amp; CEO)\nLet's say it's a car. You present that circumstance to a vision language model. The vision language model actually looks at the circumstances and says, this is what happened and, I wasn't very good at it. You then take that response, the prompt, and you go and prompt an AI model to go find in your whole link of data, other circumstances like that, whatever that circumstance was. And then you use an AI to do, domain randomization and generate a whole bunch of other examples.\n\n**Jensen Huang** (President &amp; CEO)\nAnd then from that, you can go train the model. And so, you could use the the amperes, to go and do data processing and data curation and machine learning based search. And then you create the training dataset which you then present to your hopper systems for training. And so, each one of these architectures are completely they're all CUDA compatible and so everything runs on everything. But if you have infrastructure in place, then you can put the less intensive workloads onto the installed base of the past. All of our CPUs are very well employed.\n\n**Operator**\nWe have time for one more question. And that question comes from Atif Malik with Citi. Please go ahead.\n\n**Atif Malik** (Analyst)\nHi. Thank you for taking my question. I have a follow-up question on gross margins for Colette. Colette, I understand there are many moving parts, the BlackBull yields and ELink 72 and Ethernet mix. And you kind of tiptoed the earlier question if April is the bottom.\n\n**Atif Malik** (Analyst)\nBut second half would have to ramp like 200 basis points per quarter to get to the mid-70s range that you're giving, for the end of the fiscal year. And we still don't know much about tariffs impact to broader semiconductor. So what kind of gives you the confidence in that trajectory in the back half of this year?\n\n**Colette Kress** (EVP &amp; CFO)\nYeah. Thanks for the question. Our gross margins, they're quite complex in terms of the material and everything that we put together in a Blackwell system. Tremendous amount of opportunity to look at a lot of different pieces of that on how we can better improve our gross margins over time. Remember, we have many different configurations as well, on Blackwell that will be able to help us do that.\n\n**Colette Kress** (EVP &amp; CFO)\nSo, together, working, after we get some of these really strong ramping completed for our customers, we can begin a lot of that work. If not, we're going to probably start as soon as possible if we can. And if we can improve it in the short term, we will also do that. Tariffs, at this point, it's a little bit of an unknown. It's an unknown until we understand further, what the U.\n\n**Colette Kress** (EVP &amp; CFO)\nS. Government's plan is, both its timing, its where and how much. So, at this time, we are awaiting. But again, we would, of course, always follow, export controls and or tariffs in that manner.\n\n**Operator**\nLadies and gentlemen, that does conclude our question and answer session. I'm sorry.\n\n**Jensen Huang** (President &amp; CEO)\nThank you.\n\n**Colette Kress** (EVP &amp; CFO)\nNo, no, we're going to open up to, Jensen.\n\n**Jensen Huang** (President &amp; CEO)\nI just want to thank you.\n\n**Jensen Huang** (President &amp; CEO)\nI just want to thank you. Thank you, Colette. Demand for Blackwall is extraordinary. AI is evolving beyond perception and generative AI into reasoning. With reasoning AI, we're observing another scaling law, inference time or test time scaling.\n\n**Jensen Huang** (President &amp; CEO)\nThe more computation, the more the model thinks, the smarter the answer. Models like OpenAI, Broad3, DeepSeq R1 are reasoning models that apply inference time scaling. Reasoning models can consume 100 times more compute. Future reasoning models can consume much more compute. DeepSeq R1 has ignited global enthusiasm.\n\n**Jensen Huang** (President &amp; CEO)\nIt's an excellent innovation, but even more importantly, it has open sourced a world class reasoning AI model. Nearly every AI developer is applying R1 or chain of thought and reinforcement learning techniques like R1 to scale their model's performance. We now have three scaling laws, as I mentioned earlier, driving the demand for AI computing. The traditional scaling laws of AI remains intact. Foundation models are being enhanced with multi modality and pre training is still growing.\n\n**Jensen Huang** (President &amp; CEO)\nBut it's no longer enough. We have two additional scaling dimensions. Post training scaling, where reinforcement learning, fine tuning, model distillation require orders of magnitude more compute than pre training alone. Inference time scaling and reasoning, where a single query can demand 100 times more compute. We designed Blackwell for this moment, a single platform that can easily transition from pre training, post training and test time scaling.\n\n**Jensen Huang** (President &amp; CEO)\nBlackwell's FP4 transformer engine and NVLink 72 scale up fabric and new software technologies let Blackwell process reasoning AI models 25 times faster than Hopper. Blackwell in all of its configurations is in full production. Each Grace Blackwell NVLink72 rack is an engineering marvel. 1,500,000 components produced across three fifty manufacturing sites by nearly 100,000 factory operators. AI is advancing at light speed.\n\n**Jensen Huang** (President &amp; CEO)\nWe're at the beginning of reasoning AI and inference time scaling. But we're just at the start of the age of AI. Multimodal AI, enterprise AI, sovereign AI and physical AI are right around the corner. We will grow strongly in 2025. Going forward, data centers will dedicate most of CapEx to accelerated computing and AI.\n\n**Jensen Huang** (President &amp; CEO)\nData centers will increasingly become AI factories and every company will have them either rented or self operated. I want to thank all of you for joining us today. Come join us at GTC in a couple of weeks. We're going to be talking about Blackwell Ultra, Rubin and other new computing, networking, reasoning AI, physical AI products and a whole bunch more. Thank you.\n\n**Operator**\nThis concludes today's conference call. You may now disconnect.",
        "fetched_at": "2026-02-04T16:11:44.179Z"
      },
      {
        "ticker": "NVDA",
        "title": "Yahoo Finance",
        "published_date": "Nov 20, 2024, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/NVDA/earnings/NVDA-Q3-2025-earnings_call-225518.html",
        "content": "**Operator**\nGood afternoon. My name is Jay Lunn, I'll be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's third quarter earnings call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be a question-and-answer session. If you would like to ask a question during this time, simply press star followed by the number one on your telephone keypad. If you would like to withdraw your question, press the star one again. Thank you. Stewart Stecker, you may begin your conference.\n\n**Stewart Stecker** (Head of Investor Relations)\nThank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2025. With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer, and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter of fiscal 2025. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially.\n\n**Stewart Stecker** (Head of Investor Relations)\nFor a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10K and 10Q, and the reports that we may file on form 8K with the Securities and Exchange Commission. All our statements are made as of today, November 20, 2024, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. With that, let me turn the call over to Colette.\n\n**Colette Kress** (EVP and CFO)\nThank you, Stewart. Q3 was another record quarter. We continue to deliver incredible growth. Revenue of $35.1 billion was up 17% sequentially and up 94% year on year, and well above our outlook of $32.5 billion. All market platforms posted strong sequential and year-over-year growth fueled by the adoption of NVIDIA Accelerated Computing and AI. Starting with data center, another record was achieved in data center. Revenue of $30.8 billion, up 17% sequential and up 112% year on year. NVIDIA Hopper demand is exceptional, and sequentially, NVIDIA H200 sales increased significantly to double-digit billions, the fastest product ramp in our company's history. The H200 delivers up to 2X faster inference performance and up to 50% improved TCO. Cloud service providers were approximately half of our data center sales, with revenue increasing more than 2X year on year.\n\n**Colette Kress** (EVP and CFO)\nCSPs deployed NVIDIA H200 infrastructure and high-speed networking with installations scaling to tens of thousands of DPUs to grow their business and serve rapidly rising demand for AI training and inference workloads. NVIDIA H200-powered cloud instances are now available from AWS, CoreWeave, and Microsoft Azure, with Google Cloud and OCI coming soon. Alongside significant growth from our large CSPs, NVIDIA GPU regional cloud revenue jumped 2X year on year as North America, India, and Asia-Pacific regions ramped NVIDIA cloud instances and sovereign cloud buildouts. Consumer internet revenue more than doubled year on year as companies scaled their NVIDIA Hopper infrastructure to support next-generation AI models, training, multimodal and agentic AI, deep learning recommender engines, and generative AI inference and content creation workloads. NVIDIA's Ampere and Hopper infrastructures are fueling inference revenue growth for customers. NVIDIA is the largest inference platform in the world.\n\n**Colette Kress** (EVP and CFO)\nOur large install base and rich software ecosystem encourage developers to optimize for NVIDIA and deliver continued performance and TCO improvements. Rapid advancements in NVIDIA software algorithms boosted Hopper inference throughput by an incredible 5X in one year and cut time to first token by 5X. Our upcoming release of NVIDIA NIM will boost Hopper inference performance by an additional 2.4X. Continuous performance optimizations are a hallmark of NVIDIA and drive increasingly economic returns for the entire NVIDIA installed base. Blackwell is in full production after a successfully executed mass change. We shipped 13,000 GPU samples to customers in the third quarter, including one of the first Blackwell DGX engineering samples to OpenAI. Blackwell is a full-stack, full-infrastructure AI data center scale system with customizable configurations needed to address a diverse and growing AI market.\n\n**Colette Kress** (EVP and CFO)\nFrom x86 to ARM, training to inferencing GPUs, InfiniBand to Ethernet switches, and NVLink, and from liquid-cooled to air-cooled. Every customer is racing to be the first to market. Blackwell is now in the hands of all of our major partners, and they are working to bring up their data centers. We are integrating Blackwell systems into the diverse data center configurations of our customers. Blackwell demand is staggering, and we are racing to scale supply to meet the incredible demand customers are placing on us. Customers are gearing up to deploy Blackwell at scale. Oracle announced the world's first ZetaScale AI cloud computing clusters that can scale to over 131,000 Blackwell GPUs to help enterprises train and deploy some of the most demanding next-generation AI models.\n\n**Colette Kress** (EVP and CFO)\nYesterday, Microsoft announced they will be the first CSP to offer in private preview Blackwell-based cloud instances powered by NVIDIA GB200 and Quantum InfiniBand. Last week, Blackwell made its debut on the most recent round of MLPerf training results, sweeping the Perf GPU benchmarks and delivering a 2.2X leap in performance over Hopper. The results also demonstrate our relentless pursuit to drive down the cost of compute. Just 64 Blackwell GPUs are required to run the GPT-3 benchmark compared to 256 H100s for a 4X reduction in cost. NVIDIA Blackwell architecture with NVLink switch enables up to 30X faster inference performance and a new level of inference scaling throughput and response time that is excellent for running new reasoning inference applications like OpenAI's O1 model. With every new platform shift, a wave of startups is created. Hundreds of AI-native companies are already delivering AI services with great success.\n\n**Colette Kress** (EVP and CFO)\nThough Google, Meta, Microsoft, and OpenAI are the headliners, and Anthropic, Perplexity, Mistral, Adobe Firefly, Runway, Midjourney, Lightricks, Harvey, Codium, Cursor, and Bridge are seeing great success while thousands of AI-native startups are building new services. The next waves of AI are enterprise AI and industrial AI. Enterprise AI is in full throttle. NVIDIA AI Enterprise, which includes NVIDIA NeMo and NIM microservices, is an operating platform of agentic AI. Industry leaders are using NVIDIA AI to build copilots and agents. Working with NVIDIA, Cadence, Cloudera, Cohesity, NetApp, Nutanix, Salesforce, SAP, and ServiceNow are racing to accelerate development of these applications with the potential for billions of agents to be deployed in the coming years.\n\n**Colette Kress** (EVP and CFO)\nConsulting leaders like Accenture and Deloitte are taking NVIDIA AI to the world's enterprises. Accenture launched a new business group with 30,000 professionals trained on NVIDIA AI technology to help facilitate this global buildout.\n\n**Colette Kress** (EVP and CFO)\nAdditionally, Accenture, with over 770,000 employees, is leveraging NVIDIA-powered agentic AI applications internally, including one case that cuts manual steps in marketing campaigns by 25% to 35%. Nearly 1,000 companies are using NVIDIA NIM, and the speed of its uptake is evident in NVIDIA AI Enterprise monetization. We expect NVIDIA AI Enterprise full-year revenue to increase over 2X from last year, and our pipeline continues to build. Overall, our software, service, and support revenue is annualizing at $1.5 billion, and we expect to exit this year annualizing at over $2 billion. Industrial AI and robotics are accelerating. This is triggered by breakthroughs in physical AI foundation models that understand the physical world, like NVIDIA NeMo for enterprise AI agents. We built NVIDIA Omniverse for developers to build, train, and operate industrial AI and robotics.\n\n**Colette Kress** (EVP and CFO)\nSome of the largest industrial manufacturers in the world are adopting NVIDIA Omniverse to accelerate their businesses, automate their workflows, and to achieve new levels of operating efficiency. Foxconn, the world's largest electronics manufacturer, is using digital twins and industrial AI built on NVIDIA Omniverse to speed the bring-up of its Blackwell factories and drive new levels of efficiency. In its Mexico facility alone, Foxconn expects a reduction of over 30% in annual kilowatt-hour usage. From a geographic perspective, our data center revenue in China grew sequentially due to shipments of export-compliant Hopper products to industries. As a percentage of total data center revenue, it remains well below levels prior to the onset of export controls. We expect the market in China to remain very competitive going forward. We will continue to comply with export controls while serving our customers.\n\n**Colette Kress** (EVP and CFO)\nOur sovereign AI initiatives continue to gather momentum as countries embrace NVIDIA Accelerated Computing for a new industrial revolution powered by AI. India's leading CSPs, including Tata Communications and Yotta Data Services, are building AI factories for tens of thousands of NVIDIA GPUs. By year-end, they will have boosted NVIDIA GPU deployments in the country by nearly 10X. Infosys, TCS, Wipro are adopting NVIDIA AI Enterprise and upskilling nearly 500,000 developers and consultants to help clients build and run AI agents on our platform. In Japan, SoftBank is building the nation's most powerful AI supercomputer with NVIDIA DGX Blackwell and Quantum InfiniBand. SoftBank is also partnering with NVIDIA to transform the telecommunications network into a distributed AI network with NVIDIA AI Aerial and ARAN platform that can process 5G RAN on AI and CUDA. We are launching the same in the U.S. with T-Mobile.\n\n**Colette Kress** (EVP and CFO)\nLeaders across Japan, including Fujitsu, NEC, and NTT, are adopting NVIDIA AI Enterprise and major consulting companies, including EY Strategy and Consulting, to help bring NVIDIA AI technology to Japan's industries. Networking revenue increased 20% year on year. Areas of sequential revenue growth include InfiniBand and Ethernet switches, SmartNICs, and BlueField DPUs. Though networking revenue was sequentially down, networking demand is strong and growing, and we anticipate sequential growth in Q4. CSPs and supercomputing centers are using and adopting the NVIDIA InfiniBand platform to power new H200 clusters. NVIDIA Spectrum-X Ethernet for AI revenue increased over 3X year on year, and our pipeline continues to build with multiple CSPs and consumer internet companies planning large cluster deployments. Traditional Ethernet was not designed for AI. NVIDIA Spectrum-X uniquely leverages technology previously exclusive to InfiniBand to enable customers to achieve massive scale of their GPU compute.\n\n**Colette Kress** (EVP and CFO)\nUtilizing Spectrum-X, xAI's Colossus 100,000 Hopper supercomputer experienced zero application latency degradation and maintained 95% data throughput versus 60% for traditional Ethernet. Now moving to gaming and AI PCs. Gaming revenue of $3.3 billion increased 14% sequentially and 15% year on year. Q3 was a great quarter for gaming with notebook, console, and desktop revenue, all growing sequentially and year on year. RTX 40 demand was fueled by strong back-to-school sales as consumers continued to choose GeForce RTX GPUs and devices to power gaming, creative, and AI applications. Channel inventory remains healthy, and we are gearing up for the holiday season.\n\n**Colette Kress** (EVP and CFO)\nWe began shipping new GeForce RTX AI PCs with up to 321 AI TOPS from ASUS and MSI, with Microsoft's Copilot+ capabilities anticipated in Q4. These machines harness the power of RTX ray tracing and AI technologies to supercharge gaming, photo and video editing, image generation, and coding.\n\n**Colette Kress** (EVP and CFO)\nThis past quarter, we celebrated the 25th anniversary of the GeForce 256, the world's first GPU. From transforming computing graphics to igniting the AI revolution. NVIDIA's GPUs have been the driving force behind some of the most consequential technologies of our time. Moving to ProViz. Revenue of $486 million was up 7% sequentially and 17% year on year. NVIDIA RTX workstations continue to be the preferred choice to power professional graphics, design, and engineering-related workloads. Additionally, AI is emerging as a powerful demand driver, including autonomous vehicle simulation, generative AI model prototyping for productivity-related use cases, and generative AI content creation in media and entertainment. Moving to automotive. Revenue was a record $449 million, up 30% sequentially and up 72% year on year. Strong growth was driven by self-driving ramps of NVIDIA Orin and robust end-market demand for NEVs.\n\n**Colette Kress** (EVP and CFO)\nVolvo Cars is rolling out its fully electric SUV built on NVIDIA Orin and Drive OS. Okay, moving to the rest of the P&L. GAAP gross margin was 74.6% and non-GAAP gross margin was 75%. Down sequentially, primarily driven by a mix shift of the H100 systems to more complex and higher-cost systems within data center. Sequentially, GAAP operating expenses and non-GAAP operating expenses were up 9% due to higher compute, infrastructure, and engineering development costs for new product introductions. In Q3, we returned $11.2 billion to shareholders in the form of share repurchases and cash dividends. Well, let me turn to the outlook for the fourth quarter. Total revenue is expected to be $37.5 billion, plus or minus 2%, which incorporates continued demand for Hopper architecture and the initial ramp of our Blackwell products.\n\n**Colette Kress** (EVP and CFO)\nWhile demand is greatly exceeding supply, we are on track to exceed our previous Blackwell revenue estimate of several billion dollars as our visibility into supply continues to increase. On gaming, although sell-through was strong in Q3, we expect fourth quarter revenue to decline sequentially due to supply constraints. GAAP and non-GAAP gross margins are expected to be 73% and 73.5% respectively, plus or minus 50 basis points. Blackwell is a customizable AI infrastructure with seven different types of NVIDIA-built chips, multiple networking options, and for air and liquid-cooled data centers. Our current focus is on ramping to strong demand, increasing system availability, and providing the optimal mix of configurations to our customer. As Blackwell ramps, we expect gross margins to moderate to the low 70s. When fully ramped, we expect Blackwell margins to be in the mid-70s.\n\n**Colette Kress** (EVP and CFO)\nGAAP and non-GAAP operating expenses are expected to be approximately $4.8 billion and $3.4 billion respectively. We are a data center-scale AI infrastructure company. Our investments include building data centers for the development of our hardware and software stacks and to support new introductions. GAAP and non-GAAP other income and expenses are expected to be an income of approximately $400 million, excluding gains and losses from non-affiliated investments. GAAP and non-GAAP tax rates are expected to be 16.5%, plus or minus 1%, excluding any discrete items. Further financial details are included in the CFO commentary and other information available on our IR websites. In closing, let me highlight upcoming events for the financial community. We will be attending the UBS Global Technology and AI Conference on December 3rd in Scottsdale.\n\n**Colette Kress** (EVP and CFO)\nPlease join us at CES in Las Vegas, where Jensen will deliver a keynote on January 6th, and we will host a Q&A session for financial analysts the next day on January 7th. Our earnings call to discuss results for the fourth quarter of fiscal 2025 is scheduled for February 26, 2025. We will now open the call for questions. Operator, can you poll for questions, please?\n\n**Operator**\nAt this time, I would like to remind everyone in order to ask a question, press star, then the number one on your telephone keypad. We'll pause for just a moment to compile the Q&A roster. As a reminder, please limit yourself to one question. Your first question comes from the line of CJ Muse of Cantor Fitzgerald. Your line is open.\n\n**C.J. Muse** (Senior Managing Director)\nYeah, good afternoon. Thank you for taking the question. I guess just a question for you on the debate around whether scaling for large language models have stalled. Obviously, we're very early here, but we'd love to hear your thoughts on this front. How are you helping your customers as they work through these issues? And then obviously, part of the context here is we're discussing clusters that have yet to benefit from Blackwell. So is this driving even greater demand for Blackwell? Thank you.\n\n**Jensen Huang** (President and CEO)\nFoundation model pre-training scaling is intact, and it's continuing. As you know, this is an empirical law, not a fundamental physical law, but the evidence is that it continues to scale. What we're learning, however, is that it's not enough, that we've now discovered two other ways to scale. One is post-training scaling.\n\n**Jensen Huang** (President and CEO)\nOf course, the first generation of post-training was reinforcement learning human feedback, but now we have reinforcement learning AI feedback and all forms of synthetic data-generated data that assists in post-training scaling. And one of the biggest events and one of the most exciting developments is Strawberry, ChatGPT o1, OpenAI's o1, which does inference time scaling, or what's called test time scaling.\n\n**Jensen Huang** (President and CEO)\nThe longer it thinks, the better and higher quality answer it produces. And it considers approaches like chain of thought and multi-path planning and all kinds of techniques necessary to reflect and so on and so forth. And intuitively, it's a little bit like us doing thinking in our head before we answer a question. And so we now have three ways of scaling, and we're seeing all three ways of scaling. And as a result of that, the demand for our infrastructures is really great.\n\n**Jensen Huang** (President and CEO)\nYou see now that at the tail end of the last generation of foundation models, we're at about 100,000 Hoppers. The next generation starts at 100,000 Blackwells. And so that kind of gives you a sense of where the industry is moving with respect to pre-training scaling, post-training scaling, and then now, very importantly, inference time scaling. And so the demand is really great for all of those reasons. But remember, simultaneously, we're seeing inference really starting to scale up for our company.\n\n**Jensen Huang** (President and CEO)\nWe are the largest inference platform in the world today because our installed base is so large, and everything that was trained on Ampere's and Hopper's inference incredibly on Ampere's and Hopper's. And as we move to Blackwells for training foundation models, it leaves behind it a large installed base of extraordinary infrastructure for inference. And so we're seeing inference demand go up. We're seeing inference time scaling go up. We see the number of AI-native companies continue to grow. And of course, we're starting to see enterprise adoption of agentic AI really is the latest rage. And so we're seeing a lot of demand coming from a lot of different places.\n\n**Operator**\nYour next question comes from the line of Toshiya Hari of Goldman Sachs. Your line is open.\n\n**Toshiya Hari** (Managing Director)\nHi, good afternoon. Thank you so much for taking the question. Jensen, you executed the mask change earlier this year. There were some reports over the weekend about some heating issues. On the back of this, we've had investors ask about your ability to execute to the roadmap you presented at GTC this year with Ultra coming out next year and the transition to Rubin in 2026. Can you sort of speak to that? And some investors are questioning that.\n\n**Toshiya Hari** (Managing Director)\nSo if you can sort of speak to your ability to execute on time, that would be super helpful. And then a quick Part B on supply constraints. Is it a multitude of componentry that's causing this, or is it specifically CoWoS, HBM? Is the supply constraintsare the supply constraints getting better? Are they worsening? Any sort of color on that would be super helpful as well. Thank you.\n\n**Jensen Huang** (President and CEO)\nYeah, thanks. Thanks. So let's see. Back to the first question. Blackwell production is in full steam. In fact, as Colette mentioned earlier, we will deliver this quarter more Blackwells than we had previously estimated. And so the supply chain team is doing an incredible job working with our supply partners to increase Blackwell. And we're going to continue to work hard to increase Blackwell through next year. It is the case that demand exceeds our supply.\n\n**Jensen Huang** (President and CEO)\nThat's expected as we're in the beginnings of this generative AI revolution, as we all know. We're at the beginning of a new generation of foundation models that are able to do reasoning and able to do long thinking. Of course, one of the really exciting areas is physical AI, AI that now understands the structure of the physical world. Blackwell demand is very strong. Our execution is going well. There's obviously a lot of engineering that we're doing across the world. You see now systems that are being stood up by Dell and CoreWeave. I think you saw systems from Oracle stood up. You have systems from Microsoft, and they're about to preview their Grace Blackwell systems. You have systems that are at Google. All of these CSPs are racing to be first.\n\n**Jensen Huang** (President and CEO)\nThe engineering that we do with them is, as you know, rather complicated. The reason for that is because although we build full stack and full infrastructure, we disaggregate all of this AI supercomputer, and we integrate it into all of the custom data centers and architectures around the world. That integration process is something we've done several generations now. We're very good at it, but still, there's a lot of engineering that happens at this point. As you see from all of the systems that are being stood up, Blackwell's in great shape. As we mentioned earlier, the supply and what we're planning to ship this quarter is greater than our previous estimates. With respect to the supply chain, there are seven different chips, seven custom chips that we built in order for us to deliver the Blackwell systems.\n\n**Jensen Huang** (President and CEO)\nThe Blackwell systems go in air-cooled or liquid-cooled, NVLink 8 or NVLink 72, or NVLink 8, NVLink 36, NVLink 72. We have x86 or Grace, and the integration of all of those systems into the world's data centers is nothing short of a miracle, and so the component supply chain necessary to ramp at the scale, you have to go back and take a look at how much Blackwell was shipped last quarter, which was zero, and in terms of how much Blackwell total systems were shipped this quarter, which is measured in billions, the ramp is incredible, and so almost every company in the world seems to be involved in our supply chain, and we've got great partners, everybody from, of course, TSMC and Amphenol, the connector company, incredible company, Vertiv and SK Hynix and Micron, and Amkor, and KYEC.\n\n**Jensen Huang** (President and CEO)\nAnd there's Foxconn and the factories that they've built and Quanta and Wiwynn and, gosh, Dell and HP and Supermicro, Lenovo. And the number of companies is just really quite incredible. Quanta. And I'm sure I've missed partners that are involved in the ramping of Blackwell, which I really appreciate. And so anyways, I think we're in great shape with respect to the Blackwell ramp at this point. And then lastly, your question about our execution of our roadmap. We're on an annual roadmap, and we're expecting to continue to execute on our annual roadmap. And by doing so, we increase the performance, of course, of our platform. But it's also really important to realize that when we're able to increase performance and do so at X factors at a time, we're reducing the cost of training. We're reducing the cost of inferencing.\n\n**Jensen Huang** (President and CEO)\nWe're reducing the cost of AI so that it could be much more accessible. But the other factor that's very important to note is that when there's a data center of some fixed size, and a data center always is of some fixed size. It could be, of course, tens of megawatts in the past, and now most data centers are now 100 megawatts to several hundred megawatts, and we're planning on gigawatt data centers. It doesn't really matter how large the data centers are. The power's limited. And when you're in the power-limited data center, the highest performance per watt translates directly into the highest revenues for our partners. And so on the one hand, our annual roadmap reduces cost.\n\n**Jensen Huang** (President and CEO)\nBut on the other hand, because our per watt is so good compared to anything out there, we generate for our customers the greatest possible revenues. And so that annual rhythm is really important to us, and we have every intention of continuing to do that. And everything's on track as far as I know.\n\n**Operator**\nYour next question comes from the line of Timothy Arcuri of UBS. Your line is open.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. I'm wondering if you can talk about the trajectory of how Blackwell is going to ramp this year. I know, Jensen, you did just talk about Blackwell being better than I think you had said several billions of dollars in January. It sounds like you're going to do more than that. But I think in recent months, also, you said that Blackwell crosses over Hopper in the April quarter. So I guess I had two questions. First of all, is that still the right way to think about it, that Blackwell will cross over Hopper in April?\n\n**Timothy Arcuri** (Managing Director)\nAnd then, Colette, you kind of talked about Blackwell bringing down gross margin to the low 70s% as it ramps. So I guess if April is the crossover, is that the worst of the pressure on gross margin? So you're going to be kind of in the low 70s% as soon as April. I'm just wondering if you can sort of shape that for us. Thanks.\n\n**Jensen Huang** (President and CEO)\nColette, why don't you start?\n\n**Colette Kress** (EVP and CFO)\nSure. Let me first start with your question, Tim. Thank you regarding our gross margins. And we discussed that our gross margins, as we are ramping Blackwell in the very beginning, and the many different configurations, the many different chips that we are bringing to market, we are going to focus on making sure we have the best experience for our customers as they stand that up.\n\n**Colette Kress** (EVP and CFO)\nWe will start growing in for our gross margins, but we do believe those will be in the low 70s in that first part of the ramp. So you're correct. As you look at the quarters following after that, we will start increasing our gross margins, and we hope to get to the mid-70s quite quickly as part of that ramp.\n\n**Jensen Huang** (President and CEO)\nHopper demand will continue through next year, surely the first several quarters of the next year. And meanwhile, we'll ship more Blackwells next quarter than this, and we'll ship more Blackwells the quarter after that than our first quarter. And so that kind of puts it in perspective. We are really at the beginnings of two fundamental shifts in computing that is really quite significant. The first is moving from coding that runs on CPUs to machine learning that creates neural networks that runs on GPUs.\n\n**Jensen Huang** (President and CEO)\nThat fundamental shift from coding to machine learning is widespread at this point. There are no companies who are not going to do machine learning. And so machine learning is also what enables generative AI. And so on the one hand, the first thing that's happening is $1 trillion worth of computing systems and data centers around the world is now being modernized for machine learning. On the other hand, secondarily, I guess, is that on top of these systems, we're going to be creating a new type of capability called AI. And when we say generative AI, we're essentially saying that these data centers are really AI factories. They're generating something. Just like we generate electricity, we're now going to be generating AI.\n\n**Jensen Huang** (President and CEO)\nIf the number of customers is large, just as the number of consumers of electricity is large, these generators are going to be running 24/7. Today, many AI services are running 24/7, just like an AI factory. We're going to see this new type of system come online. I call it an AI factory because that's really as close to what it is. It's unlike a data center of the past. These two fundamental trends are really just beginning. We expect this to happen, this growth, this modernization, and the creation of a new industry to go on for several years.\n\n**Operator**\nYour next question comes from the line of Vivek Arya of Bank of America Securities. Your line is open. Thanks for taking my question.\n\n**Vivek Arya** (Managing Director)\nColette, just to clarify, do you think it's a fair assumption to think NVIDIA could recover to kind of mid-70s gross margin in the back half of calendar 2025? Just wanted to clarify that. And then, Jensen, my main question, historically, when we have seen hardware deployment cycles, they have inevitably included some digestion along the way. When do you think we get to that phase, or is it just too premature to discuss that because you're just at the start of Blackwell? So how many quarters of shipments do you think is required to kind of satisfy this first wave? Can you continue to grow this into calendar 2026? Just how should we be prepared to see what we have seen historically, right, the periods of digestion along the way of long-term kind of secular hardware deployment?\n\n**Colette Kress** (EVP and CFO)\nOkay. Vivek, thank you for the question. Let me clarify your question regarding gross margins. Could we reach the mid-70s in the second half of next year, and yes, I think it is a reasonable assumption or a goal for us to do, but we'll just have to see how that mix of ramp goes, but yes, it is definitely possible.\n\n**Jensen Huang** (President and CEO)\nThe way to think through that, Vivek, is I believe that there will be no digestion until we modernize $1 trillion worth of data centers. If you just look at the world's data centers, the vast majority of it is built for a time when we wrote applications by hand, and we ran them on CPUs. It's just not a sensible thing to do anymore.\n\n**Jensen Huang** (President and CEO)\nIf every company's CapEx, if they're ready to build a data center tomorrow, they ought to build it for a future of machine learning and generative AI because they have plenty of old data centers, and so what's going to happen over the course of next X number of years, and let's assume that over the course of four years, the world's data centers could be modernized as we grow into IT. As you know, IT continues to grow about 20%-30% a year, let's say, and so let's say by 2030, the world's data centers for computing is, call it a couple trillion dollars. We have to grow into that. We have to modernize the data center from coding to machine learning. That's number one. The second part of it is generative AI.\n\n**Jensen Huang** (President and CEO)\nWe're now producing a new type of capability that the world's never known, a new market segment that the world's never had. If you look at OpenAI, it didn't replace anything. It's something that's completely brand new. In a lot of ways, as when the iPhone came, it was completely brand new. It wasn't really replacing anything. We're going to see more and more companies like that. They're going to create and generate out of their services, essentially, intelligence. Some of it would be digital artist intelligence like Runway. Some of it would be basic intelligence like OpenAI. Some of it would be legal intelligence like Harvey. Digital marketing intelligence like Writer. So on and so forth. The number of these companies, what are they called, AI-native companies, are just in hundreds. Almost every platform shift, there were internet companies, as you recall.\n\n**Jensen Huang** (President and CEO)\nThere were cloud-first companies. There were mobile-first companies. Now they're AI natives. And so these companies are being created because people see that there's a platform shift, and there's a brand new opportunity to do something completely new. And so my sense is that we're going to continue to build out, to modernize IT, modernize computing, number one. And then number two, create these AI factories that are going to be for a new industry for the production of artificial intelligence.\n\n**Operator**\nYour next question comes from the line of Stacy Rasgon of Bernstein Research. Your line is open.\n\n**Stacy Rasgon** (Senior Analyst)\nHi, guys. Thanks for taking my questions. Colette, I had a clarification and a question for you. The clarification is when you say low 70s% gross margins, is 73.5% count as low 70s%, or do you have something else in mind? And for my question, you're guiding total revenues.\n\n**Stacy Rasgon** (Senior Analyst)\nI mean, total data center revenues in the next quarter must be up, quote-unquote, \"several billion dollars,\" but it sounds like Blackwell now should be up more than that. But you also said Hopper was still strong. So is Hopper down sequentially next quarter? And if it is, why? Is it because of the supply constraints? China has been pretty strong. Is China kind of rolling off a bit into Q4? So any color you can give us on sort of the Blackwell ramp and the Blackwell versus Hopper behavior into Q4 would be really helpful. Thank you.\n\n**Colette Kress** (EVP and CFO)\nFirst, starting on your first question there, Stacy, regarding our gross margin and defining low. Low, of course, is below the mids. And let's say we might be at 71%, maybe about 72%, 72 and a half. We're going to be in that range.\n\n**Colette Kress** (EVP and CFO)\nWe could be higher than that as well. We're just going to have to see how it comes through. We do want to make sure that we are ramping and continuing that improvement, the improvement in terms of our yields, the improvement in terms of the product as we go through the rest of the year. So we'll get up to the mid-70s by that point. The second statement was a question regarding our Hopper. And what is our Hopper doing? We have seen substantial growth for H200, not only in terms of orders, but the quickness in terms of those that are standing that up. It is an amazing product, and it's the fastest growing and ramping that we've seen. We will continue to be selling Hopper in this quarter in Q4 for sure.\n\n**Colette Kress** (EVP and CFO)\nThat is across the board in terms of all of our different configurations, and our configurations include what we may do in terms of China. But keep that in mind that folks are also at the same time looking to build out their Blackwell. So we've got a little bit of both happening in Q4. But yes, is it possible for Hopper to grow between Q3 and Q4? It's possible, but we'll just have to see.\n\n**Operator**\nYour next question comes from the line of Joseph Moore of Morgan Stanley. Your line is open.\n\n**Joseph Moore** (Managing Director)\nGreat. Thank you. I wonder if you could talk a little bit about what you're seeing in the inference market. You've talked about Strawberry and some of the ramifications of longer scaling inference projects.\n\n**Joseph Moore** (Managing Director)\nBut you've also talked about the possibility that as some of these Hopper clusters age, that you could use some of the Hopper latent chips for inference. So I guess, do you expect inference to outgrow training in the next kind of 12-month timeframe? And just generally, your thoughts there.\n\n**Jensen Huang** (President and CEO)\nOur hopes and dreams is that someday the world does a ton of inference. And that's when AI has really succeeded. It's when every single company is doing inference inside their companies for the marketing department and forecasting department and supply chain group and their legal department and engineering, of course, and coding, of course. And so we hope that every company is doing inference 24/7 and that there will be a whole bunch of AI-native startups, thousands of AI-native startups that are generating tokens and generating AI.\n\n**Jensen Huang** (President and CEO)\nEvery aspect of your computer experience, from using Outlook to PowerPointing or when you're sitting there with Excel, you're constantly generating tokens. Every time you read a PDF, open a PDF, it generated a whole bunch of tokens. One of my favorite applications is NotebookLM, this Google application that came out. I used the living daylights out of it just because it's fun. I put every PDF, every archive paper into it just to listen to it as well as scanning through it. So I think that's the goal, is to train these models so that people use it. There's now a whole new era of AI, if you will, a whole new genre of AI called physical AI. Just those large language models understand the human language and the thinking process, if you will. Physical AI understands the physical world.\n\n**Jensen Huang** (President and CEO)\nIt understands the meaning of the structure and understands what's sensible and what's not, and what could happen and what wouldn't. Not only does it understand, but it can predict and roll out a short future. That capability is incredibly valuable for industrial AI and robotics. That's fired up so many AI-native companies, robotics companies, and physical AI companies that you're probably hearing about. It's really the reason why we built Omniverse. Omniverse is so that we can enable these AIs to be created and learn in Omniverse and learn from synthetic data generation and reinforcement learning physics feedback instead of human feedback. It's now physics feedback. To have these capabilities, Omniverse was created so that we can enable physical AI. The goal is to generate tokens. The goal is to inference. We're starting to see that growth happening.\n\n**Jensen Huang** (President and CEO)\nSo I'm super excited about that. Now, let me just say one more thing. Inference is super hard. And the reason why inference is super hard is because you need the accuracy to be high on the one hand. You need the throughput to be high so that the cost could be as low as possible. But you also need the latency to be low. And computers that are high throughput as well as low latency is incredibly hard to build. And these applications have long context lengths because they want to understand. They want to be able to inference within understanding the context of what they're being asked to do. And so the context length is growing larger and larger. On the other hand, the models are getting larger. They're multi-modality. Just the number of dimensions that inference is innovating is incredible.\n\n**Jensen Huang** (President and CEO)\nThis innovation rate is what makes NVIDIA's architecture so great because our ecosystem is fantastic. Everybody knows that if they innovate on top of CUDA and on top of NVIDIA's architecture, they can innovate more quickly, and they know that everything should work. And if something were to happen, it's probably likely their code and not ours. And so that ability to innovate in every single direction at the same time, having a large install base so that whatever you create could land on an NVIDIA computer and be deployed broadly all around the world in every single data center, all the way out to the edge into robotic systems, that capability is really quite phenomenal.\n\n**Operator**\nYour next question comes from the line of Aaron Rakers. Sorry, Aaron Rakers of Wells Fargo. Your line is open.\n\n**Aaron Rakers** (Managing Director)\nYeah. Thanks for taking the question. I wanted to ask you, as we kind of focus on the Blackwell cycle and think about the data center business, when I look at the results this last quarter, Colette, you mentioned that obviously the networking business was down about 15% sequentially. But then your comments were that you were seeing very strong demand. You mentioned also that you had multiple cloud CSP design wins for these large-scale clusters. So I'm curious if you could unpack what's going on in the networking business and where maybe you've seen some constraints and just your confidence in the pace of Spectrum-X progressing to that multiple billions of dollars that you previously had talked about. Thank you.\n\n**Colette Kress** (EVP and CFO)\nLet's first start with the networking. The growth year over year is tremendous.Our focus since the beginning of our acquisition of Mellanox has really been about building together the work that we do in terms of in the data center. The networking is such a critical part of that. Our ability to sell our networking with many of our systems that we are doing in data center is continuing to grow and do quite well. So this quarter is just a slight dip down, and we're going to be right back up in terms of growing. They're getting ready for Blackwell and more and more systems that will be using not only our existing networking, but also the networking that is going to be incorporated in a lot of these large systems that we are providing them to.\n\n**Operator**\nYour next question comes from the line of Atif Malik of Citi. Your line is open.\n\n**Atif Malik** (Managing Director)\nThank you for taking my question.I have two quick ones for Colette. Colette, on the last earnings call, you mentioned that sovereign demand is in low double-digit billions. Can you provide an update on that? And then can you explain the supply constraint situation in gaming? Is that because you're shifting your supply towards data center?\n\n**Colette Kress** (EVP and CFO)\nSo first, starting in terms of sovereign AI, such an important part of growth, something that has really surfaced with the onset of generative AI and building models in the individual countries around the world. And we see a lot of them, and we talked about a lot of them in the call today and the work that they are doing.\n\n**Colette Kress** (EVP and CFO)\nSo our sovereign AI and our pipeline going forward is still absolutely intact as those are working to build these foundational models in their own language, in their own culture, and working in terms of the enterprises within those countries. And I think you'll continue to see this be a growth opportunity that you may see with our regional clouds that are being stood up and/or those that are focusing in terms of AI factories for many parts of the sovereign AI. This is areas where this is growing not only in terms of in Europe, but you're also seeing this in terms of growth in terms of in the Asia-Pacific as well.\n\n**Colette Kress** (EVP and CFO)\nLet me flip to your second question that you asked regarding gaming. So our gaming right now from a supply, we're busy trying to make sure that we can ramp all of our different products.\n\n**Colette Kress** (EVP and CFO)\nAnd in this case, our gaming supply, given what we saw selling through, was moving quite fast. Now, the challenge that we have is how fast could we get that supply getting ready into the market for this quarter? Not to worry, I think we'll be back on track with more supply as we turn the corner into the new calendar year. We're just going to be tight for this quarter.\n\n**Operator**\nYour next question comes from the line of Ben Reitzes of Melius Research. Your line is open.\n\n**Ben Reitzes** (Managing Director)\nYeah. Hi. Thanks a lot for the question. I wanted to ask Colette and Jensen with regard to sequential growth. So very strong sequential growth this quarter, and you're guiding to about 7%. Do your comments on Blackwell imply that we re-accelerate from there as you get more supply?\n\n**Ben Reitzes** (Managing Director)\nJust in the first half, it would seem that there would be some catch-up. So I was wondering how prescriptive you could be there. And then, Jensen, just overall, with the change in administration that's going to take place here in the U.S. and the China situation, have you gotten any sense or any conversations about tariffs or anything with regard to your China business? Any sense of what may or may not go on? It's probably too early, but wondering if you had any thoughts there. Thanks so much.\n\n**Jensen Huang** (President and CEO)\nWe got one quarter at a time.\n\n**Colette Kress** (EVP and CFO)\nWe are working right now on the quarter that we're in and building what we need to ship in terms of Blackwell. We have every supplier on the planet working seamlessly with us to do that. And once we get to next quarter, we'll help you understand in terms of that ramp that we'll see to the next quarter going after that.\n\n**Colette Kress** (EVP and CFO)\nWhatever the new administration decides, we will, of course, support the administration. And that's the highest mandate. And then after that, do the best we can, just as we always do. And so we have to simultaneously, and we will, comply with any regulation that comes along fully and support our customers to the best of our abilities and compete in the marketplace. We'll do all of these three things simultaneously.\n\n**Operator**\nYour final question comes from the line of Pierre Ferragu of New Street Research. Your line is open.\n\n**Pierre Ferragu** (Managing Partner)\nHey, thanks for taking my question. Jensen, you mentioned in your comments you have the pre-training, the actual language models, and you have reinforcement learning that becomes more and more important in training and in inference as well. And then you have inference itself. And I was wondering if you have a sense, a high-level typical sense of out of an overall AI ecosystem, maybe one of your clients or one of the large models that are out there. Today, how much of the compute goes into each of these buckets? How much for the pre-training, how much for the reinforcement, and how much into inference today? Do you have any sense for how it's splitting and where the growth is the most important as well?\n\n**Jensen Huang** (President and CEO)\nWell, today, it's vastly in pre-training of foundation model because, as you know, post-training, the new technologies are just coming online. And whatever you could do in pre-training and post-training, you would try to do so that the inference cost could be as low as possible for everyone.\n\n**Jensen Huang** (President and CEO)\nHowever, there are only so many things that you could do a priori. And so you'll always have to do on-the-spot thinking and in-context thinking and reflection. And so I think that the fact that all three are scaling is actually very sensible based on where we are. And in the area of foundation model, now we have multimodal foundation models. And the amount of petabytes of video that these foundation models are going to be trained on is incredible. And so my expectation is that for the foreseeable future, we're going to be scaling pre-training, post-training, as well as inference time scaling, which is the reason why I think we're going to need more and more compute.\n\n**Jensen Huang** (President and CEO)\nAnd we're going to have to drive as hard as we can to keep increasing the performance by X factors at a time so that we can continue to drive down the cost and continue to increase the revenues and get the AI revolution going.\n\n**Pierre Ferragu** (Managing Partner)\nThank you.\n\n**Operator**\nThank you. I'll turn the call back over to Jensen Huang for a closing remark.\n\n**Jensen Huang** (President and CEO)\nThank you. The tremendous growth in our business is being fueled by two fundamental trends that are driving global adoption of NVIDIA computing. First, the computing stack is undergoing a reinvention, a platform shift from coding to machine learning, from executing code on CPUs to processing neural networks on GPUs. The trillion-dollar install base of traditional data center infrastructure is being rebuilt for software 2.0, which applies machine learning to produce AI. Second, the age of AI is in full swing.\n\n**Jensen Huang** (President and CEO)\nGenerative AI is not just a new software capability, but a new industry with AI factories manufacturing digital intelligence, a new industrial revolution that can create a multi-trillion-dollar AI industry. Demand for Hopper and anticipation for Blackwell, which is now in full production, are incredible for several reasons. There are more foundation model makers now than there were a year ago. The computing scale of pre-training and post-training continues to grow exponentially. There are more AI-native startups than ever, and the number of successful inference services is rising. With the introduction of ChatGPT o1, OpenAI o1, a new scaling law called test-time scaling has emerged. All of these consume a great deal of computing. AI is transforming every industry, company, and country. Enterprises are adopting agentic AI to revolutionize workflows. Over time, AI coworkers will assist employees in performing their jobs faster and better.\n\n**Jensen Huang** (President and CEO)\nInvestments in industrial robotics are surging due to breakthroughs in physical AI, driving new training infrastructure demand as researchers train world foundation models on petabytes of video and Omniverse synthetically generated data. The age of robotics is coming. Countries across the world recognize the fundamental AI trends we are seeing and have awakened to the importance of developing their national AI infrastructure. The age of AI is upon us, and it's large and diverse. NVIDIA's expertise, scale, and ability to deliver full stack and full infrastructure let us serve the entire multi-trillion-dollar AI and robotics opportunities ahead. From every hyperscale cloud, enterprise private cloud, to sovereign regional AI clouds, on-prem, to industrial edge, and robotics. Thanks for joining us today, and catch up next time.\n\n**Operator**\nThis concludes today's conference call. You may now disconnect.",
        "fetched_at": "2026-02-04T16:11:48.948Z"
      }
    ]
  },
  "META": {
    "ticker": "META",
    "last_updated": "2026-02-04T16:12:24.465Z",
    "total_transcripts": 4,
    "transcripts": [
      {
        "ticker": "META",
        "title": "Yahoo Finance",
        "published_date": "Jan 28, 2026, 4:30 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/META/earnings/META-Q4-2025-earnings_call-405037.html",
        "content": "**Operator**\nGood afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta Fourth Quarter and Full Year 2025 Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be an opportunity to ask questions. If you would like to ask a question, please press star one on your telephone keypad. To withdraw your question, again, press star one. We ask that you limit yourself to one question, and this call will be recorded. Thank you very much. Kenneth Dorell, Meta's Director of Investor Relations, you may begin.\n\n**Kenneth Dorell** (Director of Investor Relations)\nThank you. Good afternoon, and welcome to Meta Platforms' Fourth Quarter and Full Year 2025 Earnings Conference Call. Joining me today to discuss our results are Mark Zuckerberg, CEO, and Susan Li, CFO. Our remarks today will include forward-looking statements, which are based on assumptions as of today. Actual results may differ materially as a result of various factors, including those set forth in today's earnings press release and in our quarterly report on Form 10-Q filed with the SEC. We undertake no obligation to update any forward-looking statement. During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.meta.com. And now I'd like to turn the call over to Mark.\n\n**Mark Zuckerberg** (CEO)\nAll right. Hey, everyone. Thanks for joining us. We ended 2025 strong, with more than 3.5 billion people now using at least one of our apps every day. That includes more than 2 billion daily actives each on Facebook and WhatsApp, and just shy of that on Instagram. Our business also performed very well, thanks to record-breaking holiday demand and AI-driven performance gains. We are now seeing a major AI acceleration. I expect 2026 to be a year where this wave accelerates even further on several fronts. We're starting to see agents really work. This will unlock the ability to build completely new products and transform how we work. In 2025, we rebuilt the foundations of our AI program. Over the coming months, we're going to start shipping our new models and products.\n\n**Mark Zuckerberg** (CEO)\nI expect our first models will be good, but more importantly, we'll show the rapid trajectory that we're on. And then I expect us to steadily push the frontier over the course of the year as we continue to release new models. I'm very excited about the products that we're building. Our vision is building personal superintelligence. We're starting to see the promise of AI that understands our personal context, including our history, our interests, our content, and our relationships. A lot of what makes agents valuable is the unique context that they can see, and we believe that Meta will be able to provide a uniquely personal experience. We're also working on merging LLMs with the recommendation systems that power Facebook, Instagram, Threads, and our ad system.\n\n**Mark Zuckerberg** (CEO)\nOur world-class recommendation systems are already driving meaningful growth across our apps and ads business, but we think that the current systems are primitive compared to what will be possible soon. Today, our systems help people stay in touch with friends, understand the world, and find interesting and entertaining content. But soon, we'll be able to understand people's unique personal goals and tailor feeds to show each person content that helps them improve their lives in the ways that they want. This also has implications for commerce. Our ads today help businesses find just the right, very specific people who are interested in their products. New agentic shopping tools will allow people to find just the right, very specific set of products from the businesses in our catalog.\n\n**Mark Zuckerberg** (CEO)\nWe're focused on making these experiences work across both our feeds and across business messaging, significantly increasing the capabilities of WhatsApp over time. New kinds of content will soon be possible as well. People want to express themselves and experience the world in the most immersive and interactive ways possible. We started with text and then moved to photos when we got phones with cameras and then moved to video when mobile networks got fast enough. Soon, we'll see an explosion of new media formats that are more immersive and interactive and only possible because of advances in AI. Our feeds will become more interactive overall. Today, our apps feel like algorithms that recommend content. Soon, you'll open our apps, and you'll have an AI that understands you and also happens to be able to show you great content or even generate great personalized content for you.\n\n**Mark Zuckerberg** (CEO)\nGlasses are the ultimate incarnation of this vision. They're going to be able to see what you see, hear what you hear, talk to you, and help you as you go about your day, and even show you information or generate custom UI, right there in your vision. Sales of our glasses more than tripled last year, and we think that they're some of the fastest-growing consumer electronics in history. Billions of people wear glasses or contacts for vision correction, and I think that we're at a moment similar to when smartphones arrived, and it was clearly only a matter of time until all those flip phones became smartphones. It's hard to imagine a world in several years where most glasses that people wear aren't AI glasses.\n\n**Mark Zuckerberg** (CEO)\nFor Reality Labs, we are directing most of our investment towards glasses and wearables going forward, while focusing on making Horizon a massive success on mobile and making VR a profitable ecosystem over the coming years. I expect Reality Labs losses this year to be similar to last year, and this will likely be the peak as we start to gradually reduce our losses going forward while continuing to execute on our vision. As we plan for the future, we will continue to invest very significantly in infrastructure to train leading models and deliver personal superintelligence to billions of people and businesses around the world. I recently announced Meta Compute with the belief that being the most efficient at how we engineer, invest, and partner to build our infrastructure will become a strategic advantage.\n\n**Mark Zuckerberg** (CEO)\nDina Powell McCormick also joined us as President and Vice Chairman, and she will lead our efforts to partner with governments, sovereigns, and strategic capital partners to expand our long-term capacity, including ensuring positive economic impact in the communities that we operate in around the world. An important part of Meta Compute will be making long-term investments in silicon and energy. We will continue working with key partners while advancing our own silicon program. We're architecting our systems that we can be flexible in the systems that we use, and we expect the cost per gigawatt to decrease significantly over time through optimizing both our technology and supply chain. The last thing that I wanna mention is that I think that 2026 is going to be the year that AI starts to dramatically change the way that we work.\n\n**Mark Zuckerberg** (CEO)\nAs we navigate this, our North Star is building the best place for individuals to make a massive impact. So to do this, we're investing in AI-native tooling, so individuals at Meta can get more done. We're elevating individual contributors and flattening teams. We're starting to see projects that used to require big teams now be accomplished by a single, very talented person. I wanna make sure that as many of these very talented people as possible choose Meta as the place that they can make the greatest impact, to deliver personalized products to billions of people around the world. And if we do this, then I think that we're gonna get a lot more done, and I think it's gonna be a lot more fun. All right, that's everything I wanted to cover.\n\n**Mark Zuckerberg** (CEO)\nThis is gonna be a big year for delivering personal superintelligence, accelerating our business, building infrastructure for the future, and shaping how our company will work going forward. As always, I am grateful for all the hard work of our teams and to all of you for being on this journey with us. Now, here's Susan.\n\n**Susan Li** (CFO)\nThanks, Mark, and good afternoon, everyone. Let's begin with our segment results. All comparisons are on a year-over-year basis, unless otherwise noted. Our community across the Family of Apps continues to grow, and we estimate more than 3.5 billion people used at least one of our Family of Apps on a daily basis in December. Q4 total Family of Apps revenue was $58.9 billion, up 25% year-over-year. Q4 Family of Apps ad revenue was $58.1 billion, up 24% or 23% on a constant currency basis. In Q4, the total number of ad impressions served across our services increased 18%. Impression growth was healthy across all regions, driven primarily by engagement and user growth and, to a lesser degree, ad load optimizations.\n\n**Susan Li** (CFO)\nThe average price per ad increased 6% year-over-year, benefiting from increased advertiser demand, largely driven by improved ad performance. Family of Apps other revenue was $801 million, up 54%, driven by WhatsApp paid messaging revenue growth, as well as Meta Verified subscriptions. Within our Reality Labs segment, Q4 revenue was $955 million, down 12% year-over-year. As we noted on the last call, the year-over-year decline in Reality Labs revenue is due to us lapping the introduction of Quest 3S in Q4 of 2024, as well as retail partners procuring Quest headsets during the third quarter of 2025 to prepare for the holiday season, which was recorded as revenue in Q3. Moving now to our consolidated results.\n\n**Susan Li** (CFO)\nQ4 total revenue was $59.9 billion, up 24% or 23% on a constant currency basis. Q4 total expenses were $35.1 billion, up 40% compared to last year. Year-over-year growth was driven primarily by employee compensation expenses, legal expenses, and infrastructure costs. Growth in employee compensation expenses reflects the technical hires we've added this year, particularly AI talent. Legal expense growth was due to both lapping legal accrual reversals in Q4 of 2024 and charges recorded in Q4 2025. Infrastructure expense growth was driven by higher depreciation, cloud spend, and other operating expenses. We ended Q4 with over 78,800 employees, up 6% year-over-year, driven by hiring in priority areas of monetization, infrastructure, Meta Superintelligence Labs, as well as regulation and compliance.\n\n**Susan Li** (CFO)\nFourth quarter operating income was $24.7 billion, representing a 41% operating margin. Q4 interest and other income was $609 million, driven primarily by unrealized gains on our equity investments. Our tax rate for the quarter was 10%, slightly lower than our outlook of 12%-15% due to the settlement of matters with tax authorities. Net income was $22.8 billion or $8.88 per share. Capital expenditures, including principal payments on finance leases, were $22.1 billion, driven by investments in data centers, servers, and network infrastructure. Free cash flow was $14.1 billion. We ended the quarter with $81.6 billion in cash and marketable securities and $58.7 billion in debt. Turning now to the business performance.\n\n**Susan Li** (CFO)\nThere are two primary factors that drive our revenue performance: our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we're continuing to drive incremental engagement from ranking and product improvements. Instagram Reels had another strong quarter, with watch time up more than 30% year-over-year in the U.S. Engagement is benefiting from several optimizations we made to improve the quality of recommendations, including simplifying our ranking architecture to enable more efficient model scaling. This unlocked the ability for our systems to consider longer interaction histories to better identify a person's interests. On Facebook, video time continued to grow double digits year-over-year in the U.S., and we're seeing strong results from our ranking and product efforts on both feed and video surfaces.\n\n**Susan Li** (CFO)\nThe optimizations we made in Q4 drove a 7% lift in views of organic feed and video posts on Facebook, resulting in the largest quarterly revenue impact from Facebook product launches in the past two years. We're continuing to increase the freshness and originality of content recommendations as well. On Facebook, our systems are surfacing over 25% more Reels published that day than the prior quarter. On Instagram, we grew the prevalence of original content in the U.S. by 10 percentage points in Q4, with 75% of recommendations now coming from original posts. Threads is also seeing strong momentum, again, benefiting from recommendation improvements. The optimizations we made in Q4 drove a 20% lift in Threads time spent. Turning to 2026, we see a lot of opportunity to drive additional gains.\n\n**Susan Li** (CFO)\nThis includes scaling the complexity and amount of training data we use in our models, while continuing to make our systems more responsive to people's real-time interests. We're also focused on incorporating LLMs to understand content more deeply across our platform, which will enable more personalized recommendations. Another big area of investment this year is developing the next generation of our recommendation systems. We have several big bets on this front, including building new model architectures from the ground up that will work on top of LLMs, leveraging the world knowledge and reasoning capabilities of an LLM to better infer people's interests. Beyond improvements to our recommendation systems, we expect to use the models developed by Meta Superintelligence Labs to deliver compelling and differentiated AI products. One area we're already seeing promise is with AI dubbing of videos into local languages.\n\n**Susan Li** (CFO)\nWe are now supporting nine different languages, with hundreds of millions of people watching AI-translated videos every day. This is already driving incremental time spent on Instagram, and we plan to launch support for more languages over the course of this year. We are also seeing strong traction with our media creation tools. Nearly 10% of the Reels people view each day are now created in our Edits app, almost tripling from last quarter. Within Meta AI, the number of daily actives generating media tripled year-over-year in Q4. This year, we expect to advance the capabilities of our underlying media generation models and ship new features to further enhance the product experience. Another area we're focused on for Meta AI is personalization. We're seeing in our early testing that personalized responses drive higher levels of engagement, and we expect to significantly advance the personalization of Meta AI this year.\n\n**Susan Li** (CFO)\nThis dovetails with our investments in content understanding, which will enable our systems to develop a deeper understanding of each person's interests and preference, preferences, while also identifying the most relevant content across our platform to pull into responses. Turning to the second driver of our revenue performance, increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. Here, our focus remains on tuning our systems to identify the right time and place to deliver ads. In some cases, this enables us to grow the overall level of ad load while preserving the user experience. However, an increasingly important part of this work is finding opportunities to drive incremental conversions within the same overall level of ad load by determining when a person is more interested in seeing an ad.\n\n**Susan Li** (CFO)\nIn fact, in the second half of 2025, our initiatives on Facebook to redistribute ads across users and sessions delivered a nearly four times larger revenue impact than Facebook ad load increases. We also continue to make progress on bringing ads to our newer services. Within Threads, we're beginning to expand ads to all remaining countries this month, including the U.K., European Union, and Brazil. On WhatsApp, we expect to complete the rollout of ads in Status throughout the year, with the level of ads remaining low in the near term while we follow our standard approach of optimizing ad formats and performance before ramping inventory. Moving to the second part of increasing monetization efficiency, improving performance for the businesses who use our tools. We're seeing very strong results from the ad performance investments we made throughout 2025, with year-over-year conversion growth accelerating through the fourth quarter.\n\n**Susan Li** (CFO)\nWe expect the set of investments we're making in 2026 will enable us to drive further gains as we continue to integrate AI across all layers of the marketing and customer engagement funnel. The first area is our ad system, where we're continuing to scale the complexity and size of our models to better select which ads to show. In Q4, we doubled the number of GPUs we use to train our GEM model for ads ranking. We also adopted a new sequence learning model architecture, which is capable of using longer sequences of user behavior and processing much richer information about each piece of content. The GEM and sequence learning improvements together drove a 3.5% lift in ad clicks on Facebook, and a more than 1% gain in conversions on Instagram in Q4.\n\n**Susan Li** (CFO)\nThis new sequence learning architecture is significantly more efficient than our prior architectures, which should enable us to further scale up the data, complexity, and compute we use in our future ranking models to deliver performance gains. As we scale up our foundational ads models like GEM, we are also developing more advanced models to use downstream of them at runtime for ads inference. In Q4, we launched a new runtime model across Instagram Feed, Stories, and Reels, resulting in a 3% increase in conversion rates in Q4. We continue to progress on our model unification efforts under Lattice as well. After seeing strong success with the consolidation of Facebook Feed and video models in the first half of 2025, in Q4, we consolidated models for Facebook Stories and other surfaces into the overall Facebook model.\n\n**Susan Li** (CFO)\nThis, along with a series of back-end improvements, drove a 12% increase in ads quality. In 2026, we expect to consolidate more models than we had in the prior two years as we continue to evolve our systems towards running a smaller number of highly capable models. Moving to the next area, ads products. We continue investing in ways to help businesses leverage AI to reduce the friction of setting up and optimizing an ad campaign. In Q4, we started testing our Meta AI business assistant with advertisers, which helps with tasks like campaign optimization and account support. In the coming months, we'll make it available to more advertisers, so each business has an AI assistant they can chat with that remembers their business's goals and provides personalized recommendations on how to improve performance. Another area we're deploying AI to improve performance is ad creative.\n\n**Susan Li** (CFO)\nThe combined revenue run rate of video generation tools hit $10 billion in Q4, with quarter-over-quarter growth outpacing the increase in overall ads revenue by nearly three times. We are also seeing very good results from our incremental attribution feature, which optimizes for incremental conversions in real time. Our latest model rollout in Q4 is driving a 24% increase in incremental conversions versus our standard attribution model, and this product has already achieved a multi-billion dollar annual run rate just seven months since launching. The last area of our monetization work I'll cover is business messaging, where we're seeing strong momentum across our portfolio of solutions.\n\n**Susan Li** (CFO)\nClick-to-Message ads revenue growth accelerated in Q4, with the U.S. up more than 50% year-over-year, driven by strong adoption of our website-to-message ads, which direct people to a business's website for more information before choosing to launch a chat. Paid messaging within WhatsApp continues to scale as well, crossing a $2 billion annual run rate in Q4. Finally, we're seeing good early traction with our business AIs in Mexico and the Philippines, with over one million weekly conversations between people and business AIs now happening on our messaging platforms. This year, we will expand availability of our business AIs to more markets, while also extending their capabilities, so they not only answer questions on topics like product availability, but can help people get things done right within WhatsApp.\n\n**Susan Li** (CFO)\nWe speak a lot about how AI is improving our products, but I'd like to take a moment to give an update on how it's changing the way we work. Mark mentioned our focus on making Meta a place where individuals can have significant impact. A big focus of this is to enable the adoption and advancement of our AI coding tools, where we're seeing strong momentum. Since the beginning of 2025, we've seen a 30% increase in output per engineer, with the majority of that growth coming from the adoption of agentic coding, which saw a big jump in Q4. We're seeing even stronger gains with power users of AI coding tools, whose output has increased 80% year-over-year. We expect this growth to accelerate through the next half. Next, I would like to discuss our approach to capital allocation.\n\n**Susan Li** (CFO)\nWe have significant opportunities to improve our core business in 2026. We plan to continue to prioritize investing in the business to support these opportunities, while also positioning us for an entirely new and exciting product cycle over the coming years, powered by our AI models. Procuring sufficient infrastructure capacity is central to these initiatives, and we're working to meet our silicon needs by deploying a variety of chips that optimally support each of our different workloads. To that end, in Q4, we extended our Andromeda ads retrieval engine, so it can now run on NVIDIA, AMD, and MTIA. This, along with model innovations, enabled us to nearly triple Andromeda's compute efficiency. In Q1, we will extend our MTIA program to support our core ranking and recommendation training workloads, in addition to the inference workloads it currently runs.\n\n**Susan Li** (CFO)\nMore broadly, as we invest in infrastructure to meet our business needs, we continue to prioritize maintaining long-term flexibility, so we can adapt to how the market develops. We're doing so in several ways, including changing how we develop data center sites, establishing strategic partnerships, contracting cloud capacity, and establishing new ownership structures for some of our large data center sites. We have a strong net cash balance and expect our business will continue to generate sufficient cash to fund our infrastructure investments in 2026, which is reflected in our expectations. Nonetheless, we will continue to look for opportunities to periodically supplement our strong operating cash flow with prudent amounts of cost-efficient external financing, which may lead us to eventually maintain a positive net debt balance.\n\n**Susan Li** (CFO)\nMoving to our financial outlook, we expect our first quarter 2026 total revenue to be in the range of $53.5 billion-$56.5 billion. Our guidance assumes foreign currency is an approximately 4% tailwind to year-over-year total revenue growth based on current exchange rates. Turning to the expense and CapEx outlooks, we expect full year 2026 total expenses to be in the range of $162 billion-$169 billion. The majority of expense growth will be driven by infrastructure costs, which includes third-party cloud spend, higher depreciation, and higher infrastructure operating expenses. The second-largest contributor to total expense growth is employee compensation, driven by investments in technical talent. This includes 2026 hires to support our priority areas, particularly AI, as well as a full year of expenses from 2025 hires.\n\n**Susan Li** (CFO)\nAt a segment level, we expect expense growth to be driven by the Family of Apps, with Reality Labs' operating losses remaining similar to 2025 levels. We anticipate 2026 capital expenditures, including principal payments on finance leases, to be in the range of $115 billion-$135 billion, with year-over-year growth driven by increased investment to support our Meta Superintelligence Labs efforts and core business. Despite the meaningful step up in infrastructure investment, in 2026, we expect to deliver operating income that is above 2025 operating income. Absent any changes to our tax landscape, we expect our full year 2026 tax rate to be 13%-16%. Finally, we recently aligned with the European Commission on further changes to our less personalized ads offering, which we will begin rolling out this quarter.\n\n**Susan Li** (CFO)\nHowever, we continue to monitor legal and regulatory headwinds in the E.U. and the U.S. that could significantly impact our business and financial results. For example, we continue to see scrutiny on youth-related issues and have a number of trials scheduled for this year in the U.S., which may ultimately result in a material loss. In closing, 2025 was another strong year for our company. The investments we've made to improve our business are continuing to drive strong growth, and we have an exciting roadmap this year to deliver new experiences and services for our global community. As always, thank you to our teams for their hard work and commitment to our mission. With that, Krista, let's open up the call for questions.\n\n**Operator**\nThank you. We will now open the lines for a question-and-answer session. To ask a question, please press star one on your touchtone phone. To withdraw your question, again, press star one. Please limit yourself to one question. Please pick up your handset before asking your question to ensure clarity. If you are streaming today's call, please mute your computer speakers. Your first question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.\n\n**Brian Nowak** (Managing Director)\nThanks for taking my questions. I've one for Mark, one for Susan. Mark, one is a long-term question. As you think about ramping all this investment and the personal intelligence opportunity, the Meta Compute opportunity, can you walk us through a little bit how you think about the largest revenue or ROIC long-term opportunities you're trying to unlock with those over the next, call it three, five, 10 years through all the investment? And then, Susan, a little more near term, more like 2026. I think the guide is the fastest growth you've had in almost five years.\n\n**Brian Nowak** (Managing Director)\nI know you have a lot of improvements on recommendations and in monetization efficiency, but can you just sort of help us a little bit understand two or three of the biggest drivers of this inflection you're seeing on revenue in 2026?\n\n**Mark Zuckerberg** (CEO)\nYeah, I guess I can start with the first one. Although I have to say up front that I think my answers to a lot of your questions on this particular call may be somewhat unfulfilling because we're in this interesting period where we've been rebuilding our AI effort, and we're six months into that, and I'm happy with how it's going. But we are going to be rolling out our initial set of models and products and businesses around that over the coming months, and I will have a lot more to share on all of those fronts at that point.\n\n**Mark Zuckerberg** (CEO)\nSo I'm happy to offer kind of a high-level view of some of the stuff, but, but I apologize in advance that not much of this is going to be particularly detailed, but it will be exciting as we roll it out. I think the theme on the business, I mean, this is... I don't think I'm going to break any new ground here, but you know, there are several major business opportunities that we're focused on. You know, I think that one is just going to be improving the core products and accelerating the core, the current business. I talked about that in terms of the connecting of the recommendation systems and the LLMs, which I think will both improve the quality of the organic experience and of advertising.\n\n**Mark Zuckerberg** (CEO)\nWe're going to see the generation of media improve the quality of content, which, coupled with the improvements in the recommendation systems, we expect to generally accelerate the quality and effectiveness of the core business, both for people who use it organically and for businesses. So I think that will have a compounding effect. And then, there's gonna be, you know, several many, I think, new business opportunities that come up. I mean, we have been working on Meta AI for a while. I think you're starting to see some of the way that products like that get monetized across the industry. When we get that to a scale and depth that we want, we think that there are gonna be opportunities both in terms of subscriptions and advertising and all of the different things that you see on that.\n\n**Mark Zuckerberg** (CEO)\nI mean, yeah, I think, you know, there's a number of things on shopping and commerce that I'm quite excited about that I alluded to in the comments up front. And as the models launch and we demonstrate some of the capabilities, both in the first set of models and over the year, I think the models are gonna get a lot better too. We'll be able to have different products paired with those that I think will facilitate different businesses for, you know, businesses who use us and our platforms, as well as direct-to-consumer businesses. I guess it's probably also worth flagging because I don't think we, either of us, mentioned the Manus acquisition in the upfront comments.\n\n**Mark Zuckerberg** (CEO)\nI think that is going to be a good example of a significant number of businesses that already pay a subscription to basically use their tool to accelerate their business results. Integrating that kind of thing into our Ads and Business Manager, so that way we can just offer more integrated solutions for the, you know, many, many millions of businesses that use and rely on our platforms, is gonna be really powerful, both for accelerating their results using the existing products that we have, and I think adding new lines as well. You know, a somewhat high-level answer, and I think the picture will become clearer and I think more exciting if we do our jobs well over the course of the year.\n\n**Susan Li** (CFO)\nBrian, on your second question, there's obviously a range of outcomes captured in the Q1 2026 revenue outlook. It overall reflects our expectation for a strong quarter of growth. The range embeds an outlook for accelerated growth, and that's really underpinned by the strong demand that we saw through the end of Q4 and continuing into the start of 2026. Now, I will say we also expect foreign currency to be a 4-point benefit to year-over-year growth, so that is a three-point larger tailwind than it was in Q4 2025, as we lap the strengthening of the U.S. dollar a year ago. But overall, you know, we see that advertisers are responding to ad performance improvements that we made. They're driving strong conversion growth.\n\n**Susan Li** (CFO)\nWe've made a lot of these investments over the course of 2025, including advances to our ads ranking and delivery systems, the more effective redistribution of ad load, new features and ad products like Advantage+, better measurement, and just a lot of great work that has helped to drive the continued performance of our ads.\n\n**Operator**\nYour next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.\n\n**Eric Sheridan** (Managing Director)\nThanks so much for taking the question. Maybe two, if I could. In prior periods, you've talked about being capacity constrained internally and not having enough compute to sort of achieve the goals you have on a platform and a product standpoint. I wanna know if we get any update on currently how you think about your own internal needs for compute against that roadmap. And the second part of the question would be: as we continue to see the ads business sorta scale, especially in terms of dollar growth year-over-year, have we yet seen the full first order effects of scaling the business against applying more compute to it? Or how should investors think about the directional relationship between applying more compute and rate of change in terms of outcomes on the monetization side? Thank you.\n\n**Susan Li** (CFO)\nOn your first question, we do continue to be capacity constrained. Our teams have done a great job ramping up our infrastructure through the course of 2025, but demands for compute resources across the company have increased even faster than our supply. So we expect over the course of 2026 to have significantly more capacity this year as we add cloud. But we'll likely still be constrained through much of 2026 until additional capacity from our own facilities comes online later in the year. With that said, I think, you know, we have done a good job internally mitigating the impact of compute constraints on our business. I expect that will continue to be the case in 2026.\n\n**Susan Li** (CFO)\nWe're continuing to focus on increasing our infrastructure efficiency in several ways, including by optimizing workloads, improving infrastructure utilization, diversifying our chip supply, and just investing in efficiency improvements as part of our core technology development efforts in areas like content and ads ranking. So that was your first question. The second question about how the ads business scales. I think I don't have an extremely precise answer to this question. What I'd say is, you know, one of the ways that we are working to drive ads performance improvements is by improving our larger scale models, along with our lighter weight ones that we use for ads inference at runtime. You know, we don't typically use our larger model architectures, like GEM for inference because their size and complexity would make it too cost prohibitive.\n\n**Susan Li** (CFO)\nSo the way that we drive performance from those models is by using them to transfer knowledge to smaller, lightweight models used at runtime. But I would say that we think that there is room for our larger models to benefit from having more compute. And I think as we scale up the compute available to those models, and the foundational models in different areas that power the different stages of ads ranking and recommendation, you know, we expect that we will see gains coming from that.\n\n**Operator**\nYour next question comes from the line of Mark Shmulik with Bernstein. Please go ahead.\n\n**Mark Shmulik** (Managing Director and Senior Analyst of U.S. Internet)\nYes, thanks for taking the questions, too, if I may. Mark, kind of with your comments that you kind of expect to see some meaningful changes in how work and things are done this year, I guess, would you be surprised if kind of by the end of the year, we've yet to see meaningful progress and adoption on some of the newer products and initiatives that you're launching? Or, you know, should we just be a bit more patient on the timeline here? And then, Susan, kind of with the guidance provided on OI still expected to grow kind of faster this year than last year, you know, let's say in a few months, we realize we need more investment and resources to continue to go after the AI opportunity, but perhaps macro might be a bit weaker.\n\n**Mark Shmulik** (Managing Director and Senior Analyst of U.S. Internet)\nHow hard of a line is there in terms of the tie of investment levels to core performance? Thank you.\n\n**Mark Zuckerberg** (CEO)\nI think the first question was asking about kind of when do I expect the product impact to be? I mean, we're going to roll out new products over the course of the year. I think the important thing is we're not just launching one thing and we're building a lot of things. I think therelike, AI is going to enable a lot of new experiences. I outlined thematically a bunch of these in the upfront comments around, you know, a personal AI, around, LLMs combining with the recommendation systems. I think that's a somewhat longer-term research project that I think will yield dividends over a long period of time, but we're already definitely seeing optimizations of the recommendation systems as we're including more of the AI research improvements and advances into that. The content is going to improve.\n\n**Mark Zuckerberg** (CEO)\nThere are going to be new formats. There are going to be improvements on the glasses. There are all these different things, as well as several new things that we think are new, that we're going to try that are not just extensions of the current things that we're doing. Yeah, I mean, I would expect that we'll roll these out over the course of the year and that you know, sometimes it takes a few iterations for things to really hit and reach the kind of product market fit that you need.\n\n**Mark Zuckerberg** (CEO)\nBut I think we have enough time, hopefully, to, you know, in the-- we're starting off early enough in the year, that I would expect that we'll see some successes by the end of the year on this, as well as on the work side. What we were talking about is I think it's very hard for anyone exactly to predict what the shape of, you know, how organizations working is going to feel. But it... I just think the fact that agents are really starting to work now is quite profound, and I think is going to allow-- we're already starting to see the people who adopt them are just being significantly more productive.\n\n**Mark Zuckerberg** (CEO)\nThere's a big delta between the people who do it and do it well, and the people who don't. I think that's going to just be a very profound dynamic for, I think, across the whole sector and probably the whole economy going forward in terms of the productivity and efficiency with which we can run these companies, which I think, you know, my hope is that we can use that to just get a lot more done than we were able to before. I'm most focused on making sure that Meta is a great company to have a big impact, right?\n\n**Mark Zuckerberg** (CEO)\nYou'll be able to use these kind of agentic tools anywhere, but you will only be able to come and ship things to billions of people if you join a company like Meta, and there aren't that many companies like Meta. So, I think if we make it so that we can harness these kind of tools, then I think that we should, over some period of time, start to see a real acceleration in the amount of output that we could have. Now, how to predict exactly the time frame for adopting that, somewhat hard, right? I'm not going to predict a specific quarter or something like that, but the trend seems like unmistakably like this is going to happen.\n\n**Mark Zuckerberg** (CEO)\nAnd that, to me, is something that is very exciting and, like I said in my comments up front, also, like, honestly, kind of fun, right? I think it just makes it more fun to be able to build a lot of things. And, you know, that's what we're here to do.\n\n**Susan Li** (CFO)\nMark, on your second question, I want to make sure and clarify something. So I think in the question, you had said that operating income growth in 2026 would be higher than 2025, and I want to make sure my comments were super clear. In 2026, we expect to deliver operating income above 2025 operating income. So this is comparing absolute dollars, not year-over-year growth. So to give some context on that, you know, we are going into 2026 with strong revenue growth at the start. Of course, we are just a few weeks in, set against, you know, a healthy macro backdrop, so obviously hard to extrapolate the current trends to the full year and, you know, there are many, many moving variables in the current landscape.\n\n**Susan Li** (CFO)\nWe're really taking advantage of the current business strength to reinvest a lot of the revenue into what we see as very attractive investment opportunities in AI infrastructure and talent. It's hard to assess, you know, what all of those investment opportunities will be over the course of the year as we continue to work through our capacity options. And of course, it remains a very competitive hiring market, but we'd like to invest aggressively where we can. We continue to use our framework that we shared at this point, several years ago, of growing consolidated operating profit over time to guide those investments. Based on where our plans are rolling up today, again, in 2026, we expect to deliver more operating income than we did in 2025.\n\n**Operator**\nYour next question comes from the line of Doug Anmuth with JPMorgan. Please go ahead.\n\n**Doug Anmuth** (Head of U.S. Internet Equity Research)\nThanks so much for taking the questions. One for Mark and one for Susan. Mark, could you just provide more detail on the progress of the MSL team several months in, and more on your view on the path to a frontier model this year? And then, Susan, I know you expect to grow operating income in 2026. Do you also expect to have positive free cash flow? Just how should we think about the current and any future, JVs for data center and compute build-out? Thanks.\n\n**Mark Zuckerberg** (CEO)\n... I'm not sure I have anything else to add on the current progress on this. I mean, that's why I said up front that I think this is somewhat of an unfulfilling time to be answering some of these questions. We're about six months in to building MSL. I'm very pleased with the quality of the team. I think we have the most talent-dense research effort in the industry, and some of the early indicators look positive. But look, I think that this is gonnathis is a long-term effort, right? We're not here to do this to ship, like, one model or one product. We're doing a lot of models over time and a lot of different products.\n\n**Mark Zuckerberg** (CEO)\nAnd I wanna make sure that the work can speak for itself, and also that you know we all internalize that this is a journey that we're on, and the first set of things that we put out, I think, are gonna be more about showing the trajectory that we're on, rather than being a single moment in time. So, yeah, I'm quite optimistic, but don't have anything else, you know, particularly concrete to share.\n\n**Susan Li** (CFO)\nDoug, on the first part of your question, you know, we are making very significant investments in infrastructure capacity this year to support our AI efforts, and we believe we're in a strong position to support them with the cash generation of our business this year. And, you know, at the same time, we'll continue to explore different paths, as we build out our infrastructure capacity that help us provide, you know, that help provide us the long-term flexibility and option value that we look for as we support our future capacity needs against the backdrop of a very wide range of possible capacity demand over the years to come. So we don't have anything additional to announce at this point.\n\n**Susan Li** (CFO)\nYou know, we are looking at, you know, all of the different opportunities to stand up capacity across kind of the different time frames that we need them.\n\n**Operator**\nYour next question comes from the line of Justin Post with Bank of America. Please go ahead.\n\n**Justin Post** (Managing Director)\nGreat. A couple, maybe one for Mark and one for Susan. It just seems like you're gonna have a tremendous amount of capacity. How do you think about expanding your opportunities beyond ads? Things like subscriptions or licensing cloud models, just with all the interesting things you're building. I don't expect any product announcements, but can you do things beyond ads? And then for Susan, it's really interesting to see the acceleration, even ex-FX and advertising. I'm just wondering if you're seeing a general acceleration in e-commerce activity. Where do you think the dollars are coming from, and is the entire internet ecosystem accelerating? I'm just wondering your thoughts on that.\n\n**Mark Zuckerberg** (CEO)\nSo yes, we are focused on things beyond ads. I think the numbers make it so that for the next couple of years, ads are going to be by far the most important driver of growth in our business. So that's why as we're working on this, we have a balance of new things that we're trying to do, while also investing very heavily in making sure that all of the work that we're doing in AI improves both the quality and business performance of the core apps and businesses that we run there.\n\n**Mark Zuckerberg** (CEO)\nYeah, I mean, we'll have more to share on that, but I mean, all these things, even if they scale very quickly, are going to take, you know, some time to be meaningful at the scale of what the ads business is. And while we're doing that, we're just very focused on also delivering more value to businesses and more quality in the apps that we run ads in.\n\n**Susan Li** (CFO)\nJustin, on your second question, we saw healthy year-over-year growth across all verticals in Q4, with the exception of politics as we lapped the U.S. presidential election last year. The online commerce vertical was the largest contributor to year-over-year growth. That was followed by professional services and technology. So in online commerce, year-over-year growth was strong. It was actually relatively consistent with Q3 levels, and that was broad-based across advertiser regions and sizes. In general, we saw that the demand leading up to the holiday shopping period that sustained through Cyber Five and into the end of the year, you know, was very healthy for us.\n\n**Susan Li** (CFO)\nProfessional services, in this category, we saw strong, broad-based growth with nice contributions from lead generation ads due to product improvements we've made, including from Advantage+ lead campaigns that we fully rolled out at the start of Q4. And, you know, the tech vertical continues to be strong for us, too. Again, broad-based across advertiser regions and sizes. So in general, I would say it was very healthy, broadly driven growth.\n\n**Operator**\nYour next question comes from the line of Ross Sandler with Barclays. Please go ahead.\n\n**Ross Sandler** (Managing Director and Senior Equity Research Analyst)\nYeah. Mark, you mentioned bringing Horizon Worlds into mobile. We haven't heard much from the Horizon Worlds squad on these calls, so interesting that that's making it in. It seems like the combo of AI and what you guys have built with Horizon might open up the door to a bunch of new potential areas in gaming or, you know, new forms of kind of communication. So could you just elaborate on what the plan is there? Thank you.\n\n**Mark Zuckerberg** (CEO)\nYeah. So let me talk about the basic theme here. You know, one core idea that I've talked about on some of these calls over the years is that people always want to express themselves and experience the world in whatever the richest format is that they can. So I talked about this upfront today. It's when we started, a lot of this was text, right? That was the kind of the best we could do. Then we all got phones. They had cameras. Like, a lot of this medium became visual, but with photos. We went through a period where the mobile networks were kind of weak, and every time you wanted to watch a video, it would buffer. And once that got worked out, now the majority of the content is video. And one of the core ideas that-...\n\n**Mark Zuckerberg** (CEO)\nWe have had for a while, is that that is not the end of the line. All right, video will continue to be here for a long time. It's going to continue growing. It's not going anywhere, just like photos and text, in many ways, continue to grow even as the market continues to grow beyond that. But I don't think that video is the ultimate kind of final format. I just think that this is gonna get we're gonna get more formats that are more interactive and immersive, and you're gonna get them in your feeds.\n\n**Mark Zuckerberg** (CEO)\nSo you can imagine this, I mean, there's obviously a lot of details to fill in on this, but you can imagine, you know, being able to, people being able to easily, through a prompt, create a world or create a game and, be able to share that with people who they care about, and you see it in your feed, and you can jump right into it, and you can engage in it. And there are 3D versions of that, and there are 2D versions of that, and Horizon, I think, fits very well with the kind of immersive 3D version of that. But there's definitely a version of the future where, you know, any video that you see, you can, like, tap on and jump into it and, like, engage and, like, and be, be kind of like experience it in a, in a more meaningful way.\n\n**Mark Zuckerberg** (CEO)\nI think that the investments that we've done in both a lot of the virtual reality software and Horizon, as well as a number of other areas around the company, are actually going to pair well with these AI advances to be able to bring some of those experiences to hundreds of millions and billions of people through mobile. So anyway, that's the thing that I'm quite excited about, but it's, it's just sort of one flavor of a, of a theme that I think is going to be very interesting. I think there are going to be lots of different types of interactive and immersive content that become possible. I think Horizon is going to be one very interesting example that, that I'm quite excited to see how this unfolds.\n\n**Operator**\nYour next question comes from the line of Ron Josey with Citi. Please go ahead.\n\n**Ron Josey** (Managing Director)\nGreat. Thanks for taking the question. I wanted to drill down, maybe, Susan, on your comments around ranking recommendation model changes. You know, clearly, lots of tailwinds here, given the results from GEMs, Andromeda, Lattice, consolidation of models, et cetera. So can you help us understand a little bit more just about the roadmap and where we stand within ranking recommendation model changes? There, there's a thesis out there that maybe we're, you know, there's a limiting factor, or maybe we're waiting on newer models, but any insights there would be very helpful as we think about the next, as the future going forward. Thank you.\n\n**Susan Li** (CFO)\nYeah, thanks for the question, Ron. I'm just sorting out if your question was more specific to ads or if it was more specific to kind of the engagement side, but I'll try to talk a little bit about both. So on the sort of core engagement piece, you know, we launched several ranking improvements in Q4 on Facebook and Instagram that drove incremental engagement, and there isn't really one single launch, you know, that is driving most of the gains. It's, you know, multiple optimizations to our recommendation systems that are helping us make more accurate predictions about what will be interesting to each person. And, you know, I talked a little bit about some of these, the specific instantiations on both Facebook and on Instagram.\n\n**Susan Li** (CFO)\nWe see, you know, a lot of headroom to improve recommendations in 2026, which we expect will drive additional engagement growth on both apps. First, we plan on to continue scaling up our models and increase the amount of data we use, including a longer history of content interactions, to further improve the overall quality of recommendations. We're also going to start validating the use of ad signals and organic content recommendations as we continue to work towards having a more shared platform for organic and ads recommendations over time. Second, we're gonna continue to make recommendations even more adaptive to what a person is engaging with during their session, so the recommendations we surface are more relevant to what they're interested in at that moment.\n\n**Susan Li** (CFO)\nFinally, we will work on more deeply incorporating LLMs into our existing recommendation systems, given their capability to more deeply understand content. And so this will, I think, in particular, be useful for content that has been more recently posted since there's less engagement data to base recommendations off of. On the ad side, again, we've talked about a lot of the sort of model work in the ads world across Andromeda and Lattice and GEM. I'll touch maybe specifically, you know, on GEM in Q4. We extended GEM to cover Facebook Reels. Now it covers all major surfaces across Facebook and Instagram. We also doubled the size of the GPU cluster we use to train it.\n\n**Susan Li** (CFO)\nIn 2026, we're expecting to meaningfully scale up GEM training to an even larger cluster, increasing the complexity of the model, expanding the data that we train it on, leveraging new sequence learning architecture that we had begun deploying in Q4. And we're also going to further improve how we transfer the learnings from our GEM foundation models to the runtime models that we're using. So, you know, there's a lot more headroom, I think, across many, many components of the stack. This is the first time we have found a recommendation model architecture that can scale with similar efficiency as LLMs, and, you know, we're hoping that this will unlock the ability for us to significantly scale up the size of our ranking models, you know, while preserving an attractive ROI.\n\n**Operator**\nYour next question will come from the line of Ken Gawrelski with Wells Fargo. Please go ahead.\n\n**Ken Gawrelski** (Managing Director and Senior Internet Analyst)\nThank you very much. Two, if I may, please. First, for Mark, how critical is it for Meta to have a leading general-purpose model, or is there a sufficient capability in a model that really excels at specific use cases, maybe similar to what you see at Anthropic in coding today? If you could opine on that. And then second, maybe, I just want to push again, maybe on this last question, Susan.\n\n**Ken Gawrelski** (Managing Director and Senior Internet Analyst)\n... on the, the visibility you have, you talked about the improvements you're making in 2026 on the, on the models, the fine-tuning, of the core, both in engagement and, and ad relevance. Could you talk about, are you seeing any signs of diminishing returns to those investments? And, and do you think, do you have visibility beyond 2026 into, further opportunities there? Thank you.\n\n**Mark Zuckerberg** (CEO)\nI, I think the question was around how important is it for us to have a general model? You know, the way that I think about Meta is we're a, like, a deep technology company. Some people think about us as we build these apps and experiences, but the thing that allows us to build all these things is that we build and control the underlying technology that allows us to integrate and design the experiences that we want, and not just be constrained to what others in the ecosystem are building or allow us to build. So, I, I think that this is a, a really fundamental thing, where my guess is that frontier AI, for many reasons, some competitive, some safety-oriented, are not going to always be available through an API to everyone.\n\n**Mark Zuckerberg** (CEO)\nSo I think, like, it's very important, I think, to be able to have the capability to build the experiences that you want if you wanna to, to be one of the major companies in the world that helps to shape the future of these products. So that, that I think is... It's going to be, I think, important from a business perspective, and I think it's just important from, like, a creative and mission perspective, to be able to actually design and build the experiences that we believe that we should be building for people. But yeah, I mean, I think it's quite important, otherwise we wouldn't be so focused on this, where we're clearly extremely focused on this.\n\n**Susan Li** (CFO)\nYou know, interestingly, a year ago on this call, I think I talked about the set of investments we were making in 2025, as part of our 2025 budgeting process across our ads performance and organic engagement initiatives. You know, and those, those investments have generally paid off, and we, you know, feel really good about, about kind of the, the process we ran in terms of using projected ROI to stack rank investments. Make sure that we, you know, had a robust measurement system, funded things that were positive ROI, and then tracking how they performed over the course of the year.\n\n**Susan Li** (CFO)\nAnd we are, you know, we've just finished running our 2026 budgeting process, and we have funded a similar set of investments, which we expect will enable us to continue delivering strong revenue growth in 2026. Having said that, you know, I expect both full year reported and constant currency revenue growth to be below the levels in Q1, for a few reasons. First, we would expect that currency tailwinds will dissipate later in the year based on current rates. Second, we'll be lapping stronger periods of growth later in the year that benefited from our 2025 ad performance investments and the strong macro landscape. And finally, we expect there could be some headwinds from our introduction of the revised, less personalized ads offering in the EU that begins rolling out later in Q1.\n\n**Susan Li** (CFO)\nBut again, similar to 2025, we feel good about the process by which we identified investment opportunities with attractive ROIs and funded them as part of our budget, to support, you know, key initiatives across our ranking and recommendation systems, and to increase the capacity efficiency of our models, all of which are key to sort of driving, to driving growth for us.\n\n**Operator**\nYour next question comes from the line of Mark Mahaney with Evercore. Please go ahead.\n\n**Mark Mahaney** (Senior Managing Director)\nOkay, two questions, please. Meta AI, any update on what you're seeing there in terms of engagement and usage? And do you think you're just starting to be able to apply improvements to that specific functionality? And then just real quickly on share repurchases, Susan, I don't think you bought any stock back in the quarter. It's been a while, maybe a year, since you haven't bought anything back. You talked about capital allocation a little bit into the year. It didn't sound like you're gonna be buying back stock anytime soon, but just do you want to clarify that? Thanks a lot.\n\n**Susan Li** (CFO)\nYes, I'm happy to take both of those. So, Meta AI, the quick update there is, you know, it's now available in over 200 markets. The largest daily active user markets for Meta AI align with where our apps are also very popular. Though the apps people engage most with Meta AI differ, in some places, you know, it's primarily WhatsApp driven, for example, India or Indonesia. In the U.S., Facebook is a stronger driver of engagement. And in general, we see a lot of opportunity to make it easier for people to accomplish the tasks that they already come to our services for every day, and if we do that well, then the way people use our products will continue to expand.\n\n**Susan Li** (CFO)\nWe're focused on making Meta AI the most personalized assistant, while tapping into the vast amount of, you know, information, trends, content from our platform, to offer differentiated insights. We think we have a very strong track record in building highly personalized experiences, and we're bringing that into Meta AI so that we can tailor responses to each person's personal interests and preferences. On your second question, which is about share repurchases, you know, share repurchase levels will vary from time to time, for a lot of reasons, including whether we believe there are areas that have a greater near-term need for capital. Right now, we think the highest order priority for the company is investing our resources to position ourselves as a leader in AI.\n\n**Susan Li** (CFO)\nAnd so that is really that's kind of the first order use of capital, but we'll continue to be opportunistic and evaluate repurchases versus other uses of cash.\n\n**Kenneth Dorell** (Director of Investor Relations)\nGreat! I think we will wrap it here. Thank you everyone for joining us today. We look forward to speaking with you again soon.\n\n**Operator**\nThis concludes today's conference call. Thank you for your participation, and you may now disconnect.",
        "fetched_at": "2026-02-04T16:11:59.143Z"
      },
      {
        "ticker": "META",
        "title": "Yahoo Finance",
        "published_date": "Oct 29, 2025, 4:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/META/earnings/META-Q3-2025-earnings_call-368931.html",
        "content": "**Operator**\nGood afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta Third Quarter Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be a question and answer session. If you would like to ask a question, please press star one on your telephone keypad. To withdraw your question, again press star one. We ask that you limit yourself to one question, and this call will be recorded. Thank you very much. Kenneth Dorell, Meta's Director of Investor Relations, you may begin.\n\n**Kenneth Dorell** (Director of Investor Relations)\nThank you. Good afternoon and welcome to Meta Platforms' Third Quarter 2025 Earnings Conference Call. Joining me today are Mark Zuckerberg, CEO, and Susan Li, CFO. Our remarks today will include forward-looking statements, which are based on assumptions as of today. Actual results may differ materially as a result of various factors, including those set forth in today's earnings press release and in our quarterly report on Form 10-Q filed with the SEC. We undertake no obligation to update any forward-looking statement. During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.appmeta.com. I would now like to turn the call over to Mark.\n\n**Mark Zuckerberg** (CEO)\nAll right. Thanks, Ken. Thanks, everyone, for joining today. We had another strong quarter with 3.5 billion people using at least one of our apps every day. Instagram hit a major milestone with 3 billion monthly actives, and we're seeing good momentum across our other apps as well, including Threads, which recently passed 150 million daily actives and remains on track to become the leader in its category. I am very focused on establishing Meta as the leading frontier AI lab, building personal superintelligence for everyone, and delivering the app experiences and computing devices that will improve the lives of billions of people around the world. Our approach of advancing open-source AI means that when Meta innovates, everyone benefits. Meta's Superintelligence Lab is off to a strong start. I think that we've already built the lab with the highest talent density in the industry.\n\n**Mark Zuckerberg** (CEO)\nWe're heads down developing our next generation of models and products, and I'm looking forward to sharing more on that front over the coming months. We're also building what we expect to be an industry-leading amount of compute. Now, there's a range of timelines for when people think that we're going to get superintelligence. Some people think that we'll get there in a few years. Others think it will be five, seven years, or longer. I think that it's the right strategy to aggressively front-load building capacity so that way we're prepared for the most optimistic cases. That way, if superintelligence arrives sooner, we will be ideally positioned for a generational paradigm shift and many large opportunities.\n\n**Mark Zuckerberg** (CEO)\nIf it takes longer, then we'll use the extra compute to accelerate our core business, which continues to be able to profitably use much more compute than we've been able to throw at it. We're seeing very high demand for additional compute, both internally and externally. In the worst case, we would just slow building new infrastructure for some period while we grow into what we build. The upside is extremely high for both our existing apps and new products and businesses that are becoming possible to build. Across Facebook, Instagram, and Threads, our AI recommendation systems are delivering higher quality and more relevant content, which led to 5% more time spent on Facebook in Q3 and 10% on Threads. Video is a particular bright spot, with video time spent on Instagram up more than 30% since last year.\n\n**Mark Zuckerberg** (CEO)\nAs video continues to grow across our apps, Reels now has an annual run rate of over $50 billion. Improvements in our recommendation systems will also become even more leveraged as the volume of AI-created content grows. Social media has gone through two eras so far. The first was when all content was from friends, family, and accounts that you followed directly. The second was when we added all of the creator content. Now, as AI makes it easier to create and remix content, we're going to add yet another huge corpus of content on top of those. Recommendation systems that understand all this content more deeply and can show you the right content to help you achieve your goals are going to be increasingly valuable. Our ads business continues to perform very well, largely due to improvements in our AI ranking systems as well.\n\n**Mark Zuckerberg** (CEO)\nThis quarter, we saw meaningful advances from unifying different models into simpler, more general models, which drive both better performance and efficiency. Now, the annual run rate going through our completely end-to-end AI-powered ad tools has passed $60 billion. One way that I think about our company overall is that there are three giant transformers that run Facebook, Instagram, and ads recommendations. We have a very strong pipeline of lots of ways to improve these models by incorporating new AI advances and capabilities. At the same time, we are also working on combining these three major AI systems into a single unified AI system that will effectively run our family of apps and business, using increasing intelligence to improve the trillions of recommendations that we'll make for people every day. I'm also very excited about the new products that we're going to be able to build.\n\n**Mark Zuckerberg** (CEO)\nMore than a billion monthly actives already use Meta AI, and we see usage increase as we improve our underlying models. I'm very excited to get a frontier model into Meta AI, and I think that the opportunity there is very large. The same goes for our business AI. Every day, people have more than 1 billion active threads with business accounts across our messaging platforms, ranging from product questions to customer support. Our business AIs will enable tens of millions of businesses to scale these conversations and improve their sales at low cost. The better our models get, the better this is going to work for all businesses. This quarter, we also launched Vibes, which is the next generation of our AI creation tools and content experiences. Retention is looking good so far, and its usage keeps growing quickly week over week.\n\n**Mark Zuckerberg** (CEO)\nI'm looking forward to ramping up the growth of Vibes over the coming months. More broadly, I think that Vibes is an example of a new content type enabled by AI, and I think that there are more opportunities to build many more novel types of content ahead as well. As our new models become ready, I'm looking forward to starting to show everyone some of the new kinds of products that we're working on. At Connect, we announced our 2025 line of AI glasses, and the response so far has been great. The new Ray-Ban Meta Smart Glasses and Oakley Meta Vanguards are both selling well, as people love the improved battery life, camera resolution, new AI capabilities, and the great design. There is our new Meta Ray-Ban display glasses, our first glasses with a high-resolution display and the Meta Neural Band to interact with them.\n\n**Mark Zuckerberg** (CEO)\nThey sold out in almost every store within 48 hours, with demo slots fully booked through the end of next month. We are going to have to invest in increasing manufacturing and selling more of those. This is an area where we are clearly leading and have a huge opportunity ahead. Taking a step back, if we deliver even a fraction of the opportunity ahead for our existing apps and the new experiences that are possible, then I think that the next few years will be the most exciting period in our history. We've got a lot to do, but we're making real progress, delivering strong business results, building the talent density and infrastructure needed for the next era, and leading the way on AI devices that will define the next computing platform.\n\n**Mark Zuckerberg** (CEO)\nI'm proud of how our teams are rising to the challenge, and I'm grateful for their dedication, hard work, and creativity. As always, thank you all for being a part of this journey with us. Now, here's Susan.\n\n**Susan Li** (CFO)\nThanks, Mark, and good afternoon, everyone. Let's begin with our segment results. All comparisons are on a year-over-year basis unless otherwise noted. Our community across the family of apps continues to grow, and we estimate more than 3.5 billion people used at least one of our family of apps on a daily basis in September. Q3 total family of apps revenue was $50.8 billion, up 26% year over year. Q3 family of apps ad revenue was $50.1 billion, up 26%, or 25% on a constant currency basis. In Q3, the total number of ad impressions served across our services increased 14%. Impression growth was healthy across all regions, driven by engagement and user growth, particularly on video services. The average price per ad increased 10% year over year, benefiting from increased advertiser demand, largely driven by improved ad performance.\n\n**Susan Li** (CFO)\nThis was partially offset by impression growth, particularly from lower monetizing regions and services. Family of apps other revenue was $690 million, up 59%, driven by WhatsApp paid messaging revenue growth, as well as Meta verified subscriptions. Within our reality lab segment, Q3 revenue was $470 million, up 74% year over year. The significant year-over-year growth in Q3 was partly due to retail partners stocking up on Quest headsets ahead of the holiday season. We did not have a similar benefit in the third quarter of last year since our Quest 3S headset launched in the fourth quarter of 2024. Aside from this, strong AI glasses revenue also contributed to revenue growth in Q3. Moving now to our consolidated results. Q3 total revenue was $51.2 billion, up 26% or 25% on a constant currency basis. Q3 total expenses were $30.7 billion, up 32% compared to last year.\n\n**Susan Li** (CFO)\nYear-over-year expense growth accelerated 20 percentage points from Q2, due primarily to three factors. First, legal-related expense growth was higher than in Q2 due to charges we recorded in the third quarter, as well as us lapping a period of accrual reversals in the third quarter a year ago. Second, employee compensation growth accelerated, driven by technical hires, particularly AI talent. Finally, growth in infrastructure costs accelerated due to increased infrastructure operating costs associated with our expanded data center fleet, depreciation on our incremental CapEx spend, and third-party cloud spend. We ended Q3 with over 78,400 employees, up 8% year over year, driven by hiring in priority areas of monetization, infrastructure, Reality Labs, Meta Superintelligence Labs, as well as regulation and compliance. Third quarter operating income was $20.5 billion, representing a 40% operating margin.\n\n**Susan Li** (CFO)\nQ3 interest and other income was $1.1 billion, driven primarily by unrealized gains on our marketable equity securities. Our tax rate for the quarter was 87%, which was unfavorably impacted by a one-time non-cash reduction in deferred tax assets that we no longer anticipate using under new U.S. tax law. Our tax rate would have been 14% excluding this charge. Although the transition to the new U.S. tax law resulted in an accounting charge in the third quarter, we continue to expect we will recognize significant cash tax savings for the remainder of the current year and future years under the new law, and this quarter's charge reflects the total expected impact from the transition to the new U.S. tax law. Net income was $2.7 billion, or $1.05 per share. Excluding the one-time tax charge, our net income and EPS would have been $18.6 billion and $7.25 per share, respectively.\n\n**Susan Li** (CFO)\nCapital expenditures, including principal payments on finance leases, were $19.4 billion, driven by investments in servers, data centers, and network infrastructure. Free cash flow was $10.6 billion. We repurchased $3.2 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders. We ended the quarter with $44.4 billion in cash and marketable securities and $28.8 billion in debt. Turning now to the business outlook, there are two primary factors that drive our revenue performance: our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, daily actives continue to grow year over year across Facebook, Instagram, and WhatsApp. We're continuing to see improvements to our products and recommendations drive incremental engagement, with year-over-year growth in global time spent accelerating on both Facebook and Instagram in Q3.\n\n**Susan Li** (CFO)\nIn the U.S., overall time spent on Facebook and Instagram grew double digits year over year, driven by continued video strength as well as healthy growth in non-video time on Facebook. The engagement gains continue to be driven by product work and ongoing improvements to our recommendation systems as we optimize our model architectures, implement advanced modeling techniques, and integrate more signals about people's interests. We also continue to focus on increasing the freshness of recommended content. On Facebook, our systems are now surfacing twice as many Reels published that day than at the start of the year. Looking to 2026, we expect to advance our recommendation systems across several dimensions. On Instagram, one focus is evolving our systems to surface content across a broader set of topics that cater to the diverse interests of each person.\n\n**Susan Li** (CFO)\nThis follows a similar approach we've implemented on Facebook that has driven good results. We also expect to make significant progress on our longer-term ranking innovations in 2026. We're seeing promising new results from our research efforts to create foundational ranking models and expect the new model innovations we're developing as part of this will enable us to significantly scale up the amount of data and compute we use to train our recommendation models in 2026, yielding more relevant recommendations. Another large focus next year is leveraging LLMs to improve content understanding. We expect this is going to enable our systems to more precisely label the keywords and topics within videos and posts, which will allow our systems to both develop deeper intuition about a person's interests and retrieve the content that matches them. Finally, we're making good progress with Meta AI and Threads.\n\n**Susan Li** (CFO)\nThe number of people using Meta AI across our family of apps continues to grow, and we're increasingly leveraging first-party content into Meta AI results, with the majority of Meta AI's responses to Facebook deep dive queries in the U.S. now showing related Reels. We're also seeing a lot of traction with media generation. People have created over 20 billion images using our products, and since launching Vibes within Meta AI in September, we've seen media generation in the app increase more than tenfold. On Threads, we see strong growth in both daily actives and the depth of engagement as we continue to improve recommendations. The ranking optimizations we made in Q3 alone drove a 10% increase in time spent on Threads. We also continue to ship new features, including launching direct messaging in Q3, so anyone on Threads can now message one another within the app.\n\n**Susan Li** (CFO)\nNow to the second driver of our revenue performance: increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to refine ad supply across each of our major services within Facebook and Instagram to better deliver ads at the time and place they are most relevant to people. Longer term, we have exciting ad supply opportunities on both Threads and WhatsApp status. Ads are now running globally in feed on Threads, and we're following our typical monetization playbook of optimizing the ads formats and performance before we ramp supply. Within WhatsApp status, we're continuing to gradually introduce ads and expect to complete the rollout next year. The second part of increasing monetization efficiency is improving marketing performance.\n\n**Susan Li** (CFO)\nAdvancing our ad systems remains a critical aspect of this work, and we are driving performance gains through ongoing improvements in our larger-scale ads ranking models. For example, we continue to broaden the adoption of Lattice, our unified model architecture. In Q3, we rolled out Lattice to app ads, which drove a nearly 3% gain in conversions for that objective. Since introducing Lattice back in 2023, along with other backend improvements, we have now cut the number of ads ranking and recommendation models by approximately 100, as we consolidated smaller and more specialized models into larger ones that use the Lattice architecture to generalize learnings across surfaces and objectives. We continue to observe performance improvements as we combine models and expect to drive additional gains as we consolidate another 200 models over the coming years into a smaller number of highly capable models.\n\n**Susan Li** (CFO)\nIn addition to advancing our foundational ads models, we're innovating on our runtime models we use downstream of them for ads inference. For example, we began piloting a new runtime ads ranking model in Q3 that leverages more compute and data than our prior models to select more relevant ads. In testing, we've seen this new model drive a more than 2% lift in conversions on Instagram. We also significantly improved performance of Andromeda in Q3 by combining models across retrieval and early-stage ranking into a single model, driving a 14% increase in ads quality on Facebook services. Within our ads products, we're seeing continued momentum with Advantage Plus. In Q3, we completed the rollout of our streamlined campaign creation flow for Advantage Plus lead campaigns.\n\n**Susan Li** (CFO)\nNow advertisers running sales app or lead campaigns have end-to-end automation turned on from the beginning, allowing our systems to look across our platform to optimize performance by automatically choosing criteria like who to show the ads to and where to show them. The annual run rate of revenue running through our end-to-end automated solutions has now reached $60 billion following the implementation of the new streamlined creation flow, as we continue to see more advertisers leverage the performance benefits of our solutions. Within our Advantage Plus Creative Suite, the number of advertisers using at least one of our video generation features was up 20% versus the prior quarter, as adoption of image animation and video expansion continues to scale. We've also added more generative AI features to make it easier for advertisers to optimize their ad creatives and drive increased performance.\n\n**Susan Li** (CFO)\nIn Q3, we introduced AI-generated music so advertisers can have music generated for their ad that aligns with the tone and message of the creative. Finally, business messaging remains a significant opportunity for us. We're seeing strong growth across our portfolio of solutions, including with click-to-WhatsApp ads, which grew revenue 60% year over year in Q3. We're also making good progress on our business AI efforts, where we've been focused on building a turnkey AI that helps businesses generate leads and drive sales. We've been opening access in recent months to more businesses within our initial test markets, the Philippines and Mexico, and have seen strong usage with millions of conversations between people and business AIs taking place since July. This month, we expanded availability within WhatsApp and Messenger to all eligible businesses in Mexico and the Philippines, respectively.\n\n**Susan Li** (CFO)\nIn the U.S., we're also starting to roll out the ability for merchants to add their business AIs to their website so we can support the full sale funnel from ad to purchase. Next, I would like to discuss our approach to capital allocation. Our primary focus is deploying capital to support the company's highest order priorities, including developing leading AI products, models, and business solutions. As we make significant investments in infrastructure to support this work, we are focused on preserving maximum long-term flexibility to ensure we can meet our future capacity needs while also being able to respond to how the market develops in the years ahead. We're doing so in several ways, including staging data center sites so we can spring up capacity quickly in future years as we need it, as well as establishing strategic partnerships that give us option value for future compute needs.\n\n**Susan Li** (CFO)\nThe strong financial position and cash generation of our business enable us to make these investments while also accessing additional pools of cost-efficient capital. Moving to our financial outlook, we expect Q4 2025 total revenue to be in the range of $56 to $59 billion. Our guidance assumes foreign currency is an approximately 1% tailwind to year-over-year total revenue growth based on current exchange rates. Our outlook reflects an expectation for continued strong ad revenue growth, partially offset by lower year-over-year Reality Labs revenue in Q4. The anticipated reduction in Reality Labs revenue is due to us lapping the introduction of Quest 3S in Q4 of last year, as well as retail partners procuring Quest headsets during Q3 of this year to prepare for the holiday season, which were recorded as revenue in the third quarter.\n\n**Susan Li** (CFO)\nTurning to the expense and CapEx outlooks, I'll first start with 2025 before providing some commentary on our planning for 2026. We expect full-year 2025 total expenses to be in the range of $116 to $118 billion, updated from our prior outlook of $114 to $118 billion and reflecting a growth rate of 22% to 24% year over year. We currently expect 2025 capital expenditures, including principal payments on finance leases, to be in the range of $70 to $72 billion, increased from our prior outlook of $66 to $72 billion. On to tax. Absent any changes to our tax landscape, we expect our Q4 2025 tax rate to be 12% to 15%.\n\n**Susan Li** (CFO)\nTurning now to 2026, we are at an exciting point for our company, where we have continued runway to improve our core services today, as well as the opportunity to build new AI-powered experiences and services that will transform how people engage with our products in the future. We expect the set of investments we're making within our ads and organic engagement initiatives next year will enable us to continue to deliver strong revenue growth in 2026, while our progress on AI models and products will position us to capitalize on new revenue opportunities in the years to come. A central requirement to realizing these opportunities is infrastructure capacity. As we have begun to plan for next year, it's become clear that our compute needs have continued to expand meaningfully, including versus our own expectations last quarter.\n\n**Susan Li** (CFO)\nWe are still working through our capacity plans for next year, but we expect to invest aggressively to meet these needs, both by building our own infrastructure and contracting with third-party cloud providers. We anticipate this will provide further upward pressure on our CapEx and expense plans next year. As a result, our current expectation is that CapEx dollar growth will be notably larger in 2026 than 2025. We also anticipate total expenses will grow at a significantly faster % rate in 2026 than 2025, with growth primarily driven by infrastructure costs, including incremental cloud expenses and depreciation. Employee compensation costs will be the second largest contributor to growth, as we recognize a full year of compensation for employees hired throughout 2025, particularly AI talent and ad technical talent in priority areas.\n\n**Susan Li** (CFO)\nFinally, we continue to monitor active legal and regulatory matters, including the increasing headwinds in the EU and the U.S. that could significantly impact our business and financial results. For example, in the EU, we continue to engage constructively with the European Commission on our less personalized ads offering. However, we cannot rule out the Commission imposing further changes to that offering that could have a significant negative impact on our European revenue as early as this quarter. In the U.S., a number of youth-related trials are scheduled for 2026 and may ultimately result in a material loss. In closing, this was another good quarter for our business. We have an exciting set of opportunities to continue improving our core business while delivering innovative new experiences and services for the people and businesses using our products in the years to come.\n\n**Susan Li** (CFO)\nWith that, Krista, let's open up the call for questions.\n\n**Operator**\nThank you. We will now open the lines for a question and answer session. To ask a question, please press star one on your touchtone phone. To withdraw your question, again, press star one. Please limit yourself to one question. Please pick up your handset before asking your question to ensure clarity. If you are streaming today's call, please mute your computer speakers. Your first question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.\n\n**Brian Nowak** (Analyst)\nThanks for taking my questions. I have two for Susan. The first one, Susan, the pipeline for core improvements to come in 2026 with models and ad ranking models and more types of compute seems very exciting, and the infrastructure build seems sizable behind that. Can you help us a little understand some of the early quantifiable signals you're seeing on A/B tests from some of these improvements to come that make you most excited and give you confidence you're going to get ROIC from all this CapEx? That's the first one. The second one's a little faster. How large is the Reality Labs revenue headwind in the 4Q guidance? Thanks.\n\n**Susan Li** (CFO)\nThanks, Brian, for the question. I think your first question had a couple parts to it, so I'm going to try to disaggregate those parts and let me know if this addresses what you're getting to. I will say that the growth in 2026 CapEx relative to 2025 comes from growth in each of the core areas: Meta Superintelligence Labs, core AI, as well as non-AI spend. All of those areas are growing, but the Meta Superintelligence Labs AI needs are growing the most. In terms of the core AI pipeline, I think we talked about last year when we were going into the 2025 budget process, we had a roadmap of resource investments across both headcount and compute that we thought would pay off in 2026. It's really a very broad range of different ads ranking and performance efforts.\n\n**Susan Li** (CFO)\nWe're continuing to see that those have paid off through the course of the year. There is a long list of specific efforts, but one of the measures that we look at to monitor this is how are we driving ad performance? How are conversions growing? Conversions is a complex metric for us because advertisers optimize for so many different conversions on different values. When we control for that and look at value-weighted conversion rates, we're seeing very strong year-over-year growth, and weighted conversions continue to grow faster than impressions. We also talked about some of the new model architecture over the course of the year and the degree to which the new model architecture is enabling us also to take advantage of having more data and more compute to drive ads performance. We expect that that's going to be a continued story in 2026.\n\n**Susan Li** (CFO)\nWe are, in fact, at the beginning of our 2026 budgeting process now, and we see a similar list of revenue investments that we're excited to be able to invest in. We think that that's going to be a big part of our ability to continue to drive strong revenue performance throughout the year. On your second question, which is the Reality Labs revenue headwind, I don't think we have quantified the exact size of that. We expect that Q4 Reality Labs revenue will be lower than last year for a couple of reasons that I alluded to. The biggest factor is we're lapping the introduction of Quest 3S in Q4 of last year, and we don't have a new headset in the market this year. We also recorded all of our holiday-related Quest 3S sales in Q4 2024 since the headset was launched in October 2024.\n\n**Susan Li** (CFO)\nThis year, we're recognizing some of those Quest 3S sales in Q3 as retail partners have procured Quest headsets in advance of the holiday season. We're still expecting significant year-over-year growth in AI glasses revenue in Q4 as we benefit from strong demand for the recent products that we've introduced, but that is more than offset by the headwinds to the Quest headsets.\n\n**Operator**\nYour next question comes from the line of Doug M. with JP Morgan. Please go ahead.\n\n**Doug Anmuth** (Analyst)\nGreat. Thanks for taking the question. I appreciate the strategy to front-load capacity for superintelligence. Can you just talk about your thought process in kind of triangulating the CapEx dollar growth and the significantly faster expense growth next year with core growth in the business, then the impact on earnings and free cash flow? Do you have targets that we should be thinking about for cash on hand or net cash overall? Thanks.\n\n**Susan Li** (CFO)\nThanks, Doug. We're right now, I would say, in the process ofwe're relatively early, actually still in the process of putting together our budget for 2026. It is, on the capacity side, a particularly dynamic process. We're certainly seeing that we wish we had more capacity today than we do. We would be able to put it towards good use. Certainly, not only would the Meta Superintelligence Labs team appreciate having more capacity, but we'd be able to put it towards good and ROI positive use in the core business as well. We're really trying to plan ahead not only to ensure that we have the capacity we need in 2026, but also to give ourselves the sort of flexibility and option value to have the capacity that we think we could need in 2027 and 2028. That said, there are lots of moving pieces in the budget.\n\n**Susan Li** (CFO)\nIt's not baked yet. It's still sort of in the process of coming together. We don't have specific targets to share, but we do feel like our strategic priority is really making sure that we have the compute that we need to be well positioned to succeed at AI. That's sort of the foremost priority as we're putting together the budget.\n\n**Mark Zuckerberg** (CEO)\nYeah, I mean, I'll add a few thoughts on this too, although, as Susan said, we're still working through the actual budget, and I think we'll typically have more to share on that early next year. To date, we keep on seeing this pattern where we build some amount of infrastructure to what we think is an aggressive assumption, and then we keep on having more demand to be able to use more compute, especially in the core business in ways that we think would be quite profitable than we end up having compute for.\n\n**Mark Zuckerberg** (CEO)\nI think that suggests that being able to make a significantly larger investment here is very likely to be a profitable thing over some period because the primary use of it is going to be to accelerate the AI research and the new AI work that we're doing and how that relates to both the core business and new products. Any compute that we don't need for that, we feel pretty good that we're going to be able to absorb a very large amount of that to just convert into more intelligence and better recommendations in our family of apps and ads in a profitable way. Of course, it's possible to overshoot that, right? If we do, this is what I mentioned in my comments, then we see that there's just a lot of demand for other new things that we would build internally, externally.\n\n**Mark Zuckerberg** (CEO)\nAlmost every week, people come to us from outside the company asking us to stand up an API service or asking if we have different compute that they could get from us. We haven't done that yet, but obviously, if you got to a point where you overbuilt, you could have that as an option. The very worst case would be that we effectively have just pre-built for a couple of years, in which case, of course, there would be some loss and depreciation, but we'd grow into that and use it over time.\n\n**Mark Zuckerberg** (CEO)\nMy view on this is that rather than continuing to be constrained on CapEx and feeling in the core business like we have significant investments that we could make that we're not able to make that would be profitable, the right thing to do is to try to accelerate this to make sure that we have the compute that we need both for the AI research and new things that we're doing and to try to get to a different state on our compute stance on the core business. That's kind of how I'm thinking about that overall. Of course, there's a lot of operational constraints too on what one can build, right? We are basically trying to work through this all, and I think we'll have more to share in the coming months and over the course of next year.\n\n**Mark Zuckerberg** (CEO)\nI think that there's just a huge, huge amount of opportunities ahead here.\n\n**Operator**\nYour next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.\n\n**Eric Sheridan** (Analyst)\nThanks so much for taking the question. Mark, I wanted to reflect on some of your comments with respect to scaling towards superintelligence and bringing it back to consumer AI. Maybe reflect a little bit on the signals you've gotten on the way consumers across family of apps interact with Meta AI today and how you think about scaling and exiting models from the superintelligence effort might change the utility and behavior around Meta AI in the years ahead. Thanks.\n\n**Mark Zuckerberg** (CEO)\nYeah, I mean, a lot of people use Meta AI today. As I said in my comments up front, there's more than a billion people who use it on a monthly basis. What we see is that as we improve the quality of the model, primarily for post-training Llama 4 at this point, we continue to see improvements in usage.\n\n**Mark Zuckerberg** (CEO)\nOur view is that when we get the new models that we're building in Meta Superintelligence Labs in there and get truly frontier models with novel capabilities that you don't have in other places, then I think that this is just a massive latent opportunity. We know, I mean, I would guess that Meta Platforms has the best track record of any company out there of taking a new product that people love and getting it to billions of people in terms of usage. I think that the ability to plug in leading models is going to, I would predict, lead to a very large amount of use of these things over the coming years. I'm very excited about that in terms of new products. It's not just Meta AI as an assistant.\n\n**Mark Zuckerberg** (CEO)\nI think that there are going to be all kinds of new products around different content formats, and we're starting to see that with video and content creation. I think there's going to be a lot more like that that I'm quite excited about. There are the business versions of all of these too, like Business AI. Of course, one part of the story is the new things that will be possible to build. The other part is how more intelligent models are just going to improve the core business and improve the recommendations that we make across the family of apps and improve the recommendations and advertising. I think that there's just a, as we've shown, there's sort of this very large amount of headroom, and the opportunity there keeps growing as we are improving and optimizing the AI there.\n\n**Mark Zuckerberg** (CEO)\nI think that really shows no sign of being near the end. I think that there's quite a bit more to do there. Like I said in response to the last question, we are sort of perennially operating the family of apps and ads business in a compute-starved state at this point, which is, on the one hand, sort of an odd thing to say given the compute that we've built up. We really are taking a lot of the resources and using them to advance future things that we're doing. We think that there's a lot more compute that we could put towards these that would just unlock a huge amount of opportunity in the core business as well.\n\n**Operator**\nYour next question comes from the line of Mark Schmulick with Bernstein. Please go ahead.\n\n**Mark Shmulik** (Analyst)\nYes, hi. Thanks for taking the questions. Susan, as you think about the visibility into kind of the runway next year of continued ad performance and engagement improvements, how do you think about kind of the scale of those improvements versus kind of the progress we've seen over the last two years? Mark, as you think about kind of the timing of some of these newer efforts coming out of Meta Superintelligence Labs, is us anchoring to kind of an updated frontier model launch sometime next year like the right way for us to think about it? Should we be looking at kind of progress from new products you're excited to see ship like Vibes? Thank you.\n\n**Susan Li** (CFO)\nThanks, Mark. On the sort of ads improvement side, some of the innovations that we have been launching actually involve improving our larger scale models. We don't use our larger model architectures like GEM for inference because their size and complexity would make it too cost-prohibitive. The way that we drive performance from those models is by using them to transfer knowledge to smaller, lightweight models that are used at runtime. In addition to the foundation model work, we are working on advancing our inference models by developing new techniques and architectures that then allow us to scale up compute and complexity in an ROI-positive way. In general, we obviously have a very large base of advertisers.\n\n**Susan Li** (CFO)\nThere's a lot of demand liquidity in the system, and even small scale improvements that we are able to make in terms of driving basis point improvements in the performance of ads or single-digit increases in conversions relative to impressions in a given quarter off of a large base mean that we're really able to continue to grow the absolute dollars of revenue growth in a pretty meaningful way.\n\n**Operator**\nYour next question comes from the line of Justin Post with Bank of America. Please go ahead.\n\n**Justin Post** (Analyst)\nThank you.\n\n**Kenneth Dorell** (Director of Investor Relations)\nHey, Justin, just give us one second. I think there was a second part of Mark's question that we just want to get to on Meta Superintelligence Labs.\n\n**Mark Zuckerberg** (CEO)\nI'll keep it quick. I don't think we have any specific timing to announce certainly on the models or products, but I expect that you will see both. We expect to build novel models and novel products, and I'm excited to share more when we have it.\n\n**Operator**\nJustin, please go ahead.\n\n**Justin Post** (Analyst)\nGreat, thanks. Mark, you mentioned the prior two content cycles, and obviously, you've been able to generate very attractive margins on them. As we get into the AI cycle, obviously, some concerns on the investment. Can you talk a little bit about how you're thinking about tools that could be coming out for users? I know there's some new competition. Secondly, how do you think about margins in this content cycle? Any reason to think they would be different versus prior cycles? Thank you.\n\n**Mark Zuckerberg** (CEO)\nI think it's too early to really understand what the margins are going to be for the new products that we build. I think certainly each product has somewhat different characteristics, and I think we'll kind of understand how that goes over time. My general goal is to build a business that maximizes value for the people who use our products and maximizes profitability, not margins.\n\n**Mark Zuckerberg** (CEO)\nI think we'll kind of just try to build the best things that we can and try to deliver the most value that we can for most people.\n\n**Operator**\nYour next question comes from the line of Ross Sandler with Barclays. Please go ahead.\n\n**Ross Sandler** (Analyst)\nGreat. Hey, Mark, some of the goals for competing AI labs are around achieving AGI or these other milestones that are kind of like out there and a little esoteric. How are you setting up your new team in terms of achieving those types of goals versus products that can generate revenue from Meta kind of right out of the gate? Is the goal that you had articulated to us previously around giving billions of people kind of a personal AI to use still the direction of travel that you see, or are there other things like kind of this Vibes or Sora angle that you think are potentially important? How should we think about the overall direction? Thank you.\n\n**Mark Zuckerberg** (CEO)\nSure. The way that I think about this is that the research is going to enable new technological capabilities to exist, and then those capabilities can get built into all kinds of different products. The ability to reason more intelligently is, for example, very important across a large number of things. It would be useful for an assistant. It will also be useful in business AI. It will also be useful in the AI agent that we're building to help advertisers figure out what their campaigns are going to be. It will also have implications for eventually how we do ranking and recommendations of people's feeds and make different decisions there. That's just one example. Certainly, the capability to be able to produce very high-quality, good video is going to be useful for giving people new creative tools.\n\n**Mark Zuckerberg** (CEO)\nIt will help increase the amount of content inventory that can be shown in Instagram and Facebook and therefore should enable an increase in engagement there. It should help advertisers be able to create creative that will help us monetize better. You can just go kind of down the list of capabilities that you'd expect. I think each one will enable a bunch of different things. I think the art of product development here is looking at the list of technology capabilities and figuring out what new products are going to be useful and prioritizing those. Fundamentally, I would sort of expect this exponential curve in new technology capabilities that are going to become available.\n\n**Mark Zuckerberg** (CEO)\nThe other thing that I expect is that I think being the best in a given area will drive great returns rather than this is not like a check-the-box exercise of like, OK, we can generate some kind of content and someone else can. I think that the company that is the best at each of these capabilities, I think, will get a large amount of the potential value for doing that. There are lots of different capabilities to build. I'm not sure that any one company is going to be the best at all of them. I doubt that's going to be the case. A lot of what we're trying to do is not like not kind of do some things that others have done. We're really trying to build novel capabilities.\n\n**Mark Zuckerberg** (CEO)\nI'm keeping this high level because I don't want to necessarily, from a competitive or strategic perspective, get into what we're prioritizing. That hopefully gives you a sense of how we're thinking about what we're doing. We want to be able to kind of build novel things, build them into a lot of our products, and then have the compute to scale them to billions of people. We think that that's going to both show up in terms of new products being possible and new businesses and very significant improvements to the current business too.\n\n**Operator**\nYour next question comes from the line of Mark Mahoney with Evercore ISI. Please go ahead.\n\n**Mark Mahaney** (Analyst)\nThanks. Can I just ask a question on Meta AI and both the product and the monetization path? When you look at it, what you've seen that's most encouraging to you in terms of the adoption and the use of Meta AI, and then when you think about, I know you generally like to roll out and then deepen engagement and then later think about monetization, where do you think you are on that path now? Is it clear to you what the monetization options are for Meta AI? Thank you very much.\n\n**Mark Zuckerberg** (CEO)\nI mean, I think the most promising thing that we're seeing is, one, that we were able to build something that a large number of people use. I think that that's valuable. Secondly, there is a clear correlation as we improve the models in ways that we think make them better, that people use them more. That shows that we have a runway to basically be able to improve engagement and turn this into a product that's leading over time. In terms of where we are on this, we basically just did this huge effort to boot up Meta Superintelligence Labs and build what I am very proud of. I think the highest talent density lab in the industry at this point.\n\n**Mark Zuckerberg** (CEO)\nThere are a lot of really great researchers and infrastructure folks and data folks who are now a part of this effort who are focused on training the next generation of work and doing some really novel work. When that is ready, I think that we will be able to plug that into a number of the products that we're building. I think that that will be very exciting. I think that that's really the next thing that we're looking at. From there, I think that these models will also improve monetization in all of the different ways that we've talked about so far in terms of improving engagement, improving advertising, helping advertisers engage.\n\n**Mark Zuckerberg** (CEO)\nThe one opportunity that we usually talk about on these calls but hasn't come up as much here is just the ability to make it so that advertisers are increasingly just going to be able to give us a business objective and give us a credit card or bank account and have the AI system basically figure out everything else that's necessary, including generating video or different types of creative that might resonate with different people that are personalized in different ways, finding who the right customers are. All of the capabilities that we're building, I think, go towards improving all of these different things. I'm quite optimistic about that.\n\n**Operator**\nYour next question comes from the line of Ronald Josey with Citi. Please go ahead.\n\n**Ronald Josey** (Analyst)\nGreat. Thanks for taking the question. This maybe dovetails perfectly off of Mark, what you just talked about. We heard a lot about end-to-end automation here, I think, reaching a $60 billion ARR. I wanted to hear about if you can talk to us more just about adoption rates amongst the advertisers and then maybe bigger picture as you incorporate ranking recommendation changes like Andromeda or GEMS or Lattice. Just talk to us how this automation is driving, call it, a higher ROI for advertisers overall if you bring it all together. Thank you.\n\n**Susan Li** (CFO)\nYeah, we've been sort of laying the continued brick-by-brick build of Advantage Plus and extending the set of objectives that it applies to over time. In Q3, we completed the global rollout of the streamlined campaign creation flow for Advantage Plus lead campaigns. Now advertisers who are running sales app or lead campaigns have end-to-end automation turned on from the beginning. Like the kind of application of the streamlined campaign creation flow for other objectives, this generally allows advertisers to optimize and automate several aspects of the campaign setup process at once. That includes things like audience selection, where to show the ad, how the budget gets paced and distributed across ad sets to drive the most efficient outcomes. We see that Advantage Plus continues to drive performance gains.\n\n**Susan Li** (CFO)\nAdvertisers who run lead campaigns using Advantage Plus are seeing a 14% lower cost per lead on average than those who are not. I would say that we think that there is still a lot of opportunity generally to grow adoption of Advantage Plus. A lot of advertisers only use our end-to-end automated solutions for a portion of their campaigns, so we can grow share there. To capture that opportunity, we're focused on driving continued performance improvements and addressing some of the key use cases that we still need in order to grow adoption. We're also working to broaden adoption among advertisers who use one of our single-step automated solutions, for example, advertisers who might only use a piece of it, like Advantage Plus audiences, by helping them understand the benefits of using more than one automated solution at the same time.\n\n**Susan Li** (CFO)\nI would say Advantage Plus is sort of an ongoing platform by which we both continue to expand the feature set that is available in Advantage Plus and then expand the extensibility or the coverage of that feature set to the broader set of advertisers. I think Mark mentioned that the annual revenue run rate now for advertisers who are using these automated options is $60 billion. We see that there's room to continue growing that.\n\n**Operator**\nYour next question comes from the line of Yousef Squali with Truist Securities. Please go ahead.\n\n**Youssef Squali** (Analyst)\nGreat. Thank you very much, Mark. On wearables in particular, do you think you'll be able to sell enough hardware to recoup your investment, or is that dependent on maybe creating new avenues for revenue from things like advertising services and commerce through that new computing platform? If so, what are kind of the gating factors there? Susan, how do you see the on-balance sheet versus off-balance sheet financing of your AI initiatives? You've recently struck a deal with Blue Owl for the Louisiana data center. Is that part of the CapEx guide for 2026? If it's not, how significant will that way of funding be for Meta going forward? Basically, would that slow down your CapEx growth past 2026? Thank you.\n\n**Mark Zuckerberg** (CEO)\nI can talk about wearables, and then Susan can jump in on the other part. I think that there are a few pieces here. One is that the work on Ray-Ban Meta and the Oakley Meta Vanguards products is going very well. I think, yeah, I mean, at some point, if these continue going as well as it has been, then I think it will be a very profitable investment. I think that there's some revenue that we get from basically selling the devices and then some that will come from additional services and from the AI on top of it. I think that there's a big opportunity. Certainly, the investment here is not just to kind of build just the device. It's also to build these services on top.\n\n**Mark Zuckerberg** (CEO)\nRight now, a lot of people get the devices for a range of things that don't even include the AI, even though they like the AI. I think over time, the AI is going to become the main thing that people are using them for. I think that that's going to end up having a big business opportunity by itself. As products like the Ray-Ban Meta and Oakley Meta Vanguards are growing, we're also going to keep on investing in things like the more full field of view product form of the Orion prototype that we showed at Connect last year. Those things are obviously earlier in their curve towards getting to being a sustaining business. Our general view is that we want to build these out to reach many hundreds of millions or billions of people.\n\n**Mark Zuckerberg** (CEO)\nThat's the point at which we think that this is going to be just an extremely profitable business.\n\n**Susan Li** (CFO)\nYousef, to your second question, the JV that we announced with Blue Owl is sort of an example of finding a solution that enabled us to partner with external capital providers to co-develop data centers in a way that gives us long-term optionality in supporting our future capacity needs, just given both the magnitude but also uncertainty of what the capacity outlook in future years looks like. In terms of how that is recognized as CapEx, our prior CapEx reflected a portion of the data center build cost prior to the joint venture being established. Going forward, the construction costs of the data center will not be recorded in CapEx. As the data center is constructed, we will contribute 20% of the remaining construction costs required, which is in line with our ownership stake. Those will be recorded as other investing cash flows.\n\n**Operator**\nYour last question comes from the line of Kenneth Dorell with Wells Fargo. Please go ahead.\n\n**Ken Gawrelski** (Analyst)\nThank you. Just one for me, please. Mark, as you think about with hopefully a leading frontier model next year in hand, could you talk about where you think the value will accrue in this evolving ecosystem? Will it be with the platforms, or do you think that this will be mostly the value will accrue to the scaled first-party applications? Thank you.\n\n**Mark Zuckerberg** (CEO)\nI guess I'm not exactly sure what you mean by platform versus application in this context. I think that there's just a lot of value to create with AI overall. Clearly, you're seeing the people who are making the hardware, NVIDIA is doing an amazing job, right? I think extremely well-deserved success. The cloud partners and companies are doing very well. I think that will likely continue. I think that there's a huge opportunity there. If you look at it today, the companies that are building apps, a lot of the apps are still relatively small. I think that's obviously going to be a huge opportunity. What we've seen overall is basically people take individual technology advances and build them into products that then build either communities or other kinds of network effects and then end up being very sustaining businesses.\n\n**Mark Zuckerberg** (CEO)\nI think what we haven't really seen as much in the history of the technology industry is the rate of new capabilities being introduced because around each of these capabilities, you can build many new products that I think each will turn into interesting businesses. I don't know. I'm generally pretty optimistic about there being a very large opportunity. In terms of new things to build, I think being able to build them and then scale them to billions of people is a huge muscle that Meta has developed, and I think we do very well. I certainly think that's going to deliver a huge amount of value, both in the core business for all the ways that we talked about, how it's going to improve recommendations and the quality of the services, as well as unifying the models together.\n\n**Mark Zuckerberg** (CEO)\nThat way, when these systems are deciding what to show, they can just pull from a wider pool. These are things that we've just seen over the 20-plus years of running the company, that they just deliver consistent wins. We're going to keep on being able to make the systems more general and smarter and make better recommendations for people and have a larger pool of inventory. That is all going to be great. There's going to be a lot of new things that I think we're going to be able to take and scale to billions of people over time and build new businesses, whether that's advertising or commerce supported or people paying for it or different kinds of things. I think it's pretty early, but I think we're seeing the returns in the core business.\n\n**Mark Zuckerberg** (CEO)\nThat's giving us a lot of confidence that we should be investing a lot more, and we want to make sure that we're not underinvesting.\n\n**Kenneth Dorell** (Director of Investor Relations)\nGreat. Thank you, everyone, for joining us today. We look forward to speaking with you again soon.\n\n**Operator**\nThis concludes today's conference call. Thank you for your participation, and you may now disconnect.",
        "fetched_at": "2026-02-04T16:12:04.065Z"
      },
      {
        "ticker": "META",
        "title": "Yahoo Finance",
        "published_date": "Jul 30, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/META/earnings/META-Q2-2025-earnings_call-340546.html",
        "content": "**Operator**\nGood afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta Second Quarter Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there will be a question and answer session.\n\n**Operator**\nSession. And this call will be recorded. Thank you very much. Kenneth Dorrell, Meta's Director of Investor Relations, you may begin.\n\n**Kenneth Dorell** (Director - IR)\nThank you. Good afternoon, and welcome to Meta's second quarter twenty twenty five earnings conference call. Joining me today are Mark Zuckerberg, CEO and Susan Lee, CFO. Our remarks today will include forward looking statements, which are based on assumptions as of today. Actual results may differ materially as a result of various factors, including those set forth in today's earnings press release and in our quarterly report on Form 10 Q filed with the SEC.\n\n**Kenneth Dorell** (Director - IR)\nWe undertake no obligation to update any forward looking statement. During this call, we will present both GAAP and certain non GAAP financial measures. A reconciliation of GAAP to non GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.atmeta.com. And now I'd like to turn the call over to Mark.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAlright. Thanks, Ken. Thanks, everyone, for joining today. We had another strong quarter with more than 3,400,000,000 people using at least one of our apps each day and strong engagement across the board. Our business continues to perform very well, which enables us to invest heavily in our AI efforts.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOver the last few months, we've begun to see glimpses of our AI systems improving themselves, and the improvement is slow for now but undeniable. And developing superintelligence, which we define as AI that surpasses human intelligence in every way, we think is now in sight. Meta's vision is to bring personal superintelligence to everyone so that people can direct it towards what they value in their own lives. And we believe that this has the potential to begin an exciting new era of individual empowerment. A lot has been written about all the economic and scientific advances that superintelligence can bring, and I'm extremely optimistic about this.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nBut I think that if history is a guide, then an even more important role will be how superintelligence empowers people to be more creative, develop culture and communities, connect with each other, and lead more fulfilling lives. To build this future, we've established Meta Superintelligence Labs, which includes our foundations, product, and fair teams as well as a new lab that is focused on developing the next generation of our models. We're making good progress towards LAMA four point one and four point two. And in parallel, we are also working on our next generation of models that will push the frontier in the next year or so. We're building an elite talent dense team.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAlexander Wang is leading the overall team. Nat Friedman is leading our AI products and applied research, and Xingjia Zhao is chief scientist for the new effort. They are all incredibly talented leaders, and I'm excited to work closely with them and the world class group of AI researchers and infrastructure and data engineers that we're assembling. I spent a lot of time building this team this quarter, and the reason that so many people are excited to join is because Meta has all of the ingredients that are required to build leading models and deliver them to billions of people. The people who are joining us are gonna have access to unparalleled compute as we build out several multi gigawatt clusters.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOur Prometheus cluster is coming online next year, and we think it's going to be the world's first gigawatt plus cluster. We're also building out Hyperion, which will be able to scale up to five gigawatts over several years, and we have multiple more Titan clusters in development as well. We are making all these investments because we have conviction that superintelligence is going to improve every aspect of what we do. From a business perspective, I mentioned last quarter that there are five basic opportunities that we are pursuing, improved advertising, more engaging experiences, business messaging, Meta AI, and AI devices. So I can go into a bit of detail on each.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOn advertising, the strong performance this quarter is largely thanks to AI unlocking greater efficiency and and gains across our ad system. This quarter, we expanded our new AI powered recommendation model for ads to new surfaces and improved its performance by using more signals and longer context. It's it's driven roughly 5% more ad conversions on Instagram and 3% on Facebook. We're also seeing good progress with AI for ad creative, with a meaningful percent of our ad revenue now coming from campaigns using one of our generative AI features. This is gonna be especially valuable for smaller advertisers with limited budgets, while agencies will continue, the important work to help larger brands apply these tools strategically.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThe second opportunity is more engaging experiences. AI is significantly improving our ability to show people content that they're gonna find interesting and useful. Advancements in our recommendation systems have improved quality so much that it has led to a 5% increase in time spent on Facebook and 6% on Instagram just this quarter. There is a lot of potential for content itself to get better too. We're seeing early progress with the launch of our AI video editing tools across Meta AI and our new edits app, and there's a lot more to do here.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThe third opportunity is business messaging. I've talked before about how I believe every business will soon have a business AI just like they have an email address, social media account, and website. We're starting to see some product market fit in a number of countries where we're testing these agents, and we're integrating these business AIs into ads on Facebook and Instagram as well as directly into ecommerce websites. The fourth opportunity is Meta AI. Its reach is already quite impressive with more than a billion monthly actives.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOur focus is now deepening the experience and making Meta AI the leading personal AI. As we continue improving our models, we see engagement grow, so our next generation of models is gonna continue to really help here. And the fifth opportunity is AI devices. We continue to see strong momentum with our Ray Ban Meta Glasses with sales accelerating. We are also launching new performance AI glasses with the Oakley Meta Houstons.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThey have longer battery life, higher resolution camera, and are designed for sports. The percent of people using Meta AI is growing, and we're seeing new users' AI retention increase too, which is a good sign, for that continued use. I think that AI glasses are gonna be the main way that we integrate superintelligence into our day to day lives, so it's important to have all of these different styles and products that appeal to different people in different settings. Finally, we're seeing people continue to spend more time with our Quest ecosystem, and the community continues to grow steadily. We launched the Meta Quest three s Xbox edition last month, and we're seeing record interest in cloud gaming.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd beyond gaming, we continue to see a broader set of use cases with media and web browsing contributing a significant portion of engagement. We're gonna have more to share on all of this, especially the Reality Labs work at Connect on September 17. So I encourage you all to tune into that. Overall, this has been a busy quarter. Strong business performance and and real momentum in assembling both the talent and the compute that we need to build personal superintelligence for everyone.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nI am very grateful to our teams who are working hard to deliver all of this, and thanks to all of you for being on this journey with us. And now here's Susan.\n\n**Susan Li** (CFO)\nThanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year over year basis unless otherwise noted. Q2 total revenue was $47,500,000,000 up 22% on both a reported and constant currency basis. Q two total expenses were $27,100,000,000 up 12% compared to last year.\n\n**Susan Li** (CFO)\nIn terms of the specific line items, cost of revenue increased 16% driven mostly by higher infrastructure costs and payments to partners, partially offset by a benefit from the previously announced extension of several useful lives. R and D increased 23% mostly due to higher employee compensation and infrastructure costs. Marketing and sales increased 9% primarily due to an increase in professional services related to our ongoing platform integrity efforts as well as marketing costs partially offset by lower employee compensation. G and A decreased 27% driven mostly by lower legal related costs. We ended Q2 with over 75,900 employees down 1% quarter over quarter as the vast majority of the employees impacted by performance related reductions earlier this year were no longer captured in our headcount.\n\n**Susan Li** (CFO)\nThis was partially offset by continued hiring in priority areas of monetization, infrastructure, Reality Labs, AI, as well as regulation and compliance. Second quarter operating income was $20,400,000,000 representing a 43% operating margin. Our tax rate for the quarter was 11% which reflects excess tax benefits from share based compensation due to the increase in our share price versus prior periods. Net income was $18,300,000,000 or $7.14 per share. Capital expenditures including principal payments on finance leases were $17,000,000,000 driven by investments in servers, data centers, and network infrastructure.\n\n**Susan Li** (CFO)\nFree cash flow was $8,500,000,000 We repurchased $9,800,000,000 of our Class A common stock and paid 1,300,000,000 in dividends to shareholders. We also made $15,100,000,000 in non marketable equity investments in the second quarter which includes our minority investment in Scale AI along with other investment activities. We ended the quarter with $47,100,000,000 in cash and marketable securities and $28,800,000,000 in debt. Moving now to our segment results. I'll begin with our Family of Apps segment.\n\n**Susan Li** (CFO)\nOur community across the Family of Apps continues to grow and we estimate more than 3,400,000,000 people used at least one of our Family of Apps on a daily basis in June. Q two total family of apps revenue was $47,100,000,000 up 22% year over year. Q two family of apps ad revenue was $46,600,000,000 up 21 or 22% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year over year growth. On a user geography basis, ad revenue growth was strongest in Europe and rest of world at 2423% respectively.\n\n**Susan Li** (CFO)\nNorth America and Asia Pacific grew 2118%. In q two, the total number of ad impressions served across our services increased 11% with growth mainly driven by Asia Pacific. Impression growth accelerated across all regions due primarily to engagement tailwinds on both Facebook and Instagram and to a lesser extent ad load optimizations on Facebook. The average price per ad increased 9% benefiting from increased advertiser demand largely driven by improved ad performance. Pricing growth slowed modestly from the first quarter due to the accelerated impression growth in Q2.\n\n**Susan Li** (CFO)\nFamily of Apps other revenue was $583,000,000 up 50% driven by WhatsApp paid messaging revenue growth as well as Meta Verified subscriptions. We continue to direct majority of our investments toward the development and operation of our family of apps. In q two, family of apps expenses were $22,200,000,000 representing 82% of our overall expenses. Family of expenses were up 14% mainly due to growth in employee compensation and infrastructure costs partially offset by lower legal related costs. Family of Apps operating income was $25,000,000,000 representing a 53% operating margin.\n\n**Susan Li** (CFO)\nWithin our Reality Labs segment, q two revenue was $370,000,000 up 5% year over year due to increased sales of AI glasses partially offset by lower Quest sales. Reality Labs expenses were $4,900,000,000 up 1% year over year driven by higher non headcount related technology development costs. Reality Labs operating loss was $4,500,000,000 Turning now to the business outlook. There are two primary factors that drive our revenue performance. Our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time.\n\n**Susan Li** (CFO)\nOn the first, daily actives continue to grow across Facebook, Instagram, and WhatsApp as we make additional improvements to our recommendation systems and product experiences. We continue to see momentum with video engagement in particular. In q two, Instagram video time was up more than 20% year over year globally. We're seeing strong traction on Facebook as well, particularly in The US where video time spent similarly expanded more than 20% year over year. These gains have been enabled by ongoing optimizations to our ranking systems to better identify the most relevant content to show.\n\n**Susan Li** (CFO)\nWe expect to deliver additional improvements throughout the year as we further scale up our models and make recommendations more adaptive to a person's interest within their session. Another emphasis of our recommendations work is promoting original content. On Instagram, over two thirds of recommended content in The US now comes from original posts. In the second half, we'll be focused on further increasing the freshness of original posts so the right audiences can discover original content from creators soon after it is posted. We are also making good progress on our longer term ranking innovations that we expect will provide the next leg of improvements over the coming years.\n\n**Susan Li** (CFO)\nOur research efforts to develop cross surface foundation recommendation models continue to progress. We are also seeing promising results from using LLMs in threads recommendation systems. The incorporation of LLMs are now driving a meaningful share of the ranking related time spent gains on threats. We're now exploring how to extend the use of LLMs in recommendation systems to our other apps. We're leveraging LAMA and several other back end processes as well including actioning bug reports so we can identify and resolve recurring issues more quickly and efficiently.\n\n**Susan Li** (CFO)\nThis has resulted in top line bug reports in The U. S. And Canada in Facebook feed and notifications dropping by roughly 30% over the past ten months. The primary way we're using LaMa in our apps today is to power Meta AI which is now available in over 200 countries and territories. WhatsApp continues to be the largest driver of queries as people message Meta AI directly for tasks such as information gathering, homework assistance, and generating images.\n\n**Susan Li** (CFO)\nOutside of WhatsApp, we're seeing Meta AI become an increasingly valuable complement to our content discovery engines. Meta AI usage on Facebook is expanding as people use it to ask about posts they see in feed and find content across our platform and search. Another way we expect Meta AI will help with content discovery is through the automatic translation and dubbing of foreign language content into the audience's local language. We'll have more to share on our efforts there later this year. Moving to Reality Labs.\n\n**Susan Li** (CFO)\nThe growth of Ray Ban Meta sales accelerated in q two with demand still outstripping supply for the most popular SKUs despite increases to our production earlier this year. We're working to ramp supply to better meet consumer demand later this year. Now to the second driver of our revenue performance, increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to optimize ad supply across each surface to better deliver ads at the time and place they are most relevant to people.\n\n**Susan Li** (CFO)\nIn q two, we also began introducing ads within feed on threads and the updates tab of WhatsApp, which is a separate space away from people's chats. As of May, advertisers globally can now run video and image ads to Threads users in most countries including The United States. While ad supply remains low and Threads is not expected to be a meaningful contributor to overall impression growth in the near term, we are optimistic about the longer term opportunity with threads as the community and engagement grow and monetization scales. On WhatsApp, we are rolling out ads and status and channels along with channel subscriptions in the updates tab to help businesses reach the more than 1,500,000,000 daily actives who visit that part of the app. We expect the introduction of ads and status will be gradual over the course of this year and next with low levels of expected ad supply initially.\n\n**Susan Li** (CFO)\nWe also expect WhatsApp Ads and Status to earn a lower average price than Facebook or Instagram ads for the foreseeable future due in part towards WhatsApp's skew toward lower monetizing markets and more limited information that can be used for targeting. Given this, we do not expect ads and status to be a meaningful contributor to total impressions or revenue growth for the next few years. The second part of increasing monetization efficiency is improving marketing performance. There are three areas of this work that I'll focus on today. Improving our ad systems, advancing our ads products including by building tools that assist in ads creation, and evolving our ads platform to drive results that are optimized for each business's objectives.\n\n**Susan Li** (CFO)\nFirst is our ad systems where we're innovating in both the ads retrieval and ranking stages to serve more relevant ads to people. A lot of this work involves us continuing to advance the modeling innovations we've introduced previously while expanding their adoption across our platform. The Andromeda model architecture we began introducing in the 2024 powers the ads retrieval stage of our ad system, where we select the few thousand most relevant ads from tens of millions of potential candidates. In q two, we made enhancements to Andromeda that enabled it to select more relevant and more personalized ads candidates while also expanding coverage to Facebook reels. These improvements have driven nearly 4% higher conversions on Facebook mobile feed and reels.\n\n**Susan Li** (CFO)\nOur new generative ads recommendation system or GEM powers the ranking stage of our ad system which is the part of the process after ads retrieval where we determine which ads to show someone from candidates suggested by our retrieval engine. In q two, we improved the performance of GEM by further scaling our training capacity and adding organic and ads engagement data on Instagram. We also incorporated new advanced sequence modeling techniques that helped us double the length of event sequences we use enabling our systems to consider a longer history of the content or ads that a person has engaged with in order to provide better ad selections. The combination of these improvements increased ad conversions by approximately 5% on Instagram and 3% on Facebook feed and reels in q two. Finally, we expanded coverage of our Lattice model architecture in q two.\n\n**Susan Li** (CFO)\nWe first began deploying Lattice in 2023 with our later stage ads ranking efforts allowing us to run significantly larger models that generalize learnings across objectives and surfaces in place of numerous smaller ads models that have historically been optimized for individual objectives and surfaces. In April, we began deploying Lattice to earlier stage ads ranking models as well. This is leading not only to greater capacity and engineering efficiency, but also improved performance. With the recent Lattice deployments driving a nearly 4% increase in ad conversions across Facebook feed and reels in q two. Next, ad products.\n\n**Susan Li** (CFO)\nHere, we're seeing strong momentum with our advantage plus suite of AI powered solutions. In q two, we completed the rollout of our streamlined campaign creation flow for advantage plus sales and app campaigns, which makes it easier for advertisers to realize the performance benefits from Advantage Plus by having it turned on at the beginning. We've seen lifts in advertiser adoption of sales and app campaigns since we've expanded availability and are working to complete the rollout for leads campaigns in the coming months. Within our advantage plus creative suite, adoption of GenAI ad creative tools continues to broaden. Nearly 2,000,000 advertisers are now using our video generation features, image animation, and video expansion, and we're seeing strong results with our text generation tools as we continue to add new features.\n\n**Susan Li** (CFO)\nIn q two, we started testing AI powered translations so that advertisers can automatically translate the caption of their ads to 10 different languages. While it's early, we've seen promising performance lifts in our prelaunch tests. We're also continuing to see strong adoption of image expansion among small and medium sized advertisers, which speaks to how these tools help businesses who have fewer resources to develop creative. With larger advertisers, we expect agencies will continue to be valuable partners in helping apply these new tools to drive performance. Outside of Advantage Plus, we're seeing good momentum in business messaging, particularly in The US where click to message revenue grew more than 40% year over year in q two.\n\n**Susan Li** (CFO)\nThe strong US growth is benefiting from a ramp in adoption of our website to message ads, which drive people to a business's website for more information before choosing to launch a chat with the business in one of our messaging apps. Finally, we continue to evolve our ads platform to drive results that are optimized for each business's objectives and the way they measure results. In q two, we completed the global rollout of our incremental attribution feature, which is the only product on the market that optimizes for and reports on incremental conversions, which are conversions that would not have happened without a person seeing the ad. We also launched omnichannel ads globally in q two, which enable advertisers to optimize for incremental sales both in store and online with just one campaign. In tests, advertisers using omnichannel ads have seen a median 15% reduction in total cost per purchase compared to website only optimization.\n\n**Susan Li** (CFO)\nNext, I would like to discuss our approach to capital allocation. Our primary focus remains investing capital back into the business with infrastructure and talent being our top priorities. I'll start with hiring. Our approach to adding headcount continues to be targeted at the company's highest priority areas. We expect talent additions across all of our priority areas will continue to drive overall headcount growth through this year in 2026, while headcount growth in our other functions remains constrained.\n\n**Susan Li** (CFO)\nWithin AI, we've had a particular emphasis on recruiting leading talent within the industry as we build out Meta Superintelligence Labs to accelerate our AI model development and product initiatives. Next, infrastructure. We expect having sufficient compute capacity will be central to realizing many of the largest opportunities in front of us over the coming years. We continue to see very compelling returns from our AI capacity investments in our core ads and organic engagement initiatives and expect to continue investing significantly there in 2026. We also expect that developing leading AI infrastructure will be a core advantage in developing the best AI models and product experiences.\n\n**Susan Li** (CFO)\nSo we expect to ramp our investments significantly in 2026 to support that work. Moving to our financial outlook. We expect third quarter twenty twenty five total revenue to be in the range of $47,500,000,000 to $50,500,000,000 Our guidance assumes foreign currency is an approximately 1% tailwind to year over year total revenue growth based on current exchange rates. While we are not providing an outlook for fourth quarter revenue, we would expect our year over year growth rate in the 2025 to be slower than the third quarter as we lap a period of stronger growth in the 2024. Turning now to the expense outlook.\n\n**Susan Li** (CFO)\nWe expect full year 2025 total expenses to be in the range of 114,000,000,000 to $118,000,000,000 narrowed from our prior outlook of $113,000,000,000 to $118,000,000,000 and reflecting a growth rate of 20 to 24% year over year. While we're still very early in planning for next year, there are a few factors we expect will provide meaningful upward pressure on our 2026 total expense growth rate. The largest single driver of growth will be infrastructure costs driven by a sharp acceleration in depreciation expense growth and higher operating costs as we continue to scale up our infrastructure fleet. Aside from infrastructure, we expect the second largest driver of growth to be employee compensation as we add technical talent in priority areas and recognize a full year of compensation expenses for employees hired throughout 2025. We expect these factors will result in a 2026 year over year expense growth rate that is above the 2025 expense growth rate.\n\n**Susan Li** (CFO)\nTurning now to the CapEx outlook. We currently expect twenty twenty five capital expenditures including principal payments on finance leases to be in the range of 66,000,000,000 to $72,000,000,000 narrowed from our prior outlook of $64,000,000,000 to $72,000,000,000 and up approximately $30,000,000,000 year over year at the midpoint. While the infrastructure planning process remains highly dynamic, we currently expect another year of similarly significant CapEx dollar growth in 2026 as we continue aggressively pursuing opportunities to bring additional capacity online to meet the needs of our AI efforts and business operations. Onto tax. With the enactment of the new US tax law, we anticipate a reduction in our US federal cash tax for the remainder of the current year and future years.\n\n**Susan Li** (CFO)\nThere are several alternative ways of implementing the provisions of the act which we are currently evaluating. While we estimate that the 2025 tax rate will be higher than our q two tax rate, we cannot quantify the magnitude at this time. In addition, we continue to monitor an active regulatory landscape including the increasing legal and regulatory headwinds in The EU that could significantly impact our business and our financial results. For example, we continue to engage with the European Commission on our less personalized ads offering or LPA, which we introduced in November 2024 based on feedback from the European Commission in connection with the DMA. As the commission provides further feedback on LPA, we cannot rule out that it may seek to impose further modifications to it that would result in a materially worse user and advertiser experience.\n\n**Susan Li** (CFO)\nThis could have a significant negative impact on our European revenue as early as later this quarter. We have appealed the European Commission's DMA decision, but any modifications to our model may be imposed during the appeal process. In closing, this was another strong quarter for our business as our investments in infrastructure and technical talent continue to improve core ads performance and engagement on our platforms. We expect the significant investments we're making now will allow us to continue leveraging advances in AI to extend those gains and unlock a new set of opportunities in the years to come. With that, Krista, let's open up the call for questions.\n\n**Operator**\nThank you. We will now open the lines for a question and answer session. You. And your first question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.\n\n**Eric Sheridan** (Managing Director)\nThanks so much for taking the questions. Mark, when you think about where the AI parts of your business have been evolving over the last three to six months, wanted to know what your key learnings were as you went deep into that strategy that informed some of the shifts in both talent acquisition and compute, coupled with some of the blogs you put out recently in terms of how that strategy might have evolved based on those key learnings. And Susan, building on Mark's comments on scaling talent and compute, I wonder if you go a little bit deeper in how we should be thinking about those two components driving some of the commentary you've given around the OpEx and CapEx over the next twelve to eighteen months. Thanks so much.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. Sure. I can start. At at a high level, I think that there are all these questions that people have about what are gonna be the timelines to get to really strong AI or superintelligence or, you know, whatever whatever you wanna call it. And I guess at each step along the way so far, we've observed the more kind of aggressive assumptions or the fastest assumptions have been the ones that have most accurately predicted what would happen.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd and I think that that just continued to happen over the course of this year too. And someone have given a number of those anecdotes on these earnings calls in the past. And I think, certainly, some of the work that we're seeing with teams internally being able to adapt Llama four to build autonomous AI agents that can help improve the Facebook algorithm to increase quality and engagement are, like I mean, that's, like, a fairly profound thing if you think about it. I mean, it's it's it's happening in low volume right now, so I'm not sure that that result by itself was a major contributor to this quarter's earnings or anything like that. But but I think the trajectory on this stuff is very optimistic.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd I I think it's one of the interesting challenges in in running a business like this now is there's just a very high chance it seems like the world is gonna look pretty different in a few years from now. And on the one hand, there are all these things that we can do. There are improvements to our core products that exist. And then I think we have this principle that that that we believe in across the company, which we tell people, take superintelligence seriously. And the the basic principle is this idea that that we think that this is going to really shape all of our systems sooner rather than later, not necessarily on the on the trajectory of a quarter or two, but on the trajectory of a few years.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd, and I think that that's just gonna change a lot of the assumptions around how different things work across the company. So, anyway, I I think it's basically just we're we're continually observing how how this works, what the trajectory or the pace of of of AI progress has been. I think it continues to be on the faster end, and that, I think, informs a lot of the decisions from everything from the importance and value of having the absolute best and most elite talent teams team at the company to making sure that we have a leading compute fleet so that the people here can do, obviously, the researchers here have more compute per person to be able to lead their research and then roll it out to billions of people across our products, making sure that we build and drive these products through all of the different things that we do, which I think is one of the things that our company is the best in the world at, is basically, you know, when we take a technology, we're good at driving that through all of our apps and our ad systems and all that stuff.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nIt's not just gonna kinda sit on the vine. I I I think that there's no other company, I think, that is as good as us at kinda taking something and and kind of getting it in front of billions of people. So, yeah, I mean, we're we're just gonna push very aggressively on all of that. But but at some level, yeah, this is this is there's sort of a bet in the trajectory that we're seeing, and those are the signals that we're seeing. But, we're just trying to read it.\n\n**Susan Li** (CFO)\nEric, for the second part of your question, you know, we, we haven't, in fact, kicked off our budgeting process for 2026. So the thinking about next year, there are clearly many, many moving pieces in a very dynamic operating environment. But there are certain aspects that we have some visibility into today, including the rough shape of our 2026 infrastructure plans, you know, and that flows through into our expense expectations next year. And we also have some visibility into the compensation expense growth that we'll recognize from the AI talent that we're hiring this year. And so those, you know, those two things are part of why we gave a little bit of an early preview into the expectations for growth for 2026, total expenses, as well as for 2026, for 2026 CapEx.\n\n**Susan Li** (CFO)\nSo on the total expenses side, you know, as I mentioned, we expect infrastructure will be the single largest accelerate, contributor to 2026 expense growth. That's driven primarily by a sharp acceleration in depreciation expense growth in 2026, largely driven by recognizing incremental depreciation from assets that we purchased in place and service in '26 as well as from infrastructure deployed through 2025 that will recognize a full year of depreciation next year. We also expect a greater mix of our CapEx to be in shorter lived assets in 2025 and 2026 than it has been in prior years. And then the other component of infra cost growth next year would come from higher operating expenses, including energy costs, leases, maintenance, and operational expenses that are associated with maintaining that fleet. And we also expect some increased spend on cloud services in '26 to meet our capacity needs as well as growth in network related costs.\n\n**Susan Li** (CFO)\nSo a lot going on on the infrastructure side as it contributes to the 2026 total expense number. After that, employee compensation is the next largest driver of expense growth in '26, again, primarily in the investments that we're making in technical talent, including recognizing a full year of compensation expense for the AI talent we hire this year. I realize this answer is getting a little long, so I'll try to wrap up quickly. On the CapEx side, you know, the big driver of our increased CapEx in '26 will be scaling GenAI capacity as we build out training capacity. That's gonna drive higher spend across, you know, servers, networking, data centers next year.\n\n**Susan Li** (CFO)\nWe also expect that we're gonna continue investing significantly in CoreAI in 2026. And, again, this is a pretty, you know, very dynamic area of planning, but we wanted to share kind of our our early thoughts as things are shaping up.\n\n**Operator**\nYour next question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.\n\n**Brian Nowak** (Managing Director)\nThanks for taking my question. I've I've two that the first one, Mark, just to kinda go back to the intelligence lab and serve the the vision for super intelligence. As you sort of sit here now versus twelve months ago, can you just sort of walk us through any any changes of technological constraints or technological gating factors that you are most focused on overcoming in the next twenty four months that may have been different than they were in the past just to make sure you can really lead in the idea of superintelligence over the next ten years? And then the second one, to Susan or Mark, one on the core. You've made so many improvements to the core to drive higher engagement recommendations, etcetera.\n\n**Brian Nowak** (Managing Director)\nCan you just walk us through a couple of the factors you're still most excited about to come in the next eighteen months that you think could drive further lift to engagement on the on the core platform? Thanks.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSure. I mean, in terms of, you know, the research agenda and a bunch of the areas that we're very focused on, I I do think focusing on self improvement is a very important area of research. And and there's obviously different scaling paradigms, and and I I don't wanna get too much into the detail of of research that we're doing on on on this. But I I think that for developing superintelligence, at some level, you're not just gonna be learning from people because you're trying to build something that is fundamentally smarter than people. So it's going to need to learn how to, or you're gonna need to develop a way for it to be able to improve itself.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSo that, I think, is a is a very fundamental thing that, is going to have very broad implications for how we build products, how we run the company, new things that we can invent, new discoveries that can be made, society more broadly. I I think that that's that's a good just a very fundamental part of this. In in terms of the shape of the effort overall, I guess I've just gotten a little bit more convinced around the the ability for small talent dense teams to be the optimal configuration for driving frontier research. And it's a it's a bit of a different setup than we have on our other world class machine learning systems. So if you look at, like, what we do in Instagram or Facebook or our ad system, we can very productively have many hundreds or thousands of people basically working on improving those systems.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd we have very well developed systems for kind of individuals to run tests and be able to test a bunch of different things. You don't need every researcher there to have the whole system in their head. But I think for this, for the leading research on superintelligence, you really want the smallest group that can hold the whole thing in their head, which, you know, drives, I think, some of the physics around the team size and and and and how and the dynamics around how that works. But I'll I'll I'll hand it over to Susan to talk about more of the practical stuff.\n\n**Susan Li** (CFO)\nBrian, on the, on the sort of forward looking road map for, the core recommendation engine, you know, there are a handful of shorter term things that we're focused on in the near term. One is we're focused on making recommendations even more adaptive to what a person is engaging with during their session so that the recommendations we surface are the most relevant to what they're interested in at that moment. And we're making optimizations to help the best content from smaller creators break out by matching it to the right audiences sooner after it gets posted. We're also working on improving the ability for our systems to discover more diversified and niche interests for each person through interest exploration and learning explicit user preferences. We're also planning to scale up our models further and incorporate more advanced techniques that should improve the overall quality of, of recommendations.\n\n**Susan Li** (CFO)\nBut we also have a lot of long term bets in the hopper around areas like developing foundational models that will support recommendations across multiple services, incorporating LLMs more deeply into our recommendations into our recommendation systems. And a big focus of this work is going to be on optimizing the systems to make them more efficient so that we can continue to scale up the capacity that we use for our recommendation systems without eroding the, the ROI that that we deliver.\n\n**Operator**\nYour next question comes from the line of Doug Anmuth with JPMorgan. Please go ahead.\n\n**Douglas Anmuth** (MD &amp; Internet Analyst)\nThanks so much for taking the questions. One for Mark and one for Susan. Mark, Meta has been a huge proponent of open source AI. How has your thinking changed here at all just as you pursue superintelligence and push for even greater returns on your significant infrastructure investments? And then, Susan, your comments on 26 CapEx suggest more than $100,000,000,000 of spend next year potentially.\n\n**Douglas Anmuth** (MD &amp; Internet Analyst)\nDo you continue to expect to finance all this yourself, or could there be opportunities to partner here? Thanks.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. I mean, on on open source, I don't think that our thinking has particularly changed on this. We've always open sourced some of our models and not open sourced everything that we've done. So I would expect that we will continue to produce and share leading open source models. I also think that there are couple of trends that are playing out.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOne is that we're getting models that are so big that they're just not practical for a lot of other people to use. So it's we we kind of wrestle with whether it's productive or helpful to share that or if that's, you know, really just primarily helping competitors or something like that. So I think that there's there's that concern. And then, obviously, as you approach real superintelligence, I think there's a whole different set of safety concerns that I think we need to take very seriously that I that I wrote about in in in my note this morning. But I think the bottom line is I I I would expect that we will continue open sourcing work.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nI I expect us to continue to be a leader there. I also expect us to continue to not open source everything that we do, which is a continuation of of kind of what we what we've been been kind of working on. And and, yeah, I mean, I I think Susan will talk a little bit more about the infrastructure, but it it really is a a massive investment. Know, we think it will be good over time, but, you know, we we do take very seriously that this is a, just massive amount of capital to convert into many gigawatts of compute, which we think is is going to help us produce, leading research and and quality products in in running the business. I do look for opportunities to basically convert capital into quality of products that we can deliver for people, But this is is certainly a a a massive bet that we're we're we're kind of we're focused on, and and we wanna make sure that what we that what we build accrues to building the best products that we can deliver to the billions of people who use our services.\n\n**Susan Li** (CFO)\nDoug, on your second question about how, we expect to finance, the the growing CapEx next year, we certainly expect that we will we will finance, you know, some some large large share of that ourselves, but we're also exploring ways to work with financial partners to co develop data centers. We don't have any finalized transactions to announce, but we generally believe that there will be models here that will attract significant external financing to support large scale data center projects, that are developed using, you know, our ability to build world world class infrastructure while providing us with flexibility should our infrastructure requirements change over time. So we are exploring many different paths.\n\n**Operator**\nYour next question comes from the line of Justin Post with Bank of America. Please go ahead.\n\n**Justin post** (Managing Director)\nGreat. Thank you. I'll ask another one on the infrastructure. Mark, your spend is now approaching some of the biggest hyperscalers out there. Do Do you think of all this capacity mostly for internal uses, or do you think there's a way to share or even come up with a business model where leveraging that capacity for external uses?\n\n**Justin post** (Managing Director)\nAnd then, Susan, when when you think about the the ROI on this CapEx, I'm sure you have internal models. I'm sure you can't share all that. But how are you thinking about the ROI, and are you optimistic about the long term returns? Thank you.\n\n**Susan Li** (CFO)\nJustin, I can go ahead and and take a crack at both of those. And, obviously, Mark, you should you should feel free to weigh in. You know, right now, we are focused on, ensuring that we have enough capacity for our internal use cases, which includes both all of the core AI work that we do to support the recommendation, engine work on the organic, content side to support all the ads ranking and recommendation work, and then, of course, to make sure that we are building the training capacity that we think we need in order to build frontier AI models, and to make sure that we're preparing ourselves for, the types of inference use cases that we think, you know, might, that we might have ahead of us as we, eventually, you know, focus not only on developing frontier models, but also how we can expand, into the kinds of consumer use cases, that we think will, you know, be hopefully hopefully widely useful and, and engaging for our users. So at present, we're not really thinking about, external use case, external use cases on the infrastructure, but it's a, you know, it it it's it's a good question.\n\n**Susan Li** (CFO)\nOn your second question, which is really around the sort of ROI on on CapEx, you know, there are a couple things. So, again, on the core AI side, we continue to see strong ROI. Our ability to measure that is quite good, and we feel sort of, you know, very good about the the rigorous measurement and returns that that we see there. On the Gen AI side, we are clearly much, much earlier on the return curve, and we don't expect, that the Gen AI work is going to be a meaningful driver of revenue, you know, this year or, or next year. But we remain, you know, generally very optimistic about the the monetization opportunities that will open up, and Mark spoke to them in his, in his script, the sort of five pillars, I won't repeat them here.\n\n**Susan Li** (CFO)\nAnd we think that over the medium to long term time frame, those are opportunities that are very adjacent and intuitive, you know, for where our in terms of where our business is today, why they would be big opportunities for us, and that there will be sort of big markets attached, attached to each of them. So, you know, we, again, are also I would say the last thing I would add here is we are building the infrastructure with fungibility in mind. Obviously, there are a lot of things that you have to build up front in terms of the data center, shells, the networking infrastructure, etcetera. But we will be, you know, ordering servers, which ultimately will be the biggest bulk of CapEx spend as we need them, and when we need them, and making sort of the the best decisions at those times in terms of figuring out where the capacity will go to use.\n\n**Operator**\nYour next question comes from the line of Mark Schmulek with Bernstein. Please go ahead.\n\n**Mark Shmulik** (MD &amp; Senior Analyst - US Internet)\nYes. Thank you for taking my questions. Mark, as you go after the superintelligence vision, especially for those of us on the outside, what are kind of some of the markers or KPIs that you're tracking on whether you're on track and making progress? Is it really against kind of those five pillars you outlined above? Or should we be thinking more broadly?\n\n**Mark Shmulik** (MD &amp; Senior Analyst - US Internet)\nAnd Susan, obviously, AI delivering great ROI today, all those investments, and also building towards kind of longer term goals. Just curious, has there just been any change or adjustment to how you think about the relationship between revenues or core business performance and the cadence of investment? Thank you.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. In terms of what to look at I mean, what I'm gonna look at internally, the quality of the people on the teams, the quality of the models that we're producing, the rate of improvement of our other AI systems across the company, and and the extent to which the the leading kind of foundation models that we're building contribute to improving all of the other AI systems and and kind of everything that we're doing around the company. Then I think you just get into our standard product and business playbook, which is translating that technology into new products, which will first scale to billions of people, and then over time, we will monetize. But I think that there's there's gonna be some some lag in that. Right?\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd and and that, I think, is is kind of, you know, always the way that that we work as well. You know, whether we're we're building some new social product or or this, you know, something like Meta AI or a new new product around this, it's we're gonna work on on getting to leading scale, building the highest quality product, focus on that for a few years. And then once we're really confident in that position, then we'll focus on ramping up the business around it. So it's I mean, going back to the last question a little bit, it's it's sort of you know, when you compare this business to the some of the cloud businesses, it's like, we do have this delay where we focus on building research and then, doing research and then ramping consumer products, and it often does take, some period of time before we really are ramping up the business around it. I think that that's kind of a known property of our of our business and the cycle around it.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nBut I guess on the flip side, we believe that if you are building superintelligence, you should use all of your GPUs to, make it so that you're, serving your customers really well with that. And and we think that there's gonna be a much higher return that we can do by generating that directly rather than just kind of renting or leasing out the infrastructure at other companies.\n\n**Susan Li** (CFO)\nOn the second part of your question, you know, we've said in the past that our primary focus from a profitability perspective is driving consolidated operating profit growth over time. And it won't be linear. In some years, we'll deliver above average profit growth. And in years where we're making big investments, I think we will see that impact the amount of operating profit growth that we can deliver. And at the moment, we see a lot of attractive investment opportunities that we believe are gonna set us up to to to deliver compelling profit growth in the coming years, you know, for all of our investors.\n\n**Susan Li** (CFO)\nAnd so we're focused on constraining investments elsewhere as we pursue those those investments. But we really believe that, you know, this is a this is a time for us to really make investments in the future of AI as I think it will open up both new opportunities for us in addition to strengthen our core business.\n\n**Operator**\nYour next question comes from the line of Ron Josey with Citi. Please go ahead.\n\n**Ron Josey** (Managing Director)\nGreat. Thanks for taking the question. Mark, I wanted to to ask you on Meta AI, and I think you talked about in the call just growing engagement overall, particularly on WhatsApp. And now we have a billion users on the platform, and and the focus is now on driving personalization. So I wanna understand a little bit more how these next gen models can help drive adoption here, particularly with Behemoth coming online at some point.\n\n**Ron Josey** (Managing Director)\nAnd then as, you know, people are using Meta AI with WhatsApp, you know, thoughts on on search and queries and potentially monetizing that. Thank you.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. I'm not gonna get super deep into the road map on this, but the the basic you know, we do see that as we continue improving the the models behind Meta AI and and post training, it just engagement increases. And as we swap in the updated models, when we go from LAMA four to LAMA 4.1, when we have that, we expect that. You know, just the the models are inherently pretty general. So it's yeah.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYou focus on specific areas, but in general, just just sort of gets better at a lot of different things that that people wanna ask it or wanna do with it. And I think with each version, both, like, what we're doing on a week to week basis in terms of continuing to train it and when we drop kind of new generations or or big dot releases of of of each generation, that will improve engagement too. So we're we're focused on that. I'm not gonna go into the specific research areas or or capabilities that we're planning on dropping in the future, but I I you know, obviously, I'm pretty excited about it.\n\n**Ron Josey** (Managing Director)\nThank you.\n\n**Operator**\nWe Our last question comes from the line of Youssef Squali with Truist Securities. Please go ahead.\n\n**Youssef Squali** (MD &amp; Head of Internet and Digital Media Research Group)\nGreat. Thank you guys for taking the question. Type two. So, Mark, the ReBand initiative has been a hallmark for you guys so far. Where are we on the development of Glasses as that new computational platform that you've talked about in the past?\n\n**Youssef Squali** (MD &amp; Head of Internet and Digital Media Research Group)\nIs it moving faster or slower than you thought? And as you leverage Meta AI, do do you believe glasses ultimately replace smartphones, or do you need the new form factor that's AI first? And then, Susan, just quickly, how do you guys see SBC progressing over the next couple of years? Is it fair to assume it'll grow materially faster than revenue and OpEx? And how do you minimize shareholder dilution? Thank you.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. I can talk a bit about the glasses. Yeah. I mean, we're I'm I'm very excited about the progress that I think both the the Ray Ban metas and I'm I'm very excited about the Oakley meta, the the Houstons too and and and other things that that we have planned.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. I mean, this this product category is clearly doing quite well. And I I think it's good for a lot of things. It is stylish eyewear, so people like wearing them just as glasses. It it has a a bunch of interesting functionality, and then the use of Meta AI in them just continues to grow.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd and the percent of people who are using it for that on a daily basis is is increasing, and that's, that's all good to see. I mean, I continue to think that glasses are basically going to be the ideal form factor for AI because you can let an AI see what you see throughout the day, hear what you hear, talk to you. Once you get a display, in there, whether it's the kind of wide holographic field of view like we we, showed with Orion or just a smaller display that, might be good for displaying some information, then that's also going to unlock a lot of value where you can just interact with an AI system throughout the day in this multimodal way. It can see the content around you. It can generate a UI for you, show show you information, and and and be helpful.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nI mean, I I personally think that, you know, just like you know, if know, I wear contact lenses. I I feel like if I didn't have my vision corrected, I'd be sort of at a cognitive disadvantage going through the world. And I think in the future, if you don't have glasses that have AI or some way to interact with AI, I think you're kinda similar. We'd probably be at a, you know, pretty significant cognitive disadvantage compared to other people in in who you're who you're working with or competing against. So I think that this is a pretty fundamental form factor.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThere are a lot of different versions of it. Right now, we're building ones that I think are stylish but but aren't focused on the display. I think there's a whole set of different things to explore with displays. This is kind of what we've been maxing out with Reality Labs over the last, you know, five to ten years is basically doing the research on all of these different things. And and it's a it's a you know, I I don't know.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nTen years ago, I would have like, the the other thing that's awesome about glasses is they they are gonna be the the ideal way to blend the physical and digital worlds together. It's the whole metaverse vision, think, is gonna is going to end up being extremely important too, and AI is gonna accelerate that too. It's just that if you'd asked me five years ago whether we'd have kind of holograms that created immersive experiences or super intelligence first, I think most people would have thought that you'd get the holograms first. And it's this interesting kind of quirk of the tech industry that I think we're gonna end up having really strong AI first. But because we've been investing in this, I think we're just several years ahead on on on building out glasses.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd I think that that's something that we're excited to keep on investing in heavily because I I think it's gonna be a really important part of the the future.\n\n**Kenneth Dorell** (Director - IR)\nYoussef, we didn't quite catch your second question. Do you mind just repeating it?\n\n**Youssef Squali** (MD &amp; Head of Internet and Digital Media Research Group)\nSure. Just as you look at the the the the spend on stock based compensation over the next couple of years with all these hires, I'm assuming that that we're gonna see that materially or grow materially faster maybe than revenue and OpEx. And just wanna know how how what you guys are doing to plan to minimize shareholder dilution. Is it mostly buybacks or or anything else? Thank you.\n\n**Susan Li** (CFO)\nThanks, Youssef. So, I mean, the impact of, you know, the sort of increased compensation costs, including SBC, of our AI hires this year is reflected in the revised 2025 expense outlook and in the twenties the comments I made about sort of the 2026, expense outlook. Those are obviously a big driver of 2026 expense growth as we recognize the full year of compensation for the additional talent we're bringing on. Having said that, you know, we you know, so we've factored that into our sort of expense outlook. Having said that, we certainly, you know, we are very focused on on making sure on keeping an eye on dilution.\n\n**Susan Li** (CFO)\nAnd, you we generally believe that our strong financial position is going to allow us to support these investments while continuing to repurchase shares as part of the sort of buyback program that offsets equity compensation and as well as provide quarterly cash dividend distributions to our investors.\n\n**Kenneth Dorell** (Director - IR)\nGreat. Thank you everyone for joining us today. We look forward to speaking with you again soon.",
        "fetched_at": "2026-02-04T16:12:08.751Z"
      },
      {
        "ticker": "META",
        "title": "Yahoo Finance",
        "published_date": "Apr 30, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/META/earnings/META-Q1-2025-earnings_call-310648.html",
        "content": "**Operator**\nGood afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta First Quarter Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there will be a question and answer session.\n\n**Operator**\nAnd this call will be recorded. Thank you very much. Kenneth Dorrell, Meta's Director of Investor Relations, you may begin.\n\n**Kenneth Dorell** (Director of Investor Relations)\nThank you. Good afternoon and welcome to Meta's first quarter twenty twenty five earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and Susan Lee, CFO. Our remarks today will include forward looking statements, which are based on assumptions as of today. Actual results may differ materially as a result of various factors, including those set forth in today's earnings press release and in our annual report on Form 10 ks filed with the SEC.\n\n**Kenneth Dorell** (Director of Investor Relations)\nWe undertake no obligation to update any forward looking statement. During this call, we will present both GAAP and certain non GAAP financial measures. A reconciliation of GAAP to non GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.appmeta.com. And now I'd like to turn the call over to Mark.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAlright. Thanks, Ken. Thanks, everyone, for joining today. We've had a strong start to the year. Our community keeps growing with more than 3,400,000,000 people now using at least one of our apps each day.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOur business is also performing very well, and I think we're well positioned to navigate the macroeconomic uncertainty. The major theme right now, of course, is how AI is transforming everything we do. And, you know, as we continue to increase our investments and focus more of our resources on AI, I thought it would be useful today to lay out the five major opportunities that we are focused on. Those are improved advertising, more engaging experiences, business messaging, Meta AI, and AI devices. And these are each long term investments that are downstream from us building general intelligence and leading AI models and infrastructure.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nEven with our significant investments, we don't need to succeed in all of these areas to have a good ROI. But if we do, then I think that we will be wildly happy with the investments that we are making. The first opportunity is improved advertising. Our goal is to make it so that any business can basically tell us what objective they're trying to achieve, like selling something or getting a new customer, and how much they're willing to pay for each result, and then we just do the rest. Businesses used to have to generate their own ad creative and define what audiences they wanted to reach, but AI has already made us better at targeting and finding the audiences that will be interested in their products than many businesses are themselves, and that keeps improving.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd now AI is generating better creative options for many businesses as well. I think that this is really redefining what advertising is into an AI agent that delivers measurable business results at scale. And if we deliver on this vision, then over the coming years, I think that the increased productivity from AI, will make advertising a meaningfully larger share of global GDP than it is today. In just the last quarter, we are testing a new ads recommendation model for Reels, which has already increased conversion rates by 5%, and we're seeing 30% more advertisers are using AI creative tools in the last quarter as well. The second opportunity is more engaging experiences.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThis will come in two forms, better recommendations for existing content types and better new types of content. In the last six months, improvements to our recommendation systems have led to a 7% increase in time spent on Facebook, a 6% increase on Instagram, and 35% on threads. Threads now, also has more than 350,000,000 monthly actives and continues to be on track to become our next major social app. In addition to better recommendations for existing content types, AI is also enabling the creation of better content as well. Some of this will be helping people produce better content to share themselves.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSome of this will be AI generating content directly for people that is personalized for them. Some of this will be in existing formats like photos and videos, and some of it will be increasingly interactive. I've often talked about this long term trend of content becoming richer over time. Our feeds started mostly with text and then became mostly photos when we all got mobile phones with cameras, and then became mostly video when mobile networks became fast enough to handle that well. We are now in the video era, but I don't think that this is the end of the line.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nIn the near future, I think that we're gonna have content in our feeds that you can interact with and that it'll interact back with you, rather than you just watching it. Over the long term, as AI unlocks more productivity in the economy, I also expect that people will spend more of their time on entertainment and culture, which will create an even larger opportunity to create more engaging experiences across all of these apps. The the third opportunity is business messaging. Right now, the vast majority of our business is advertising and feeds on Facebook and Instagram. But WhatsApp now has more than 3,000,000,000 monthly actives with more than a hundred million people in The US and growing quickly there.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nMessenger is also used by more than a billion people each month, and there are now as many messages sent each day on Instagram as there are on Messenger. So business messaging should be the next pillar of our business. In countries like Thailand and Vietnam, where there is a low cost of labor, we see many businesses conduct commerce through our messaging apps. There's actually so much business through messaging that those countries are both in our top 10 or 11 by revenue even though they're ranked in the thirties in global GDP. This phenomenon hasn't yet spread to developed countries because the cost of labor is too high to make this a profitable model before AI, but AI should solve this.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSo in the next few years, I expect that just like every business today has an email address, social media account, and website, they'll also have an AI business agent that can do customer support and sales, and they should be able to set that up very easily given all the context that they've already put into our business platforms. And we're gonna have more to share on upcoming calls about our progress in this area. The fourth opportunity is Meta AI. Across our apps, there are now almost a billion monthly actives using Meta AI. Our focus for this year is deepening the experience and making AI the leading personal AI with an emphasis on personalization, voice conversations, and entertainment. I think that we're all gonna have an AI that we talk to throughout the day while we're browsing content on our phones and eventually as we're going through our days with glasses.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd I think that this is gonna be one of the most important and valuable services that has ever been created. In addition to building Meta AI into our apps, we just released our first Meta AI standalone app. It is personalized, so you can talk to it about interests that you've shown while browsing reels or different content across our apps. And we built a social feed into it so you can discover entertaining ways that others are using Meta AI, and initial feedback on the app has been good so far. Over time, I expect that the business opportunity for Meta AI to follow our normal product development playbook.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nFirst, we build and scale the product, and then once it is at scale, then we focus on revenue. In this case, I think that there will be a large opportunity to show product recommendations or ads as well as a premium service for people who want to unlock more compute for additional functionality or intelligence. But I expect that we're gonna be largely focused on scaling and deepening engagement for at least the next year before we'll really be ready to start building out the business here. The fifth opportunity is AI devices, which is increasingly how we are thinking about our work on the next generation of computing platforms. Glasses are the ideal form factor for both AI and the metaverse.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThey enable you to let an AI see what you see, hear what you hear, and talk to you throughout the day, and they let you blend the physical and digital worlds together with holograms. More than a billion people worldwide wear glasses today, and it seems highly likely that these will become AI glasses over the next five to ten years. Building the devices that that people use to experience our services lets us deliver the highest quality AI and social experiences. And this will serve as an amplifier on all of the opportunities I've mentioned so far as well as unlocking some new opportunities as well. Ray Ban Meta AI glasses have tripled in sales in the last year, and the people who have them are using them a lot.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nWe've got some exciting new launches with our partner, SLR Luxottica, later this year as well that should expand that category and add some new technological capabilities to the glasses. On Quest, we are also seeing deeper engagement as Quest three s makes VR accessible to more people, and more people are creating experiences in Horizon with AI tools. Now everything that I've talked about today is built on top of our AI models and our infrastructure. We released the first Llama four models earlier this month, and they are some of the most intelligent, best multimodal, lowest latency, and most efficient models that anyone has built. We have more models on the way, including the massive LAMA four behemoth model.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOverall, we are focused on building full general intelligence. All of the opportunities that I've discussed today are downstream of delivering general intelligence and doing so efficiently. The pace of progress across the industry and the opportunities ahead for us are staggering. I wanna make sure that we're working aggressively and efficiently, and I also wanna make sure that we are building out the leading infrastructure and teams that we need to achieve our goals. So to that end, we are accelerating some of our efforts to bring capacity online more quickly this year as well as some longer term projects that will give us the flexibility to add capacity in the coming years as well, and that has increased our planned investment for this year.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nMore broadly, this has been a good start to what I expect will continue to be an intense year. We've got a lot more exciting work in the pipeline that I'm looking forward to sharing soon. I continue to think that this year is gonna be a pivotal moment for our industry, and I am grateful for everyone who is working so hard at the company to deliver all of this amazing technology and new experiences. As always, thank you all for being on this journey with us. And now, Susan.\n\n**Susan Li** (Chief Financial Officer)\nThanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year over year basis unless otherwise noted. Q1 total revenue was $42,300,000,000 up 16% or 19% on a constant currency basis. Q1 total expenses were $24,800,000,000 up 9% compared to last year.\n\n**Susan Li** (Chief Financial Officer)\nIn terms of the specific line items, cost of revenue increased 14% driven primarily by higher infrastructure costs and payments to partners, partially offset by a benefit from the previously announced extension of server useful lives. R and D increased 22%, mostly due to higher employee compensation and infrastructure costs. Marketing and sales increased 8% driven mainly by an increase in professional services related to our ongoing platform integrity efforts. G and A decreased 34% driven primarily by lower legal related costs. We ended Q1 with over 76,800 employees, up 4% quarter over quarter.\n\n**Susan Li** (Chief Financial Officer)\nFirst quarter operating income was $17,600,000,000 representing a 41% operating margin. Our tax rate for the quarter was 9% as we recognized excess tax benefits from share based compensation due to the increase in our share price versus prior periods. Net All expenditures, including principal payments on finance leases, were $13,700,000,000 driven by investments in servers, data centers, and network infrastructure. Free cash flow was $10,300,000,000 We repurchased $13,400,000,000 of our Class A common stock and paid $1,300,000,000 in dividends to shareholders, ending the quarter with $70,200,000,000 in cash and marketable securities and 28,800,000,000 in debt. Moving now to our segment results.\n\n**Susan Li** (Chief Financial Officer)\nI'll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, and we estimate more than 3,400,000,000 people used at least one of our Family of Apps on a daily basis in March. Q one total Family of Apps revenue was $41,900,000,000 up 16% year over year. Q one Family of Apps ad revenue was $41,400,000,000 up 16% or 20% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year over year growth.\n\n**Susan Li** (Chief Financial Officer)\nOn a user geography basis, ad revenue growth was strongest in rest of world and North America at 1918% respectively. Europe and Asia Pacific grew fourteen percent and twelve percent. In q one, the total number of ad impressions served across our services increased 5%, and the average price per ad increased 10%. Impression growth was mainly driven by Asia Pacific. Pricing growth benefited from increased advertiser demand in part driven by improved ad performance.\n\n**Susan Li** (Chief Financial Officer)\nThis was partially offset by impression growth, particularly from lower monetizing regions and surfaces. Family of apps other revenue was $510,000,000, up 34%, driven mostly by business messaging revenue growth from our WhatsApp business platform as well as Meta Verified subscriptions. We continue to direct the majority of our investments toward the development and operation of our family of apps. In q one, family of apps expenses were $20,100,000,000 representing 81% of our overall expenses. Family of expenses were up 10% mainly due to growth in employee compensation and infrastructure costs, which were partially offset by lower legal related expenses.\n\n**Susan Li** (Chief Financial Officer)\nFamily of Apps operating income was $21,800,000,000 representing a 52% operating margin. Within our Reality Labs segment, q one revenue was $412,000,000 down 6% year over year due to lower Meta Quest sales, which were partially offset by increased sales of Ray Ban Meta AI glasses. Reality Labs expenses were $4,600,000,000 up 8% year over year driven primarily by higher employee compensation. Reality Labs operating loss was $4,200,000,000. Turning now to the business outlook.\n\n**Susan Li** (Chief Financial Officer)\nThere are two primary factors that drive our revenue performance, our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we're focused both on enhancing our core family of apps today and building the next generation of devices and experiences through Reality Labs. I'll start with our family of apps. In the first quarter, we saw strong growth in video consumption across both Facebook and Instagram, particularly in The US where video time spent grew double digits year over year. This growth continues to be driven primarily by ongoing enhancements to our recommendation systems, and we see opportunities to deliver further gains this year.\n\n**Susan Li** (Chief Financial Officer)\nWe're also progressing on longer term efforts to develop innovative new approaches to recommendations. A big focus of this work will be on developing increasingly efficient recommendation systems so that we can continue scaling up the complexity and compute used to train our models while avoiding diminishing returns. There are promising techniques we're working on that will incorporate the innovations from LLM model architectures to achieve this. Another area that is showing early promise is integrating LLM technology into our content recommendation systems. For example, we're finding that LLM's ability to understand a piece of content more deeply than traditional recommendation systems can help better identify what is interesting to someone about a piece of content leading to better recommendations.\n\n**Susan Li** (Chief Financial Officer)\nWe began testing using LaMa in Thread's recommendation systems at the end of last year given the app's text based content and have already seen a 4% lift in time spent from the first launch. It remains early here, but a big focus this year will be on exploring how we can deploy this for other content types, including photos and videos. We also expect this to be complementary to Meta AI as it can provide more relevant responses to people's queries by better understanding their interests and preferences through their interactions across Facebook, Instagram, and threads. Earlier this year, we began testing the ability for Meta AI to better personalize its responses by remembering certain details from people's prior queries and considering what that person engages with on our apps. We are already seeing this lead to deeper engagement with people we've rolled it out to, and it is now built into Meta AI across Facebook, Instagram, Messenger, and our new standalone MetaAI app in The US and Canada.\n\n**Susan Li** (Chief Financial Officer)\nWe're also continuing to focus on helping people connect over content. In q one, we launched a new experience on Instagram in The US that consists of a feed of content your friends have left a note on or liked, and we're seeing good results. We also just launched Blend, which is an opt in experience in direct messages that enables you to blend your Reels algorithm with your friends to spark conversations over each other's interests. These features all lean into Instagram's position at the intersection of entertainment and social connection. WhatsApp remains at its core a private messaging app, but it has evolved to also become a place people come to get updates from accounts they are connected to or follow.\n\n**Susan Li** (Chief Financial Officer)\nToday, there are tens of billions of views of status posts on WhatsApp each day, and we continue to invest in the updates tab as a place people can go to do more. Creators remain another big focus for us, and we're investing in tools to help them produce the best original content on our platforms. Last week, we launched our standalone edits app, which supports the full creative process for video creators from inspiration and creation to performance insights. Edits has an ultra high resolution short form video camera and includes generative AI tools that enable people to remove the background of any video or animate still images with more features coming soon. Moving to Reality Labs, we're seeing very strong traction with Ray Ban Meta AI glasses with over four times as many monthly actives as a year ago, and the number of people using voice commands is growing even faster as people use it to answer questions and control their glasses.\n\n**Susan Li** (Chief Financial Officer)\nThis month, we fully rolled out live translations on Ray Ban Meta AI glasses to all markets for English, French, Italian, and Spanish. Now when you are speaking to someone in one of these languages, you'll hear what they say in your preferred language through the glasses in real time. Now to the second driver of our revenue performance, increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to optimize ad supply across each service to better deliver ads at the time and place they are most relevant to people.\n\n**Susan Li** (Chief Financial Officer)\nWe are also starting to introduce ads on unmonetized services like Threats, which we opened up to all eligible advertisers this month to reach people in over 30 different markets to start, including The US. As we do for any newly monetized surface, we expect to gradually ramp ad supply as we optimize the ad formats and ensure they feel native to the app. We don't expect threads to be a meaningful driver of overall impression or revenue growth in 2025. The second part of increasing monetization efficiency is improving marketing performance. We're continuing to improve our ad systems by developing new modeling technologies to more efficiently predict the right ad to show.\n\n**Susan Li** (Chief Financial Officer)\nIn q one, we introduced our new generative ads recommendation model or JEM for ads ranking. This model uses a new architecture we developed that is twice as efficient at improving ad performance for a given amount of data and compute. This efficiency gain enabled us to significantly scale up the amount of compute we use for model training with JEM trained on thousands of GPUs, our largest cluster for ads training to date. We began testing the new model for ads recommendations on Facebook Reels earlier this year and have seen up to a 5% increase in ad conversions. We're now rolling it out to additional services across our apps.\n\n**Susan Li** (Chief Financial Officer)\nOn the ads product side, we're seeing continued momentum with our Advantage Plus suite of AI powered solutions. We've been encouraged by the initial tests of our streamlined campaign creation flow for sales, app, and lead campaigns, which starts with Advantage Plus turned on from the beginning for advertisers. In April, we rolled this out to more advertisers and expect to complete the global rollout later this year. We're also seeing strong adoption of Advantage Plus Creative. This week, we are broadening access of video expansion to Facebook reels for all eligible advertisers, enabling them to automatically adjust the aspect ratio of their existing videos by generating new pixels in each frame to optimize their ads for full screen surfaces.\n\n**Susan Li** (Chief Financial Officer)\nWe also rolled out image generation to all eligible advertisers. And this quarter, we plan to continue testing a new virtual try on feature that uses GenAI to place clothing on virtual models, helping customers visualize how an item may look and fit. Last, we continue to evolve our ads platform to drive results that are optimized for each business' objectives and the way they measure value. One example of this is our incremental attribution feature, which enables advertisers to optimize for driving incremental conversions or conversions we believe would not have occurred without an ad being shown. We're seeing strong results in testing so far with advertisers using incremental attribution in tests seeing an average 46% lift in incremental conversions compared to their business as usual approach.\n\n**Susan Li** (Chief Financial Officer)\nWe expect to make this available to all advertisers in the coming weeks. Next, I would like to discuss our approach to capital allocation. Our primary focus remains investing capital back into the business with infrastructure and talent being our top priorities. Starting with headcount, our hiring continues to be targeted at technical roles within our company priorities. In the first quarter, the significant majority of the roughly 2,800 employees we added were to support our priorities of monetization, infrastructure, generative AI, regulation and compliance, and Reality Labs.\n\n**Susan Li** (Chief Financial Officer)\nOn infrastructure, we have two primary focuses to meet the growing compute needs of our services and AI initiatives. The first way is by significantly scaling up our infrastructure footprint. Our CapEx growth this year is going toward both generative AI and core business needs with the majority of overall CapEx supporting the core. We expect the significant infrastructure footprint we are building will not only help us meet the demands of our business in the near term, but also provide us an advantage in the quality and scale of AI services we can deliver. We continue to build this capacity in a way that grants us maximum flexibility in how and when we deploy it to ensure we have the agility to react to how the technology and industry develop in the coming years.\n\n**Susan Li** (Chief Financial Officer)\nThe second way we're meeting our compute needs is by increasing the efficiency of our workloads. In fact, many of the innovations coming out of our ranking work are focused on increasing the efficiency of our systems. This emphasis on efficiency is helping us deliver consistently strong returns from our core AI initiatives. For example, we shared on the q three twenty twenty four call that improvements to our AI driven feed and video recommendations drove a roughly 8% lift in time spent on Facebook and a 6% lift on Instagram over the first nine months of last year. Since then, we've been able to deliver similar gains in just six months' time with improvements to our AI recommendations delivering 76% time spent gains on Facebook and Instagram respectively.\n\n**Susan Li** (Chief Financial Officer)\nBefore moving to our financial guidance, I want to acknowledge the dynamic macro environment and note that our range reflects the potential for a wider set of outcomes. We continue to feel good about the fundamental drivers of revenue growth and believe the past work we've done to streamline our operations and cost profile puts us in a strong position to navigate a variety of outcomes. Moving to our financial outlook. We expect second quarter twenty twenty five total revenue to be in the range of 42,500,000,000.0 to $45,500,000,000 Our guidance assumes foreign currency is an approximately 1% tailwind to year over year total revenue growth based on current exchange rates. Turning now to the expense outlook.\n\n**Susan Li** (Chief Financial Officer)\nWe expect full year 2025 total expenses to be in the range of 113,000,000,000 to $118,000,000,000 lowered from our prior outlook of $114,000,000,000 to $119,000,000,000 Turning now to the CapEx outlook. We anticipate our full year twenty twenty five capital expenditures, including principal payments on finance leases, will be in the range of $64,000,000,000 to $72,000,000,000 increased from our prior outlook of $60,000,000,000 to $65,000,000,000. This updated outlook reflects additional data center investments to support our AI efforts as well as an increase in the expected cost of infrastructure hardware. The majority of our CapEx in 2025 will continue to be directed to our core business. On to tax.\n\n**Susan Li** (Chief Financial Officer)\nAbsent any changes to our tax landscape, we expect our full year 2025 tax rate to be in the range of 12% to 15%. In addition, we continue to monitor an active regulatory landscape, including legal and regulatory headwinds in The EU and The US that could significantly impact our business and our financial results. The European Commission recently announced its decision that our subscription for no ads model is not compliant with the DMA. Based on feedback from the European Commission in connection with the DMA, we expect we will need to make some modifications to our model, which could result in a materially worse user experience for European users and a significant impact to our European business and revenue as early as the third quarter of twenty twenty five. We will appeal the commission's DMA decision, but any modifications to our model may be imposed before or during the appeal process.\n\n**Susan Li** (Chief Financial Officer)\nIn closing, this was another solid quarter for our business. We believe the investments we're making across our company priorities will position us well in the coming years to continue delivering engaging services for our community, compelling results for advertisers, and strong business performance. With that, Christa, let's open up the call for questions.\n\n**Operator**\nThank you. We will now open the lines for a question and answer session. And your first question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.\n\n**Brian Nowak** (Managing Director)\nGreat. Thanks for taking my questions. I have two. The first one's on LAMA. Mark, can you the LLM landscape continues to sort of evolve and be somewhat competitive.\n\n**Brian Nowak** (Managing Director)\nCan you sort of talk us through some of the key areas of advancement you are most focused on and excited about as we sort of think about Behemoth and and next versions of of LAMA to come? And then the the second one on on Meta AI, almost a billion users globally. Any help on sort of how you're seeing US traction there and the types of recurring user behaviors that you're seeing in the early Meta AI use cases? Thanks.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSure. I can talk about the the LLMs. On the Meta AI usage, I'm not sure if we have more stats to share on that now. Yeah. It's I mean, I'll I'll defer to Susan on if there's anything that we're that we're ready on that.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nOn the LLM, yeah, there's a lot of progress being made in in a a lot of different dimensions. And the reason why we wanna build this out is, one, is that we think it's important that for for kind of how critical this is for our business that we sort of have control of our own destiny and are not depending on on another company for something so critical. But two, we wanna make sure that we can shape the development to be optimized for our infrastructure and the use cases that we want. So to that end, LAMA four, the shape of the model with 17,000,000,000 parameters per expert was designed specifically for the infrastructure that that we have in order to provide low latency experience to be voice optimized. One of the key things if you're having a voice conversation with AI is it needs to be low latency.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSo that way, you know, when you're having a conversation with it, there's no large gap between when you stop speaking and it start and it starts. So everything from the shape of the model to the research that we're doing to the techniques that go into it are are kind of fit into that. Similarly, another thing that we focused on was context window length. And, you know, in some of our models, we have really we're industry leading on context window length. And part of the reason why we think that that's important is because we're very focused on providing a personalized experience.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd there are different ways that you can put personalized personalization context into an LLM, but one of the ways to do it is to include some of that context in the context window. And having a long context window that can incorporate a lot of the background that a person has shared across our apps is one way to do that. So that's like it it kind of is giving you a flavor of the products that we're trying to build and then some specific technical architecture decisions and research prioritization that we basically have made in order to deliver the specific experience that we're going for. I could go on and and add and add a lot more. The reason you know, it's it I think it's also very important to deliver big models like Behemoth, not because we're gonna end up serving them in production, but because of the technique of distilling from larger models.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nRight? The LAMA four models that we've published so far and the ones that we're using internally and, and and some of the ones that we'll build in the future are basically distilled from the Behemoth model in order to, get the, you know, 95% of the intelligence of the large model in a form factor that is much lower latency and much more efficient. So these things are all very important. Obviously, we wouldn't be able to do that kind of distillation, from other closed models. So that that kinda gives you a flavor for for how we're thinking about the development of this.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nAnd and then, of course, the models and the infrastructure that we're building out power all of the the the the opportunities that I mentioned before.\n\n**Susan Li** (Chief Financial Officer)\nBrian, I'm happy to answer your second question about Meta AI. You know, the top use case right now for Meta AI from a query perspective is really around information gathering as people are using it to search for and understand and analyze information, followed by social interactions from you know, ranging from casual chatting to more in-depth discussion or debate. We also see people use it for writing assistance, interacting with visual content, seeking help. And we see meta, people engage with Meta AI from several different entry points. WhatsApp continues to see the strongest Meta AI usage across our family of apps.\n\n**Susan Li** (Chief Financial Officer)\nMost of that WhatsApp engagement is in one on one threads, followed by Facebook, which is the second largest driver of Meta AI engagement where we're seeing strong engagement from our feed deep dives integration that lets people ask Meta AI questions about the content that's recommended to them. And we're obviously excited about the launch of the Meta AI standalone app.\n\n**Operator**\nYour next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.\n\n**Eric Sheridan** (Managing Director)\nThanks so much for taking the question. Maybe following up on Brian's question and coming at it from a different angle, I appreciate the color on the use cases you're seeing today for Meta AI. How would you suspect those use cases evolve with a standalone app? Can you bring us into a little bit the decision process to do a standalone app? What that might change in terms of utility, frequency, or scale relative to what you see inside family of apps today?\n\n**Eric Sheridan** (Managing Director)\nAnd how you think about positioning Meta AI as a standalone app against the competitive landscape today of other, stand alone sort of consumer AI apps? Thank you.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. I can talk about that. We're gonna focus on both integrating it into our family of apps in more ways and building a stand alone experience. You know, I think some people want faster access to it or or a more built out feature set than you can build into an app like WhatsApp. So so the stand alone app will be valuable for that.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nI also think that the stand alone app is going to be particularly important in The United States because WhatsApp, as Susan said, is the largest surface that people use that AI in, which makes sense if you wanna text an an AI, having that be closely integrated and a good experience in the messaging app that you use makes a lot of sense. But, you know, we're while we have, you know, more than a hundred million people use WhatsApp in The United States, it we're clearly not the primary messaging app in The United States at this point. IMessage is. We we hope to to become the leader over time, but we're in a different position there than we are in most of the rest of the world on WhatsApp. So, so I think that the Meta AI app as a stand alone is gonna be particularly important in The United States to to establishing leadership in as as the the main personal AI that people use.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nBut we're gonna keep on advancing the experiences across the board in all of these different areas.\n\n**Operator**\nYour next question comes from the line of Justin Post with Bank of America. Please go ahead.\n\n**Justin post** (Managing Director)\nGreat. Thank you. A couple of questions.\n\n**Justin post** (Managing Director)\nJust on the guide in the second quarter, are reports of potential supply issues in e commerce. How you thought about that in the guide and maybe how you're thinking about it for the back half? And then a bigger picture question, you know, your CapEx spend is now close to some hyperscalers with with very big client basis. Just help us conceptualize the kind of ecosystem you're building with your CapEx. I know you gave a lot of help on the intro, but but maybe the ROI works without direct enterprise spend to drive revenues. How how you're thinking about that? Thank you.\n\n**Susan Li** (Chief Financial Officer)\nThanks, Justin. You know, on the q two guide, there's a uncertainty, uncertainty, obviously, in how the macro environment will evolve over time and how that could impact different segments of our business. You know, our q two revenue outlook aims to factor that in and partly, that's partly why the $3,000,000,000 range reflects the potential for a wider range of outcomes. Specifically, we have seen some reduced spend in The US from Asia based ecommerce exporters, which we believe is in anticipation of the de minimis exemption going away on May 2. A portion of that spend has been redirected to other markets, but overall spend for those advertisers is below the levels prior to April.\n\n**Susan Li** (Chief Financial Officer)\nBut our q two outlook, you know, reflects the trends we're seeing so far in April, which have generally been healthy. So it's very early. Hard to know how things will play out over the quarter and certainly, certainly harder to know that for the rest of the year. Your second question, is, is, about why we're investing more in CapEx. And, you know, we really believe that our ability to build world class infrastructure gives us a meaningful advantage in both developing the leading AI technology and services over the coming years.\n\n**Susan Li** (Chief Financial Officer)\nAnd there are a lot of opportunities also for us to improve our core business, by putting more compute against our ads and recommendation work. So even with the capacity that we're bringing online in 2025, you know, we are having a hard time, meeting the demand that teams have for compute compute resources across the company. So we are going to continually, invest, you know, meaningfully here across our infrastructure footprint, but we are also also really looking to build this capacity in a way that gives us the maximum flexibility in how and when we deploy it over the coming years so we can respond to how the market and technology develop.\n\n**Operator**\nYour next question comes from the line of Doug Anmuth with JPMorgan. Please go ahead.\n\n**Douglas Anmuth** (Managing Director &amp; Internet Analyst)\nThanks for taking the questions. I just wanted to follow-up on CapEx and infrastructure spending. Just on the higher range for CapEx, can you just help us understand how much of that is tied to the additional data center investments versus the increased hardware costs? And really, what's driving those higher hardware costs? And then separately, there have been some articles suggesting that you've been looking to partner to share some of the costs of the AI infrastructure build out.\n\n**Douglas Anmuth** (Managing Director &amp; Internet Analyst)\nCan you just help us understand your thought process there and some of the pros and cons of going alone versus partnering? Thanks.\n\n**Susan Li** (Chief Financial Officer)\nThanks, Doug. You know, so our increased CapEx outlook, you know, reflects both of those updates. The increased data center spend this year as we, have made some adjustments to flex our build strategy, that will enable us to really stand up capacity more quickly, both in '25 and '26. We haven't broken down sort of the exact drivers. The higher cost we expect to incur for infrastructure hardware this year really comes from, you know, suppliers who source from countries around the world.\n\n**Susan Li** (Chief Financial Officer)\nAnd there's just a lot of uncertainty around this given the ongoing, trade discussions. And so that is both reflected in the wider range that we are giving, and we're also working on, you know, on our end on mitigations by optimizing our supply chain, and our outlook is really trying to reflect our best understanding of the potential impact, this year, you know, across all of that uncertainty. On the second part of your question, you know, we are you know, we're pleased to have partners investing alongside us and bringing LAMA to market like AWS and Azure who are helping us host LAMA. We're always looking for opportunities to continue deepening or expanding those partnerships, but we are funding the infrastructure that is being used to train LAMA, and we don't have any expectation that that will change, at this point.\n\n**Operator**\nYour next question comes from the line of Mark Schmulich with Bernstein. Please go ahead.\n\n**Mark Shmulik** (MD, Senior Analyst)\nYes. Thanks for taking the questions. Mark, in your conversation last night with Satya, I think you both discussed a bit around, you know, kind of the the portion of code being written internally by AI. Know, kind of back to some of your previous comments around, you know, this being the year where we might see a, you know, AI kind of, the place of a mid level engineer. You know, with the world evolving so quickly, can you share some places where you've seen strong traction there?\n\n**Mark Shmulik** (MD, Senior Analyst)\nAnd, you know, are we progressing kind of faster, slower, or as you expected towards this milestone? And then, Susan, with the expense kind guidance coming down just a touch, how should we think about just the overall cadence of expected spending really as it relates to kind of core business performance and this the realities of the day to day world we're living in? Thank you.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nI can talk about the coding agent work. I I don't think that there's been any real change in our prediction for the the timing of this. So I'd say it's basically still on track for something around a mid level engineer kind of starting to become possible sometime this year, scaling into next year. So I'd expect that, you know, by the middle to end of next year, AI coding agents are going to be doing a substantial part of AI research and development. So we're focused on that.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nInternally, we're also very focused on building AI agents or systems that can help, you know, run different experiments to increase recommendations across our other AI products that, like, the the the ones that do recommendations across our feeds and things like that. So I I think that, if it works, should just accelerate our progress in in those areas. That's, that's the the basic bet that we're making.\n\n**Susan Li** (Chief Financial Officer)\nYour second question, about our lowered expense outlook. You know, really, we are four months into the year. The lowered outlook reflects more refined forecasts, including updated expectations for both employee compensation, as well as some other nonheadcount related operating expenses this year. And that's partially offset by higher expected infrastructure costs related to our increased CapEx outlook as well as, higher expected Reality Labs cost of goods sold. And we've maintained our $5,000,000,000 range just, given the more dynamic operating environment that we're in.\n\n**Susan Li** (Chief Financial Officer)\nAnd what I would say is, you know, our investment posture today reflects, you know, the significant opportunities that we see across each of the company and priorities that we're investing in this year. We will obviously continue evaluating depending on how macro conditions more broadly evolve, but we really feel like these are big strategic priorities for us and are critical for us to continue investing in. And in fact, you know, I think one of the aims of our efficiency work over the last two years was to put us in a stronger financial position so that we can continue investing in key priorities through tougher financial cycles.\n\n**Operator**\nYour next question comes from the line of Ross Sandler with Barclays. Please go ahead.\n\n**Ross Sandler** (Analyst)\nMark, yesterday in one of your many kind of podcast or keynote presentations, you had mentioned that like a bunch of projects that your teams, want to or aspire to do are kind of bottlenecked by the AI capacity, which, you know, Susan just talked about earlier, and that even, you know, some of the testing that the ad ranking team wants to run is just getting kinda delayed. So I I guess looking out either, you know, this year, next year, whenever, when do you kinda see some of this, constraint being eased back? And, you know, more broadly, you know, we're kind of three years past the IDFA impact to your business. So where do you, you know, where do you think we are in terms of just the overall improvements to the ad ranking system, the ROI that you guys are able to deliver? And, like, what what inning are we in on that in your opinion? Thank you very much.\n\n**Susan Li** (Chief Financial Officer)\nI can take a shot at both of those, and, Mark, you can obviously chime in. On the first question, you know, the cap the capacity landscape we are in is pretty dynamic, both in terms of the many moving parts in terms of us bringing capacity online, but also in terms of the, the demand from different product groups in our company, whether they are in the GenAI teams or whether they're doing more of the core AI work around ranking and recommendations. So both the supply and demand, you know, are quite fluid, and so we don't have a sort of a fixed answer in terms of, you know, when we expect that, that we will sort of have enough supply to meet all demand, but that's something that we are working very hard to alleviate, and it's part of, why we accelerated bringing more data center space online, this year. And, also, we're very focused on increasing the efficiency of our workloads over the course of the year. On our your second question, about, you know, ads performance, ads ranking, you know, we have invested for many years and continue to, invest in driving ad performance improvements.\n\n**Susan Li** (Chief Financial Officer)\nYear over year conversion growth remains strong, and in fact, we continue to see conversions grow at a faster rate than ad impressions in q one, so reflecting increased conversion rates. And, you know, ads ranking and modeling improvements are a big driver of overall performance gains. We have a lot of innovations, in model architecture in both the ads retrieval and ranking stages of the ads delivery process to serve more relevant ads to people. We talked about the, introduction of the new, gem ads recommendation model in q one, and we have talked about some of the prior model architecture improvements like Lattice and Andromeda in past quarters. For us, we really, you know, believe first and foremost that advertising is a relative performance game.\n\n**Susan Li** (Chief Financial Officer)\nThat's especially important for us because the vast majority of our business is direct response advertising. So we we feel good about how the prior investments are paying off, and we continue to, invest in a lot of different work to, constantly improve our ads ranking and recommendations, performance.\n\n**Operator**\nYour next question comes from the line of Kenneth Gavroski with Wells Fargo. Please go ahead.\n\n**Ken Gawrelski** (Analyst)\nThank you so much. Two for me, please. First, maybe, Mark, how should we think about the timing of AI capabilities necessary to drive WhatsApp for business adoption in higher cost higher labor, cost labor markets. What is Meta doing to accelerate that adoption? And do you see this as mostly incremental to to SME ad spend that you're already capturing?\n\n**Ken Gawrelski** (Analyst)\nAnd then for Susan, one, What is the revised CapEx outlook for this year for '25 mean about future years? Does it mean anything? Or you talked about this being an acceleration in your revised outlook statement. Should we think about this as a new starting point for the to think about '26 and beyond, or or should we just start fresh in '26 and think about the the needs and and and capacity at that point? Thank you.\n\n**Susan Li** (Chief Financial Officer)\nI'm I'm happy to take I'll I'll I'll go ahead and take, both of those. And, Mark, you should feel free to chime in, wherever you, would like. You know, so Mark talked a little bit about our general vision that every business will soon, you know, have an AI, that is an expert on their business for their customers to talk to in the same way that today they've got email and websites, social media presences, etcetera. We are currently testing business AIs with a limited set of businesses in The US, and a few additional countries on WhatsApp, Messenger, and on, ads on Facebook and Instagram. We've been starting with small businesses and focusing first on helping them sell their goods and services with business AIs.\n\n**Susan Li** (Chief Financial Officer)\nBut, ultimately, we are working on tools to support businesses at every stage of the customer funnel from lead generation to order management and customer service. And a core area that we're addressing right now is really the ability for businesses to customize and control the agent to achieve the outcome that they want. So we've launched a new agent management experience and dashboard that makes it easier for businesses to train their AI based on existing information on their website or WhatsApp profile or their Instagram and Facebook pages. And we're starting with the ability for businesses to activate AI in their chats with customers. We are also testing business AIs on Facebook and Instagram ads that you can ask about product and return policies or assist you in making, a purchase within our in app browser.\n\n**Susan Li** (Chief Financial Officer)\nSo, again, the ultimate vision is to build an experience that serves customers across all of these different services and apps. No matter where you engage with the business AI, it should be one agent that recalls your history and your preferences. And we're hearing encouraging feedback, particularly that adopting these AIs are saving the businesses that we're testing with a lot of time in helping to determine which conversations make sense for them to spend more time on. And then your second question, right, was about 2026 CapEx. You know, infrastructure, as I alluded to earlier, just is a very dynamic planning area, given the continued advances in a in AI.\n\n**Susan Li** (Chief Financial Officer)\nAnd also for us, the fact that we continue to find a lot of good, use cases to put capacity toward in our core AI ranking and recommendations work. So I would say it's too early to discuss plans beyond 2025.\n\n**Operator**\nYour next question comes from the line of Youssef Squali with Truist Securities. Please go ahead.\n\n**Youssef Squali** (MD &amp; Head of Internet and Digital Media Research Group)\nGreat. Thank you guys for taking the question. So, Mark, in a world where we, we now have maybe five to 10 chatbots including Meta AI on our smartphones doing virtually the same thing, do do do you think this is a market much like search where the winner takes most, or is it likely to be much more fragmented? But in either case, what would you say are the the top two or three competitive advantages of Meta dot ai? And then, Susan, on the EU decision connection with the DMA, what kind of modifications will you need to make to the apps?\n\n**Youssef Squali** (MD &amp; Head of Internet and Digital Media Research Group)\nAnd can you maybe just help us gauge the potential financial fallout understanding that it may still obviously be too early? Thank you.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYeah. On on Meta AI, I mean, I think that there are going to be a number of different agents that people use just like people use different apps for for different things. I'm not sure that people are gonna use multiple agents for the same exact things, but I I'd imagine that something that is more focused on kind of enterprise productivity might be different from something that is somewhat more optimized for personal productivity, and that might be somewhat different from something that is optimized for for entertainment and and social connectivity. So and then there will be there will be different experiences. One of the trends that I think we're starting to see now is personalization across of the across these.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nYou know, right now, if the experience is unpersonalized, then you can kinda just go to different apps and get, you know, reasonably similar answers to different questions. But once an AI starts getting to know you and what you care about and context and can build up memory from the conversations that you've had with it over time, I think that will start to become somewhat more of a differentiator. So that's one thing that we think will matter. And then, of course, there's all the different modalities, being able to not just answer questions about in text, but being able to do voice and multimodal and be able to produce images and videos and understand all those things and have good conversations about that, I think, is gonna be important overall. So, yeah, I mean, I think Meta AI is is well positioned, but we have a lot of work to do in order to make it the leading personal AI.\n\n**Susan Li** (Chief Financial Officer)\nAnd, Youssef, on your second second question, you know, it is really too early to speak about what those changes could be because we are in the process of engaging with the European Commission. I think maybe the most, useful sort of metric I could give you is just that our advertising revenue in the European economic area in Switzerland, which would be the geographies impacted here, was 16% of our worldwide total revenue in 2024. Again, we are continuing to engage actively with the European Commission further on this, so we hope to have more clarity by next quarter's call.\n\n**Kenneth Dorell** (Director of Investor Relations)\nChrista, we have time for one last question.\n\n**Operator**\nYour last question comes from the line of Mark Mahaney with Evercore ISI. Please go ahead.\n\n**Mark Mahaney** (Senior Managing Director)\nThanks. I'll just throw in two. I think you called out that the China based retailers is one sort of at some potentially soft advertising vertical. Anything else you'd call out? And I would just suggest autos.\n\n**Mark Mahaney** (Senior Managing Director)\nWas that an area of any softness? And then on the Reality Labs and on the losses associated with Reality Labs, they've been very consistent, whatever, 4,000,000,000 a quarter for quite some time. Is there is there light at the end of the tunnel? Is there reason to think? Is there is there factor that that would occur that would cause those losses to come down?\n\n**Mark Mahaney** (Senior Managing Director)\nAnd when would that be? But but maybe more importantly, what what is gonna cause those losses to come down? Thank you very much.\n\n**Susan Li** (Chief Financial Officer)\nMark, let me take your first question about, other verticals. You know, we generally saw healthy growth in most verticals, in q one. We did see some weakness in gaming and politics. So year over year growth in gaming was negative, in q one as we lapped a period of strong spend from China based advertisers that were promoting a larger volume of game titles in q one of twenty twenty four. And then year over year growth in the government and politics vertical dropped sharply as expected with the conclusion of of US of US elections, and but that continues to just be a very small, small vertical overall. And then your your second question on Reality Labs.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nThe Reality Labs one. I mean, we're we're basically focused on doing the work more efficiently, but as the AI glasses have really taken off, I've talked about this on a number of calls, There are more investments that that I think makes sense to to make around making sure that we can distribute this and grow it very quickly. I mean, some of the if you look at the some of the leading consumer electronics products of other categories, by the time they get to their third generation, you know, they're they're often selling, you know, 10,000,000 units and scaling from there. And, you know, I'm not sure if we're gonna do exactly that, but I think that that's, like, the ballpark of the opportunity that we have. And, and that's something that I think we're we're kind of focused on on scaling to that and then scaling beyond that for the generations after that.\n\n**Mark Zuckerberg** (Founder, Chairman &amp; CEO)\nSo I I think some of the the, effort that we're that we're doing is going to we're gonna get more efficient in some parts of the work that we do, but then as a bunch of the products start to hit and start to to grow even bigger than than than and the the number that I just said is just sort of like the sort of a near term milestone, then, you know, then then I think we'll we'll continue scaling in in terms of distribution. And then at some point, just like the other products that we we build out, we will feel like we're at a sufficient scale that we're gonna primarily focus on making sure that we're monetizing and building an efficient business around it. But but that's kinda where we're at on it. We're we're we're definitely focused on doing the work more efficiently, but also very optimistic about what we're seeing in the results, especially on the AI glasses side.\n\n**Kenneth Dorell** (Director of Investor Relations)\nGreat. Thank you everyone for joining us today. Excuse me. And we look forward to speaking to you again soon.",
        "fetched_at": "2026-02-04T16:12:13.627Z"
      }
    ]
  },
  "TSLA": {
    "ticker": "TSLA",
    "last_updated": "2026-02-04T16:12:51.955Z",
    "total_transcripts": 4,
    "transcripts": [
      {
        "ticker": "TSLA",
        "title": "Yahoo Finance",
        "published_date": "Jan 28, 2026, 5:30 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/TSLA/earnings/TSLA-Q4-2025-earnings_call-393464.html",
        "content": "**Travis Axelrod** (Head of Investor Relations)\nGood afternoon, everyone, and welcome to Tesla's fourth quarter 2025 Q&A webcast. My name is Travis Axelrod, Head of Investor Relations, and I'm joined today by Elon Musk, Vaibhav Taneja, and a number of other executives. Our Q4 results were announced at about 3 P.M. Central Time in the update deck we published at the same link as this webcast. During this call, we will discuss our business outlook and make forward-looking statements. These comments are based on our predictions and expectations as of today. Actual events or results could differ materially due to a number of risks and uncertainties, including those mentioned in our most recent filings with the SEC. During the question and answer portion of today's call, please limit yourself to one question and one follow-up. Please use the Raise Hand button to join the question queue.\n\n**Travis Axelrod** (Head of Investor Relations)\nBefore we jump into Q&A, Elon has some opening remarks. Elon?\n\n**Elon Musk** (Co-Founder and CEO)\nThanks, Travis. So, we've updated the Tesla mission to amazing abundance, and this is intended to send a message of optimism about the future. I think we're most likely headed to an exciting, amazing era of abundance. And I think with the advent or with the continued growth of AI and robotics, I think we actually are headed to a future of universal high income. Not universal basic income, but universal high income. I mean, there's gonna be a lot of change along the way, but that is what I see as the most likely outcome. So I think that it makes sense to update Tesla's mission to reflect that goal.\n\n**Elon Musk** (Co-Founder and CEO)\nAnd obviously, along that way, we're going to keep improving safety, driving down the cost of goods, and getting people access to anything they need, without compromise. And still making sure that the environment is great, nature is great, and people can have whatever they want, which seems like probably the best future. So, I'm open to other ideas, but that sounds like it sounds like the best future you could possibly imagine. I guess it would be that everyone can have whatever they want, including amazing medical care, and but we still keep, you know, the beauty of nature and Earth. I think that's probably the best outcome.\n\n**Elon Musk** (Co-Founder and CEO)\nAnd we're seeing obviously the first steps along that way this year for Tesla, first major steps, as we increase vehicle autonomy and begin to produce Optimus robots at scale. We're making very, very big investments, so this is gonna be a very big CapEx year, as Vaibhav will get into. That is deliberate, because we're making big investments for an epic future. So I think all these investments make a lot of sense. We'll continue to make sure that when we do spend capital, it is spent very efficiently. But it's a lot of things. You know, major investments in batteries and the entire supply chain for batteries.\n\n**Elon Musk** (Co-Founder and CEO)\nSo, we're also gonna be significant manufacturers of solar cells, and we're making massive investments in AI chips. So, but I think these all make a ton of strategic sense. And then I guess I have, like, one... It's not like it's not exactly bad news, but it's a... it's time to basically bring the Model S and X programs to an end with an honorable discharge.\n\n**Elon Musk** (Co-Founder and CEO)\nBecause we're really moving into a future that is based on autonomy and so if you're interested in buying a Model S and X, now would be the time to order it, because we expect to wind down S and X production in next quarter and basically stop production of Model S and X next quarter. We'll obviously continue to support the Model S and X programs for as long as people have the vehicles, but we're gonna take the Model S and X production space in our Fremont factory and convert that into an Optimus factory, which will... with the long-term goal of having 1 million units a year of Optimus robots in the current S/X space in Fremont.\n\n**Elon Musk** (Co-Founder and CEO)\nSo that is slightly sad, but it is time to bring the S/X programs to an end and shift really, it's part of our overall shift to an autonomous future. As my profile picture on X said for a few months there, \"The future is autonomous.\" And so let's say with respect to Full Self-Driving and Robotaxi, people are obviously following with very close attention the progress of FSD, and you can experience it for yourself. If you've got a Tesla, you can notice, really, with every software update, the car gets better and better at autonomy.\n\n**Elon Musk** (Co-Founder and CEO)\nAnd we're, you know, we're able to do our first rides with no safety monitor in the car in Austin. These were paid rides, so these were just sort of randomly selected paid rides with no safety monitor. I think maybe as of maybe yesterday or so, we actually don't even have a chase car or anything like that. So these are just cars with no people in them, and no one's following the car in Austin. So we're obviously being very cautious about this 'cause we wanna have no injuries or serious accidents along the way.\n\n**Elon Musk** (Co-Founder and CEO)\nSo I think it makes sense to be very cautious, but you'll see the amount of autonomy increase dramatically, I think, every month, essentially. So and then there will also be an opportunity, something we've talked about for a long time, for existing owners of Teslas to add or subtract their cars to the fleet. Kinda like how Airbnb works, where you can add or subtract your house to the Airbnb inventory. And I think probably the value of the Tesla, the sort of partial people adding or subtracting their cars to Tesla autonomous fleet is probably a little underweighted by a lot of people 'cause we've got millions of cars with AI4 that can do this.\n\n**Elon Musk** (Co-Founder and CEO)\nSo, it's that, it might potentially provide an opportunity for a lot of customers to earn more by lending their car to the fleet than their lease cost to Tesla. Yeah, which is kind of... It's kinda like you get, in that scenario, you basically get paid to own a Tesla. It's quite a good scenario. And we expect to have fully autonomous vehicles in, you know, probably, I don't know, somewhere between a quarter and half of the United States by the end of the year, pending regulatory approval. You know, a big factor would be if there's some kind of federal preemption for autonomous vehicles.\n\n**Elon Musk** (Co-Founder and CEO)\nIn the absence of that, you kinda have to go on a city-by-city or state-by-state basis. But nonetheless, we even if it is city by city, state by state, we expect to be in, you know, I don't know, dozens of cities, dozens of major cities by the end of the year. With respect to energy, the Tesla energy team has done incredible work, and the growth rate on that work is continuing to be very strong. We're building more manufacturing capacity and expect that energy will have very high growth for really as far into the future as we can imagine. The solar opportunity is underestimated.\n\n**Elon Musk** (Co-Founder and CEO)\nWe think the best way to add significant capability to the grid is, or energy to the grid, let's say it's powering AI data centers, is solar and batteries on Earth and solar in space. So that's why we're gonna work towards getting 100 gigawatts a year of solar cell production, integrating across the entire supply chain, from raw materials all the way to finished solar panels. Maybe a bit more about Optimus. We'll probably unveil Optimus 3 in a few months. And I think it's gonna be quite surprising to people. It's an incredibly capable robot. And as I mentioned, we are replacing the S/X line in Fremont with a 1 million unit per year line of Optimus.\n\n**Elon Musk** (Co-Founder and CEO)\nNow, because it is a completely new supply chain, it's just, it's a... There's really nothing from the existing supply chain that exists in Optimus. Everything is designed from physics first principles. So that means, the normal S-curve of manufacturing ramp will be longer for Optimus than it is for products that have at least some portion of an existing supply chain. Like, when everything's new, the production rate will be proportionate to the least lucky, least confident part of the entire supply chain. And if there's 10,000 things that need to go right, it's, you know, it only takes one to be slow to lag that.\n\n**Elon Musk** (Co-Founder and CEO)\nBut, so it will be sort of a stretched out S-curve, but I'm confident that we'll get to 1 million units a year of, in Fremont, of, Optimus 3. And this Optimus really, really will be a general purpose robot that can learn by observing human behavior. So you can, like, demonstrate a task or literally verbally describe a task or show it a task, even show it a video, and it will be able to do that task. So it's a... It's gonna be a very capable robot. I think long-term, Optimus will have a very significant impact on the U.S. GDP. Like, it will actually move the needle on U.S. GDP significantly. So, in conclusion,...\n\n**Elon Musk** (Co-Founder and CEO)\nYou know, there's still obviously many who doubt our ambitions for creating amazing abundance, but we're confident it can be done, and that we're making the right moves technologically to ensure that it does. And Tesla's obviously not, never, never been a company to shy away from solving some of the hardest problems. You know, that it's, I think that's kind of how you build value in a company is you solve hard problems. It's like I don't know how you create value by solving easy problems. So there's a lot of hard problems that the Tesla team is gonna solve, but it's an incredibly talented, hardworking team. And I'd like to thank actually everyone at Tesla for their incredible hard work.\n\n**Elon Musk** (Co-Founder and CEO)\nIt's an honor to work with such a talented group. Thank you to everyone who is supporting this mission. The future is more exciting than you can imagine.\n\n**Travis Axelrod** (Head of Investor Relations)\nFantastic. Thank you so much, Elon. Next, we have some remarks from Vaibhav. Go ahead.\n\n**Vaibhav Taneja** (CFO)\nThanks, Travis. So Q4 2025 was an interesting quarter in a couple of respects. On the autos front, while in Q3, we saw a surge in U.S. demand before the higher consumer credit cliff, pulling in some demand from Q4. In other parts of the world, we saw increase in demand, leading to record deliveries in smaller countries like Malaysia, Norway, Poland, Saudi Arabia, and Taiwan, while continued strength in the rest of APAC and EMEA. We therefore ended 2025 with a bigger backlog than in recent years. Note that none of these countries have the latest version of FSD Supervised available yet. On the storage front, we had yet another record in terms of deployments. I would like to thank our customers and Tesla in continuing this momentum.\n\n**Vaibhav Taneja** (CFO)\nOn the automotive margins front, automotive margins, excluding credits, improved sequentially from 15.4% to 17.9%. The automotive gross profit was flat sequentially, despite 16% lower deliveries, primarily due to regional mix, as we had proportionately more deliveries in APAC and EMEA. As we look to 2026, with the progress that has been made with autonomy, our focus is on ramping production at all our factories. Our biggest constraint globally continues to be on the battery pack front. While our teams have been creative in trying to resolve the situation by now putting 4680 cells in non-structural packs, we continue to iterate improving things from here on. FSD adoption continued to improve in the quarter, reaching nearly 1.1 million paid customers globally. Of these, nearly 70% were upfront purchases.\n\n**Vaibhav Taneja** (CFO)\nIt is important to note that beginning this quarter, we are transitioning fully to a subscription-based model for FSD. Therefore, net additions to this figure will primarily be via subscription model and in the short term, will impact automotive margins. On the energy front, we achieved yet another record in terms of gross profit for the quarter and ended the year with nearly $12.8 billion in revenue at 26.6% year-over-year growth. This was the result of high deployments in all regions and continued strength and demand for both Megapack and Powerwall. As we look at 2026, our backlog remains strong, well-diversified globally, and we expect increasing deployments with the launch of Megapack 3 and Megablock. However, we expect margin compression from the increased low-cost competition, impacts to market from policy uncertainty, and the cost of tariffs.\n\n**Vaibhav Taneja** (CFO)\nServices and Others margin declined from 10.5% to 8.8%, primarily from higher employee-related costs for service centers as we start preparing for the ramp in activity from the growth in the fleet size. We did see a momentum in margin, we did see an improvement in margin from our Supercharging business, which is included within services and other. Additionally, note that our Robotaxi business-related costs, while not material, are also included within this. Given that this, we're still in the early phase of our fleet deployment and are still doing a lot of validation testing, the revenue and cost per mile metrics are not meaningful to discuss at the moment. Then on total gross margin front, you know, we ended the quarter with over 20.1%, something which we haven't achieved for over the last two years.\n\n**Vaibhav Taneja** (CFO)\nThis improvement came despite the impact of lower fixed cost absorption and the impact of tariffs, which were in excess of $500 million in Q4. Operating expenses increased sequentially, primarily from increased stock-based compensation for employees, and as we started recording charges on for one operational milestone under our 2025 CEO Performance Award, that was deemed to be probable over the award term. Additionally, our spend on AI-related initiatives and new products like Cybercab, Semi, Optimus, and Megapack, etc., continues to be on elevated levels, and we expect this trend to continue for the full year 2026. Net income was negatively impacted from mark-to-market charges on a Bitcoin holding, which depreciated 23% as compared to the last quarter, and, the impact of unfavorable impact of FX, primarily from our large intercompany borrowings.\n\n**Vaibhav Taneja** (CFO)\nOn the free cash flow front, we ended up at $1.4 billion. You know, we did end up CapEx being slightly below our previous guidance of $9 billion. But like, as Elon already mentioned, this year is going to be a huge investment year from a CapEx perspective. And at the moment, we are expecting that CapEx will be in excess of $20 billion. You know, we'll be paying for 6 factories, namely the refinery, LFP factory, Cybercab, Semi, a new Megafactory, the Optimus factory. On top of it, we'll also be spending money for building our AI compute infrastructure, and we'll continue investing in our existing factories to build more capacity, and then, you know, also the related infrastructure along with it. And we'll also further expand our fleet of Robotaxi and Optimus.\n\n**Vaibhav Taneja** (CFO)\nWhile this may seem a lot, we believe this is the right strategy to position the company for the next era, and we'll make such investments, as Elon mentioned, in a very capital-efficient manner. Note that this does not include potential investments in solar cell manufacturing or our Terafab, as we're still in early phase, and we plan to provide an update in future quarters. We're starting not the next chapter, but a new book on the progression of this company. 2026 year would be when all of this began. While at times it feels daunting, it is going to be the most exciting change in Tesla's history, and we could not have even dreamed of embarking on this journey without the support of our customers and our investors. Thanks for again showing the confidence in us, and let's get ready for a future of amazing abundance. Thanks.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much, Vaibhav. Now we're going to head over to investor questions. As always, we will start with questions from Say.com. The first question is, \"Today, today, there are approximately 90 million cars sold globally each year. Does Tesla have a view, based on its Robotaxi ambition, what this number will be in 5 or 10 years, and how does this impact Tesla's EV strategy to have more models?\n\n**Lars Moravy** (VP of Vehicle Engineering)\nYeah. Thanks, Travis. As Elon said, the future is autonomous, and obviously, autonomy and Cybercab are going to change the global market size and mix quite significantly. I think that's quite obvious. You know, general transportation is gonna be better served by autonomy, as it will be safer and cheaper, and over 90% of vehicle miles traveled are with two or less passengers now, which is why we designed Cybercab that way. In this new autonomous market, we at Tesla have the advantage of efficiency, cost, and manufacturing at scale that really no one else has, and we've built that over the last decades, and we believe that that segment that we are creating will grow millions year-over-year.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah. Just to add to what Lars said there, it's worth the point that Lars made, which is that 90% of miles driven are with one or two passengers, or one or two occupants, essentially, is a very important one. Because that implies that the Cybercab, which is a dedicated, you know, two-seater or dedicated Robotaxi. It's a little confusing with the terms Robotaxi and Cybercab. Sorry about the confusion, but... And in fact, in some states, we're not allowed to use the word cab or taxi, so it's gonna get even more strange. It's gonna be like Cyber vehicle or something, Cybercar.\n\n**Elon Musk** (Co-Founder and CEO)\nBut the Cybercab, which is a specific vehicle model that we're making, does not have a steering wheel or pedals. So this is clearly, you know, there's no fallback mechanism here. It's like this car either drives itself or it does not drive. And we expect to start production in April. As always, it's an S-curve of... The production rate is an S-curve, so starts off very slowly and then grows exponentially, then you hit the linear, and then ultimately, you know, it asymptotes at whatever your target volume is. So, but we would expect over time to make a far more Cybercabs than all of our other vehicles combined, given that 90% of distance driven or distance being-\n\n**Vaibhav Taneja** (CFO)\nTraveled.\n\n**Elon Musk** (Co-Founder and CEO)\n-distance traveled, exactly, no longer driving, is one or two people. I think it's like 80% is just one. So it would mean that long-term, Cybercab, we would make several times more Cybercabs per year than all of our other vehicles combined.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you so much. The next question, a bit related, \"Are there still plans to launch new models to address different price segments and vehicle types which could materially expand the TAM for Tesla?\n\n**Lars Moravy** (VP of Vehicle Engineering)\nYeah. To further on what we were just talking about, we've launched our least expensive models ever over the last few months and are continuing to expand that, those models globally. And over the last decade, we have continually brought down the cost of our vehicles without sacrificing range, performance, or premiumness, and we'll continue to do that, as Vaibhav said, investing in our factories, but these are all trade-offs of where we spend our time or money. And to Elon's point, just now, with Cybercab coming, we are aiming to bring that Tesla premium ride experience to our largest market yet. That could be 5 or 10 times our current levels of production. This new autonomous market, you have to start thinking about us as moving to providing transportation as a service more than the total-\n\n**Elon Musk** (Co-Founder and CEO)\nYes\n\n**Lars Moravy** (VP of Vehicle Engineering)\n... addressable market, for the purchased vehicles alone. Of course, we do have plans to have Robotaxis in various shapes and sizes, but obviously, Cybercab will be the grand majority of that volume.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah, the vast majority of miles traveled will be autonomous in the future. You know, I would say probably less than  I'm just guessing, but probably less than 5% of miles driven will be where somebody's actually driving the car themselves in the future. Maybe as low as 1%.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. The next question is, historically, Tesla has spoken about gross margin per model. Are there standalone gross margin targets for the current models, excluding the benefits for FSD sales?\n\n**Vaibhav Taneja** (CFO)\nYou know, we've talked about this with the previous two questions, but transportation, as we know, is changing, and I think we cannot keep applying the same framework from a car sales model to the future, what we are trying to do. So it has to be looked at it more holistically. You know, autonomy software will be the driver for growth from now on. And as we aim to maximize the global fleet, we've been laser-focused on COGS from our side to make sure, because that is something which we manage. So we will keep focusing on that, but I think we need to look at it from a different dimension.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah, like, this Cybercab, that is, the whole design of Cybercab was, it was to optimize the, the fully considered cost per mile, of autonomous driving. And you, you, you're-- it's a different design problem than if you're trying to design, cars for people who, who will be driving, versus being driven. And, and, and so, so Cybercab is, like, like I said, super optimized for, minimum cost per mile and, and also for a much higher duty cycle. So it, we, we would expect, Cybercab to be used, you know, probably 50 or 60 hours a week, instead of the 10 or 11 hours a week that, a, a driven vehicle is used.\n\n**Elon Musk** (Co-Founder and CEO)\nSo, you know, typically, people will might drive their car for an hour and a half a day on average, so it's like 10 hours per week out of 168. But I think an autonomous vehicle is likely to be used probably five times as often, which means that you need to design the vehicle for much more wear and tear per unit of time and much more resilience. It's more like a commercial truck that's in continuous operation or close to continuous operation. That's how you design an autonomous vehicle. So we will have larger vehicles than the Cybercab in the future that are designed for full autonomy.\n\n**Elon Musk** (Co-Founder and CEO)\nAnd we've actually shown pictures of this, and in fact, have shown prototypes, so this is not exactly a secret. In fact, we've given people rides in them. So, you know, we're not keeping this, hiding this light under a bushel here. You know, it's like, we're literally saying what we're gonna do and have said what we're gonna do for a while. So, you know, I really think long term, we would really, the only vehicles that we'll make will be autonomous vehicles, with the exception of the next generation Roadster, which we're hoping to debut in April. Hopefully. It's gonna be something out of this world.\n\n**Travis Axelrod** (Head of Investor Relations)\nFantastic. The next question we'd unfortunately have to skip because it's not related to Tesla, and we would like to remind folks who use the Say Platform to please focus these questions on Tesla. So, with that in mind, we're gonna move on to the next question, which is: What is the current bottleneck to increase robotaxi deployment and personal use unsupervised FSD? The safety and performance of the most recent models, is it the safety and performance of the most recent models, or is it people to monitor the robotaxis in-car or remotely, or is there some other blocker? I don't know, Ashok, if you wanted to kick off on this one.\n\n**Ashok Elluswamy** (VP of AI Software)\nYeah. We have scaled the robotaxi service that's available to customers over the last year in order to just learn the scaling problems without having to like wait for the unsupervised. Basically, I had two, two goals. One is, like, learn as much as possible from the fleet with the safety monitors, and secondly, be laser focused with the engineering team to solve the unsupervised FSD problem. I think we did both. Like, by the end of last year, we, you know, we had a long tail of issues that we were able to churn through, and then, in the last couple of weeks, we had started our unsupervised robotaxi service to public customers in Austin. I think some customers took rides last week, and also the service continues today without any rear car or something like that.\n\n**Ashok Elluswamy** (VP of AI Software)\nSeparately, we did scale the fleet size in the Bay Area and in Austin, and through that, we learned, you know, issues with charging and other issues that we would have seen once we sort of like scaled the unsupervised fleet. So both are happening in parallel. A variant of the software that's used for the robotaxi service was shipped to customers with V14, and customers saw a huge jump in performance, like a lot of, you know, happy feedback from customers. So, and since then, we have improved the software significantly as well. And customers will continue to see with their own software releases that the software is so good that, you know, they're like screaming to remove the tire monitoring software because they're bored inside the car too much.\n\n**Lars Moravy** (VP of Vehicle Engineering)\nAdding to that a little bit with what Ashok said about learning about our charging and service needs. You know, we're using our vast network of charging and service centers that really only Tesla has in this space to jumpstart our infrastructure build-out needs to get ahead of robotaxi and autonomous vehicle demand. And we expect that because of this network, we are the only company capable of scaling at the rate that is needed for the tsunami of autonomy that is coming.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Moving on to the next question. After the unveil of the Cybertruck, Elon stated that if it didn't sell well, Tesla would build a more conventional-looking pickup. How practical would it be to create this new design on the Cybertruck architecture, and could it be conveniently built on the existing production lines?\n\n**Lars Moravy** (VP of Vehicle Engineering)\nActually, in its segment, Cybertruck continues to be a leader and is selling more than any other electric truck out there, while our competition continues to pull back. But to the question itself, from a line standpoint, we always design our lines to be super flexible. We built 3 and Y on the same line. We built S and X on the same line, still, showing that we can do that. The Cybertruck line was designed in the same way and is one of our most fully ready-for-autonomy platforms.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah. But yeah, we will transition the Cybertruck line to just a fully autonomous line. And there's obviously a market there for cargo delivery, like you say, like localized cargo delivery within a city, within a few hundred miles, something like that. There's a pretty... There's a lot of cargo that needs to move locally within a city and an autonomous Cybertruck could be very useful for that.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Moving on to the next question. Regarding Optimus, could you share the current number of units deployed in Tesla factories and actively performing production tasks? What specific roles or operations are they handling, and how has their integration impacted factory efficiency or output?\n\n**Elon Musk** (Co-Founder and CEO)\nYeah, I mean, we're still very much at the early stages of Optimus. It's an R&D. It's still in the R&D phase. So, we have had Optimus do some basic tasks in the factory, but as we iterate on new versions of Optimus, we deprecate the old versions. And so it's not. I wouldn't say it's like. It's not in usage in our factories in a material way. It's more so that the robot can learn. We wouldn't expect to have, you know, any kind of significant Optimus production volume until probably the end of this year.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat, and-\n\n**Ashok Elluswamy** (VP of AI Software)\nAdding to it, like, Optimus Gen 3 is an awesome robot that-\n\n**Elon Musk** (Co-Founder and CEO)\nIt is awesome.\n\n**Ashok Elluswamy** (VP of AI Software)\nYeah, it's an awesome robot that minimizes any differences. It's basically, it looks like a human. People could be easily confused that it's a human. And this helps our strategy for the AI, too, because you can learn from how humans do these tasks, and it's very easy to teach the robot to do in the same way as opposed to previous robots.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah, I mean, I guess one thing I should say, like, is, you know, there's a lot of news of like, you know, various companies announcing layoffs and whatnot, but, you know, at our Tesla factory in Fremont, we actually expect to increase headcount over time, and to significantly increase output from our factories. So yeah, we don't have any layoff plans. We expect to actually increase headcount.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. The next question, similar to the other, autonomy questions, but slightly different. When is FSD going to be 100% unsupervised?\n\n**Elon Musk** (Co-Founder and CEO)\nWell, it is 100% unsupervised. FSD is 100% unsupervised. I mean, we obviously have cars operating with no one in them and no safety monitor and no follow car or anything like that in Austin right now. For customers, you know, we're being very, just very cautious with the rollout. I mean, with each successive version, as we prove it out and we make sure that there are no sort of unique issues in, you know, in particular cities, 'cause, like, sometimes you get, like, some very, you know, difficult intersection, and it'll be an intersection where a lot of humans have accidents, by the way.\n\n**Elon Musk** (Co-Founder and CEO)\nThere's, like, some pretty nutty intersections where there are a lot of humans make mistakes and have accidents in various cities. So we want to make sure that, you know, FSD can handle those unusual intersections. Like if you take L.A., for example, where Wilshire and Santa Monica combine is like there's about, I don't know, 20 traffic lights, and people are constantly having accidents there. So, you want to make sure that FSD can handle unique things in a particular city, so... And we're also just being paranoid about safety. But with each successful release of FSD, we will reduce the amount of driver monitoring that's needed, proportionate to the safety of the FSD build.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. As it relates to Robotaxi, what has surprised you about the rollout so far? We've talked about what's constrained the fleet expansion to date, but it appears there are 200 vehicles based on public tracking. Is that something that we can confirm?\n\n**Ashok Elluswamy** (VP of AI Software)\nI wouldn't say there's anything that, like, really surprised us, because, because we are a large fleet, we had all the metrics, so there was no sort of, sort of a surprise. It was just continued work to grind down on the long tail of issues, and that's what enabled us to launch the unsupervised service in Austin.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah, and I mean, in terms of Robotaxi vehicles carrying paid customers, I think we're well over 500 at this point between the Bay Area and Austin.\n\n**Ashok Elluswamy** (VP of AI Software)\nYeah, there's yeah, varying amounts of like vehicles, depending on the load, but yeah, you can have like more vehicles during like peak times and then like fewer vehicles in the off hours.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah. This will probably, you know, double every month type of thing. It's gonna, it's on an exponential curve.\n\n**Vaibhav Taneja** (CFO)\nI mean, one other thing, people forget that, you know, we've been deliberate on all this, in the sense that we have the supporting infrastructure already been in place, whether it's service centers, charging. Yes, we'll have to augment as the fleet grows, depending upon the density of where the demand is and whatnot, but it's not something like we just stumbled upon it, and we're starting to... We've been at it for years. Yes, not every city is designed the same way. Same thing, our infrastructure is also not the same in every city, but you have to give us credit that it's been a journey. And like Lars said, if there's some company which can do it, we've already been at it, so we should be able to deliver much better.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. The next question is about chase cars, which we already covered. So moving on to the last question, Elon, you've been spending significant personal time on Tesla's chip design.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah.\n\n**Travis Axelrod** (Head of Investor Relations)\nWhat was the forcing function behind this increased involvement? And do you think external chip sales will represent a significant portion of Tesla's valuation by the end of the decade?\n\n**Elon Musk** (Co-Founder and CEO)\nWell, I mean, I tend to spend time on whatever the most critical issue is for the company, and completing the AI5 chip design and having it be a great chip is arguably the number one most critical thing to get done, which is why I'm spending more time on that than currently anything else at Tesla. Spend pretty much every Saturday on this and a chunk of every Tuesday. So it's like a... You know, if I'm spending my Saturdays on something, it's gonna be something pretty important. I do think AI5 will be a very good chip, and I'm quite confident about the design at this point.\n\n**Elon Musk** (Co-Founder and CEO)\nAnd then AI6, which will follow that, it'll be aspirationally would follow that in under a year, will, will be yet another big leap beyond AI5. So I feel pretty good about our chip strategy right now. But in terms of selling it outside of Tesla, we first need to make sure we have enough chips for all of our vehicle production and all of our Optimus production. And then we will actually use the AI5 chips in our data centers. We already use the AI4 chips in our data centers. So when we do training, it's a combination of the AI4 chips and NVIDIA hardware, primarily that we do training with.\n\n**Elon Musk** (Co-Founder and CEO)\nSo, but you say by the end of the decade, I mean, it's like things are changing so fast that it's hard to imagine, like, what happens at the end of the decade. I mean, we might... I mean, when I look ahead at, say, what's the limiting factor for Tesla growth, if you go, say, three or four years out, I think it actually is chip production. Is there enough AI, okay, enough AI logic and enough AI, and enough memory, enough RAM for our volume?\n\n**Elon Musk** (Co-Founder and CEO)\nAnd right now, I see that as being the thing that probably limits our growth in three or four years, which probably would imply that we're not selling chips outside of Tesla, because we need them. And in fact, I think it's gonna make sense, and this is definitely gonna be a sort of a controversial thing, but I think Tesla needs to build a Terafab.\n\n**Elon Musk** (Co-Founder and CEO)\nYou know, I mentioned this at the shareholder meeting, but even when we look at the best case output of all of our key suppliers, and I'd say even they're beyond suppliers, they're like strategic partners, like Samsung, TSMC, and Micron, and we say, like: \"What's the most you could possibly make?\" Then it's not enough. So I think in order to remove the constraint, the probable constraint in three or four years, we are gonna have to build a Tesla Terafab, a very big fab that includes logic, memory, and packaging, domestically. And that's actually also gonna be very important to ensure that we are protected against any geopolitical risks.\n\n**Elon Musk** (Co-Founder and CEO)\nI think people may be underweighting some of the geopolitical risks that are gonna be a major factor in a few years. So, now, you know, a lot of people are like, \"That's crazy. Fabs are really hard.\" I'm like: \"Yes, I know fabs are really hard. I don't think they're easy.\" But,\n\n**Lars Moravy** (VP of Vehicle Engineering)\nWe do hard things.\n\n**Elon Musk** (Co-Founder and CEO)\nWe do a lot of hard things. You know, we didn't used to have car factories, that we didn't use to have battery cell factories or lithium refineries or, you know, Megapack factories or, you know, all these other things. We figured it out. So I think we-- if we don't do the Tesla Terafab, we're gonna be limited by supplier output of chips. And I think maybe memory is an even bigger limiter than AI logic. So you know, for example, we have chip supply deals with TSMC in Arizona and Samsung in Texas, but currently there are no advanced memory fabs at scale in the United States. There are zero, literally zero.\n\n**Elon Musk** (Co-Founder and CEO)\nHopefully, you know, Micron will have something going in a few years, because they're all headquartered in Idaho, you know, where they make a lot of potato chips, but they need to make computer chips, too. So, anyway, we're working with our strategic partners on the chip front, memory and logic, but I think we've got to also try our hand at building a large-scale fab that integrates logic, memory, and packaging. And if we don't do that, we're just gonna be fundamentally limited by supply chain, especially if there's some geo- in a worst-case geopolitical situation, it would be quite a severe situation. So I think -- quite frankly, it'd be crazy not to try the Terafab.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat.\n\n**Elon Musk** (Co-Founder and CEO)\nWe'll have a bigger announcement on this in the future.\n\n**Travis Axelrod** (Head of Investor Relations)\nAwesome. With that, we're gonna move on to analyst questions. The first analyst is Emmanuel from Wolfe Research. Emmanuel, please feel free to unmute yourself.\n\n**Emmanuel Rosner** (Managing Director and Senior Autos and Auto Tech Analyst)\nGreat. Thank you so much. It's Emmanuel Rosner from Wolfe Research. My first question is on the CapEx. You signal a pretty large increase to over $20 billion for this year. Was hoping to better understand where the investments are going. Any way of two-dimension for us, which of the product line or technologies account for the bulk of the increase? And also, do you view this as, like, one-time in nature, 2026, or I guess, how much of this is an ongoing level of high spending for a number of years? And then just finally, still on that, with that level of spending, you're going to be burning cash. How, what should we think about your cash balance or any other way to finance this?\n\n**Vaibhav Taneja** (CFO)\nYeah. So, yeah, Emmanuel, I tried to put this in my opening remarks, too, but I'll try and go a little bit deeper. There's about six factories which we are starting production in this year, so there's a lot of cash CapEx, which is going into that. Then, as we are trying to scale Optimus, we need a lot more compute, so we're putting more money towards compute as well.\n\n**Elon Musk** (Co-Founder and CEO)\nFor training.\n\n**Vaibhav Taneja** (CFO)\nFor training.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah.\n\n**Vaibhav Taneja** (CFO)\nThen we're also gonna be spending money to expand the capacity at, you know, at existing factories. On top of it, you know, just keep in mind that we're not-- none of these numbers, which I shared of $20 billion factor in anything to do with the solar fab or the semiconductor chip fab. Those would be, as Elon mentioned, would come later on. And you think your second part of your question was, is this one-off or would we expect more? I think we're getting into this investment phase because we have big aspirations. And when you look at it, some of these aspirations are, I call them as infrastructure play, especially if you have to do a chip fab and we have to do a solar cell manufacturing fab, those are infrastructure plays.\n\n**Vaibhav Taneja** (CFO)\nAnd that funding takes a little bit longer, and you would be in an investment cycle for a little bit longer. Initially, third part of your question was: How are we gonna fund it? Initially, obviously, we have over $44 billion of cash and investments on the books, so we'll use our internal resources, but there are ways where we can fund it, especially when we look at the robotaxi fleet, because, you know, anytime you have a consistent stream of cash flow, you can go and get money from the banks. And we have had conversations with banks about it, and that is something how we're gonna do it.\n\n**Vaibhav Taneja** (CFO)\nAnd then on the infrastructure play side, yeah, like I said, we don't have a number yet, but given that it's an infrastructure play, it's a longer tail, we will have to look at a little bit more in terms of how we fund it, whether it's through more debt or other means.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Our next question comes from, Andrew, from Morgan Stanley. Andrew, please feel free to unmute yourself.\n\n**Speaker 8** (Analyst)\nGreat. Thanks so much for taking the question. I just wanna start on the xAI investment that you guys announced today. You know, you talked about there being some collaboration, you know, between the companies. So I'm just hoping to get more information or if you're hoping that you could shed more light on what that looks like and maybe how the work xAI is doing can be leveraged at Tesla and vice versa?\n\n**Vaibhav Taneja** (CFO)\nYeah, I mean, if you looked at the disclosure, which we also put in there, we do talk about this is literally a furtherance of our Master Plan Four. And even today, if you look at Tesla vehicles, we are using Grok in there. And as we look at things, whether we can do it ourselves, yes, there are a lot of things which we can do ourselves, but if there are things which xAI can help accelerate our progress, then why should we not do that? And that is the reason why we've gone ahead with such an investment, because this is part of the strategic initiative. 'Cause as it is, if you remember, I talked about how many things which we are doing ourselves.\n\n**Vaibhav Taneja** (CFO)\nIf there are ways and means we can find efficient ways for others to help us, and xAI literally fits into that mold, so that's why we went ahead with it.\n\n**Elon Musk** (Co-Founder and CEO)\nWe just had, like, a lot of investors ask us to do this. There was, like, a lot of, you know, investor Tesla shareholders said, like, we should invest in xAI. So that's like, we're just doing what shareholders, like, asked us to do, pretty much. Grok will be, you know, I think, very helpful in, say, maximizing the efficiency of the management of a large autonomous fleet. So, I mean, if you've got a autonomous fleet that's, you know, in the future, 10 million vehicles or tens of millions of vehicles, then optimizing the efficient use of that fleet, Grok will be, I think, way, way better than any heuristic solution, or sort of manually managed solution.\n\n**Elon Musk** (Co-Founder and CEO)\nAnd if you say you're managing, say, a large team of Optimus robots to build a factory or build a refinery, you know, and, say, hypothetic, like a... This is a hypothetical example, a rare earth ore refinery, which we do desperately need in our, in, America. Then, you'd, you say, \"Well, who like, what's gonna organize, the Optimus robots to build that ore refinery?\" That would. You know, you need, kind of need a, an orchestra conductor. And so then Grok would be, kind of the orchestra conductor for the Optimus robots to build the, hypothetically, an, a rare. It might, it might not be hypothetical in the future. I'm just saying it's not, not currently in our plans.\n\n**Elon Musk** (Co-Founder and CEO)\nBut, you know, we do need a lot more ore refining capacity in the U.S. So then, what, what's gonna manage, let's say, 1,000 Optimus robots, to do-\n\n**Travis Axelrod** (Head of Investor Relations)\nYou're on mute right now, so I'm not sure if you're trying to ask a follow-up question. We're gonna move on to the next question, which is coming from Dan Levy at Barclays.\n\n**Dan Levy** (Senior Equity Research Analyst)\nGreat. Great, thank you. Elon, you talked about some of the constraints on memory. Given the very tight supply, are there any near-term constraints on procuring memory? And if there are, to what extent could you look at modifying the functionality in the vehicles, similar to what you did in 2021 when we saw shortages on MCUs, and maybe how are you thinking about bridging in the next few years?\n\n**Elon Musk** (Co-Founder and CEO)\nWell, the Tesla AI is very compute efficient and very memory efficient. You know, so I think one of the metrics one should consider for any given AI model is the intelligence per gigabyte. Especially when you're constrained on RAM, having an AI that has very high intelligence density per gigabyte. So you can say, like, whatlike, for a given number of gigabytes, how much functionality can you get out of it? I actually think Tesla is ahead of the rest of the world in intelligence density of AI by an order of magnitude or more.\n\n**Elon Musk** (Co-Founder and CEO)\nLike, this is gonna sound like a pretty bold statement, but I kind of know what the, you know, what the intelligence efficiency of the, of the big models are like Grok and, like, honestly, and you know, a bunch of the other models. And Tesla's AI is like, in terms of its memory efficiency, I think more than an order of magnitude better. So that puts us in a pretty good position, actually, for scaling. And we do think that there is. We do have a solution for logic and memory, for, let's say, the next roughly three years.\n\n**Elon Musk** (Co-Founder and CEO)\nBut if you start going beyond three years, and we look at the scaling plans, and how many fabs are getting built, and especially if you factor in geopolitical uncertainty, you know, there's always, there's always risk that, maybe the, those chips don't arrive, that people were expecting to arrive. So that's, that's why I think we, we need to have more fab capacity in the U.S., just in case, you know, chips don't stop arriving for any reason. But, you know, this, this is, this is really existential for, for Tesla, because, if... You know, Optimus is completely useless without an AI chip. It's not like- you know, at least the cars, we can put steering wheels and pedals in, or retrofit them if need be.\n\n**Elon Musk** (Co-Founder and CEO)\nBut, but Optimus is just a mannequin without, you know, it's like the Tin Man or whatever from The Wizard of Oz, but, but even worse, at least the Tin Man could walk. Optimus won't even be able to - it would just sit there without an AI chip. So we've got a good solution for a significant scale through, you know, for the next roughly three years. Beyond that, we will be supplier limited, and so we've got to figure out some game plan to not be supplier limited.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Our next question is gonna come from George at Canaccord. George, please feel free to unmute yourself.\n\n**Speaker 7** (Analyst)\nHi, everyone. Thank you for taking my question. So, yeah, there's been a surge of startups, particularly from China, entering the humanoid market, and just wondering what the long-term competitive advantages that keep Tesla ahead are, and how, based on what you've seen, will Optimus fundamentally differ from these competitors? Thank you.\n\n**Elon Musk** (Co-Founder and CEO)\nWell, I do think that by far the biggest competition for humanoid robots will be from China. China is incredibly good at scaling manufacturing. Actually quite good at AI, as you can see from, you know, the open source or not the open source, but the sort ofI guess some of them are open, actually. But basically, the models that China is distributing for free are actually quite good, and they keep getting better. So China is very good at AI, very good at manufacturing, and will definitely be the toughest competition for Tesla. To the best of our knowledge, we don't see any significant competitors outside of China. But China will definitely be tough competition.\n\n**Elon Musk** (Co-Founder and CEO)\nThere's no two ways about it. So, I always think, like, people sort of outside of China kind of underestimate China. China's an ass kicker next level. So, you know, I guess, you know, we're gonna build. We think Optimus will be much more capable than any robot that we are aware of under development in China. So we think we'll be ahead in terms of the real-world intelligence, the electromechanical dexterity, especially the hand design, which is by far the hardest thing in the robot. And in fact, I'd say there's really three hard things about humanoid robots.\n\n**Elon Musk** (Co-Founder and CEO)\nBuilding an incredible hand that has the same degrees of freedom and dexterity as a human hand is an incredibly difficult engineering challenge. Then there's the real-world AI and scaling production. Those are the three hardest problems by far for humanoid robots. I think Tesla is the only company that actually has all three of those components. So yeah.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. And our last question is gonna come from Colin, at Oppenheimer. Colin, please feel free to unmute yourself.\n\n**Speaker 9** (Analyst)\nThanks so much. Guys, you know, you talked a lot about the CapEx spend, but, you know, this is an incredibly ambitious technology development program that you're talking about. Can you talk a little bit about the R&D spend and how you're thinking about the synergies of the different components, you know, particularly on the hardware side? You know, if you think about, you know, batteries into chips into memory, and the efficiency of the system, and what sort of advantages you think you'll end up getting out of, you know, some of these purpose-built devices that you'll end up integrating into multiple end markets?\n\n**Elon Musk** (Co-Founder and CEO)\nWell, really what we're trying to do is make sure that we can scale to very high volume with autonomous vehicles, with humanoid robots, and that we address geopolitical risk. Which I think, you know, there's so many companies out there that are asleep at the switch with regard to geopolitical risk. They're like... or they just have their head in the sand and hope nothing bad will happen. I'm way more paranoid than that. I always think of Andy Grove's famous statement, \"Only the paranoid survive.\" You know, why did he come up with that statement at Intel? Hmm, let's think. So I think there's a lot of wisdom in that statement.\n\n**Elon Musk** (Co-Founder and CEO)\nSo we're gonna be paranoid and make sure that we can continue to build batteries and robots and AI chips no matter what happens. And companies that don't do that, a bunch of them will cease to exist.\n\n**Vaibhav Taneja** (CFO)\nYeah, I mean, remember, all this comes out of necessity. It's not that we want to do it-\n\n**Elon Musk** (Co-Founder and CEO)\nYeah\n\n**Vaibhav Taneja** (CFO)\nit's just we have, we have no choice.\n\n**Elon Musk** (Co-Founder and CEO)\nYeah, I mean, we built the most advanced lithium refinery in the world, by the way. So it's not just... Like, our lithium refinery in Corpus Christi is not just a copy of what others have done. It's an entirely new process that is fundamentally more efficient and more advanced than anything else in the world. The same is true of our cathode refinery here in Austin. And we wish others would build this. Can other people please, for the love of God, -\n\n**Vaibhav Taneja** (CFO)\nHelp\n\n**Elon Musk** (Co-Founder and CEO)\nin the name of all that is holy, can others please build this, build this stuff?\n\n**Lars Moravy** (VP of Vehicle Engineering)\nIt's not the first time you asked.\n\n**Vaibhav Taneja** (CFO)\nExactly. I mean, this is not the first time you've said something like this.\n\n**Elon Musk** (Co-Founder and CEO)\nLike, why do we have to build these things? Why can others not also please, can someone else build these things? Well, I mean, this is a, it's very hard to build these things. And we build them out of desperation, not because nobody else is building lithium refineries and cathode refineries. You know, we're pretty much the largest, not just the largest, but also the only lithium refinery and cathode refinery in America. So, yeah. So we're making moves to make sure that no matter what happens, Tesla will prosper.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Unfortunately, that's all the time we have for Q&A today. We really appreciate everyone's questions, and we look forward to talking to you next quarter. Thank you very much, and goodbye.\n\n**Elon Musk** (Co-Founder and CEO)\nVery cool.",
        "fetched_at": "2026-02-04T16:12:29.147Z"
      },
      {
        "ticker": "TSLA",
        "title": "Yahoo Finance",
        "published_date": "Oct 22, 2025, 5:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/TSLA/earnings/TSLA-Q3-2025-earnings_call-366307.html",
        "content": "**Travis Axelrod** (Head of Investor Relations)\nGood afternoon, everyone, and welcome to Tesla's third quarter 2025 Q&A webcast. My name is Travis Axelrod, Head of Investor Relations, and I'm joined today by Elon Musk, Vaibhav Taneja, and a number of other executives. Our Q3 results were announced at about 3:00 P.M. Central Time in the update deck we published at the same link as this webcast. During this call, we will discuss our business outlook and make forward-looking statements. These comments are based on our predictions and expectations as of today. Actual events or results could differ materially due to a number of risks and uncertainties, including those mentioned in our most recent filings with the SEC. We urge shareholders to read our definitive proxy statement, which contains important information about the matters to be voted on at the 2025 annual meeting.\n\n**Travis Axelrod** (Head of Investor Relations)\nDuring the question and answer portion of today's call, please limit yourself to one question and one follow-up. Please use the raise hand button to join the question queue. Before we jump into Q&A, Elon has some opening remarks. Elon?\n\n**Elon Musk** (CEO)\nThank you. We're at a critical inflection point for Tesla and our strategy going forward as we bring AI into the real world. I think it's important to emphasize that Tesla really is the leader in real-world AI. No one can do what we can do with real-world AI. I have pretty good insight into AI in general. I think that Tesla has the highest intelligence density of any AI out there in the car, and that is only going to get better. We're really just at the beginning of scaling quite massively Full Self-Driving and robotaxi and fundamentally changing the nature of transport. I think people just don't quite appreciate the degree to which this will take off. Honestly, it's going to be like a shock wave. The cars are all out there.\n\n**Elon Musk** (CEO)\nThere are, you know, we have millions of cars out there that, with a software update, become Full Self-Driving cars. You know, we're making a couple million a year. In fact, with the advent of what we see now as a clarity on achieving Full Self-Driving, unsupervised Full Self-Driving, I should say, I feel confident in expanding Tesla's production. That is our intent to expand as quickly as we can our future production. I was reticent to do that until we had clarity on achieving unsupervised Full Self-Driving. At this point, I feel like we've got clarity and it makes sense to expand production as fast as we reasonably can. We're also making a huge impact on the energy sector with battery storage. With both the Powerwall and especially with the Megapack, we are dramatically improving the ability to generate more energy from the grid.\n\n**Elon Musk** (CEO)\nLet me sort of talk a little bit about that, which is if you look at total U.S. energy capability, for example, there's roughly a terawatt of continuous power available in the U.S. The average usage over a 24-hour cycle is only half a terawatt because of the big difference between day and night usage. If you buffer the energy with batteries, you can effectively double the energy output in the United States just with batteries building no incremental power plants. It's very difficult to build power plants. They take a long time. There's a lot of permitting. It's not an industry that's used to moving fast. We see the potential there for Tesla battery packs to greatly improve the energy output per year for any given grid, U.S. or otherwise.\n\n**Elon Musk** (CEO)\nWe're also on the cusp of something really tremendous with Optimus, which I think is likely to be, or has potential to be, the biggest product of all time. It's a difficult project. It's worth noting that it's not like it's just automatic. I'm unaware of any robot program by Ford or GM or any of our U.S. sort of car companies. People, I think, maybe think of Tesla as a car company. We mostly make cars and battery packs. It's not just like an obvious fall-off-a-log thing to make Optimus. We do have the ingredients of real-world AI and exceptional electrical and mechanical engineering capabilities and the ability to scale production, which I don't think anyone else has all of those ingredients. With version 14 of self-driving, people, you can see the reactions of people online. They're quite amazed. Actually, anyone in the U.S.\n\n**Elon Musk** (CEO)\ncan get version 14 if they just go and select, \"I want the advanced software\" in their car. If you're listening right now and you'd like to try it out, just go in settings and say, \"I want the advanced software,\" and you will get version 14. On the Megapack front, we unveiled Megablock, Megapack 3. We also have exciting plans for Megapack 4. Megapack 4 will incorporate a lot of what is normally in a substation and be able to output at probably 35 kilovolts directly. This greatly improves our ability to deploy Megapack because it's not dependent on building a substation of 335 kV for Megapack 4. That'll be the engineering priority for Megapack. We look forward to unveiling Optimus V3, probably in Q1. I think it'll be ready for it to show off. That, I think, is going to be quite remarkable.\n\n**Elon Musk** (CEO)\nIt won't even seem like a robot. It'll seem like a person in a robot suit, which is kind of how we started off with Optimus. It'll seem so real that you'll need to like poke it, I think, to believe that it's actually a robot. Obviously, the real-world intelligence we've developed for the car, most of that transfers to Optimus. It's a very good starting point. In conclusion, we're excited about the updated mission of Tesla, which is sustainable abundance. Going beyond sustainable energy to say sustainable abundance is the mission, where we believe with Optimus and self-driving that you can actually create a world where there is no poverty, where everyone has access to the finest medical care. Optimus will be an incredible surgeon, for example. I'd imagine if everyone had access to an incredible surgeon.\n\n**Elon Musk** (CEO)\nI think there's, you know, of course, we need to make sure Optimus is safe and everything. I do think we're headed for a world of sustainable abundance. I'm excited to work with the Tesla team to make that happen.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much, Elon. Vaibhav also has some opening remarks.\n\n**Vaibhav Taneja** (CFO)\nThanks, Travis. Q3 was a special quarter at multiple levels. We set new records not just for deliveries and deployments, but also around a range of financial metrics from total revenues, energy gross profit, energy margins, to fresh free cash flow. This was the result of continued confidence of our customers in our products and the relentless efforts by the Tesla team. The strength in deliveries was attributed to strong performance across all regions. Greater China and APAC were up sequentially 33% and 29% respectively. North America was up 28%, while EMEA was up 25%. The pace in deliveries was the function of continued excitement around the new Model Y.\n\n**Vaibhav Taneja** (CFO)\nWe had previously talked about 2025 being the year of the Y and have since delivered on that promise with the new Model Y released in Q1, followed by Model Y long-wheelbase and performance, and more recently, Standard Y in North America and EMEA. We're now operating our robotaxi in two markets, Austin and most Bay Area cities. We've already expanded our coverage area in Austin three times since the initial launch and are on pace to continue expanding further. Unlike our competitors, our robotaxi fleet blends in the markets we operate in since they don't have extra sensor sets or peripherals which make them stick out. This is an underappreciated aspect of our current vehicle offerings, which are all designed for autonomous driving. We feel that as people experience the supervised FSD at scale, the demand for our vehicles, like Elon said, would increase significantly.\n\n**Vaibhav Taneja** (CFO)\nOn the FSD adoption front, we've continued to see decent progress. However, note that total paid FSD customer base is still small, around 12% of our current fleet. We're working with regulators in places like China and EMEA to obtain approvals so that we can get FSD in those regions as well. Now, covering a little bit on the financial side, automotive revenues increased 29% sequentially in line with the growth in deliveries. While regulatory credits declined sequentially, we entered into new contracts and continued delivery on previously entered contracts. Our automotive margins, excluding credits, increased marginally from 15% to 15.4%, which was attributed to improvements in material cost and better fixed cost absorption due to higher volumes. The energy storage business continued to deliver with record deployments, gross profit, and margins.\n\n**Vaibhav Taneja** (CFO)\nAs discussed before, this business has a bigger impact from tariffs, as measured by a percentage of COGS, since currently all sales procured are from China, while we're still working on other alternatives. However, as the ramp-up of Mega Factory Shanghai is happening, this is helping us avoid tariffs because we are using this factory to supply the non-U.S. demand. Like Elon said, you know, grid-scale storage, the only way we can get to electricity fastest is by using storage. The other thing to keep in mind is we are seeing headwinds in this business given the increase in competition and tariffs. The total tariff impacts for Q3 for both businesses were in excess of $400 million, generally split evenly between them. Services and other demonstrated a marked improvement sequentially. This was a function of improvements primarily in our insurance and service center businesses.\n\n**Vaibhav Taneja** (CFO)\nNote that while small, our robotaxi costs are included within services and other, along with our other businesses like paid Supercharging, used car, parts and merchandise sales, etc. Our operating expenses increased sequentially. The largest increase included in restructuring and other related to certain actions undertaken to reduce cost and improve efficiency through convergence of our AI chip design efforts. Additionally, we incurred legal expenses related to proceedings in certain legal cases, as well as incremental costs incurred in preparation for our shareholder meeting. Such costs are recorded within SG&A. Further, our employee-related spend is increasing, especially in R&D, as we have recently granted various performance-based equity awards to employees working on AI initiatives, and therefore such spend will continue to increase going forward.\n\n**Vaibhav Taneja** (CFO)\nOur other income decreased sequentially, primarily from mark-to-market adjustments on BTC holdings, which was a much smaller gain of $80 million in Q3 versus $284 million in Q2, with the rest of the movement attributable to FX movements in the quarter. Our free cash flow for the quarter was approximately $4 billion, which was yet another record. Our total cash and investments at the end of the quarter were over $41 billion. On the CapEx front, while we are expecting to be around $9 billion for the current year, we're projecting the numbers to increase substantially in 2026 as we prepare the company for the next phase of growth in terms of not just our existing businesses, but our bets around AI initiatives, including Optimus. In conclusion, note that bringing AI into the real world is hard, but we have never shied away from doing what is hard.\n\n**Vaibhav Taneja** (CFO)\nWe are extremely excited about the future and are laying down the foundation, the benefits of which will be realized over years to come. I would like to end by thanking the Tesla team, our customers, our investors, and supporters for the continued belief in us.\n\n**Travis Axelrod** (Head of Investor Relations)\nThank you very much, Vaibhav. Now let's go to investor questions. From say.com, the first question is, what are the latest robotaxi metrics, fleet size, cumulative miles, rides completed, intervention rates, and when will safety drivers be removed? What are the obstacles still preventing unsupervised FSD from being deployed to customer vehicles?\n\n**Elon Musk** (CEO)\nI'll start off with that, and then Ashok can elaborate. We are expecting to have no safety drivers in at least large parts of Austin by the end of this year. Within a few months, we expect to have no safety drivers at all, at least in parts of Austin. We're obviously being very cautious about the deployment. Our goal is to be actually paranoid about deployment because obviously even one accident will be front-page headline news worldwide. It is better for us to take a cautious approach here. We do expect to have no safety drivers in the car in Austin within a few months. I think that's perhaps the most important data point. We do expect to be operating robotaxi in, I think, about eight to ten metro areas by the end of the year. It depends on various regulatory approvals.\n\n**Elon Musk** (CEO)\nYou can actually, I think, most of our regulatory applications are online. You can kind of see them because they're public information. We expect to be operating in Nevada and Florida and Arizona by the end of the year. Ashok?\n\n**Ashok Elluswamy** (VP of Autopilot and AI Software)\nYeah. We continue to operate our fleet in Austin without anyone in the driver's seat, and we have covered more than a quarter million miles with that. In the Bay Area, where we still have a person in the driver's seat because of the regulations, we cross more than a million miles. We continue to see that the robotaxi fleet works really well. Customers are really happy, and there's no notable issues. On the customer side, customers have used Full Self-Driving supervised for a total of six billion miles as of yesterday. That's a big milestone. Overall, the safety continues to be very good. As Elon mentioned, we are on track to remove the person from inside the car altogether, starting with Austin.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. The next question is, what is the demand and backlog for Megapack, Powerwall, solar, or energy storage systems? With the current AI boom, is Tesla planning to supply power to other hyperscalers?\n\n**Mike Snyder** (VP of Energy and Charging)\nThanks. Demand for Megapack and Powerwall continues to be really strong into next year. We received very strong positive customer feedback on our Megapack product, which will begin shipping next year out of Houston. We're seeing remarkable growth in the demand for AI and data center applications as hyperscalers and utilities have seen the versatility of the Megapack product to increase reliability and relieve grid constraints, as Elon was talking about. We've also seen a surge in residential solar demand in the U.S. due to policy changes, which we expect to continue into the first half of 2026 as we introduce a new solar lease product. We also began production of our Tesla residential solar panel in our Buffalo factory, and we will be shipping that to customers starting Q1. The panel has industry-leading aesthetics and shade performance and demonstrates our continued commitment to U.S. manufacturing.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you, Mike. Unfortunately, the next question is related to future products. This is not the appropriate venue to cover that, so we're going to have to skip it. The question after that is, what are the present challenges in bringing Optimus to market, considering app control software, engineering hardware, training general mobility models, training task-specific models, training voice models, implementing manufacturing, and establishing supply chains?\n\n**Elon Musk** (CEO)\nYeah, I mean, bringing Optimus to market is an incredibly difficult task, to be clear. It's not like some walk in the park at some point. I mean, actually, technically, Optimus can walk in the park right now. We do have Optimus robots that walk around our offices at our engineering headquarters in Palo Alto, California, basically 24 hours a day, seven days a week. Any visitors that come by, you actually can stop one of the Optimus robots and ask it to take you somewhere, and it'll literally take you to that meeting room or that location in the building. I don't want to downplay the difficulty of Optimus. It's an incredibly difficult thing. Especially, it's difficult to create a hand that is as dexterous and capable as the human hand, which is an incredible... The human hand is an incredible thing.\n\n**Elon Musk** (CEO)\nThe more you study the human hand, the more incredible you realize the human hand is and why you need four fingers and the thumb, why the fingers have certain degrees of freedom, why the various muscles are of different strengths, and the fingers are of different lengths. It turns out, actually, that those are all there for a reason. Making the hand and forearm, because most of the actuator, just like the human hand, the muscles that control your hand are actually primarily in your forearm. The Optimus hand and forearm is an incredibly difficult engineering challenge. I'd say it's more difficult than the rest of... From an electromechanical standpoint, the forearm and hand are more difficult than the entire rest of the robot. Really, in order to have a useful generalized robot, you do need an incredible hand. You need the real-world AI.\n\n**Elon Musk** (CEO)\nYou need to be able to scale up that production to have it be relevant, because it's not relevant if it's just a few hundred robots. You need to be able to make Optimus robots at volumes comparable to vehicles, if not significantly higher. If you're trying to make a million or something per year, trying to make a million Optimus robots per year, that manufacturing challenge is immense, considering that the supply chain doesn't exist. With cars, you've got an existing supply chain. With computers, you've got an existing supply chain. With a humanoid robot, there is no supply chain. In order to manufacture that, Tesla actually has to be very vertically integrated and manufacture very deep into the supply chain, manufacture the parts internally, because there just is no supply chain.\n\n**Elon Musk** (CEO)\nThis is the kind of thing where I'm like, if I put myself in the position of a startup trying to make a humanoid robot, I'm like, I don't know how to do it without an immense amount of manufacturing technology. That's why I think Tesla is in almost a unique, I think, unique position when you consider manufacturing technology, scaling, real-world AI, and a truly dexterous hand. Those are generally the things that are missing when you read about other robots that just don't have those three things. I think we can achieve all those things, those three things, with an immense amount of work. That is the game plan. My fundamental concern with regard to how much voting control I have at Tesla is, if I go ahead and build this enormous robot army, can I just be ousted at some point in the future?\n\n**Elon Musk** (CEO)\nThat's my biggest concern. That is really the only thing I'm trying to address with this. It's called compensation, but it's not like I'm going to go spend the money. It's just, if we build this robot army, do I have at least a strong influence over that robot army? Not control, but a strong influence. That's what it comes down to in a nutshell. I don't feel comfortable building that robot army if I don't have at least a strong influence.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you. We've already covered robotaxi expansion. Unfortunately, the question after that is another future product question, so we're going to have to skip that. The next one, though, is, can you update us on the $16.5 billion Samsung chip deal in Taylor? Given the importance of semiconductors to autonomy in Tesla's AI-driven future, what gives you confidence Samsung can fulfill AI5 at Tesla's timelines and achieve relatively better yields and cost versus TSMC?\n\n**Elon Musk** (CEO)\nOkay, so I'm going to give quite a long answer to this question because I have to unpack this question and then answer the unpacked version. First of all, I have nothing but great things to say about Samsung. They're an amazing company. Samsung, it is worth noting, does manufacture our AI4 computer and does a great job doing that. Now with the AI5, I need to make a point of clarification relative to some comments I've made publicly before, which is we're actually going to focus both TSMC and Samsung initially on AI5. The AI5 chip design by Tesla is, I think it's an amazing design. I've spent almost every weekend for the last few months with the chip design team working on AI5. I don't hand out praise easily, but I have to say that I think the Tesla chip team is really designing an incredible chip here.\n\n**Elon Musk** (CEO)\nBy some metrics, the AI5 chip will be 40 times better than the AI4 chip. Not 40%, 40 times. Because we have a detailed understanding of the entire software and hardware stack, we're designing the hardware to address all of the pain points in software. I don't think there really is anyone that's doing this, the entire stack, all the way through real world, calibrating against the real world where you've got cars and robots in real world. We know what the chip needs to do, and just as importantly, we know what the chip doesn't need to do. To give you some examples here, with the AI5, we deleted the legacy GPU or the traditional GPU, which is in AI4. AI5 does not have, we just deleted the legacy GPU because it basically is a GPU. We also deleted the image signal processor.\n\n**Elon Musk** (CEO)\nThere's a long list of deletions that are very important. As a result of these deletions, we can actually fit AI5 in a half radical and with good margin for the traces from the memory to the chip, the Tesla chip accelerators, the ARM CPU cores, and the PCI blocks. This is a beautiful chip. I've poured so much life energy into this chip personally. I'm confident this is going to be a winner, next level. It makes sense to have both Samsung and TSMC focus on AI5. Technically, the Samsung fab has slightly more advanced equipment than the TSMC fab. These will both be made in the U.S., one TSMC in Arizona, Samsung in Texas. We're going to make, starting off, just to be confident of having our goal, explicit goal is to have an oversupply of AI5 chips.\n\n**Elon Musk** (CEO)\nBecause if we have too many AI5 chips for the cars and robots, we can always put them in the data center. We already use AI4 for training in our data center. We use a combination of AI4 and NVIDIA hardware. We're not about to replace NVIDIA, to be clear, but we do use both in combination, AI4 and NVIDIA hardware. The AI5 excess production, we can always put in our data centers. NVIDIA keeps improving. The challenge that they have is that they've got to satisfy a large range or a lot of requirements from a lot of customers. Tesla only has to satisfy requirements from one customer. That's Tesla. That makes the design job radically easier and means we can delete a lot of complexity from the chip. I can't emphasize how important this is.\n\n**Elon Musk** (CEO)\nWhen you look at the various logic blocks in the chip, as you increase the number of logic blocks, you also increase the interconnections between the logic blocks. You can think of it like just highways, like how many highways do you need to connect the various parts of the chip? Especially if you're not sure how much data is going to go between each logic block on the chip, you kind of end up having giant highways going all over the place. It becomes an almost impossibly difficult design problem. NVIDIA has done an amazing job of dealing with almost an impossibly difficult set of requirements. In our case, we're going for radical simplicity.\n\n**Elon Musk** (CEO)\nThe net effect is that I think AI5 will be the best performance per watt, maybe by a factor of two or three, and the best performance per dollar for AI, maybe by a factor of 10. The proof's in the pudding. Obviously, we need to actually get this chip made and made at scale. That's what it looks like.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you, Elon. We've already covered unsupervised FSD. The next question is, instead of trying to replace hardware three with hardware four, why not give an equal incentive to trade in for a new vehicle?\n\n**Vaibhav Taneja** (CFO)\nYeah, we've not completely given up on Hardware 3. However, over the last year, we've offered the customers the option to transfer Full Self-Driving to their new vehicle, which at times we've been running some promotions. If they got Full Self-Driving, they can get better preferential rates. We've been definitely taking care of this, but we do want to solve autonomy first. We will come back with a way to take care of these customers. These customers are very important. They were the early adopters. For what it's worth, my daily commuter is a Hardware 3 car, which I use Full Self-Driving on a daily basis. We will definitely take care of you guys.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you.\n\n**Ashok Elluswamy** (VP of Autopilot and AI Software)\nOnce the V14 release series is fully done, we are planning on working on a V14 Lite version for Hardware 3, probably expected in Q2 next year.\n\n**Travis Axelrod** (Head of Investor Relations)\nAwesome. Thanks, Ashok. All righty. Our final question from Say is, how long until we see self-driving Tesla semi-trucks? Could you see this technology replacing trains?\n\n**Travis Axelrod** (Head of Investor Relations)\nYeah, I guess I'll start with that in terms of the semi-production plan and schedule. The factory is going on schedule. We've completed the building and are installing the equipment now. We've got our fleet of validation trucks driving on the road. We'll have larger builds towards the end of this year and then our first online builds in the first part of next year, ramping into the Q2 timing with real volume coming in the back half of the year. That's going quite well. That's the first step to obviously getting autonomous trucks on the road. In terms of trains, you know they're really great for long point-to-point deliveries. They're super efficient, but you know that last mile, the load unload, can be better served for shorter distances with autonomous semis, and that would be great.\n\n**Travis Axelrod** (Head of Investor Relations)\nWe do expect that to probably shift as we, you know really, as Elon said, change the way transportation is considered. We're looking forward to that timeline. Ashok, I know you can take the Full Self-Driving part.\n\n**Ashok Elluswamy** (VP of Autopilot and AI Software)\nCurrently, the team is like super focused on solving for passenger vehicle autonomy. That said, the same technology will extend quite easily to the semi-truck once we have a little bit of data from the semi-trucks.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. We will move over to analyst questions. The first question comes from Emmanuel at Wolfe. Emmanuel, please go ahead and unmute yourself.\n\n**Emmanuel Rosner** (Managing Director and Senior Autos and Auto Tech Analyst)\nGreat. Thanks so much. Hi, everybody. Elon, you talked about expanding production of vehicles as fast as possible now that you have confidence in the unsupervised autonomy. How should we think about that in the context of your existing capacity of 3 million units? Is that where you're hoping to get volume to? What sort of timeline are we talking about? Would this require some level of boosting or incentivizing demand? Would this basically be prioritizing volume over near-term profitability given the longer-term opportunity?\n\n**Elon Musk** (CEO)\nOur capacity isn't quite 3 million, but it will be 3 million at some point. Aspirationally, it could be 3 million within... We could probably hit an annualized rate of 3 million within 24 months, I think. Maybe less than 24 months. Bearing in mind, there is an entire supply chain, like a vast supply chain that's got to also move in tandem with that. We are going to expand production as fast as we can and as fast as our suppliers can sort of keep up with it. We've got to think about where we build incremental factories beyond that. The single biggest expansion in production will be the Cybercab, which starts production in Q2 next year. That's really a vehicle that's optimized for full autonomy.\n\n**Elon Musk** (CEO)\nIt, in fact, does not have a steering wheel or pedals and is really an engineering optimization on minimizing cost per mile, fully considered cost per mile of operation. For our other vehicles, they still have a little bit of the horseless carriage thing going on where, obviously, if you've got steering wheels and pedals and you're designing a car that people might want to go very fast acceleration and tight cornering, like high-performance cars, then you're going to design a different car than one that is optimized for a comfortable ride, but doesn't expect to go past sort of 85 or 90 miles an hour. It is just aiming for a gentle ride the whole time. That's what Cybercab is. Do I think we'll sacrifice margins? I don't think so. I think the demand will be pretty nutty.\n\n**Elon Musk** (CEO)\nHere's the killer app, really, what it comes down to is can you text while you're in the car? If you tell someone, yes, the car is now so good, you can be on your phone and text the entire time while you're in the car. Anyone who can buy the car will buy the car, end of story. That's what everybody wants to do. In fact, not everyone wants to do it. They do do that. The reason you've seen that there's been an uptick in accidents pretty much worldwide is because people are texting and driving. Autopilot actually dramatically improves the safety here because if somebody's looking down at their phone, they're not driving very well. That's really the game changer.\n\n**Elon Musk** (CEO)\nYou know, we do see, at this point, I feel, essentially 100% confident, I say not essentially, 100% confident that we can solve unsupervised Full Self-Driving at a safety level much greater than human. We've released 14.1. We've got a technology roadmap that's, I think, pretty amazing. We'll be adding reasoning to the car. Our world simulator for reinforcement learning is pretty incredible. When you see the Tesla reality simulator, you can't tell the difference between the video that's generated by the Tesla reality simulator and the actual video. It looks exactly the same. That allows us to have a very powerful reinforcement learning loop to further improve the Tesla AI. We're going to be increasing the parameter count by an order of magnitude. That's not in 14.1. There are also a number of other improvements to the AI that are quite radical.\n\n**Elon Musk** (CEO)\nThis car will feel like it is a living creature. That's how good the AI will get with the AI4 computer. This is before AI5. AI5, like I said, is by some metrics 40 times better. Let's just say safely it's a 10x improvement. It might almost be too much intelligence for a car. I do wonder how much intelligence should you have in a car. It might get bored. Actually, one of the things I thought, if we've got all these cars that maybe are bored, while they're sort of, if they are bored, we could actually have a giant distributed inference fleet and say, if they're not actively driving, let's just have a giant distributed inference fleet.\n\n**Elon Musk** (CEO)\nAt some point, if you've got tens of millions of cars in the fleet, or maybe at some point 100 million cars in the fleet, and let's say they had at that point, I don't know, a kilowatt of inference capability, of high-performance inference capability, that's 100 gigawatts of inference distributed with power and cooling taken, with cooling and power conversion taken care of. That seems like a pretty significant asset.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thanks, Elon. The next question comes from Adam from Morgan Stanley. Adam, please feel free to unmute yourself. Adam, go ahead and ask your question. Seems like we might be having some audio issues with Adam. We'll come back to you. The next question will then come from Dan from Barclays.\n\n**Dan Levy** (Senior Equity Research Analyst)\nHi, good evening. Thank you for taking the question. Elon, I know that Tesla's really focused on with Master Plan 4 bringing AI into the physical world. I think we've seen over the past, you know, this willingness for Tesla to engage and go into new markets, new TAMs. When you think about the growth prospects, how do we define the areas that are really within Tesla's core competency versus where do you draw the line for markets or AI applications that are outside of Tesla's core competency?\n\n**Elon Musk** (CEO)\nActually, I'm not sure what you mean by AI applications outside of Tesla's core competency. I mean, we kind of, we didn't have any of these core competencies when we started, you know. It's like we had zero core competencies, total competency of zero, actually. You can think of Tesla as like, I don't know, a dozen startups in one company. I've initiated every one of those startups. We didn't used to make battery packs, stationary battery packs, but now we do. We make them for the home, make them for, you know, utility scale with Powerwall, Megapack. We've created the Supercharging network globally. No one else has created a global Supercharging network. In fact, that North American Supercharging network is so good that basically every other manufacturer in North America has converted to our standard and uses the Tesla Supercharging network.\n\n**Elon Musk** (CEO)\nIf it was so easy, why don't they just do it? The chip design team, we started that from scratch. The Tesla AI software team, we started from scratch. I literally just say, \"Hey, we're going to start this thing.\" I post it on Twitter, now X, and then, you know, join us if you'd like to build it. In fact, Ashok was, I believe, the first person I interviewed for the Tesla Autopilot team, which we now call the Tesla AI Software Team, because it is the AI Software Team. It's core competencies created while you wait. Optimus at scale is the infinite money glitch. It's like this is a, it's difficult to express the magnitude of, like if you've got something that, like if Optimus, I think, could probably achieve 5x the productivity of a person per year because it can operate 24/7.\n\n**Elon Musk** (CEO)\nIt doesn't even need to charge. It can operate at tethered. It's plugged in the whole time. That's why I call it like if you're true of sustainable abundance, where working will be optional. There's a limit to how much AI can do in terms of enhancing the productivity of humans. There is not really a limit to AI that is embodied. That's why I call it the infinite money glitch.\n\n**Vaibhav Taneja** (CFO)\nOne thing which I'll further add is, people forget, like our first iteration of Autopilot was 10 years back. Elon had started this way back in the day.\n\n**Elon Musk** (CEO)\nWe've got the trees to prove it.\n\n**Vaibhav Taneja** (CFO)\nExactly. Even on the Optimus side, as much as people think, \"Okay, this is a new thing,\" I still remember, was it four plus years back, we were in a finance meeting with Elon and Elon said, \"Hey, our car is a robot on wheels.\" That's where we started developing. In fact, most of the engineering team, which is working on Optimus, has come from the vehicle side. That's why, you know, when we talk about manufacturing progress, we have the wherewithal because the same engineers who worked back in the day on drive units are working on actuators now. If there is any company which can do it at scale, that is going to be us.\n\n**Elon Musk** (CEO)\nWe have actually added a lot of new engineers as well to the team. There's actually a lot of the credit for the Optimus engineering that is also new engineers, many of them that are just out of college, actually. The Optimus engineering team is a very talented engineering team. I'd say like, \"Wow.\" The Optimus reviews at this point are that there's the engineering review, and then there's the manufacturing review being done simultaneously with an iterative loop between engineering design and manufacturing. We design something and we see like, \"Oh man, that's really difficult to make. We need to change that design to make it easier to manufacture.\" We have made radical improvements to the design of Optimus while increasing the functionality, but making it actually possible to manufacture. I'd say Optimus 2 is almost impossible to manufacture, frankly.\n\n**Elon Musk** (CEO)\nMy two bypass points, we've gone from a person in a robot outfit to what people have seen with Optimus 2.5 where it's doing Kung Fu. Optimus was at the Tron premiere doing Kung Fu, just out in the open, like with Jared Leto. Nobody was controlling it. It was just doing Kung Fu with Jared Leto at the Tron premiere. You can see the videos online. The funny thing is a lot of people walked past it thinking it was just a person. Even though with Optimus 2.5, you can see that it has a waist that's three inches wide that's obviously not a human. The movements were so human-like that a lot of people didn't realize they were looking at a robot. What I'm saying is Optimus 3 will be a giant improvement on that and made at scale. A very difficult thing.\n\n**Elon Musk** (CEO)\nThe Optimus engineering and manufacturing reviews, and there's the Friday night meeting with Optimus, which sometimes goes till midnight. My Saturday meeting is with the Saturday afternoons with the AI5 chip design team. Those two things are crucial to the future of the company.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Dan, did you have a follow-up?\n\n**Dan Levy** (Senior Equity Research Analyst)\nYeah, just as a related, maybe you could just talk about to what extent are the AI efforts at Tesla and xAI complimentary, or are they just different forms of AI? Maybe you can just help distinguish for the audience. Thank you.\n\n**Elon Musk** (CEO)\nYeah, there are different forms of AI. The xAI, so Grok is like a giant model that you could not possibly squeeze Grok onto a car. That's for sure. It is a giant beast of a model. With Grok, it's trying to solve for artificial general intelligence with a massive amount of AI training, compute, and inference compute. For example, Grok 5 will actually only run effectively on a GV300. That's how much of a beast that Grok 5 is. Whereas Tesla's models are, I don't know, maybe about less than 10% the size, maybe closer to 5% the size of Grok. They're really coming at the problem from very different angles. xAI and Grok, you know, they're competing with Google Gemini and OpenAI ChatGPT and that kind of thing. Some of it is complementary.\n\n**Elon Musk** (CEO)\nFor example, for Grok voice, being able to interact with Grok in the car is cool. Grok for Optimus voice recognition and voice generation is Grok. That's helpful there. They are coming at it from kind of opposite ends of the spectrum.\n\n**Travis Axelrod** (Head of Investor Relations)\nAll righty. Adam, let's give it another try. When you're ready, please unmute yourself for the next question. All righty. Unfortunately, still having audio issues. We're going to move on to Walt from Lightshed. Walt, please go ahead and unmute yourself.\n\n**Walt Piecyk** (General Partner)\nCan you hear me now?\n\n**Travis Axelrod** (Head of Investor Relations)\nYes.\n\n**Walt Piecyk** (General Partner)\nPerfect. Thank you. Just getting back to Austin, if you can remove the safety driver at your end, is the limitation in the Bay Area just regulatory, or is it kind of the market-by-market learning process? I guess similarly in the 8 to 10 markets that you mentioned to get added, is the decision there to put a safety attendant in the passenger seat or the safety driver in, is that like your step-by-step process to opening up a market, or is it really just the regulation in the individual market?\n\n**Elon Musk** (CEO)\nI think even if the regulators weren't making us do it, we'd still do that as the sort of right sort of cautious approach to a new market.\n\n**Elon Musk** (CEO)\nJust to make sure that we're being paranoid about safety, I think it makes sense to have a sort of either safety driver or safety occupant in the car when we first go to new markets to just confirm that there's not something we're missing. Because all it takes is like one in 10,000 trips to go wrong, and you've got an issue. It's just to make sure, like is there some peculiarity about a city, like a very difficult intersection or, I don't know, something that's an unexpected challenge in a city for that one in 10,000 situation? I think we probably could just let it loose in these cities, but we just don't want to take a chance.\n\n**Elon Musk** (CEO)\nWhat we're talking about here is, you know, maybe three months of safety driver in a new metro to confirm that it's good, and then we take the safety driver out, that kind of thing.\n\n**Walt Piecyk** (General Partner)\nOkay. On Full Self-Driving 14, it has a different feel than 13, and it's also, I think, a little different than what it feels like in Austin. Is it basically a different development path that you're doing in terms of the robotaxi stuff versus what you're dropping to the early adopters? When you push these new builds, is it that you're looking for notable improvements in intervention rates, or is that largely solved and it's more about adding the functionality, like the parking, the drive modes, or just the overall comfort?\n\n**Elon Musk** (CEO)\nThe first priority when we release a major new software architecture for Autopilot is safety. It starts off with safety, obviously safety prioritized, and then we solve comfort thereafter, which is why I don't recommend people take the initial version. That's why I say, like, most people should wait until 14.2 before they actually download version 14. Because by 14.2, we will have addressed many of the comfort issues. The priority is very much safety first, and then thereafter the comfort issues. That's why most people are like, yeah, I probably it'll be a little, like, it'll be safe, but jerky. We just need time to kind of smooth the rough edges and solve for comfort in addition to safety with a major new Autopilot architecture change. It really is, I mean, I know what the roadmap is for the Tesla real-world AI and at very granular detail.\n\n**Elon Musk** (CEO)\nObviously, Ashok is leading that. I mean, I spent a lot of time with the team going, you know, in excruciating detail here on what we're doing to improve the real-world AI. Like I said, this car is going to feel like it is a living creature. That's with AI4 before even AI5.\n\n**Ashok Elluswamy** (VP of Autopilot and AI Software)\nYeah, that roadmap is super exhilarating. We're waiting so much to release all the stuff we are working on. In terms of what we ship to customers versus robotaxi, it's mostly the same. Obviously, customers have somewhat features like, you know, they can choose whether the car wants to park in a spot or in a driveway or something like that, which is not super relevant for robotaxi. There's only a few minor changes like those ones. The majority of the algorithms and architecture, everything is the same between those two platforms.\n\n**Elon Musk** (CEO)\nYeah, as I mentioned earlier, we'll be adding reasoning to, I don't know, Ashok, is that like reasoning in 14.3, maybe 14.4, something like that?\n\n**Ashok Elluswamy** (VP of Autopilot and AI Software)\nYeah, AI4 or AI5, by the end of this year for sure.\n\n**Elon Musk** (CEO)\nYeah. With reasoning, it's literally going to think about which parking spot to pick. It's going to say, this is the entrance, but actually, probably there's not a parking spot right at the entrance if it's full, you know, if the parking lot is fairly full, the probability of an open parking spot right at the entrance is very low. What it'll simply do is drop you off at the entrance of the store and then go find a parking spot. It's going to get very smart about figuring out a parking spot. It's going to spot, figure out, it's going to spot empty spots much better than a human. It's got 360-degree vision. Like I said, it's going to use reasoning to solve things.\n\n**Ashok Elluswamy** (VP of Autopilot and AI Software)\nFitting that all inside the computer that has the AI4 is the actual challenge. That is what the team is working on, because obviously, you can do reasoning on the server that takes forever, but in the car, you need to make real-time decisions. Fitting all that into the computer that's in the car is the challenge.\n\n**Elon Musk** (CEO)\nYeah, that's why I say, like, I have a pretty good understanding of like AI, you know, the sort of the giant model level with Grok and with Tesla. I'm confident in saying that Tesla AI has the highest intelligence density. When you look at the intelligence per gigabyte, I think like Tesla AI is probably an order of magnitude better than anyone else. It doesn't have any choice because that AI has got to fit in the AI4 computer. The discipline of having that level of AI intelligence density will pay great dividends when you go to something that has an order of magnitude more capability like AI5. Now you have that same intelligence density, but you've got 10 times more capability in the computer.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. The next question will come from Colin at Oppenheimer. Colin, please unmute yourself when you're ready. Colin, go ahead and unmute yourself, please.\n\n**Colin Rusch** (Managing Director and Head of Sustainable Growth and Resource Optimization Research)\nThanks so much, guys. I appreciate you bringing up the challenges of hand dexterity and humanoids, along with the complexity of the supply chain and the vertical integration you guys are pursuing. I'm just trying to harmonize the timeline for the start of production next year with the current state of the supply chain and what sounds like a fair amount of work remaining on the dexterity before you can really freeze the hardware design and start to scale up production.\n\n**Elon Musk** (CEO)\nThe hardware design will not actually be frozen even through startup production. There will be continued iteration because a bunch of the things that you discover are very difficult to make. You only find that pretty late in the game. We will be doing rolling changes for the Optimus design even after startup production. I do think that the new hand is an incredible piece of engineering.\n\n**Elon Musk** (CEO)\nLike I said, we'll have a production intent prototype ready to show off in Q1, probably February or March. We're going to be building a million-unit Optimus production line, hopefully with a production start towards the end of next year. That production ramp will take a while to get to an annualized rate of a million because it's going to move as fast as the slowest, dumbest, least lucky thing out of 10,000 unique items. It will get to a million units. Ultimately, we'll do Optimus 4. That will be 10 million units. Optimus 5, maybe 50 to 100 million units. I mean, it's really pretty nutty.\n\n**Travis Axelrod** (Head of Investor Relations)\nAll righty. That is unfortunately all the time we have for Q&A today. Before we conclude, though, Vaibhav has some closing remarks.\n\n**Vaibhav Taneja** (CFO)\nThanks, Travis. I want to take the time to talk about an extremely important vote, which is being held on November 6. The meeting will shape the future of Tesla. We are asking you, as our shareholders, to support Elon's leadership through the two compensation proposals and the reelection of Ira, Kathleen, and Joe to the board. It is a team sport. Here at Tesla, the board is an integral part of the winning team. Shareholders are at the center of everything we do at Tesla. A special committee has laid out a compensation package. Like Elon said, we don't even want to call it a compensation package.\n\n**Elon Musk** (CEO)\nYeah, the point is that I just, like, there needs to be enough voting control to give a strong influence, but not so much that I can't be fired if I go insane. I think that sort of number is in the mid-20s, approximately. As a company that has already gone public, we've investigated every possible way to achieve increased voting control. Is there some way to have a super voting stock? There really isn't. There is no way to have a super voting stock after you've gone public. For example, Google, Meta, many other companies have this, but they had it before they went public, and it sort of gets, I guess, grandfathered in. Tesla does not have that.\n\n**Elon Musk** (CEO)\nLike I said, I just don't feel comfortable building a robot army here and then being ousted because of some asinine recommendations from ISS and Glass Lewis, who have no frigging clue. I mean, those guys are corporate terrorists. Let me explain the core problem here. So many of the index funds, the passive funds, vote along the lines of whatever Glass Lewis and ISS recommend. They've made many terrible recommendations in the past that, if those recommendations had been followed, would have been extremely destructive to the future of the company. If you've got passive funds that essentially defer responsibility for the vote to Glass Lewis and ISS, then you can have extremely disastrous consequences for a publicly traded company.\n\n**Elon Musk** (CEO)\nToo much of the publicly traded company is controlled by index funds, it's de facto controlled by Glass Lewis and ISS. This is a fundamental problem for corporate governance because they're not voting along lines that are actually good for shareholders. That's the big issue. I mean, that's what it comes down to: ISS, Glass Lewis, corporate terrorism.\n\n**Vaibhav Taneja** (CFO)\nYeah, I would say the special committee did an amazing job in constructing this plan for the benefit of the shareholders. There's nothing which gets passed on till the time shareholders make substantial returns. That's why, in the end, I would say I would urge you to not only vote on the plan, but also vote on all the three directors because of their exceptional knowledge and experience. Literally, we at Tesla work with these directors day in, day out. There's not even a single day that one of the directors I haven't spoken to or one of my colleagues hasn't spoken to. Even the directors out here are not just reading out of PowerPoint presentations. They're actually working with us day in, day out. I just urge you guys as shareholders to vote along the board's recommendation. Thank you, guys.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you, Vaibhav. We appreciate everyone's questions today. We look forward to talking to you next quarter. Thank you very much and goodbye.",
        "fetched_at": "2026-02-04T16:12:33.389Z"
      },
      {
        "ticker": "TSLA",
        "title": "Yahoo Finance",
        "published_date": "Jul 23, 2025, 5:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/TSLA/earnings/TSLA-Q2-2025-earnings_call-337623.html",
        "content": "**Travis Axelrod** (Head of Investor Realtions)\nGood afternoon, everyone, and welcome to Tesla's second quarter twenty twenty five q and a webcast. My name is Travis Axelrod, head of investor relations, and I'm joined today by Elon Musk, Bev Abtaneja and a number of other executives. Our Q2 results were announced at about three p. M. Central Time in the update deck to be published at the same link as this webcast.\n\n**Travis Axelrod** (Head of Investor Realtions)\nDuring this call, we will discuss our business outlook and make forward looking statements. These comments are based on our predictions and expectations as of today. Actual events or results could differ materially due to a number of risks and uncertainties, including those mentioned in our most recent filings with the SEC. During the question and answer portion of today's call, please limit yourself to one question and one follow-up. Please use the raise hand button to join the question queue.\n\n**Travis Axelrod** (Head of Investor Realtions)\nBefore we jump to q and a, Elon has some opening remarks. Elon?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nThanks, Travis.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo we've had a very exciting quarter. The we're able to successfully launch robo taxi, so providing our first drives with no one in privacy, both paying customers in Austin. And as some may have noted, we've already expanded our service area in Austin. It's bigger and longer, and and it's and it's gonna get even bigger and longer. We were expecting to really greatly increase the Austin service area to well in excess of what competitors are doing.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd that's hopefully in a week or so, two weeks?\n\n**Ashok Elluswamy** (VP - AI Software)\nYeah. Couple of weeks.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nCouple of weeks or so. And and and and then we're we're we're getting the regulatory permission to launch in the Bay Area, Nevada, Arizona, and a number of and Florida and a number of other places. So as as we get the approvals and we prove out safety, then we'll be launching autonomous ride hailing in in most of the country. And I think we'll probably have autonomous ride hailing in probably half half the population of The US by the end of the year. That's that's at least our goal subject to regulatory approvals.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI I I think we'll technically be able to do it. So assuming we have regulatory approvals, it's probably addressing half the population of The US by the end of the year. But we we we are being very cautious. We don't wanna take any chances. And so we're good.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nWe're gonna, yeah, go go cautiously. But but it's it's the service areas and the number of vehicles in in operation will increase at at a hyperexponential rate. So, you know, some other notable things. Model y in June became the best selling car in Turkey, Netherlands, Switzerland, and Austria. It is, I believe, the best selling car of any kind in the world still.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd autonomy is a is a big factor there. So even without even even without supervised even even with just supervised self self driving, it's it's a huge selling point. And it's worth noting that we do not actually yet have approval for supervised FSD in in Europe. So our sales in Europe, we think, will improve significantly once we are able to give customers the same experience that they have in The US. This is my this is, I think, a very important point to convey.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd we've been working with main country regulator, which is The Netherlands. And I think we're close to getting approval with Netherlands, then it's gonna go to the EU. It's quite a, you know, In fact, had no idea that something like EU could exist. Beyond challenges with bureaucracy, but it will we will get the approvals. And I I think we'll get, you know, some people in Europe will have experience similar to how The US in most of Europe, you know, this year, hopefully, at least partly in this quarter.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd then we also have some regular regulatory challenges in China, which we're hoping to unblock shortly where we because we we also cannot provide to advise FST in China currently. We're able to unblock that suit, and that's also those that's another major. It's really is the single biggest demand drive. And then within The US, as as we are get confident about safety in in different geographic areas, the we will loosen up on how much somebody has to be laser focused have their eyes laser focused on the road. You know?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nBecause that's that's been a common complaint. In fact, it it does create odd odd safety issue where people will sometimes disengage Autopilot, then then do something, change the radio or maybe look at the phone, drive with their knee, and then reengage Autopilot, which obviously is not is less safe than simply keeping Autopilot on. So, anyway, we're get that that that experience will will improve in in the next several weeks. The the because of our focus on Boston with that one in the privacy, the production release of autopilot is actually several months behind what people experienced on a robo text in Austin. So now we have the robo text that Austin launched.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nWe'll be provide adding back those elements so that there will be a step change improvement in the the autopilot experience for people outside of Austin. This this is really, as you can tell, this is very much sort of autonomy is is the story. Like, we need to we need the physical product without which you cannot have autonomy. But once you have a physical product, need the the autonomy is what amplifies the value to stratospheric levels. We also launched the Tesla Dyna, which has been a huge hit.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt actually got worldwide attention, which is unusual for a Dyna. Diners don't typically get, you know, headline news around Earth. But this is a pretty special diner. And if you're in the LA area, it's worth visiting. It's sort of a shining beacon of hope in in an otherwise sort of bleak urban landscape, frankly.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo really quite quite a lovely experience. Great job by the team there. On the full self driving front, continue to worry about that. We have we're continuing to make significant improvements just with the software. So the we're we're expecting to increase the parameter count.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nActually, at this point, I think we think we can probably 10 x the almost 10 x the parameter. Yeah. Roughly. Roughly 10 x the parameter count. So this is this is actually a very tricky thing to do because you if you as you increase the parameter count, you get you get choked on memory bandwidth.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nBut we currently think we can 10 x the parameter account from what people are currently experiencing. That's that's not not not just a four x, actually, x increased in in parameter account. And yeah. So so there's a lot of improvement on the existing hardware to to to happen. Energy is growing really well despite headwinds from tariffs and various supply chain challenges.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nThe the mega pack is expanding capacity quickly, and and we have upgrades to the mega pack that will make it even better. And we had record power deployment gain in q two. So I I I think battery batteries are gonna just gonna be a massive thing The the scale of batteries battery demand is, I think, not that many people appreciate just how gigantic the scale of battery demand is. We the way to think about it is that The US sustained power output for The US grid is around one terawatt, but average usage is less than half a terawatt. If you add batteries to the mix, you can run the power plants twenty four seven at full capacity, thus doubling more than doubling the energy output per year of The United States just with batteries.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nBut that's a good big deal. It's a really big deal. Optimus so we're revolving the opto Optimus design and really getting Optimus to the point where it is a phenomenal design. So an Optimus version two right now, sort of two and a half. Optimus three is is an exquisite design in my opinion and will be an as I've said many times before, predicted it will be the biggest product ever.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's a very hard problem to solve. You have to design every part of it from Physics First Principles. There's nothing that's off the shelf that actually works. So you can design every motor gearbox, power electronics, control electronics, sensors, the the mechanical elements. We also got to train optimist to use its sensors with a neural net, but we'll be applying the same techniques that we applied for a car, which is essentially a four wheeled robot.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd OPTIMIS is a robot with arms and legs. So the the the same principles that apply to optimizing AI inference of the car applied to Optimus because they're both really robots in different forms. And and Tesla, it it is important to note that Tesla is by far the best in the world at real world AI. Like like, a clear proof point with for that would be if you compare it to Tesla to Waymo. Waymo's got you know, the car is best doing with god knows how many sensors.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd yet isn't Google good at AI? Yes. But they're not good at real world AI thus far. They have Tesla is actually much better than Google by far than any much better than anyone at real world AI. And and I and by far, Tesla has the the best inference efficiency.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nLike, I think a key favorite for AI is what is the intelligence per gigabyte? And people talk about parameters, blah blah blah. But but I think we'll talk about stop talking about parameters and talk about gigabytes because with the parameters, you can have four bit parameters, eight bit parameters, 16 bit parameters. But the actual constraints in the hardware are how many gigabytes of RAM and how many gigabytes per second can you transfer from RAM. Therefore, it is not a parameter constraint.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nThere's it is a there's a byte constraint. And Tesla has the highest intelligence density of any AI by far. And I have a lot of insight into this with with xAI. XAI is you know, Grok is the smartest AI overall, but it's a you know, Grok four is a giant beast. They're sort of at the terabyte level.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd so kind of a important to note, Tesla has the best intelligence density. Intelligence density will be a very big deal in the future. It is now. So with with Optimus three, which is really the right design, it's like it doesn't have at this point, there's no no significant flaws with the Optimus three design. But it it it would we are gonna retool a bunch of things.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo it's gonna probably be prototypes of Optimus three end of this year and then scale production next year. And I'll try to scale Optimus production as fast as it's humanly possible to to do so and try to get to a million units a year as quickly as possible. You think we can get there in less than five years? That's my sort of, I guess. That that's a reasonable aspiration.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's a million years, a year, five years. It seems like an achievable target. In conclusion, so far, 2025 has been a very exciting year. A lot of major milestones. We've made clear pro demonstrable progress in autonomy that a lot of said we would not achieve.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt is worth noting that we have done what we said we're gonna do. I mean, we're always on time, but we get it done. And on the ACRS, I was sitting there with egg on their face. So great great great progress by the Tesla team. Yeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI I I do think if Tesla continues to execute well with big autonomy and and humanoid robot autonomy, it it it will be the most valuable company in the world. So a lot of execution between here and there. It doesn't just happen. But provided we execute very well, I think Tesla has a shot at being the most valuable company in the world. Alright.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nObviously, I'm extremely optimistic about future of the company. Best way to predict the future is to make it happen, and we're we're making it happen here with Tesla team. So I'd just like to say thanks to all of our supporters, and I think we're good to tell you an incredibly exciting future.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you very much, Elon. And Benloff has prepared remarks as well.\n\n**Vaibhav Taneja** (CFO)\nThanks, Travis. As Elon mentioned, q two was an interesting quarter in a few respects. We started ramping up the production of the new Model y at all our factories. We rolled out our robotaxis service in Austin and delivered a car completely autonomously from directly from the factory to the customer's home. It is a seminal point get to this thing.\n\n**Vaibhav Taneja** (CFO)\nI mean, it took a lot of effort, and I really wanna thank everybody at Tesla to make this happen. It wasn't an easy thing to do, but we did it. It took time, but we've just begun the next phase for the company. The one big bill has a lot of changes that would affect our business in the near term. The first among those changes is the repeal of the IRA EV credit of 7,500 by the end of this quarter.\n\n**Vaibhav Taneja** (CFO)\nGiven the abrupt change, we have limited supply of vehicles in The US this quarter as we have already with the lead times to auto parts to build cars. We've rolled out all our planned incentives already, and we'll start bearing them back as we start to sell. If you are in The US and looking to buy a car, place your order now as we may not be able to guarantee delivery orders placed in the later part of August and beyond. But we'll also make changes to certain emission standards by reducing the amount of penalty to zero. This, in turn, will have an impact on the new sales of regulatory credits to other OEMs and, in turn, will lead to lower revenues.\n\n**Vaibhav Taneja** (CFO)\nWhile we now plan our business around such sales, it will nonetheless impact our total revenues going forward. On the automotive product portfolio, the entire lineup is updated. Globally, we are seeing an increase in the number of test drives. We started the production of the lower cost model as planned in the first half of twenty five. However, given our focus on building and delivering as many vehicles as possible in The US before the EV credit expires and the additional complexity of ramping a new product, the ramp will happen next quarter slower than initially expected.\n\n**Vaibhav Taneja** (CFO)\nOne thing which is grossly under appreciated and need on time to moderate is that all our vehicles in the lineup are capable of a ton. This is by far the biggest differentiator between us and the competition. Our vehicles stop safety standard as is, but with FSD, they are and will continue to set a new standard for safety within vehicular transportation. We published our vehicle safety report earlier today, and you can see a car on FSD is 10x safer than the car not on FSD. We've started seeing an uptick in FSD adoption in North America in recent months, which is a very promising trend.\n\n**Vaibhav Taneja** (CFO)\nAnd just to give you perspective, you know, since the launch of since we've been moved to version 12 of FSD, we've seen the adoption rates really increase. We've started seeing the on the automotive revenue front, despite reduction in regulatory credit revenue and the auto the total automotive revenue increased by 19% sequentially even though total deliveries only improved 14%. This was primarily due to an improved a s ASPs because of the new model y. This helped in improving margin sequentially as well along with improved mix and higher cost fixed cost absorption despite an increase in cost from tariffs. We started seeing the impact of tariffs in our p and l.\n\n**Vaibhav Taneja** (CFO)\nSequentially, the cost of tariffs increased around 300,000,000 with approximately two thirds of that impact in automotive and rest in energy. However, given the latency in manufacturing and sales, the full impacts will come through in the following quarters, and so cost will increase in the near term. While we are doing our best to manage these impacts, we are in an unpredictable environment on the tariff front. The margins for the energy generation and solar businesses improved sequentially while deployment reduced primarily due to the ramp of power deployments at higher margins. We were able to achieve our highest gross profit for the business yet.\n\n**Vaibhav Taneja** (CFO)\nNote that the overall deployments will continue to vary quarter to quarter. Think, you know, covered this that, you know, industrial storage will make a difference in this drive towards AI and data center growth. The energy requirements are increasing at a rapid scale as application as AI applications are very energy hungry. The quickest path to scale up energy is deploying storage. This is something that our customers have started realizing, and despite this business having the largest impacts from tariffs, we're seeing customers willing to accept some of the tariff impacts.\n\n**Vaibhav Taneja** (CFO)\nThe big bill has certain adverse impacts even for the energy business, most notably on the residential storage business due to the early expiration of currency one by the end of this year. The challenges of the storage business, therefore, remain both from the build and from tariffs, and we're doing our best to try and manage through this. But it will we will see shifts in demand and profitability. The margins for our service and other businesses improves sequentially, primarily due to higher profits from supercharging and improvement in insurance and service center profitability. Operating expenses also grew sequentially as we continued our investment in AI projects, including additional expenses related to employee related costs, including higher stock based compensation and depreciation for AI compute.\n\n**Vaibhav Taneja** (CFO)\nOur operating expenses, our r and d related spend, will continue to grow. We believe even in the current environment, it is the right strategy to keep making investments in these areas to position us for the long term. Other income grew sequentially primarily from the mark to market adjustment on Bitcoin Holdings, which was 284,000,000 gain in q two while we got a 125,000,000 loss in q one. Just want to remind people that this would keep creating volatility based on the Bitcoin price. While other while operating cash flows increased sequentially, so did our CapEx, resulting in 146,000,000 of free cash flow.\n\n**Vaibhav Taneja** (CFO)\nWe continue to make investments in various aspects of manufacturing, like cyber cap, semi mines, and other manufacturing spend, and the expansion of our AI initiatives. Our latest expect expectation for the year in terms of CapEx is in excess of 9,000,000,000. To summarize, we have near term challenges in our business due to the negative impacts of the bill and tariffs. However, the investments that we have made for AI, robotics, and our lead in energy sets us up for a bright future. I would like to thank the whole Tesla team, our customers, our investors, and supporters for their continued belief in us.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thanks very much, Vethal. So now we're gonna move on to state.com questions. The first question is, can you give us some insight how robo taxis have been performing so far and what rate you expect to expand in terms of vehicles, geofence, cities, and supervisors?\n\n**Ashok Elluswamy** (VP - AI Software)\nMhmm. Yeah.\n\n**Ashok Elluswamy** (VP - AI Software)\nThe robo taxis has been doing great so far in Austin. Customers really love the experience. It was, like, super smooth, very safe, and, like, just a great experience overall. And we already did the first day of expansion in Austin, and we'll continue to expand in Austin to probably more than 10 x our current operating region. We're also testing in a lot of other cities as Elon mentioned.\n\n**Ashok Elluswamy** (VP - AI Software)\nThe next thing to expand would be in the San Francisco Bay Area. We are working with the government to get approval here, and in the meanwhile, launch a service with the person in the driver's seat just to expedite, and while we wait for regulatory approval. We're also testing a lot of other cities in The US, including Florida, Nevada, etcetera.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you very much, Shuk. The next question is, what are the key technical and regulatory hurdles still remaining for unsupervised FSD to be available for personal use? Can you provide a timeline?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nForward. First of me getting there, I think it's it it'll be available for its personalized personal use by the end of this year in certain geographies. We're just being very careful about it. So\n\n**Vaibhav Taneja** (CFO)\nThis is not something which we all do rush.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nNo.\n\n**Vaibhav Taneja** (CFO)\nWe wanna make sure that everything is safe before we make it available broadly.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. We're just being extremely primary.\n\n**Vaibhav Taneja** (CFO)\nYes.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nBut I I'd be I'm I'm confident that by the end of this year within a number of cities in The US, we will will it'll be available to end users. Like yeah.\n\n**Ashok Elluswamy** (VP - AI Software)\nYeah. And for what it's supposed to be the same, AA hardware, in the Austin robotaxi vehicles has some customer vehicles, and we did deliver a car autonomously from the factory to a customer this quarter.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYes.\n\n**Ashok Elluswamy** (VP - AI Software)\nAnd every Tesla manufacturer in The US and, in Europe, autonomously drives itself from the end of line to the, loading docks. And it so it's just a software upgrade away.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI I think we'll be in we'll end up delivering cars in the Great Warson area and the Bay Area by default from the factory by the end of this year. Like, a car will deliver itself to your to where you are unless you say you don't want that.\n\n**Ashok Elluswamy** (VP - AI Software)\nThat'd be super cool.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you, guys. The next question is, what specific factory tasks is Optimus currently performing, and what is the expected timeline for scaling production to enable external sales? How does Tesla envision Optimus contributing to revenue in the next two to three years?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. So the Optimus Optimus three design, as I mentioned earlier, is, I think, finally the right design. There'll be further optimizations, but there are no, I think, no fundamental changes to that are needed for the optimist three design. It has all the degrees of freedom that we really want or need. So it's you know, I have prototypes of that in, I don't know, three or three months, and it's sort totally in production.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nWe'll certainly start production on that in the beginning of next year. The production ramp is simple. It's always a good predict Yes. Cover of your production ramp when something has got an entire when everything is new because the rate of production will move as fast as the least lucky and least competent elements of the entire supply chain as well as in in internal processes. So the more new stuff that is in in a product, the slower the the ramp could be because of unexpected supply chain interruptions or mistakes made internally.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's much easier to predict sort of the the the end of the of the s curve or or late in the s curve than the beginning of the s curve. And the beginning of the s curve of of the production ramp is in any case not really material for revenue purposes. The the beginning of the s curve, that you're usually not usually yours, negative gross margin, and you're debugging a lot of issues. So that that's why, like, it's it's I I feel like fairly confident in predicting things or at least medium confident in predicting where we are at five years, but I it's hard to predict where we are in a year or two years. So that's why I think five years I think we could be at the let me put this right.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI'd be surprised if at the end of five years, you know, sixty months from now, if we are not roughly making a 100,000 Optimus robots in month in sixty months, I would be shocked.\n\n**Travis Axelrod** (Head of Investor Realtions)\nAlright. Thank you very much. Next question is, can you provide an update on the development and production timeline for TESS' more affordable models? How will these models balance cost reduction and profitability, and what impact do you expect on demand in the current economic climate?\n\n**Lars Moravy** (Vice President of Vehicle Engineering)\nWell, I I think Vibod did a good job of answering this question in his opening remarks. As we said, we started production in June, and we're ramping, you know, quality builds and things throughout the quarter. And given that that we started in North America and that, you know, our goal is to maximize production with a higher rate. So if ending q three, we're gonna keep pushing hard on our current models to avoid complexity. Unfortunately, that rolls away.\n\n**Lars Moravy** (Vice President of Vehicle Engineering)\nWe'll be running within more formal models available for everyone in q four. And, you know, the goal of those products was not to negatively impact revenue or or gross margin, but just to make a car that everyone loves and wants at a more affordable price.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you, Lars. The next question is, can you talk about the benefits of Tesla investing in xAI?\n\n**Vaibhav Taneja** (CFO)\nThis is not the forum to discuss this topic. I mean, if if if there is something which we need to discuss, we'll discuss that separately.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI I think, obviously, you know, we're a publicly traded company. Shareholders are welcome to put forward any shareholder proposals that they'd like. I recently encouraged that. And and then have shareholders vote, and we'll act in accordance with the shareholder wishes.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat.\n\n**Travis Axelrod** (Head of Investor Realtions)\nThank you very much. The next question is, can you tell us a little bit more about what goes on in the Tesla design studio?\n\n**Speaker 5** (Executive)\nDo you want me to take that one?\n\n**Speaker 5** (Executive)\nWe we kinda generally say that what happens in the studio stays in the studio and that, you know, earnings calls are not the place to disclose new product stuff. But we're, you know, we're working to make sure that we have an exciting future for for our Tesla and our in in the product lineup.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. There's a lot of exciting things happening in the design studio. It's it's not like static. And, really, what's gonna happen over the next several years is a fundamental transformation of the company from a preautonomy world to a postautonomy. And I'm working on a new master plan to articulate that as a team.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd, you know, there there there will there will be there are some teething pains as you as you transition from pre preautonomy to a postautonomy world. But I think the the future vision for Tesla is incredibly exciting and will profoundly change the world in a good way. This may sound like sort of pineapple or whatever, but I I think if well, let's just say if we execute on that plan effectively, which is you have to actually do that, Tesla will be the most valuable company in the world by far.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you. The next question is actually duplicate on unsupervised SSD for customer vehicles. We'll skip that. After that is, are there any news for hardware three users getting retrofits or upgrades?\n\n**Travis Axelrod** (Head of Investor Realtions)\nWill they get hardware four or some future version of hardware five?\n\n**Vaibhav Taneja** (CFO)\nI mean, what we want to do is we wanna get unsupervised done on hardware four first. Once it's done, then we will go back and look at what we need to do with the hardware three cars. I mean, like I said, the focus is first to get unsupervised out, and then we'll go back and see what more work we need to do.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Next quest question is, can you give an update on Dojo, and could xAI be a customer for Dojo?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nDojo two we expect to have Dojo two operating in scale sometime next year with scale being somewhere around a 100 k h 100 equivalents. And and then AI five, which is really it's spectacular too. I I don't use those words lightly. Spectacular too. The AI five will be hope hopefully be in volume production around the end of next year, but that has a lot of potential.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI think, you know, thinking about Dojo three and the AI six in first chip, It seems like intuitively, we wanna try to find convergence there where it's basically the same chip that is used where we use, say, two of them in a car or an Optimus and and maybe a larger number on a on a board, a kind of five twelve on a board or something like that. If you want high bandwidth communication between the chips at a forced survey doing doing a burn survey. That sort of seems like intuitively the sensible way to go.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. The next set of questions have all actually been covered. So we'll we'll end with, how will the BBB elimination of tax credits for solar projects affect your sales pipeline for Megapack?\n\n**Speaker 5** (Executive)\nYeah. Our our sales pipeline is is quite diversified across customers and market segments, so we aren't heavily weighted in Megapack projects that are paired with solar. And as we talked about in the opening remarks, we're seeing storage quickly being recognized for its ability to unlock grid efficiency and how quickly it can be deployed to help the grid. Additionally, although the recent bill was not favorable toward solar, we we believe solar projects will still get built because the energy is necessary. The projects are well developed, and they're ready for execution, and there's really no alternatives in the near term given gas turbine lead times and pricing.\n\n**Speaker 5** (Executive)\nWe also could continue to see growth in the data center segment and in stand alone storage projects providing capacity to the grid in several markets across The US. Overall, we're forecasting a very strong second half of the year as we increase deployments. And lastly, we we continue to invest heavily in US manufacturing to mitigate policy and tariff impacts, expecting our first LFP cell manufacturing facility to be online by the end of the year and launching our third mega factory near Houston in 2026.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you, Mike. We will now be moving to analyst questions. The first question comes from Emmanuel Rosner at Wolfe Research. Emmanuel, please feel free to unmute yourself whenever you're ready.\n\n**Emmanuel Rosner** (Managing Director - Senior Autos &amp; Auto Technology Analyst)\nGreat. Thank you so much. Can you hear me?\n\n**Travis Axelrod** (Head of Investor Realtions)\nYep.\n\n**Emmanuel Rosner** (Managing Director - Senior Autos &amp; Auto Technology Analyst)\nThanks.\n\n**Emmanuel Rosner** (Managing Director - Senior Autos &amp; Auto Technology Analyst)\nSo, Elon, are you able to share any KPIs with us in terms of the robotaxi business? How many vehicles are you operating, miles driven autonomously or the number of safety critical intervention? Just curious how the rollout is generally is going and any sort of like targets that you could share more broadly.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSure. Do you wanna\n\n**Ashok Elluswamy** (VP - AI Software)\nYeah. Have, you know, more than 7,000 miles operating in Austin area. It's you know, just because service is new, we have handful of vehicles, right now, but then we are trying to expand the service, in terms of both the area and also the number of vehicles both in Austin and other locations. So far, you know, the there's, like, no notable safety critical incidents there. You know, sometimes we have our own, restrictions as to, for example, be resting on our speed limit to 40 miles per hour course.\n\n**Ashok Elluswamy** (VP - AI Software)\nAnd if the vehicle wants to go on, like, higher speed course, we can stop the vehicle, but those are lot of convenience opposed to, safety critical nature. So for the service, that will be really good received, and we continue to, expand on it.\n\n**Emmanuel Rosner** (Managing Director - Senior Autos &amp; Auto Technology Analyst)\nGreat. And term from an economics point of view, longer term, you've previously talked about working to drive down the cost per mile on the robotaxis, maybe towards $0.30 or $0.40 per mile over time. Now that your service is live, how should we think about the main milestones to getting there?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. Well, the the the cyber cab is which is really optimized for autonomy. That that I think has got probably sub 30 per mile potential over time, maybe 25. You know, it's it's really you you like, if you design a car from scratch to to be a cost optimized robotic taxi like CyberCap. You know, you know, you you like, for example, we're we're not trying to make it, you know, corner like a like, incredibly well like a model three would, you know, or model s or even model y. Like, it's got model most the this you know, model all all of our all all of our cars that are driven by people are super fun to drive. They've got incredible acceleration, you know, incredible cornering capability. But I don't we're we're we're confident that very few people in a cyber cap want to be hurdling around.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo, you know, so we were we we've reduced the the top end speed, which means we can use more efficient tires. We don't need as much acceleration. We don't need as much, you know, big big breaks to sort of we won't want stopping distance, but we we're we're not expecting it to be heavily used. It's it's it's a gentle ride. Essentially, you you design it for a gentle ride and and then you you have a much more optimized optimized design point.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo that that's why it it seems probably we could achieve that, especially if optimist is, you know, so serving cleaning up the car and make doing maintenance and stuff. And it it's, you know, doing order automatic charging. So, yeah, I think it's gonna the actual cost per mile of cyber cap will be be very low. The cost per mile of our existing fleet will be higher, but still very competitive. So, yeah, maybe some number of 50.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI'm just guessing. Yeah. So so this really Tails Road, technically, will go from tiny to gigantic in terms of operations in pretty short period of time. Like, my guess is there's it's it has a material impact on our financials around the end of next year.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you very much. The next question comes from Adam at Morgan Stanley. Adam, please unmute yourself.\n\n**Adam Jonas** (Head - Global Auto &amp; Shared Mobility Research)\nGreat. Hello, everybody. So, Elon, as Tesla moves into this next phase of physical AI, autonomous humanoids, robotaxis, etcetera, world changing, civilizational species changing technology with dual purpose. Are you comfortable moving Tesla in this direction while only having a 13% stake in the economy sorry, in the company? Is that sustainable, or does do you still insist that something needs to happen, given, you know, your current lack of control and the types of technologies you're getting into?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. That that that is a major concern for me as I've mentioned in the past, and I hope that is addressed at the upcoming shareholders meeting. But, yeah, it is a big deal. Like, you know, I wanna find that I've got, like, so little control that I can easily be ousted by activist shareholders after having bought, you know, these these army of humanoid robots. I think that as I mentioned before, I think my control over Tesla should be enough to ensure that it goes in a good direction, but not so much control that I can't be thrown out if I go crazy.\n\n**Adam Jonas** (Head - Global Auto &amp; Shared Mobility Research)\nOkay, Elon. Don, you're not gonna go crazy. We we we we trust you. Well You can stay a little crazy. A a little crazy is okay.\n\n**Adam Jonas** (Head - Global Auto &amp; Shared Mobility Research)\nElon, though, we understand the the board of directors of a major US investment bank recently toured Optimus production. I I I that's I don't know if you wanna confirm that or not. It's just what we heard. That's cool. But when do you think others will be able to get a firsthand view of, optimists like that?\n\n**Adam Jonas** (Head - Global Auto &amp; Shared Mobility Research)\nAnd is the second half of this year too soon to have an AI day? Because it seems like everybody else in the world's doing it, and this talent war is getting freaking crazy. And, I I know I know you mentioned for recruiting purposes, this is a very important thing that you've done. I think people have have you've have copied you on this, and I'm wondering if this is if this year is too early for that. Thanks, Elon.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYes. It's a bit of a tough thing because, like, when we do an AI day, we find that some of our competitors have literally done a frame by frame examination of our slides, everything we say, and then copy us. So, you know, I'm saying, what's the the trade off? Which which does help with recruiting, but then competitors look very closely and copy us. I mean, that said, we should probably I mean, I I guess we could consider the shareholder meeting to be sort of an can do we can maybe go into depth, some some amount of depth at the Annual Shareholder Meeting with respect to Optimus and AI and sort of the chip chip stuff perhaps.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. Tesla's also really underrated in terms of AI chip design as well as AI software. So, like, there there's still not a chip that we would that that exists that we would prefer to put in our car that is an AI chip that that we would prefer to put in the car over our own, and even though it's been now out for several years. And we're confident that the AI five chip will be a profound game changer. In fact, it it it's so it's so powerful that we'll we'll have to nerf it for to some degree, for markets outside of The US because it it it flows way past the export restrictions.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo unless the export restrictions change, we actually will have to nerf our AI five show, which is kinda weird. Hopefully, those hopefully, we keep, you know, raising the bar on export restrictions. Otherwise, it gets a bit silly. We'll have a bunch of Optimus robots on stage at the shareholder meeting. The Optimus lab is cool to see.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt looks like it basically looks like the set of Westworld. You could robots in various stages. Some of them, know, in various stages of prepare. Like, I don't know. Some some combination of, like, the Tatooine Junkyard and the and Westworld is what it looks like.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's very cool. And and Optimus is walking around the office here in Palo Alto. So twenty four seven is just walking around like a small I think I'm so so optimist. Like, know, the Tesla diner, so we pop one. Yeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo it's we'll go from a world where robots are rare to where they're so common that you don't even look up.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thank you so much. The next question comes from Edison at Deutsche Bank. Edison, please unmute yourself. Edison, please go ahead and unmute yourself.\n\n**Travis Axelrod** (Head of Investor Realtions)\nRight. While Edison figures that out, we will go to the next question, which is gonna come from Dan Levi at Barclays. Dan, please go ahead and unmute yourself.\n\n**Dan Levy** (Senior Equity Research Analyst)\nGreat. Thank you. Yuan, you've talked about the opportunity to put non Tesla owned vehicles into the robotaxi network. Just talk about the gating factors to enabling that and what timeline we should expect on personally owned vehicles in the robotaxi network.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI we haven't really thought hard about that. But we need to make sure it works when the vehicles are fully under our control. And, yeah, it's kinda one step at a time here. We don't wanna jump the gun. As I said, we're being paranoid about safety.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo so it's like but I I I guess I guess it would like, next year is I'd say confidently next year. I'm not sure when next year, but confidently next year, people would be able to add or subtract their car to the Tesla fleet.\n\n**Vaibhav Taneja** (CFO)\nI mean, one thing to keep in mind is that we will have some criteria because, like, even when you put your car in a Uber or Lyft fleet, they go through a whole checklist process of making sure things are working.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's like an Airbnb or Yes. Got it.\n\n**Vaibhav Taneja** (CFO)\nYeah. So we will do something like that.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's kind of very impossible.\n\n**Vaibhav Taneja** (CFO)\nYes.\n\n**Vaibhav Taneja** (CFO)\nBecause we want like, Elon said, we wanna be parallel on security. I mean, assets, small things like tread on the tire can have an impact on safety. So that's why we would want to do some proper validation before we let other cars come in.\n\n**Travis Axelrod** (Head of Investor Realtions)\nDan, do have a follow-up?\n\n**Dan Levy** (Senior Equity Research Analyst)\nYes. Thank you. Could you just unpack the different costs associated with scaling the robotaxi business and how you think about funding those costs. Are are the cash flows in the auto business sufficient to fund it? And if not, what other funding sources do you think you'd use?\n\n**Dan Levy** (Senior Equity Research Analyst)\nYou know, would you just fund it off the balance sheet?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nWell, as soon as there is a clear cash flow stream associated with any any product, you can debt finance it.\n\n**Dan Levy** (Senior Equity Research Analyst)\nAnd in the interim?\n\n**Vaibhav Taneja** (CFO)\nWhen in the interim, we will use our balance sheet. But, like, once we get to a certain scale in terms of recurring revenues, like Elon said, we could get into a easily, kind of transaction to try and get funding.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Thanks so much. And we will now move on to Mark from Goldman Sachs. Mark, please feel free to unmute yourself.\n\n**Mark Delaney** (US Autos &amp; Industrial Tech)\nYes. Good afternoon. Thank you very much for taking the questions. With the FSD trials that Tesla has been offering to consumers and the attention on self driving more generally, are you able to comment more specifically on what you're seeing with FSD subscription trends and take rates and help us better understand how large FSD revenue may be currently?\n\n**Vaibhav Taneja** (CFO)\nSo we've definitely like, I I mentioned it my in my opening remarks. Since we have launched version 12 of FSD in North America, we've definitely seen a marked improvement in the FSD adaption. And this the other thing which we had also done last year is we did bring down the pricing, and we've made subscription much more affordable. So we have seen, you know, 25% increase since that time. So which is an encouraging trend.\n\n**Vaibhav Taneja** (CFO)\nBut, honestly, we we've just started the story around explaining the benefits of FLD. We like I said before, we released our wake up safety report. Even if you don't believe in this anything else, a car on FSD being 10x safer should be a motivator. Plus, the other thing is people don't realize even at $99 a month, it's like you're getting a personal chauffeur almost $3.33 a day. And this is by far the biggest game changer, which I know we've been talking about it because part of it is we live and breathe it. But\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI feel like Most people still don't know.\n\n**Vaibhav Taneja** (CFO)\nYeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nBut the the vast majority people don't know it exists, and it's still, like, half of Tesla owners who could use it haven't tried it even once. This they don't actually realize. Obviously, this is something we wanna educate them on.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nSo we've gotta when they come in for service, we'll reach out to them, send them, like, videos of how to make it work. And most most it it's so it's such a shocking thing. They don't they don't think a car is capable of this. So you have to have you have to show them and and and get them comfortable with turning it on and off. It's so trivial, but it's yeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nIt's like saying you've got a a cat there. Can you sing and dance? But it just looks like an old cat. And you're like, you know, until you see the cat sing and dance and talk, like, you assume it's just a cat. That's that's Tesla FC.\n\n**Vaibhav Taneja** (CFO)\nYes, sir.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nOur car is intelligent.\n\n**Vaibhav Taneja** (CFO)\nAnd so what we are gonna do to Elon's point, like, we've been giving people free time to try and try the SSD, but we'll start giving more prompts to say, okay. This particular drive, try FSD. So that I mean, because it's literally seeing is believing. Like Elon said, it's think of it like a cat. It looks like a normal cat, but this cat can sing in ads.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah.\n\n**Vaibhav Taneja** (CFO)\nSame thing on Intelligence.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. Yeah. And that 25 comment was 25% increase in the penetration rate since we've seen the release of of v 12 and v 13 in North America. Great. Thank you. Mark, did you have a follow-up question?\n\n**Mark Delaney** (US Autos &amp; Industrial Tech)\nYeah. Thanks, Travis. Tesla has historically said it would use pricing as one tool to help drive auto vehicle growth as long as free cash flow stayed positive, given the ability to monetize products like FSD. I'm curious how you're thinking about pricing from here as a potential tool to drive increased volumes, given where you stand with FSD as well as the fact that the IRA purchase tax credits are poised to go away in The U. S.\n\n**Mark Delaney** (US Autos &amp; Industrial Tech)\nStarting in the fourth quarter. So should we expect more meaningful price reductions given that monetization potential? Or do you envision price reductions being more limited compared to cost downs given where free cash flow now stands? Thanks.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nWell, we're we're in this, like, weird transition period where we'll lose a lot of incentives in The US. There's a lot of incentives actually in many other parts of world, but we'll lose them in The US. And but we'll still look at the relatively early stages of autonomy. On the other hand, autonomy is most advanced and most available from a regulatory standpoint in The US. So, I mean, does that mean, like, we could have a few rough quarters?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYeah. We probably could have a few rough quarters. I'm not saying we will, but we could. Q, you know, q four, q one, maybe q two. But once you get to autonomy at scale in the second half half of next year, certainly by the end of next year, I think the I'd be surprised if if Tesla's economics, are not, very compelling.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. The next question is gonna come from, Will from Truist. Will, please, feel free to unmute yourself when you're ready.\n\n**William Stein** (MD &amp; Senior Analyst)\nGreat. Thanks so much for taking my questions. First, I'd like to ask for a little bit more detail about the lower cost model that you talked about having, I think, started production in the first half, but you said we'll ramp later. At the last analyst days, I recall, you talked about some aspects of this, like, two two thirds or three quarters reduction in silicon carbide and not using rare earths in the in the motor and perhaps other cost downs. You also had this unboxed architecture that I think you said would not be part of this sort of interim approach.\n\n**William Stein** (MD &amp; Senior Analyst)\nCan you update us on what we should expect this thing to actually look like?\n\n**Vaibhav Taneja** (CFO)\nOh, we won't get into the looks because Yeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nYou gotta watch the model work. Yeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nThey'll lift the cat out the bag there. Dancing cat that can sing and dance. But it can it talk and sing and dance, though. That's the cool part. Yeah.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI mean, the the the fundamentally, the biggest obstacle remains that people just don't have enough some people don't the the desire to buy the car is very high. Just people don't have enough money in in the bank account to buy it. Literally, that is the issue. Not not a lack of desire, but a lackability. So the more affordable we can make the car, the better.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nI think it's it's gonna be it won't be a very big deal when people can release their car to the fleet and have it earn money for them, which I like I said, I'm think I feel confident in saying that'll happen next year in The US at least. And and in The US, we're we're legally allowed, you know, appropriate disclaimers. And and that'll make the affordability dramatically greater. Just like, you know, you could you if if you have an Airbnb and you and you rent out your your home when you're not there or rent out a a guest room or guest house or something like that, your the affordability of your home is much greater.\n\n**William Stein** (MD &amp; Senior Analyst)\nOkay. Trying another, another topic then. Can you know, we we see all these wonderful developments at x AI like Grok. And, you know, obviously, Tesla's trying to do quite a bit in AI. Elon, how do you manage the division of efforts and recruiting and talent and capital between these two that that seem like there's a very high potential that they can, in fact, compete?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nWell well, are doing different things here. So, you know, the XAI is doing, like, you know, terabyte scale models and, multiterabyte scale models. You know, Tesla's a 100 times smaller models. So one's real world AI and one's kind of, I guess, artificial superintelligence type of thing. The I mean, the really kind of the the genesis for XAI was that there there there were certain people who some people would not join Tesla, AI engineers, because they wanted to work on ASI, and they would join Tesla.\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nAnd I was like, well, maybe they'll join a new company. And now I I think the Tesla problem is extremely important, but not everyone agrees with me on that. And so rather than have them join, you know, OpenAI or Google or or some other company, it's like, might as well have them create a company in that regard for it, which is, like, which is like AI. So that's, you know and and, you know, people can make a make a decision. Do they wanna work on, like, super intelligence at data center or real world AIs?\n\n**Elon Musk** (Technoking of Tesla, CEO &amp; Director)\nKinda they're they're both compelling problems, but some people wanna work on one and some wanna work on the other. Yeah.\n\n**Travis Axelrod** (Head of Investor Realtions)\nGreat. And, unfortunately, that is all the time we have today. Thank you everyone so much for your questions, and we will see you next quarter.",
        "fetched_at": "2026-02-04T16:12:37.431Z"
      },
      {
        "ticker": "TSLA",
        "title": "Yahoo Finance",
        "published_date": "Apr 22, 2025, 5:30 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/TSLA/earnings/TSLA-Q1-2025-earnings_call-310668.html",
        "content": "**Travis Axelrod** (Head of Investor Relations)\nGood afternoon, everyone, and welcome to Tesla's first quarter 2025 Q&A webcast. My name is Travis Axelrod, Head of Investor Relations, and I'm joined today by Elon Musk, Vaibhav Taneja, and a number of other executives. Our Q1 results were announced at about 3:00 P.M. Central Time in the update deck we published at the same link as this webcast. During this call, we will discuss our business outlook and make forward-looking statements. These comments are based on our predictions and expectations as of today. Actual events or results could differ materially due to a number of risks and uncertainties, including those mentioned in our most recent filings with the SEC. During the question-and-answer portion of today's call, please limit yourself to one question and one follow-up. Please use the raise hand button to join the question queue. Before we jump into Q&A, Elon will be providing an update. Elon?\n\n**Elon Musk** (CEO)\nHello, everyone. It's never a dull moment these days. Thanks, for sure. Every day is going to be exciting. As some people know, there's been some blowback for the time that I've been spending in government with the Department of Government Efficiency, or DOGE. I think the work that we're doing there is actually very important for trying to rein in the insane deficit that is leading our country, the United States, to destruction. The DOGE team has made a lot of progress in addressing waste and fraud. The natural blowback from that is those who were receiving the wasteful dollars and the fraudulent dollars will try to attack me and the DOGE team and anything associated with me. I'm really left with two choices.\n\n**Elon Musk** (CEO)\nShould we just let the waste and fraud continue, and always continuing at it to grow at a really unsustainable pace that was bankrupting the country, or to fight the waste and fraud and try to get the country back on the right track? I believe the right thing to do is to just fight the waste and fraud and get the country back on the right track and working together with President Trump and his administration. Because if the ship of America goes down, we all go down with it, including Tesla and everyone else. I think this is critical work. The protesters that you'll see out there, they're very organized. They're paid for.\n\n**Elon Musk** (CEO)\nThey're obviously not going to say, admit that the reason that they're protesting is because they're receiving fraudulent money or that they're the recipients of wasteful largesse, but they're going to come up with some other reason. That is the real reason for the protests. The actual reason is that those receiving the waste and fraud wish to continue receiving it. That is the real thing that's going on here, obviously. Now, that said, I do think there's the large slug of work necessary to get the DOGE team in place and working in the government to get the financial house in order is mostly done. I think starting probably next month, May, my time allocation to DOGE will drop significantly.\n\n**Elon Musk** (CEO)\nI'll have to continue doing it for, I think, probably the remainder of the president's term just to make sure that the waste and fraud that we stop does not come roaring back, which it will do if it has the chance. I think I'll continue to spend a day or two per week on government matters for as long as the president would like me to do so and as long as it is useful. Starting next month, I'll be allocating far more of my time to Tesla now that the major work of establishing the Department of Government Efficiency is done. At Tesla, we've gone through many crises over the years and actually been through many near-death experiences. We probably were on the ragged edge of death at least maybe a dozen times. It's been so many times. This is not one of those times.\n\n**Elon Musk** (CEO)\nWe're not on the ragged edge of death, not even close. There are some challenges, and I expect that this year will be there'll probably be some unexpected bumps this year. I remain extremely optimistic about the future of the company. The future of the company is fundamentally based on large-scale autonomous cars and large-scale, large-volume, vast numbers of autonomous human-like robots. The value of a company that makes truly useful autonomous human-like robots and autonomous useful vehicles at scale, at low cost, which is what Tesla is going to do, is staggering. I continue to believe that Tesla, with excellent execution, will be the most valuable company in the world by far. That's an important if. We must execute well. If we do execute well, I think Tesla will be the most valuable company in the world by far.\n\n**Elon Musk** (CEO)\nIt may be as valuable as the next five companies combined. There will be a few bumps along the road before that happens. I said, I think, on the last earnings call that we'll start to see the prosperity of autonomy take effect in a material way around the middle of next year. We expect to have these be selling fully autonomous rides in June in Austin, as we've been saying for now several months. That has continued. The real question from a financial standpoint is, when does it really become material and affect the bottom line of the company and start to be a fundamental part of the, when does it move the financial needle in a significant way? That is probably around the middle of next year, second half of next year.\n\n**Elon Musk** (CEO)\nOnce it does start to move the financial needle in a significant way, it will really go exponential from there. I'd encourage people to look beyond the sort of bumps and potholes of the road immediately ahead of us, but lift your gaze to the bright, shining citadel on a hill, I don't know, some Reagan-esque imagery. That's where we're headed. In the not too distant future, like I said, end of next year type of thing. Let's see. With respect to supply chain risk, something that Tesla has been working on for several years is to localize supply chains. This actually makes sense from a cost standpoint and from a logistics risk standpoint, to have the supply chains be at least located on the continent in which the car is built.\n\n**Elon Musk** (CEO)\nWe are, I think, the least affected car company with respect to tariffs, at least in most respects. I mean, remains to be seen. Tariffs are still tough on a company when margins are still low. We do have localized supply chains in North America, Europe, and China. That puts us in a stronger position than any of our competitors. Undoubtedly, I'm going to get a lot of questions about tariffs. I just want to emphasize that the tariff decision is entirely up to the President of the United States. I will weigh in with my advice with the President, which he will listen to my advice, but then it's up to him, of course, to make his decision. I've been on the record many times saying that I believe lower tariffs are generally a good idea for prosperity.\n\n**Elon Musk** (CEO)\nThis decision is fundamentally up to the elected representative of the people, being the President of the United States. I'll continue to advocate for lower tariffs rather than higher tariffs, but that's all I can do. Let me walk you through why I'm so excited about the future of Tesla. First of all, autonomy. The team and I are laser-focused on bringing robotaxi to Austin in June. Unsupervised autonomy will first be solved for the Model Y in Austin. Actually, we should parse out the terms robotic taxi or robotaxi and just generally what's the CyberCab, because we've got a product called the CyberCab. Any Tesla, which could be an S, 3, X, or Y that is autonomous, is a robotic taxi or robotaxi. It's a bit confusing.\n\n**Elon Musk** (CEO)\nThe vast majority of the Tesla fleet that we've made is capable of being a robotaxi or a robotic taxi. Once we can make the system work where you can have paid rides fully autonomously with no one in the car in one city, that is a very scalable thing for us to go broadly within whatever jurisdiction allows us to operate. Because what we're solving for is a general solution to autonomy, not a city-specific solution for autonomy, once we make it work in a few cities, we can basically make it work in all cities in that legal jurisdiction. Once we can make it work in a few cities in America, we can make it work anywhere in America.\n\n**Elon Musk** (CEO)\nOnce we can make it work in a few cities in China, we can make it work anywhere in China, likewise in Europe, limited only by regulatory approvals. This is the advantage of having a generalized solution using artificial intelligence and an AI chip that Tesla designed specifically for this purpose, as opposed to very expensive sensors and high-precision maps of a particular neighborhood where that neighborhood may change or often changes, and then the cost stops working. We have a general solution instead of a specific solution. With regards to Optimus, we're making good progress in Optimus. We expect to have thousands of Optimus robots working in Tesla factories by the end of this year, doing useful work. We expect to scale Optimus faster than any product, I think, in history to get to millions of units per year, as soon as possible.\n\n**Elon Musk** (CEO)\nI think I feel confident in getting to a million units per year in less than five years, maybe four years. By 2030, I feel confident in predicting a million Optimus units per year. It might be 2029. Let's see. With respect to energy, our energy business is doing very well. The Megapack enables utility companies to output far more total energy than would otherwise be the case. When you think of the energy capability of a grid, it's much more than the total energy output per year. If the power plants could operate at peak power for all 24 hours as opposed to being at half power or sometimes a quarter power at night, you could double the energy output of existing power plants.\n\n**Elon Musk** (CEO)\nIn order to do that, you need to buffer the energy so that you can charge up something like a battery pack at night and then discharge into the grid during the day. This is a massive unlock on total energy output of any given grid over the course of a year. Utility companies are beginning to realize this and are buying in our Megapacks at scale. At this point, a gigawatt-class battery is quite a common thing. We have many orders in the offer for gigawatt and beyond batteries. We expect the stationary energy storage business to scale ultimately to terawatts per year. Very, very good numbers.\n\n**Elon Musk** (CEO)\nNow, the first quarters of a year are usually pretty tricky because it's usually the worst quarter of the year because people don't want to go buy a car in the middle of winter during a blizzard. We picked Q1 as a good quarter to do a cutover to the new version of the Model Y. We changed production of the world's best-selling cars, remembering the Model Y is the best-selling car of any kind on Earth, with a 1.1 million unit per year output of a single model. We did this changeover at the same time in factories all across the world. Congratulations to the Tesla team on an amazing job in pulling off what is a very difficult transition. It's really very impressive work. Yeah.\n\n**Elon Musk** (CEO)\nIn conclusion, while there are many near-term headwinds for us in the motor industry, the future for Tesla is brighter than ever. The value of the company is delivering sustainable abundance with our affordable AI-powered robots. I like this phrase, sustainable abundance for all. If you say, \"What's the ideal future that you can imagine?\" That's what you'd want. You'd want abundance for all in a way that's sustainable, it's good for the environment. Basically, this is the happy future. If you say, \"What's the happiest future you can imagine?\" One that would be a future where there's sustainable abundance for all. Closest thing to heaven we can get on Earth, basically. Thank you again to the Tesla team for all their efforts at this challenging time. I look forward to continuing to lead the team to great success in the future.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much, Elon.\n\n**Travis Axelrod** (Head of Investor Relations)\nBefore we move on, Vaibhav has some opening remarks as well.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nThanks, Elon. As Elon mentioned, in Q1, we achieved something which has never been undertaken in the automotive industry of updating all our factories for the best-selling car in the world all at the same time. People don't understand this was not a small feat. We're not aware of anybody else being able to do the best-selling car all at once within a quarter, and that too hitting all the timelines which we had established at the beginning. Big kudos to the team for making this happen. Additionally, we also hit a record gross profit for our energy storage business in the quarter. Now, getting back into the business, there has been a lot of speculation as to the reasons for decline of our vehicle deliveries in the first quarter.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nWe had previously guided that we will be updating all factories, and this would lead to several weeks of lost production, which did happen as planned. The ripple effect of the change is not having enough new Model Y available in most markets for people to see and experience till the last few weeks of the quarter. Additionally, the negative impact of vandalism and unwarranted hostility towards our brand and our people had an impact in certain markets. Despite this, we were able to sell out legacy Model Y in the U.S., China, and a few other markets within the quarter. Just so people understand, we were producing the legacy Model Y till middle to end of February. We switched over, and we were able to still sell out within that period. Big achievement by all the people at Tesla to make it happen.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nWe have a very extremely competitive vehicle lineup, which with most vehicles going through a recent update. Add to that advances in FSD, you have a personal chauffeur which can take you almost anywhere under supervision. There are numerous stories shared by customers ranging from how it has improved their daily commute to providing mobility to customers with disabilities to giving older customers the ability to travel comfortably and independently. Not only is FSD supervised safer than a human driver, but it is also improving the lives of individuals who experience it. This is something you have to experience, and anybody who has experienced just knows it. We have been doing a lot lately, trying to get those stories out, at least on X, so that people can see how other people have benefited from this.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nNow, coming into some of the financial stuff, auto margins declined sequentially, primarily due to the reduction in the total number of deliveries, lower fixed cost absorption due to factory changeovers, and lower regulatory credit revenues offset by a slight increase in pricing due to the launch of new Model Y, despite incentives which we had to sell legacy Model Y. Our energy storage business, like I said before, has achieved yet another milestone of highest gross profit in the quarter. This was despite sequential decline in deployments. The importance of this business, as Elon mentioned, is pretty profound, especially in this environment, because in order for grids to work properly with the demands from AI and all this, you need some more stability. This is by far the simplest and best solution which we are aware of, which can help do this.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nWe have also developed certain unique solutions to help our customers to achieve this. Additionally, on the Powerwall side, we have been selling the new Powerwall 3, and it has been received with very good reception from customers and to the extent that we are currently supply constrained. On services and other margins, they were slightly down sequentially, primarily because of the pressure on our used car business and insurance business. Note that we continued our journey to improve profitability in our services and collision business through better labor productivity. As previously discussed, our operating expenses continued to increase sequentially, primarily due to our AI-related initiatives, including Optimus, and also cost of development for vehicle programs, including CyberCab, Semi, and cheaper models. These expenses flow through R&D.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nWe believe, even in the current environment, it is the right strategy to keep making investments in these areas to position us for the long term. These increases were offset by decreases in SG&A from changes in our vehicle referral program. Other income reduced significantly on a sequential basis. The primary reason was Bitcoin mark-to-market loss in Q1 versus gain in Q4, resulting in a $472 million drop. The remainder of the change is because of FX remeasurement. With the adoption of the new mark-to-market standard for Bitcoin, we expect increased volatility in other income in addition to the FX liquidity. I know tariffs is the hottest topic which people talk about, and it has various impacts to our business. As Elon mentioned, on the vehicle business, we've been on this journey of regionalization for years.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nSpecifically, in the U.S., Model Y has been rated the most American-made car on Cars.com America-Made Index three years in a row. This is part of all the work which the team has been doing over the years. To the extent that today, if you look at our vehicle lineup in the U.S., we're approximately, on a weighted average basis, 85% USMCA compliant. Like Elon said, this definitely gives us a bigger edge as compared to our other OEMs in terms of managing the tariffs. We're not immune because when the Section 232 auto tariffs become effective in May, which includes Canada and Mexico, and Canada and Mexico have been part of our regionalization strategy, they will have an impact on profitability.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nI know research modeling on this impact has been about a couple of thousand gigawatts, which is pretty much in line with what we've been forecasting. The impact of tariffs on the energy business will be outsized since we source LFP battery cells from China. We're in the process of commissioning equipment for the local manufacturing of LFP battery cells in the U.S. However, the equipment which we have can only service a fraction of our total installed capacity later on. We've also been working on securing additional supply chain from non-China-based suppliers, but it will take time. Also note that Megafactory, irrespective of all the impact on the U.S. from tariffs on the energy business, we do have Megafactory China, which just started operations in Q1, and that should take care of our business outside of the U.S.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nThere's also an important impact of tariffs on our capital investments. I know this is going to sound counterintuitive since in order to onshore manufacturing or expand lines, we have to bring equipment from outside the U.S. because there is not that much capacity in the U.S. In the current trade environment, such equipment being brought in is subject to the\n\n**Elon Musk** (CEO)\nexpenses bringing in from China right now.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nExactly. The reality is that China has the basic one which has the most capacity to provide this equipment. Our CapEx guidance, inclusive of model tariffs, even with the optimization we have tried to do, is forecasted to be still in excess of $10 billion this year. We're still evaluating what more to do on this side. To summarize, we have near-term challenges in our business due to tariffs and bad image.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nWe think our strategy of providing the best product at a competitive price is going to be a winner. This is the reason we're still focused on bringing cheaper models to market soon. The start of production is still planned for June. Additionally, the advancement in FSD-related features, including pilot Robotaxi launch in Austin later this year, should help create a new era of demand. I would like to thank everyone at Tesla and our customers.\n\n**Travis Axelrod** (Head of Investor Relations)\nFantastic. Thank you very much, Vaibhav. Now we will move on to investor questions. We will start with questions from saytechnologies.com. First question is, what are the highest risk items on the critical path to Robotaxi launch and scaling?\n\n**Elon Musk** (CEO)\nIt is Ashok.\n\n**Travis Axelrod** (Head of Investor Relations)\nYeah, we've got Ashok on the line.\n\n**Elon Musk** (CEO)\nSure. Just to back, we're just stopped by the just to ambiguate the CyberCab from Robotaxi once again.\n\n**Elon Musk** (CEO)\nWhen will the Teslas, because the Teslas that will be fully autonomous in June in Austin will be Model Ys. That is currently on track to be able to do paid rides fully autonomously in Austin in June. Then to be in many other cities in the U.S. by the end of this year. It's difficult to predict the exact ramp sort of week by week and month by month, except that it will ramp up very quickly. It's going to be like basically an S curve where it's very difficult to predict the intermediate slope of the S curve, but you kind of know where the S curve is going to end up, which is the vast majority of the Tesla fleet being autonomous.\n\n**Elon Musk** (CEO)\nThat's why I feel confident in predicting large-scale autonomy around the middle of next year, certainly the second half of next year. Meaning, I predict that there will be millions of Teslas operating fully autonomously in the second half of next year. Yeah. It does seem increasingly likely that there will be a localized parameter set for sort of especially for places that have, say, very snowy weather, like say if you're in the northeast or something. You can think of it, it's kind of like a human. If you can be a very good driver in California, but are you going to be also a good driver in a blizzard in Manhattan? You're not going to be as good. There is actually some value in you can still drive, but your probability of an accident is higher.\n\n**Elon Musk** (CEO)\nIt's increasingly obvious that there's some value to having a localized set of parameters for different regions and localities. That put that in the nice-to-have category. It's not the required category. Again, really, the car is just very much like a human. It's digital neural nets and cameras, and humans operate with biological neural nets and eyes. The same strengths and weaknesses will be present for a digital neural net and cameras versus a biological neural net and eyes. Ashok, if you'd like to elaborate on that.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nYeah. Speaking to the location-specific models, we still have a generalized approach. You can see that from our deployment of FSD supervised in China, where with just very minimal data that's China-specific, the models generalize quite well to completely different driving styles.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nThat just shows that the AI-based solution that we have is the right one because if you had gone down the previous rule-based solutions or more hardcoded HTML-based solutions, it would have taken many, many years to get China to work. You can see those in the videos that people post online themselves. The generalized solution that we are pursuing is the right one that's going to scale well. You can think of this location-specific parameters that Elon alluded to as a mixture of experts. If you're sort of familiar with the AI models like Grok and others, they all use this mixture of experts to sort of specialize the parameters to specific tasks while still being general. This makes the model use a limited amount of compute to solve for the diversity of tasks that it has to solve.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nIn terms of addressing the question that asks for what are the critical things that need to get right, one thing I would like to note is validation. Self-driving is a long-tail problem where there can be a lot of edge cases that only happen very, very rarely. Currently, we are driving around in Austin using our QA fleet, but then it's super rare to get interventions that are critical for Robotaxi operation. You can go many days without getting a single intervention. You can't easily know whether you are improving or regressing in your capacity. We need to build out sophisticated simulations, including neural network-based video generation.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nThat's all happening in the background to make sure that we deliver a safe product and we are able to measure our safety, even though we can't just see it by driving around the block or something like that.\n\n**Elon Musk** (CEO)\nI mean, very basic terms. If we're seeing an accident every 10,000 miles, well, then you have to drive 10,000 miles on average before you get an accident or an intervention. It's like, okay. I mean, people must be very worried now by the sheer number of Teslas doing circuits in Austin right now. We're like, it's going to look pretty bizarre. Yeah. Some people are chasing us away. Yeah. There's just always a convoy of Teslas going all over to Austin in circles. I just can't emphasize this enough.\n\n**Elon Musk** (CEO)\nIn order to figure out long-tail things, if it's 1 in 10,000, let's say it's 1 in 20,000 miles or 1 in 30, then the average person drives 10,000 miles in a year. Now try to compress that test cycle into a matter of a few months. That means you need a lot of cars doing a lot of driving in order to compress that or do in a matter of a month what would normally take someone a year.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nI would just also add that if you haven't looked at those videos coming out of China, people are really\n\n**Elon Musk** (CEO)\noh yeah, those videos are amazing.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nThey're putting it to real test. I mean, they're taking the dirt roads.\n\n**Elon Musk** (CEO)\nFrankly, I think the Chinese consumer might be the most demanding consumer. Actually, our customers in China are awesome.\n\n**Elon Musk** (CEO)\nThey have a lot of fun with the cars. I saw one guy take a Tesla autonomously on a narrow dirt road across a mountain. I'm like, \"I'm still a very brave person.\" The Tesla's driving along on a road with no barriers. Wherever he makes a mistake, he's going to plunge to his doom. It worked.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you.\n\n**Speaker 12** (Company Representative 1)\nIf the question was on CyberCab itself, we're in B sample validation now. Yeah, yeah. We should ask that question too. We have our first big builds coming at the end of this quarter in Q2. In the coming months, we start large-scale installation of all the equipment in Giga Texas, still on schedule for production next year.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nYeah. I just want to also clarify because I think people do not understand the thing that there is no new building being built. Where is CyberCab going to place? Oh, it is in the same factory.\n\n**Speaker 13** (Company Representative 2)\nYeah, yeah. It is happening. People do not even know it is just happening upstairs and along the lines while we are still building the Model Ys and Cybertrucks every day. Yeah.\n\n**Elon Musk** (CEO)\nYeah. It is worth noting that the Tesla Gigafactory in Austin is three times the size of the Pentagon, including the garden. Yeah. Yeah. Including the Ground Zero garden. I go to the Pentagon, I am like, \"This building used to look big, but then you will not.\"\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much. The next question is, when will FSD unsupervised be available for personal use on personally owned cars? Before the end of this year.\n\n**Elon Musk** (CEO)\nNot necessarily everylet's say within the U.S., we do want to test. At Tesla, we're absolutely hardcore about safety. We go to great lengths to make the safest car in the world and have the lowest accidents per mile and fewest lives lost. We want to be very careful. We want autonomy to be definitively safer than manual driving. It's not enough that it just be as safe. It needs to be meaningfully safer than if it's cars manually driven. We want to confirm that. There's not somethingwe just want to be cautious with the rollout. We don't want to jump in at the deep end with an army. That said, I think people should be able to have it work in several cities later this year for personal use.\n\n**Elon Musk** (CEO)\nThe asset test being, you should be able tocan you go to sleep in your car and wake up at your destination? I'm confident that will be available in many cities in the U.S. by the end of this year.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much. The next question is, is Tesla still on track for releasing more affordable models this year, or will you be focusing on simplified versions to enhance affordability similar to the rear-wheel drive Cybertruck?\n\n**Speaker 14** (Company Representative 3)\nYeah. We're still planning to release models this year. As with all launches, we're working through the last-minute issues that pop up. We're knocking them down one by one. At this point, I would say that ramp maybe might be a little slower than we had hoped initially, but there's nothing just kind of given that turmoil that exists in the industry right now.\n\n**Speaker 14** (Company Representative 3)\nThere is nothing that's blocking us from starting production within the timeline we laid out in the opening remarks. I will say it's important to emphasize that, as we've said all along, the full utilization of our factories is the primary goal for these new products. Flexibility of what we can do within the form factor and the design of it is really limited to what we can do on our existing lines rather than building new ones. We've been targeting the low cost of ownership. Monthly payment is the biggest differentiator for our vehicles. That's why we're focused on bringing these new models with the lowest price to the market within the constraints I just highlighted.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much. The next question is, does Tesla see Robotaxi as a winner-take-most market?\n\n**Travis Axelrod** (Head of Investor Relations)\nAs you approach the Austin launch, how do you expect to compare against Waymo's offering, especially regarding pricing, geofencing, and regulatory flexibility?\n\n**Elon Musk** (CEO)\nThe issue with Waymo's cars is they cost way more money. That is the issue. Their cars are very expensive, made in low volume. Teslas are, I don't know, probably cost a quarter or 20% of what a Waymo costs and made in very high volume. Ironically, we're the ones that made the bet that a pure AI solution with cameras and audio, the car actually will listen for sirens and that kind of thing, is the right move. Waymo decided that an expensive sensor suite was the way to go, even though Google's very good at AI. Ironically.\n\n**Elon Musk** (CEO)\nIt is worth noting that Tesla's built an incredible AI software team and AI hardware chip design team from scratch, from nothing. We didn't acquire anyone. We just built it. Yeah, it's reallyI mean, I don't see anyone being able to compete with Tesla at present. I'm sure that'll change eventually. At least as far as I'm aware, Tesla will have, I don't know, 99% market share or something ridiculous. 90-something percent, at least. I don't know. Some of them might change, but if we have millions of cars deployed next year and unless others have millions of cars deployed, we'll haveunless we're blocked by regulatory situations, it won't be long. I mean, in a few years, we'll have 10 million autonomous cars on the roads and counting.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nThe other thing which people forget is we're not just developing the software solution.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nWe are also manufacturing the cars. Like what Waymo has, they're taking cars and then trying to put Waymo money. We don't do that. That definitely gives us a big leg up. Like Elon said, we already have a big existing fleet, which hopefully with the software update could become autonomous soon.\n\n**Elon Musk** (CEO)\nWith the software update, it will become autonomous. To be clear, the Model Ys that we're talking about in being autonomous in Austin in June are the Model Ys we make currently. There's no change to it.\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nI think people don't appreciate that the car which they can buy today\n\n**Elon Musk** (CEO)\nthe car that they have\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nor the car they have is capable of these kinds of things.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nIn fact, it does drive autonomously from the factory to the end of line, every car.\n\n**Speaker 13** (Company Representative 2)\nYeah. It's like a truck through the tunnel. The Model Ys, everything.\n\n**Elon Musk** (CEO)\nRight. Yeah. Exactly. It is inputted to use. It's doing useful work fully autonomously at the factories, as Ashok was mentioning. The cars drive themselves from end of line to where they're supposed to be picked up by a truck to be taken to a customer. I'm confident also that later this year, the first Model Y will drive itself all the way to the customer. From our factory in Austin and our one here in Fremont, California, I'm confident that from both factories, we'll be able to drive directly to a customer from the factory. Tool delivery. Yeah. Literally goes from the end of line and drives itself to your house.\n\n**Speaker 13** (Company Representative 2)\nIt's important to note in the factories, we don't have dedicated lanes or anything. People are coming in and out every day, trucks delivering supplies, parts, construction.\n\n**Elon Musk** (CEO)\nPeople can film it. By the way, you can see this from the road. It's uncovered.\n\n**Speaker 13** (Company Representative 2)\nExactly.\n\n**Elon Musk** (CEO)\nThere are videos. People take videos online. Anyone who wants to go see it can just drive past our Fremont factory and see the autonomous cars driving themselves. They drive themselves and they put themselves in the exact right spot to be picked up.\n\n**Speaker 13** (Company Representative 2)\nYeah. The logistics yard is right there in the open.\n\n**Speaker 13** (Company Representative 2)\nYou can see it. We do not move it again to another lane.\n\n**Elon Musk** (CEO)\nThey go to a specific parking spot.\n\n**Speaker 13** (Company Representative 2)\nYeah.\n\n**Elon Musk** (CEO)\nYeah. That is just a routine, everyday thing that is great.\n\n**Travis Axelrod** (Head of Investor Relations)\nThank you very much. The next question is, can you please provide an update on the unboxed method and how that is progressing?\n\n**Speaker 14** (Company Representative 3)\nSure. It is progressing. Absolutely. As I mentioned just a minute ago, it is the basis for our CyberCab manufacturing process.\n\n**Speaker 14** (Company Representative 3)\nIt's really what we changed in order to allow the low cost of production and also get the super high levels of automation. Really, levels of automation that are sort of unheard of in the vehicle manufacturing scale. This is not something that when you see it be produced, you'll think of in terms of, \"Wow, that's how a car has been built for 100 years.\" It's really something we've changed. In the past year, we've been focusing on a lot of key development areas, like marrying these large sub-assemblies together in a precise way, in an accurate way. We've also de-risked things like corrosion of uncoated aluminum structures, the sealing across the seams of the vehicle when you marry assembled components. We've even done early crash testing and proven that it's going to be just as safe as every other car we've built.\n\n**Speaker 14** (Company Representative 3)\nWith all that combined, we kind of go into the builds that we have at the end of this quarter for the CyberCab product. That is the next real big test of full-scale integration of the unboxed process. Yeah, that is kind of where we are. You will see them in test and on the test roads in a couple of months.\n\n**Elon Musk** (CEO)\nYeah. Although the line will not be upset at this rate.\n\n**Speaker 14** (Company Representative 3)\nInitially.\n\n**Elon Musk** (CEO)\nInitially. This is a revolutionary production system. I am not sure what the right word is. Unboxing sounds like something like when you get your phone. Yeah.\n\n**Speaker 14** (Company Representative 3)\nYou open it up.\n\n**Elon Musk** (CEO)\nYeah. You have a pleasant experience when you take your phone out of the box, which, of course, is nice, but this is much more revolutionary than that. This is a profound reimagining of how to make cars in the first place.\n\n**Elon Musk** (CEO)\nNo car is made like this anywhere in the world. The factory is the product as much as the car is the product. It is really just the first principles approach to manufacturing that will ultimately allow us, I think, toI'm trying to think. I'm confident ultimately it'll allow us to achieve a cycle time, meaning a unit every five seconds or less, or for single line.\n\n**Speaker 13** (Company Representative 2)\nWe want to incorporate some of these for testing into our existing production lines as well to do that with the one Cybertruck already.\n\n**Elon Musk** (CEO)\nI mean, this is something I've been thinking about for a long time. I've sort of been thinking about this for a long time. It is kind ofnot a crazy thing. A car every five seconds may sound like it's coming out like bullets, but actually, it's coming out at walking speed.\n\n**Speaker 16**\nIt's like a meter a second.\n\n**Elon Musk** (CEO)\nA meter a second. This iswe're still far away from caring about the aerodynamic drag of the manufacturing line, because you're still at 3 miles an hour type of thing.\n\n**Speaker 16**\nWe live just like us.\n\n**Elon Musk** (CEO)\nYou know, every five seconds sounds crazy, but it's 3 miles an hour that we're talking about. Yeah, you can run away from it, basically. That is still by far the fastest line on earth. I don't know. It's like half hour, half order maintenance, kind of. What's the best thing in line? I don't know if it's like about\n\n**Speaker 16**\nShanghai phase 2.\n\n**Elon Musk** (CEO)\nAnd that's us?\n\n**Speaker 16**\n33 seconds. Yes.\n\n**Elon Musk** (CEO)\nAnd we're the fastest, right?\n\n**Speaker 16**\nI would think so.\n\n**Elon Musk** (CEO)\nWe think we're the fastest at 33 seconds in our Shanghai factory. This would be six times faster or seven times faster or less.\n\n**Elon Musk** (CEO)\nYeah, I mean, it'll be slower than that at first. The point is that when you fully optimize the design and operation of the next generation factory that we're building right now, a five-second cycle time or less is the design is capable of it. If youwhen you go through a radical new architecture, you go from being an AI mean, I'd say probably Shanghai in particular is an A-plus on a moderately advanced but still traditional car production system. Sort of they're really doing about as good as possible to do within a conventional scenario. Trying to get much below sort of below like 30 seconds is extremely difficult. You start getting into sort of impossible where you have to be faster than a human could possibly move. The autonomous line, it really just needs to be robust, moving really fast.\n\n**Elon Musk** (CEO)\nThat's where you get to sub-five seconds. We'll start off with getting a C instead of an A, getting a C in a new architecture. The potential is there over time to move that up to an A-plus within an A-plus architecture.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much. The next question is, how is Tesla positioning itself to flexibly adapt to global economic risks in the form of tariffs, political biases, etc.?\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nAs Elon said, we've been a supply chain team for a while. We continue to mitigate global economic risks like tariffs and political biases by regionalizing parts supply near its factories in North America, Berlin, and Shanghai. For example, in North America, our high-volume vehicle programs have over 85% North America content, and Shanghai vehicles have over 95% local content.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nBerlin has similar levels of regionalization as North America when you exclude the battery, and we are working on regionalizing the battery as well. This is a pre-pandemic strategy that we accelerated post-pandemic through supplier diversification, dual sourcing, vertical integration, advanced analytics, and local partnerships to ensure supply chain resilience and production stability. Having said that, we are not 100% insulated, and these tariff rates are higher on our low-volume platforms than the high-volume ones.\n\n**Elon Musk** (CEO)\nYeah. In fact, there's no more vertically integrated car company than Tesla. I mean, we're the most vertically integrated car company since Henry Ford back in the day when they were doing mining iron and stuff and growing rubber trees. We are not growing rubber trees and mining iron yet. We have built a lithium refinery in South Texas, and it's the biggest lithium refinery outside of China, I think.\n\n**Elon Musk** (CEO)\nIs that right?\n\n**Speaker 16**\nYeah. I think so.\n\n**Speaker 16**\nWhat wasn't selling?\n\n**Elon Musk** (CEO)\nBut its output potential would be the biggest lithium refinery outside. We've got space to expand there if we need to build more. Right. We've got the cathode refinery in Austin next to the Gigafactory. We're going to figure out what to do about the anode. It's an ongoing subject of discussion. The best of all possible worlds would be figuring out how to have no anode. Best part being no part. That's the dream of the lithium batteries, to not have an anode. Either way, we better have the anode, the cathode, the lithium, the electrolytes, and the separator to make a cell. There's no other car company that has built lithium refineries and cathode refineries, ridiculously vertically integrated. That's our best position to protect against supply chain disruptions. Yeah.\n\n**Speaker 16**\nAnyone want to talk about the progress in the front?\n\n**Elon Musk** (CEO)\nYeah. Certainly, for our in-house cells, we've multi-sourced every component. We have every part coming from at least two different countries, large, which is we started this. The supply chain team and the engineering team worked together on this for the last couple of years to put that together. It's not something we did in a couple of months. This is years of work. We are in a good position to take advantage of that. The insourcing of lithium and cathodes, they're the two most critical parts of the battery that's right in our backyard, and we're totally insulated from.\n\n**Elon Musk** (CEO)\nThey need to be in operation.\n\n**Speaker 16**\nThey need to be in operation.\n\n**Speaker 16**\nThat's the right line.\n\n**Elon Musk** (CEO)\nWe also make our own cells, by the way.\n\n**Elon Musk** (CEO)\nCell production, if you look, there's this, you make the anode, the cathode, the lithium, the electrolyte separator, the can, and then you got to put all that together in the cell factory. There are entire companies that all they do is produce cells, but they don't do the other stuff. They don't refine lithium or the cathode or so our cell production is going quite well. I think we're currently sort of the lowest cost per kilowatt hour in the U.S. for all the cells we purchase in North America. Yeah. It's lowest cost to us. Yeah. We have the lowest cost per kilowatt hour, all things considered. The Tesla cell is the most competitive cell. Yeah. For a kilowatt hour put into a car, if it's a Tesla cell, it's lower cost than if it's a supplier cell.\n\n**Elon Musk** (CEO)\nYeah. Yeah. The plan this year is to really build off that base. Getting to lowest cost, it's the hardest challenge for the cell manufacturing. It's relatively easy to build a flashy product that does one thing well. To build something at high volume and low cost is super difficult. We're kind of using that as a base to then build off and add performance in different areas for new products coming out.\n\n**Speaker 15** (Company Representative 4)\nYeah. I mean, to Elon's point, there's a lot of advantages for regionalization. The most important thing is we're not tying up working capital for six to eight weeks on the ocean. If there's a design change, then everything that's in transit basically has to be scrapped. Secondly, port disruptions, as we saw during COVID, can be very expensive because slight disconnects can shut down production. Your only option is costly air expedite.\n\n**Speaker 15** (Company Representative 4)\nIt also gives us resilience in supply chain. If one region is down, we can bridge with others. It's more work to set up in the beginning, but it's critical to have when the need arises. Having said that, it's unrealistic to assume 100% regionalization across the board for specialized areas such as semiconductors. In such cases, our team works very closely with our partners to ensure we have strategic banks in place, and a disruption doesn't impact production while we stand up the regional manufacturing for that particular commodity. I'll say on the rest of the vehicle, like Elon was talking about with cells, we're also heavily vertically integrated. Import ingots, in terms of the castings, we recycle those in melts. There's the same thing with plastics. It doesn't mean we're not exposed.\n\n**Speaker 15** (Company Representative 4)\nWe do have some areas where we use rear-array magnets, and we've been working for years to find alternative sources and bring those up, as well as we have our induction machines. As we've mentioned in the past, we're working on our ferrite numbers for some time. As Karn said, with our heavy regionalization percentages, we're definitely the lowest exposed to this, but we're not completely immune as I've mentioned in so many other words.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Similarly related, on the battery side, does Tesla still have a battery supply constraint, as noted on the Q4 call? Does that change with tariffs?\n\n**Steven Karn** (Specialist Three)\nThis is Karn. We've been working very hard to expand battery cell production in the U.S., both with vendors and what Bonnie mentioned earlier with the 4680 program.\n\n**Steven Karn** (Specialist Three)\nWe're also working on moving the upstream supply chain for battery cells to the United States for several years. That strategy is really starting to pay off now. As it stands right now, we're not constrained on battery cell supply for vehicles. The recent tariffs do pose some challenges to Tesla Energy, like our CFO mentioned earlier. It's something we've been anticipating, and we should be able to resolve in a timely fashion. We actually have a plan in place where we're executing towards it. We also have some other sources coming online to supplement the shortfall. Of course, we have the LFP production that's happening in-house. We have a slight disconnect of aligning the right cells with the right path. That's the little bit of puzzle that we have to solve internally. As far as cells go, there's no shortage.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much. The next question is, did Tesla experience any meaningful changes in order inflow rate in Q1 relating to all of the rumors of brand damage?\n\n**Speaker 13** (Company Representative 2)\nIn Q1, as mentioned earlier, we took the best-selling car of the last two years and ramped up all four of our global factories. In less than eight weeks, we've already gone to the rate of our previous Model Ys in the factories. Just kudos again to the team for the great job there. Despite the economic strain and negative articles in California in Q1, Tesla remained the best-selling car, not just EV. Additionally, we had a record number of test drives globally in Q1 as well. Interest remains high. Right now, we continue to see good interest still in the vehicle.\n\n**Elon Musk** (CEO)\nYeah. I mean, Tesla is not immune to sort of the macro-demand for cars. When there is economic uncertainty, people generally want to pause on buying during a major capital purchase like a car. As far as absent macro issues, we do not see any reduction in demand.\n\n**Speaker 13** (Company Representative 2)\nCorrect. That is where we continue to focus on affordability. It is fun to focus there. Yeah.\n\n**Travis Axelrod** (Head of Investor Relations)\nFantastic. Thank you, guys. The next question is, regarding the Tesla Optimus pilot line, could you confirm if it is currently operational? If so, what is the current production rate of Optimus bots per week? Additionally, how might the recent tariffs impact the scalability of this production line moving forward?\n\n**Elon Musk** (CEO)\nI want to just emphasize, Optimus is still very much a development program. It is not a large volume production that is quiet. This year, we will make a few.\n\n**Elon Musk** (CEO)\nWe do expect to make thousands of Optimus robots, but most of that production is going to be at the end of the year. Almost everything in Optimus is new. There's not an existing supply chain for the motors, gearboxes, electronics, actuators, really anything in the Optimus, apart from the Tesla AI computer, which is the same as the one in the car. When you have a new complex manufactured product, it'll move as fast as the slowest and least lucky component in the entire thing. As a first-order approximation, there's like 10,000 unique things. That's why anyone who tells you they can predict with precision the production ramp of a truly new product doesn't know what they're talking about. It is literally impossible.\n\n**Elon Musk** (CEO)\nYou go through this series of constraints where it's like this part's the limiting factor, now that part's the limiting factor, now this part's the limiting factor, and multiply that by 1,000, basically. The rate of the production ramp is decided by how quickly you can solve each of those problems. Optimus was affected by the magnet issue from China because the Optimus actuators in the arm do use permanent magnets. Tesla as a whole does not need to use permanent magnets. When something is volume constrained, like an arm of the robot, you want to try to make the motors as small as possible. We did design in permanent magnets for those motors, and those were affected by the supply chain by basically China requiring an export license to send out any rare earth magnets.\n\n**Elon Musk** (CEO)\nWe're working through that with China. Hopefully, we'll get a license to use the rare earth magnets. China wants some assurances that these are not used for military purposes, which obviously they're not. They're just going into a humanoid robot. It's not a weapon system. That is an example of a challenge there. I'm confident we'll overcome these issues, and we'll, by the end of this year, have thousands of Optimus robots.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you very much. The last question we already covered earlier, whether Robotaxi was still on track for this year. With that, we can move on to analyst questions. The first question is going to come from Pierre at New Street. Pierre, please unmute yourself.\n\n**Pierre Ferragu** (Analyst)\nHey, guys, can you hear me?\n\n**Travis Axelrod** (Head of Investor Relations)\nYeah.\n\n**Pierre Ferragu** (Analyst)\nThat's great. I'm super excited to hear Robotaxi and Optimus becoming the very tangible future for Tesla.\n\n**Pierre Ferragu** (Analyst)\nI have actually a question on the legacy, not the legacy, but the current auto business. When I look back at the ramp of Model 3 a few years ago, I really saw it as being the iPhone of cars, a new product, completely reinvented, very different user experience, vastly superior, impossible to match for traditional competitors. For the iPhone, it resulted in the high end of the smartphone market quadrupling in size and actually Apple taking 60% market share. When you look at the Model 3 and the Model Y today, I think they are still really vastly superior to any other cars. I wonder why they've taken about 15% of their addressable market and not more, actually.\n\n**Pierre Ferragu** (Analyst)\nAnother way to put it is, why are there so many people still buying BMWs and Mercedes knowing that the Model 3 and the Model Y are out there and available? I wonder if you're trying to solve that rather internally, if you understand why, what are these auto buyers who are not buying a Model 3 or a Model Y missing? If you have ideas of things you could do to address that, maybe there is enormous value left on the table there. That's what I'm wondering these days.\n\n**Elon Musk** (CEO)\nThe reality is that in the future, most people are not going to buy cars. It is kind of, one could sort of say, look, if you want to continue with your phone metaphor, I mean, you can remember the days of the flip phones when there were 100 different flip phone designs.\n\n**Elon Musk** (CEO)\nThe mistake that manufacturers made was to try to make many different variants of a flip phone, which was a mistake. They should have made the iPhone. Obviously, everyone's going to want a smartphone. In the beginning of when the iPhone came out, I was like, wow, I can't believe these guys are not reacting as though this is death. They kept making variants of flip phones. Nokia, I think at one point was the most valuable company in the world or close to it. They kept making flip phones, trying to find another market niche. Maybe somebody wants a phone of a different style, maybe this different color or whatever it is. Nope, they just want a super intelligent phone that can do everything. Just one.\n\n**Elon Musk** (CEO)\nI said this many years ago, in the future, in the not too distant future, buying a gasoline car that is not autonomous will be like riding a horse while using a flip phone. Some people still do it, but it's rare.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you. The next question comes from Emmanuel Rosner at Wolfe Research. Emmanuel, please unmute yourself.\n\n**Emmanuel Rosner** (Managing Director and Senior Autos and Auto Tech Analyst)\nGreat. Thanks for taking my question. Elon, the public version of the FSD software still has a decent amount of, I guess, intermittent human interventions that are required. What's still required for the software on your end to get to a level where it doesn't need to be supervised? I'm asking that in the context of, obviously, the June launch being in the next couple of months. What still needs to happen?\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nWe are working on a number of items too. Yeah.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nI mean, we are aware of the interventions that are happening in the public builds. That is why we are hardcore burning it down. Really speaking, some initial launch city helped us focus on solving all the issues that you'd face here. For example, like we're focusing on Austin, we're not solving all the issues that customers in Boston or somewhere else might face. Here, we just have a big list of all the issues, just burn it down. That is what the team is working on, along with other sort of redundancy issues. For example, if one of the computers goes down, right down the customer fleet, it would throw the red hands and ask you to take over. We do not want that kind of situation.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nWe're solving both the reliability issues of the autonomy software and also the reliability issues of the system software together for Austin.\n\n**Elon Musk** (CEO)\nYeah. We just worked through a long tail of unusual interventions. These are really very rare. As I was saying earlier, intervention every 10,000 miles. I mean, that's a lot of driving you've got to do to even find one case within Austin's.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nYeah. Some interventions are systematic missing functionality, for example, for handling emergency vehicles correctly. You don't need to consume audio as an input. The customer-facing versions don't have audio input. The version that's going to be in Austin will have audio input and so on.\n\n**Emmanuel Rosner** (Managing Director and Senior Autos and Auto Tech Analyst)\nOkay. Would you have remote operators, for example?\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nI mean, every now and then, if a car gets stuck or something, someone will unblock it.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nIt is just because we are a bit conservative and tend towards more safety than even if it gets stuck every now and then, we do have remote support. It is not going to be required for safe operation. If anything, it is just required for more availability.\n\n**Elon Musk** (CEO)\nAnyway, it is only a couple of months away. You can just see for yourself in a couple of months in Austin.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Our next question comes from Edison at Deutsche Bank. Edison, please unmute yourself.\n\n**Edison Yu** (Analyst)\nHi. Thank you very much for the question. I want to ask about the Optimus supply chain going forward. You mentioned very fast ramp-up. What do you envision that supply chain looking like? Is it going to require many more suppliers to be in the U.S. now because of the tariffs? How does one kind of think about what needs to happen there?\n\n**Elon Musk** (CEO)\nWe have to see how things settle out. I don't know yet. I mean, some things we're doing, as we've already talked about, which is that we've already taken command steps to localize our supply chain. We're more localized than any other manufacturer. We have a lot of things underway to increase the localization to reduce supply chain risk associated with geopolitical uncertainty.\n\n**Travis Axelrod** (Head of Investor Relations)\nDid you have a follow-up, Edison?\n\n**Edison Yu** (Analyst)\nYeah. I wanted to come back actually to the Robotaxi then. Do you have a sense on how many cars or how big the scale will be initially and how that might ramp up? I know you're targeting millions of vehicles in the second half kind of of next year. Initially, at launch, how many vehicles would be reasonable?\n\n**Edison Yu** (Analyst)\nIs it going to be as simple as if one goes to Austin, let's say, in late June or July, you'd be able to request?\n\n**Elon Musk** (CEO)\nYeah. We're still debating the exact number to start off on day one. It's, I don't know, maybe 10 or 20 vehicles on day one. We watch it carefully. They scale it up rapidly after that. We want to make sure that we're paying very close attention the first time this happens. Yeah, you'll be able to end of June or July, just go to Austin and order a Tesla or autonomous drive.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. The next question comes from George at Canaccord.\n\n**George Gianarikas** (Analyst)\nHi. Thank you for taking my question. It has to do with FSD pricing.\n\n**George Gianarikas** (Analyst)\nCould we envision when you launch unsupervised FSD that there could be sort of a multi-tiered pricing approach to unsupervised versus supervised similar to what you did with Autopilot versus FSD in the past? Thank you.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nI mean, this is something which we've been thinking about. I mean, just so you know, for people who have been trying FSD and who've been using FSD, they think given the current pricing is too cheap because for $99, you're basically getting a personal show.\n\n**Elon Musk** (CEO)\nYeah. I mean, we do need to give people more time to if they want to look at a key breakpoint is, can you read your text messages or not? Can you write a text message or not? Because obviously, people are doing this, by the way, with un-autonomous drivers all the time.\n\n**Elon Musk** (CEO)\nIf you just go for a drive down the highway, you'll see people texting while driving, doing 80 miles an hour, and putting on makeup at the same time. Yeah, putting on makeup, doing their hair with the mirror down, and texting and driving at 80 miles an hour. This is a common occurrence. Eating lunch, you name it. Shaving. Anyway, right now, the car is very insistent that you pay attention to the road, which reduces the value somewhat because it's very rigorous about you paying attention to the road. We'll gradually lighten up on that every few weeks or every month. We'll relax that a little bit, make it so you can be more and more able to do things you want to do and not have the car demand your rigid attention.\n\n**Elon Musk** (CEO)\nThat value, it'll really be profound when you can basically do whatever you want, including sleep. And then that $99 is going to seem like the best $99 you've ever spent in your life.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. George, did you have a follow-up?\n\n**George Gianarikas** (Analyst)\nMy follow-up is about geographic expansion. Just maybe discuss additional markets. There's been some news around India recently that you could launch this year and next. Thank you.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nYeah, I mean, we've been working on getting into India. India is a very hot market. Especially the current, and I don't want to talk just about tariffs, but the current tariff structure with India is that any car which we send in is subject to 70% tariff. It's also like a 30% luxury tax on it. So the same car which we're sending is like 100% more expensive than what it is.\n\n**Ashok Elluswamy** (VP of AI Software and Director of Auto Pilot Software)\nThat creates a lot of anxiety as people feel, okay, they're paying too much for the car. By the way, we're not getting the money. The local government is getting the money. That is why we've been very careful trying to figure out when is the right time. Like I said, we are working on it. It would be a great market to enter because India has a big middle class, which we would want to tap in. That is the market which we want to be in. Again, these kinds of things create a little bit of tension, which we're trying to work around.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. Thank you so much. The next question comes from Adam Jonas at Morgan Stanley. Go ahead, Adam. We can't hear you, Adam.\n\n**Travis Axelrod** (Head of Investor Relations)\nMaybe we'll put you back in the queue, and we'll move to Colin Langen from Wells Fargo while Adam figures out his audio. Colin, please unmute yourself.\n\n**Colin Langan** (Analyst)\nOh, great. Do you hear me? Yes. Oh, great. You're still sticking with the vision-only approach. A lot of autonomous people still have a lot of concerns about sun glare, fog, and dust. Any color on how you anticipate on getting around those issues? Because my understanding, it kind of blinds the camera when you get glare and stuff.\n\n**Elon Musk** (CEO)\nActually, it does not blind the camera. We use an approach which is direct photon count. When you see a processed image, so the image that goes from the sort of photon counter, the silicon photon counter, that then goes through a digital signal processor or image signal processor, that's normally what happens.\n\n**Elon Musk** (CEO)\nThe image that you see looks all washed out because if you point the camera at the sun, the post-processing of the photon counting washes things out. It actually adds noise. Quite a big breakthrough that we made some time ago was to go with direct photon counting and bypass the image signal processor. You can drive pretty much straight at the sun. You can also see in what appears to be the blackest of night. Here in fog, we can see as well as people can. Probably better, but I'd say probably slightly better than people, than the average person anyway.\n\n**Colin Langan** (Analyst)\nThe camera is able to see when there's direct glare on it. I'm not surprised by that. Okay. There were obviously media reports the other day that the affordable model was delayed.\n\n**Colin Langan** (Analyst)\nDoesn't sound like that's correct. Those reports also talked about it being more of a cheaper version of the Model Y. Any color on what we should expect? Is it a cheaper version of the Model Y, or is it actually going to be a design change with it?\n\n**Vaibhav Taneja** (Chief Accounting Officer and CFO)\nI think Lars already covered it in answering one of the saytechnologies.com questions. The real thing which we are trying to focus on is affordability. Using our existing lines, there's always limitations when you're using existing lines as to how many different form factors you can bring through. That's the way I would say you should think about it. I don't know if Lars had anything more to add.\n\n**Lars Moravy** (VP of Vihicle Engineering)\nYeah. I think I said this before in other calls.\n\n**Lars Moravy** (VP of Vihicle Engineering)\nWith the recent upgrades to the Model 3 and the Model Y platforms, we made some pretty great cars at pretty great prices. We added a bunch of features and things like that. I think it's easy to consider that moving forward, Tesla doesn't make bad cars. We always make our intent is not to make a car that is any worse than any car we've ever produced in the past. The models that come out in the next months will be built on our lines, and will resemble in form and shape the cars we currently make. The key is that they'll be affordable, and you'll be able to buy one.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. We might have time for one last question. Adam, we'll try your audio again. Do you want to try to unmute yourself, Adam? All right. Unfortunately, still not working.\n\n**Travis Axelrod** (Head of Investor Relations)\nOh,\n\n**Adam Jonas** (Analyst)\nsorry.\n\n**Travis Axelrod** (Head of Investor Relations)\nThere you go.\n\n**Adam Jonas** (Analyst)\nSorry, guys. Technology.\n\n**Travis Axelrod** (Head of Investor Relations)\nGo ahead, Adam.\n\n**Adam Jonas** (Analyst)\nYeah. Hi. Yeah. In the February 28th Joe Rogan interview, Elon, you advocated for a ramp in tariffs to give people time to adjust. Otherwise, you said the system would break and bad things would happen. Are things breaking yet? If the tariffs as announced remain in place, when would things start breaking?\n\n**Elon Musk** (CEO)\nAt the risk of stating the obvious, I'm not. I mean, I'm one of many advisors to the president. I'm not the president. I've made my opinion clear to the president. Other people made their opinion clear to the president. He talks to many people, and he makes his decision. I'm hopeful that the president will observe whether my predictions are more accurate than the predictions of others and perhaps weigh my advice differently in the future. We shall see.\n\n**Elon Musk** (CEO)\nI'm an advocate of predictable tariff structures. Generally, I'm an advocate for free trade and lower tariffs. Now, one does need to take a look at where if some country is doing something predatory with tariffs or is providing extreme support for, if a government is providing extreme financial support for a particular industry, then you have to do something to counteract that. I think that that's on a case-by-case basis strategically. The president is the elected representative of the people, and it's fully within his rights to do what he would like to do.\n\n**Adam Jonas** (Analyst)\nOkay, Elon. I respect that. Just as a follow-up, and thanks again. Between China and the United States, who in your opinion is further ahead on the development of physical AI, specifically on humanoids and also drones? I'd be interested. Is it even close in kind of how? Yeah. Serious.\n\n**Elon Musk** (CEO)\nI think you know the answer for drones.\n\n**Elon Musk** (CEO)\nI mean, a friend of mine involved made this posted on X. I reposted it. I think a prophetic statement, which is, \"Any country that cannot manufacture its own drones is doomed to be the vassal state of any country that can.\" America cannot currently manufacture its own drones. That is it, again. Unfortunately. China, I believe, manufactures about 70% of all drones. If you look at the total supply chain, China is almost 100% of drones have a supply chain dependency on China. China is in a very strong position. Here in America, we need to shift more of our people and resources to manufacturing because this is I have a lot of respect for China because I think China is amazing, actually.\n\n**Elon Musk** (CEO)\nThe United States should not have such a severe dependency on China for drones and be unable to make them unless China gives us the parts, which is currently the situation. With respect to humanoid robots, I don't think there's any company in any country that can match Tesla. Tesla and SpaceX are number one. Now, I'm a little concerned that on the leaderboard, ranks 2 through 10 will be Chinese companies. I'm confident that rank one will be Tesla.\n\n**Travis Axelrod** (Head of Investor Relations)\nGreat. I think that's, unfortunately, all the time we have for today. We appreciate all your questions and look forward to talking to you next quarter. Thank you very much, and goodbye.",
        "fetched_at": "2026-02-04T16:12:41.593Z"
      }
    ]
  },
  "TSM": {
    "ticker": "TSM",
    "last_updated": "2026-02-04T16:13:17.477Z",
    "total_transcripts": 4,
    "transcripts": [
      {
        "ticker": "TSM",
        "title": "Yahoo Finance",
        "published_date": "Jan 15, 2026, 1:00 AM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/TSM/earnings/TSM-Q4-2025-earnings_call-399056.html",
        "content": "**Jeff Su** (Director of Investor Relations)\nGood afternoon, everyone, and welcome to TSMC's fourth quarter 2025 earnings conference and conference call. My name is Jeff Hsu, TSMC's Director of Investor Relations and your host for today. Today's event is being webcast live through TSMC's website at www.tsmc.com, where you can also download the earnings release materials. If you are joining us through the conference call, your dial-in lines are in listen-only mode. The format for today's event will be as follows. First, TSMC's Senior Vice President and CFO, Mr. Wendell Huang, will summarize our operations in the fourth quarter 2025, followed by our guidance for the first quarter 2026. Afterwards, Mr. Huang and TSMC's Chairman and CEO, Dr. C.C. Wei, will jointly provide the company's key messages. Then we will open both the floor and the line for the question-and-answer session as usual.\n\n**Jeff Su** (Director of Investor Relations)\nI would like to remind everybody that today's discussions may contain forward looking statements that are subject to significant risks and uncertainties which would cause actual results to differ materially from those contained in the forward looking statements. Please refer to the safe harbor notice that appears in our press release.\n\n**Jeff Su** (Director of Investor Relations)\nAnd now I would like to turn the microphone over to TSMC CFO Mr. Wendell Huang for the summary of operations and the current quarter guidance.\n\n**Wendell Huang** (CFO)\nThank you, Jeff. Good afternoon, everyone. Thank you for joining us today. My presentation will start with financial highlights for the fourth quarter of 2025 and a recap of full year 2025 after that. I will provide the guidance for the first quarter of 2026. Fourth quarter revenue increased 5.7% sequentially in NT$ supported by strong demand for our leading-edge process technologies. In U.S. dollar terms, revenue increased 1.9% sequentially to $33.7 billion, slightly ahead of our fourth quarter guidance. Gross margin increased by 2.8 percentage points sequentially to 62.3%, primarily due to cost improvement efforts, favorable foreign exchange rate, and the high capacity utilization rate. The operating expenses accounted for 8.4% of net revenue compared to 8.9% in third quarter of 2025 due to operating leverage. Thus, operating margin increased sequentially by 3.4 percentage points to 54% overall.\n\n**Wendell Huang** (CFO)\nOur fourth quarter EPS was TWD 19.5 and ROE was 38.8%. Now let's move on to revenue by technology. 3 nm process technology contributed 28% of wafer revenue in the fourth quarter while 5 nm and 7 nm accounted for 35% and 14% respectively. Advanced technologies defined as 7 nm and below accounted for 77% of wafer revenue on a full year basis. 3 nm revenue contribution came in at 24% of 2025 wafer revenue, 5 nm 36% and 7 nm 14%. Advanced technologies accounted for 74% of total wafer revenue up from 69% in 2024. Moving on to revenue contribution by platform, HPC increased 4% quarter over quarter to account for 55% of our fourth quarter revenue.\n\n**Wendell Huang** (CFO)\nSmartphone increased 11% to account for 32%, IoT increased 3% to account for 5%, Automotive decreased 1% to account for 5% while DCE decreased 22% to account for 1% on a full year basis. HPC increased 48% year over year. Smartphone, IoT, and Automotive increased by 11%, 15%, and 34% respectively in 2025 while DCE remains flat. Overall, HPC accounted for 58% of our 2025 revenue, Smartphone accounted for 29%, IoT accounted for 5%, Automotive accounted for 5%, and DCE accounted for 1%. Moving on to the balance sheet, we ended the fourth quarter with cash and marketable securities of TWD 3.1 trillion or $98 billion. On the liabilities side, current liabilities increased by TWD 182 billion quarter over quarter mainly due to the increase of TWD 95 billion in accrued liabilities and others and the increase of TWD 61 billion from the reclassification of bonds payable to current portion.\n\n**Wendell Huang** (CFO)\nIn terms of financial ratios, accounts receivable days increased by one day to 26 days. Inventory days remain steady at 74 days. Regarding cash flow and CapEx, during the fourth quarter we generated about TWD 726 billion in cash from operations, spent TWD 357 billion in CapEx and distributed TWD 130 billion for first quarter 25 cash dividend. Overall, our cash balance increased TWD 297 billion to TWD 2.8 trillion at the end of the quarter. In US dollar terms, our fourth quarter capital expenditures total $11.5 billion. Now let's look at the recap of our performance in 2025. Thanks to the strong demand for our leading edge process technologies, we continue to outperform the foundry industry. In 2025 our revenue increased 35.9% in US dollar terms to $1 billion or increased 31.6% in NT dollar terms to TWD 3.8 trillion.\n\n**Wendell Huang** (CFO)\nGross margin increased 3.8 percentage points to 59.9% mainly reflecting a higher capacity utilization rate and cost improvement efforts partially offset by an unfavorable foreign exchange rate and margin dilution from our overseas fabs. With operating leverage, our operating margin increased 5.1 percentage point to 50.8%. Overall full year EPS increased 46.4% to 66.25 NT and ROE increased 5.1 percentage point to 35.4%. In 2025 we generated 2.3 trillion NT in operating cash flow, spent 1.3 trillion NT or $40.9 billion on capital expenditures. As a result, free cash flow amounted to 1 trillion NT, up 15.2% from 2024. Meanwhile, we paid 467 billion NT in cash dividends in 2025, up 28.6% year over year as we continue to increase our cash dividend per share.\n\n**Wendell Huang** (CFO)\nTSMC shareholders receive a total of TWD 18 cash dividend per share in 2025 up from TWD 14 in 2024 and they will receive at least TWD 23 per share in 2026. I have finished my financial summary. Now let's turn to our current quarter guidance. We expect our business to be supported by continued strong demand for our leading edge process technologies. Based on the current business outlook, we expect our first quarter revenue to be between $34.6 billion and $35.8 billion which represents a 4% sequential increase or a 38% year-over-year increase. At the midpoint. Based on the exchange rate assumption of $1 to TWD 31.6, gross margin is expected to be between 63% and 65%. Operating margin between 54% and 56%. Lastly, our effective tax rate was 16% in 2025. For 2026 we expect our effective tax rate to be between 17% and 18%.\n\n**Wendell Huang** (CFO)\nThis concludes my financial presentation. Now let me turn to our key messages. I will start by talking about our fourth quarter 2025 and first quarter 2026 profitability. Compared to third quarter, our fourth quarter gross margin increased by 280 basis points sequentially to 62.3% primarily due to cost improvement efforts, a more favorable foreign exchange rate and a higher overall capacity utilization rate. Compared to our fourth quarter guidance, our actual gross margin exceeded the high end of the range provided three months ago by 130 basis points mainly as we delivered better than expected cost improvement efforts. In addition, the actual fourth quarter exchange rate was $1 to TWD 31.01 as compared to our guidance of $1 to TWD 30.6.\n\n**Wendell Huang** (CFO)\nWe have just guided our first quarter gross margin to increase by 170 basis points to 64% at the midpoint primarily driven by continued cost improvement effort including productivity gains and a higher overall capacity utilization rate partially offset by continued dilution from our overseas fabs. Looking at full year 2026, given the six factors, there are a few puts and takes I would like to share. On the one hand, we expect our overall utilization rate to moderately increase in 2026. N3 gross margin is expected to cross over to the corporate average sometime in 2026 and we continue to work hard to earn our value. In addition, we are leveraging our manufacturing excellence to drive greater productivity in our fabs to generate more wafer output. We are also increasing across node capacity optimization which includes flexible capacity support among N7, N5 and N3 nodes to support our profitability.\n\n**Wendell Huang** (CFO)\nOn the other hand, as the scale of our overseas expansion grows, we continue to forecast the gross margin dilution from the ramp up of overseas fabs in the next several years to be between 2%-3% in the early stages and widen to 3%-4% in the latter stages. Furthermore, the initial ramp up of our 2 nanometer technology will start to dilute our gross margin in the second half of the year and we expect between 2%-3% dilution for the full year of 2026. Finally, we have no control over the foreign exchange rate, but that may be another factor in 2026. Next, let me talk about our 2026 capital budget and depreciation at TSMC. A higher level of capital expenditures is always correlated to the high growth opportunities in the following years.\n\n**Wendell Huang** (CFO)\nWith our strong technology, leadership and differentiation, we are well positioned to capture the multi year structure demand from the industry megatrends of 5G, AI and HPC. In 2025 we spent $40.9 billion as compared to $29.8 billion in 2024 as we began to raise our level of capital spending in anticipation of the growth that will follow in the future years. In 2026 we expect our capital budget to be between $52 billion-$56 billion as we continue to invest to support our customers growth. About 70%-80% of the 2026 capital budget will be allocated to advanced process technologies, about 10% will be spent for specialty technologies and about 10%-20% will be spent for advanced packaging, testing, mask making and others.\n\n**Wendell Huang** (CFO)\nOur depreciation expense is expected to increase by high-teens % year over year in 2026 mainly as we ramp our 2-nanometer technologies. Even as we invest in the future growth with this level of CapEx spending in 2026, we remain committed to delivering profitable growth to our shareholders. Finally, let me talk about TSMC's long-term profitability outlook. As a foundry, our biggest responsibility is to support our customers' growth and we always view them as partners. Having said that, we are in a very capital-intensive business. In the last five years alone our CapEx totaled $167 billion. Our R&D investments totaled $30 billion. Therefore, it is important for TSMC to earn a sustainable and healthy return as we continue to invest in leading-edge specialty and advanced packaging technologies to support our customers' growth.\n\n**Wendell Huang** (CFO)\nToday we face increasing manufacturing cost challenges due to the rising cost of leading nodes. For example, the cost of tools are becoming more expensive and process complexity is increasing. As a result, the CapEx dollar required to build 1K wafers per month capacity of N2 is substantially higher than 1K wafers per month capacity. For N3, the CapEx per K cost for A14 will be even higher. We also face additional cost challenges from expansion of our global manufacturing footprint, new investments in specialty technologies and inflationary costs. These all lead to a higher level of CapEx spending. As a result, in the last three years our CapEx dollars amounted to $101 billion but is expected to be significantly higher in the next three years.\n\n**Wendell Huang** (CFO)\nHaving said that, we continue to work closely with our customers to plan our capacity while sticking to our disciplines to ensure a healthy overall capacity utilization rate through the cycle. Our pricing will remain strategic, not opportunistic. To earn our value, we will work diligently with our suppliers to drive greater cost improvements. We will also leverage our manufacturing excellence to generate more wafer output and drive greater across node capacity optimization in our FAB operations to support our profitability. By taking such actions, we believe a long term gross margins of 56% and higher through the cycle is achievable and we can earn an ROE of high 20s% through the cycle by earning a sustainable and healthy return.\n\n**Wendell Huang** (CFO)\nEven as we shoulder a greater burden of CapEx investment for our customers, we can continue to invest in technology and capacity to support their growth while delivering long-term profitable growth to our shareholders. We also remain committed to a sustainable and steadily increasing cash dividends per share on both an annual and quarterly basis.\n\n**Wendell Huang** (CFO)\nNow let me turn the microphone over to C.C. Wei.\n\n**C.C. Wei** (Chairman and CEO)\nThank you, Wendell. Good afternoon everybody. First let me start with our 2026 outlook. In 2025 we observed robust AI related demand throughout the whole year while non AI end market segment bottomed out and saw a mild recovery. Concluding 2025, the Foundry 2.0 industry which we define as all logic, wafer manufacturing, packaging, testing, mask making and others increased 16% year over year supported by our strong technology differentiation and broader customer base. TSMC's revenue increased 35.9% year over year in U.S. dollar terms outperforming the Foundry 2.0 industry growth entering 2026. We understand there are uncertainties and risk from the potential impact of tariff policies and rising component prices, especially in consumer related and price sensitive other bucket segment. As such, we will be prudent in our business planning while focusing on the fundamentals of our business to further strengthen our competitive position.\n\n**C.C. Wei** (Chairman and CEO)\nWe forecast the Foundry 2.0 industry to grow 14% year-over-year in 2026 supported by robust AI-related demand underpinned by strong demand for our leading-edge specialty and advanced packaging technologies. We are confident we can continue to outperform the industry growth. We expect 2026 to be another strong growth year for TSMC and forecast our full-year revenue to increase by close to 30% in U.S. dollar terms. Next, let me talk about AI demand and TSMC's long-term growth outlook. Recent development in the AI market continue to be very positive. Revenue from AI accelerator accounted for high-teens % of our total revenue in 2025. Looking ahead, we observe increasing AI model adoption across consumer enterprise and sovereign AI segment. This is driving need for more and more computation which supports the robust demand for leading-edge silicon.\n\n**C.C. Wei** (Chairman and CEO)\nOur customers continue to provide us with their positive outlook. In addition, our customers, and many of the cloud service providers, are also providing strong signals and reaching out directly to request the capacity to support their business. Thus, our conviction in the multi-year AI megatrend remains strong, and we believe the demand for semiconductors will continue to be very fundamental. As a foundry, our first responsibility is to fully support our customers with the most advanced technology and necessary capacity to unleash the AI innovations to address the structural increase in the long-term market demand profile. TSMC works closely with our customers to plan our capacity. This process is continuous and ongoing. In addition, as process technology complexity increases, the engagement time with customers is now at least two to three years in advance.\n\n**C.C. Wei** (Chairman and CEO)\nInternally, as we have said before, TSMC employs a disciplined capacity planning system to assess the market demand from both a top down and bottom up approaches. We focus on the overall addressable megatrend to determine the appropriate capacity to build. Based on our assessment, we are preparing to increase our capacity and stepping up our CapEx investment to support our customers' future growth. We are also putting forward existing fab schedule to the extent possible both in Taiwan and in Arizona. We are also leveraging our manufacturing excellence to drive greater productivity in our fabs to generate more output, convert N5 capacity to support N3 wherever necessary and focus on capacity optimization across nodes to maximize the support to our customers.\n\n**C.C. Wei** (Chairman and CEO)\nBased on our planning framework, we raise our forecast for the revenue growth from AI accelerator to approach a mid to high 50s% CAGR for the five years period from 2024 to 2029. Underpinned by our technology differentiation and broader customer base, we now expect our overall long-term revenue growth to approach 25% CAGR in U.S. dollar terms for the five year period starting from 2024. While we expect AI Accelerators to be the largest contributor in terms of our incremental revenue growth, our overall revenue growth will be fueled by all four of our growth platforms which are smartphone, HPC, IoT and automotive in the next several years. As the world's most reliable and effective capacity provider, we will continue to work closely with our customers to invest in leading-edge specialty and advanced packaging technologies to support their growth.\n\n**C.C. Wei** (Chairman and CEO)\nWe will also remain disciplined in our capacity planning approach to ensure we deliver profitable growth for our shareholders. Now let me talk about TSMC's global manufacturing footprint update. All our overseas decisions are based on our customers' needs as they value some geographic flexibility and a necessary level of government support. This is also to maximize the value for our shareholders. With a strong collaboration and support from our leading U.S. customers and the U.S. federal, state and city government, we are speeding up our capacity expansion in Arizona and executing well to our plan. Our first fab has already successfully entered high volume production in 4Q24. Construction of our second fab is already complete and tool moving and installation is planned in 2026.\n\n**C.C. Wei** (Chairman and CEO)\nDue to the strong demand from our customers, we are also pulling forward the production schedule and now expect to enter high volume manufacturing in the second half of 2027. Construction of our third fab has already started and we are in the process of applying for permits to begin the construction of our fourth fab and fourth advanced packaging fab. Furthermore, we have just completed the purchase of a second large piece of land nearby to support our current expansion plan and provide more flexibility in response to the very strong multi-year AI-related demand. Our plan will enable TSMC to scale up an independent Gigafab cluster in Arizona to support the needs of our leading edge customers in smartphone, AI and HPC applications.\n\n**C.C. Wei** (Chairman and CEO)\nNext in Japan, thanks to the strong support from the Japanese central government and the local government, our first specialty fab in Kumamoto has already started volume production in late 2024 with very good yield. The construction of our second fab has started and the technologies and ramp schedule will be based on our customers need and market conditions in Europe. We have received strong commitment from the European Commission and the German federal, state and city government. Construction of our specialty fab in Dresden, Germany is progressing in our plan. The ramp schedule will be based on our customers need and market conditions in Taiwan. With support from Taiwan government, we are preparing multiple phases of 2nm fabs in both Hsinchu and Kaohsiung Science Park.\n\n**C.C. Wei** (Chairman and CEO)\nWe will continue to invest in leading edge and advanced packaging facilities in Taiwan over the next few years. By expanding our global footprint while continuing to invest in Taiwan, TSMC can continue to be better to be the trusted technology and capacity provider of the global large industry for years to come. Last, let me talk about N2 and A16 status. Our 2 nanometer and A16 technologies lead the industry in addressing the insatiable demand for energy efficient computing. Yet almost all the innovators are working with TSMC. N2 successfully enter high volume manufacturing in 4Q 2025 at both our Hsinchu and Kaohsiung site with good yield. We are seeing strong demand from smartphone and HPC AI applications and expect a fast ramp in 2026. With our strategy of continuous enhancement, we also introduced N2P as an extension of N2 family.\n\n**C.C. Wei** (Chairman and CEO)\nN2P features further performance and power benefit on top of N2, and volume production is scheduled for the second half of this year. We also introduced A16 featuring our best in class Super Power Rail or SPR. A16 is best suitable for specific HPC products with complex signal route and the dense power delivery network. Volume production is on track for second half 2026. We believe N2, N2P, A16 and its derivatives will prepare our N2 family to be another large and long lasting node for TSMC while further extending our technology leadership position well into the future.\n\n**C.C. Wei** (Chairman and CEO)\nThis concludes our key message, and thank you for your attention.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Wendell. Thank you, C.C. This does conclude our prepared statements, so before we begin the Q&A session, I would like to remind everybody to please limit your question to two at a time to allow all the participants an opportunity to ask their questions. Questions will be taken both from the floor and from the call. Should you wish to raise your question in Chinese, I will translate it to English before our management answers your question. For those of you on the call, if you'd like to ask a question, please press the star then one on your telephone keypad. Now questions will be taken in the order they were received. If at any time you'd like to remove yourself from the questioning queue, please press star two. So now let's begin the question and answer session.\n\n**Jeff Su** (Director of Investor Relations)\nI think we'll take the first few questions from the floor here. So why don't we start over here with Gokul Hariharan from J.P. Morgan. Thank you.\n\n**Gokul Hariharan** (Analyst)\nThank you and Happy New Year. So, C.C., it definitely feels like you've heard what your customers have said to you over the last three, four months. Could you give us a little bit more color on what you're hearing from your customers, customers on demand? Because this is a very big step up in the capacity commitment. There is definitely a lot of concern in the financial market, especially about whether we are in a bit of a bubble. And obviously you are the one who is putting up all the capital in this industry, so you've definitely considered this very carefully as well. So give us a little bit more detail in terms of what you're hearing from the customers and your views on this cycle.\n\n**Gokul Hariharan** (Analyst)\nGiven if we think about typical semiconductor cycle, we've already probably lasted a little bit longer than usual cycles, but this definitely doesn't feel like a typical semiconductor cycle.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Gokul, let me summarize your question for the benefit of those online and those in person. So again, Gokul's question is really he would like to hear CC's views about the overall AI related demand and the semiconductor cycle. So again he Gokul notes that as Wendell and Yu said, we are substantially stepping up our CapEx to support the customers. But he does say, you know, there is concerns about an AI bubble and risk. So part of Gokul's question is how, what is the feedback? Any color we can share about what type of discussions and feedback we're getting from both customers and the customers customers that CC mentioned and how long do we think this cycle can last?\n\n**C.C. Wei** (Chairman and CEO)\nOkay, Gokul, you essentially try to ask whether the AI demand is real or not. I'm also very nervous about it. You bet. Because we have to invest about $52 billion-$56 billion for the CapEx, right? If we didn't do it carefully and that would be a big disaster to TSMC for sure. So of course I spend a lot of time in the last three or four months talking to my customer and then customers. Customer. I want to make sure that my customers demand are real. So I talk to those cloud service providers, all of them. Their answer is. I'm quite satisfied with their answer. Actually they show me the evidence that the AI really help their business. So they grow their business successfully and he or she in their financial return. So I also double check their financial status. They are very rich.\n\n**C.C. Wei** (Chairman and CEO)\nThat sounds much better than TSMC. No doubt. I also asked specifically that what's the application? Right? I mean that's for one of the hyperscaler. They told me that that helped their social media software and so the customer continue to increase. I believe that and with our own experience in the AI application, we also help to our own fab to improve the productivity. As I mentioned one time say that 1% or 2% productivity improvement that is free to TSMC. That's why also our gross margin is a little bit satisfied, you know, even in this very high cost period of time. All in all, I believe in my point of view the AI is real. Not only real, is starting to grow into our daily life. We believe that is kind of. We call it AI Megatrend.\n\n**C.C. Wei** (Chairman and CEO)\nWe certainly would believe that. So another question is, can the semiconductor industry to be good for three, four, five years in a row? I'll tell you the truth, I don't know. But I look at the AI looks like it is going to be like endless. I mean that's for many years to come. No matter what. TSMC stick on the fundamental technology, leadership, manufacturing excellence. And we work with customers to get their trust. And I think that fundamental thing why position TSMC to be very good future growth? Let me say that 25% CAGR as we projected. And we used to be conservative, you know that.\n\n**Gokul Hariharan** (Analyst)\nThanks. Thanks, C.C. My second question is on the U.S. expansion. You're pulling in some of the capacity in response to customers. You're already starting plans for the phase four. There's a lot of media reports about TSMC. You might have to build more fabs in the U.S. How should we think about U.S. expansion in principle over the next few years? I think previously you had talked about reaching 20% or even 30% of 2 nanometer capacity in the U.S. eventually the total capacity could be in the U.S. Could you give us a little bit more detail about how that is progressing and when could we get there in terms of the 30% or even 20% capacity?\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Gokul's second question is about our overseas expansion, particularly in the U.S. He notes that C.C. said we are pulling in the schedule for the Fab 2 earlier. You know, we're starting the application for the fourth Fab. And so his question is partly around recent reports that we intend to build more fabs in Arizona. So his question is how should we or how is TSMC thinking about the future expansion in Arizona? And we have said in the past that, you know, around 30% of our nanometer and more advanced capacity would be based in Arizona once we complete scaling out to this independent Gigafab cluster. So what is the time frame or timetable for that? How quickly can we get there?\n\n**C.C. Wei** (Chairman and CEO)\nThat's a long question. We build a fab in Arizona and we work hard. So today everything, even the yield or defect density is almost equal to Taiwan. And due to the strong demand, as I just answered from the AI stronger, that's a megatrend. All my AI customers are in the U.S. So they ask a lot of support from the U.S. So because of that we have to speed up our fab expansion in Arizona in Taiwan also. Actually we increase most of the capacity in Taiwan. No doubt about it, because this is most advanced one. We can progress very well in the U.S. We try to speed it up and progress is very good. We got the help from the government. Still we have to meet all the requirements for the permits or for those kind of things.\n\n**C.C. Wei** (Chairman and CEO)\nBoth in Taiwan and in Arizona we speeded up our capacity expansion to meet the AI demand. I can always say one word, the capacity is very tight. We work very hard to narrow the gap so far probably this year, next year we have to work extremely hard to narrow the gap. We just bought a second land in Arizona. Let's give you a hint. That's what we plan to do because we need it. We are going to expand many fabs over there and this Gigafab cluster can help us to improve the productivity, to drive down the cost and to serve our customer in the U.S. better. Okay.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, thank you Gokul. Let's move over here next to Laura Chen from Citibank please.\n\n**Laura Chen** (Analyst)\nThank you. Thank you CC and Wendell for very comprehensive outlook briefing and also congratulate for the great result. Of course we see that the AI semiconductor growth has seen very strong growth and I believe all of your customer and customers customers very desperate to ask more capacity support from TSMC. But I'm just wondering how does TSMC evaluate the potential power electricity supply for data center? So other than that the chips we can discuss with our customers. I think for the overall infrastructure buildup for data center a lot of factor also very important. Just want to understand more how does TSMC evaluate those key factors for the AI infrastructure buildup? And my first question.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Laura's. First question is around the AI demand. She notes again, as we said, AI megatrend and the growth is very strong and customers and ourselves are strong believers. But when we do our planning, how do we balance this against the other considerations? Do we look at things. For example, I think Laura's question is power electricity grid availability to basically assess is this part of our included as part of our planning process. Do we factor such things in?\n\n**C.C. Wei** (Chairman and CEO)\nLora, let me tell you first I worry about the electricity in Taiwan first. I need to have a lot of enough electricity so I can start to expand the capacity without any limitation. But talking about build a lot of AI data center all over the world, I use one of my customers. I answer because I asked the same question. They told me that they planned this one five, six years ago already. So as I said, those cloud service provider are smart, very smart. If I knew that I would anyway. So they say that they work on the power supply five, six years ago. So today their message to me is silicon from TSMC is a bottleneck and asked me not to pay attention to all others because they have to solve the silicon bottleneck first.\n\n**C.C. Wei** (Chairman and CEO)\nBut indeed we look at the power supply, you know, all over the world, especially in the U.S. Not only that, we also look at who support those kind of power supply like a turbine, like nuclear power plant, the plant, all those kind of things. We also look at the supply of the rack. We also look at the supply of the cooling system. Everything so far so good. So we have to work hard to narrow the gap between the demand and supply from TSMC. Did that answer your question?\n\n**Laura Chen** (Analyst)\nThat's great to know that it would not be the constraints for the further AI developments. Yeah, thank you. And my second question is on the leading edge advanced packaging, when can you remind us that what would be the revenue contribution last year for the advanced packaging overall? First of all, we see that I recall that in the past the CapEx for leading edge advanced packaging, roughly about 10%. Yeah. But now it could be up to like a 20%. So I'm just wondering that for the expansion, can you give us more detail about what kind of the plans you are looking for? Will you focus more on like 3DIC, SoIC or you also start to work on more advanced like a panel base in the longer term?\n\n**Laura Chen** (Analyst)\nI also think before we talk about that, we'll work more closely with OSAT's partner on the leading edge advanced packaging. So just wondering what kind of the process will be the key expansion plan in the space. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Laura's second question is more related to advanced packaging. What was the revenue contribution of what we call the back end, which is advanced packaging testing as a whole in 2025? And then she notes the CapEx, actually this year I believe window, we guided 10%-20% of CapEx, which is the same as last year. But anyways, she wants to know what is the focus of this CapEx? Is, is it on 3DIC, is it on SoIC Packaging Solutions on panel level? Sort of. What is the key areas we're focusing on relative to the CapEx?\n\n**Wendell Huang** (CFO)\nOkay, Laura, the revenue contribution last year from advanced packaging is close to 10%. It's about 8% for this year. We expect it to be slightly over 10%. We expect it to grow in the next five years higher or faster than the corporate and the CapEx. Yes, you're right. In the past is about 10% lower than 10%. Now we're saying advanced packaging together with mask making and others accounted for between 10% to 20%. So you can see that the investment amount is higher and we're investing in areas in advanced packaging where our customers need. So the areas that you mentioned, basically we continue to invest.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Wendell. Okay, let's move on to Charlie Chan from Morgan Stanley here.\n\n**Charlie Chan** (Managing Director)\nThanks Jeff. Happy New Year, C.C. and Wendell. So first of all, amazing results and guidance. Congratulations to the management team. So my first question is about outside of AI, what do you see for those end markets? Right? You talk about the memory cost, etc. So can you give us some kind of your underlying assumption for PC shipments, smartphone shipments, etc. And also in your HPC there are some other pieces like networking and general service. Can you comment about the growth potential for those segments? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Charlie's first question is very specific. Well, generally he wants to know about how do we see the non AI demand, especially in the context where the, you know, certain component costs, such as memory costs are rising. So he wants to know what do we see the impact on the PC and smartphone markets in terms of shipments. He's also asking very specifically what about networking, what about general server? Each these different segments.\n\n**C.C. Wei** (Chairman and CEO)\nCharlie, those also we say is called non AI, but actually that related to AI. You know that, right? Because of networking processor, you still need to have AI data to scale up or scale out. Those are the networking switches, all those kind of things. It still grow very strong. As for PC or the smartphone, to tell the truth, we expect higher memory supplies. So we expect the unit cores would be very minimal. But for TSMC, we did not feel our customers change their behavior and we look at it and then we find out that we supply most of the high end smartphones. The high end smartphone is less sensitive to the memory supplies so the demand is still strong. Using one sentence I'd like to say we still try very hard to narrow the gap.\n\n**C.C. Wei** (Chairman and CEO)\nWe have to supply a lot of wafers to them also.\n\n**Charlie Chan** (Managing Director)\nThanks, C.C. I think that's very consistent with your five-year CAGR outlook for all the four segments. And my second question is about Intel's foundry competition. I think U.S. President seems to be very happy with Intel's recent progress and even mentioned two of your key customers. Right. NVIDIA Apple may have some partnership with Intel Foundry. Should we be concerned about this so-called competition and what TSMC can really do to mitigate or avoid potential market share loss as those are key U.S. customers not limited to the two customers I just mentioned. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Charlie's second question is on the Foundry competition and, you know, competition from a U.S. IDM. He knows the U.S. President is very happy with the progress. A couple two of our key customers he also was mentioned. So his question is fundamentally, is there a concern or risk going forward of market share loss for TSMC to our Foundry competition?\n\n**C.C. Wei** (Chairman and CEO)\nKind of a simple question, I should say. No, let me explain a little bit because in these days, you know, it's not money to help you to compete, right? I also like whoever you just mentioned to invest on Intel. I like them to invest on TSMC also. But the most fundamental thing is. Let me share with you. Today's technology is so complicated. So once you want to design a very complete or advanced technology, it takes two to three years to fully utilize that technology. That's the situation, and so up to two to three years of preparation you can design your product. Once you get your product being approved, it takes another one to two years to ramp it up, so we have a competitor, no doubt about it, that's formidable competitor, but first it takes time. We don't underestimate their progress, but are we afraid of it? For 30-some years we always in a competition with our competitor, so no we have a confidence to keep our business grow as we estimated.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, C.C. All right, let's take the next two questions online in the interest of time. Operator, can we take the first call from the line, please?\n\n**Operator**\nFirst question. Arthur Lai, Macquarie, go ahead please.\n\n**Arthur Lai** (Analyst)\nHi, first, congratulations. Very strong performance. Thank you, C.C. Wei and Jeff Hsu, for taking my question. My first question is about the global capacity plan. Recently, Taiwan local news report that TSMC could exit the 8-inch business and mature node 12-inch to convert into the advanced packaging, and the investors keen to know if this is true, and the decision is based on what kinds of key factor that is C.C. just mentioned about the power density or if you know power. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Arthur Lai's first question is about basically mature nodes, our strategy on mature nodes. He knows a lot of local news has been reporting that TSMC is exiting 8-inch and 12-inch basic businesses and converting the capacity to advanced packaging. So he wants to know if this is true and, if so, what are the reasons behind the power constraints, ROI, etc.\n\n**C.C. Wei** (Chairman and CEO)\nGood question indeed. We reduce our 8-inch wafers, the capacity and 6-inch but let me assure you that we support all our customers, we discuss with our customers and to do this kind of resources more flexible and more. What is the word we say? Optimize. Optimize the resources to support our customers. But let me assure you also to my customers that we continue to support them. We will not let them down if they have a good business. We continue to support that even in the 8-inch wafers of business.\n\n**Jeff Su** (Director of Investor Relations)\nOkay Arthur, do you have a second question?\n\n**Arthur Lai** (Analyst)\nYes, thank you. My second question is regarding the consumer and demand outlook. So C.C. also mentioned that the NAND price actually inflation and you also pushing up the cost of the consumer electronics. So investors actually are concerned about the further demand softness in this year and next year or particularly next year. So can management comment about what your client or your client's client how to resolve this memory tightness or we call a memory urgency issue. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Arthur's second question is on the impact from the memory price increase and the demand softness. I believe his question really, because CC already shared the impact this year. He wants to know what is the impact for 2027.\n\n**C.C. Wei** (Chairman and CEO)\nFor TSMC? No impact. As I just mentioned, most of my customers now focus on high-end smartphone or PCs, so those kind of demand has less sensitive to the components of price, so they continue to give us a very healthy forecast this year and next year.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, thank you, C.C. All right, operator, let's move on to the next participant from the line, please.\n\n**Operator**\nBrett Simpson, Arete, go ahead please.\n\n**Brett Simpson** (Co-Founder)\nYeah, thanks very much. My question is really on AI. I mean TSMC has been supply constrained for your AI customers I think since 2024 and it sounds like 2026 is another year where we're going to see challenges. Do you think the CapEx you've laid out for this year $52-$56 billion could that mean that we start to see supply and demand more in balance in 2027? Any thought there just in terms of how you're thinking about that capacity plan and does it alleviate this supply bottlenecks that we see today? And as part of this from a supply perspective, we hear TSMC is finding it quite challenging to develop enough engineering talent quick enough both in the U.S. and in Taiwan.\n\n**Brett Simpson** (Co-Founder)\nCan you talk more about this trend and what's the scale of the labor shortage of foundry engineers at the moment? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Brett's first question is related around AI and our capacity. So he notes the supply looks to continue to be tight in 2026. But with these significant step up in our CapEx to support the customers $52-$56 billion, do we expect the supply demand or the gap so to speak to be more balanced in 2027? And then is engineering resources fab engineers a constraint or a bottleneck for us in making these expansions whether in Taiwan or the U.S.?\n\n**C.C. Wei** (Chairman and CEO)\nOkay, let me answer this question first. You know, if you build a new fab, it takes two and three years, two to three years to build a new fab. So even we start to spend $52-$56 billion. The contribution to this year almost none. And to 2027 a little bit. So we actually were looking for 2028, 2029 supply. And we hope it's a time that the gap will be narrow. For 2026 and 2027 we are focused on the short term, more output. Actually our productivity continue to increase. Our people has an incentive because of one of the TSMC's incentive is to satisfy customer. It's not because of our financial result are good, but we want to let customer feel that TSMC is trusted. That whenever they have a good opportunity to grow, we will support it.\n\n**C.C. Wei** (Chairman and CEO)\nSo, in 2026-2027, for the short term, we focus on the productivity improvement which we've done quite a good result because Wendell just mentioned that we can have a good financial result is because of that. But that's not our incentive. That's our incentive. But that's not our purpose. Our purpose is to support our customer. So, 2026-2027, for the short term, we are looking to improve our productivity. 2028-2029, yes, we start to increase our CapEx significantly and we continue this wave of the AI demand megatrend as we expected.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Brett, thank you, C.C. Brett, do you have a second question?\n\n**Brett Simpson** (Co-Founder)\nYeah, I do, and thanks. That was very clear. I guess my second question is about pricing. If I look at 2025, this was the second consecutive year where TSMC's wafer ASPs were up around 20%. As leading edge becomes a bigger portion of the mix and also you feed through price increases. When we factor in the ramp of more expensive overseas fabs, is 20% wafer ASP increases the new normal for TSMC. Typically you have an annual price negotiation about this time of the year. I'm trying to understand how you project ASPs in 26. Is your March quarter guidance factoring in price increases at leading edge. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Brad's question is on pricing. He notes that you know which he's looking at. The blended wafer price is increasing close to 20% according to his estimates. Of course that's blended both on price and mix but you know, it's a leading edge. And also we have mentioned earning our value. So he wants to know is this the new normal going forward?\n\n**C.C. Wei** (Chairman and CEO)\nThis is a tough question. I need the CFO to answer.\n\n**Wendell Huang** (CFO)\nOkay, every new node we have a price, the price will increase, the blended ASP will increase. I think they continue this way in the past and will continue the way in going forward but Brett, I think you're asking about the contribution from pricing to the profitability. Now as we mentioned before, the profitability. There are six factors affecting the profitability and price is just one of them and of course we continue trying to earn our value but in fact in the last few years the pricing benefits to the profitability was just enough to cover the inflation cost from tools, equipment, materials, labor, etc. There are other factors contributing to the higher profitability. The first one will be a high utilization rate as the demand is so high and as our disciplined approach to capacity planning. The utilization rate supports our high profitability.\n\n**Wendell Huang** (CFO)\nThe other one will be our manufacturing excellence. As C.C. Wei said, we continue to drive increasing productivity to generate more wafer output. Also, we continue to drive optimization capacity among nodes, which includes converting part of the N5 to N3. It also involves cross supports from different nodes from the mature nodes to the more advanced nodes. That is a very important advantage of TSMC, so with all these efforts we're able to maintain a good healthy sustainable return profitability so that we can continue to invest to support our customers' growth.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, thank you Wendell. In the interest of time, we'll take two more questions from the floor and one more from the line. So we'll go here. Sunny Lin, UBS and then.\n\n**Sunny Lin** (Semiconductor Analyst)\nThank you. Good afternoon. Very strong results. Congratulations. So number one, if we look at the company very different versus in the past from many angles. But if we look at the ramp from N3 now, you can generate actually higher revenue from N3 in year four, even year five of mass production versus in the past, you know, like peak revenue in the second or even third year of mass production. And so could you help us understand with this new trend, what's the financial implications? And then what does that imply for you to operate or even compete differently versus in the past?\n\n**Jeff Su** (Director of Investor Relations)\nSo Sunny's first question I think maybe is related well to our technology differentiation. But she knows that when we ramp a new, you know, in the past, when we have a new node after a few years, sort of, you know, the revenue or you know, comes down a bit. But she notes that nowadays we can still enjoy very high revenue from a node even after, in its fourth or fifth year. So her question is, what are the financial implications from this? And also from a, I believe, competitive dynamics.\n\n**C.C. Wei** (Chairman and CEO)\nIf I can answer, say we are lucky. Actually if you look at the semiconductors product right now, the trend is you need to have a lower power consumption always and then high speed performance. And for TSMC our technology differentiation become more and more clear. We have both benefit. We have a high speed and we have a low power consumption. And so our leading edge customer, the first wave, the second wave, the third wave continue to come. And so that sustain the demand for a long, long time. That's a difference. Of course this one you need to have technology leadership and which the technology leadership much easier to say. But every year you have to improve. As we said, we have N2 N2P and then you won't be surprised. And the third one will be N2 something and continuously.\n\n**C.C. Wei** (Chairman and CEO)\nAnd so that one give us the benefit and to support our customers' continuous innovation. And so they continue to stay with TSMC and so their product can be very competitive in the market. So that answer the question, say that you know, once we got the peak revenue and did not decrease, it continues because second wave, third wave customer continue to join.\n\n**Sunny Lin** (Semiconductor Analyst)\nThank you very much, CC. And then maybe a question on 2-nanometer, which is, CC, a meaningful revenue coming through in 2026. And so in the past you guide like how much a new node will contribute to sales for the year. And so any expectations on the revenue contribution from 2-nanometer in 2026. And then I recall in terms of process migration, few years ago there were lots of concerns on increasing cost per transistor. And that obviously is not declining from 5-nanometer but then now looking at 2-nanometer I think process migration seems to be re-accelerating even for smartphone and PC and then with larger demand coming from high-performance computing. And so maybe based on your feedback from clients, maybe for smartphone and PC clients, why are they re-accelerating process migration into 2-nanometer?\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Sunny's second question very quickly in two parts, 2 nanometer as we said is a fast ramp in 2020, very strong customer interest and demand, so what do we have any revenue percentage to guide for in 2026?\n\n**Wendell Huang** (CFO)\nYeah, Sunny, the 2-nanometer will be a bigger node than 3-nanometer from the start. Okay. But it's less meaningful nowadays to talk about the percentage of revenue contribution when the new node starts because the company as a whole the revenue has become much bigger than before. So yeah, revenue dollar it's a bigger node but percentage wise less meaningful.\n\n**Jeff Su** (Director of Investor Relations)\nAnd then the second part of Sunny's question from a technology perspective, as you know she noted increasing cost per transistor as we said CapEx per K going higher. So her question very simply, what's the value? What's driving smartphone HPC customers actually to see we're seeing a widening out of the adoption of N2. So what is the value that it's providing that the customers are willing to adopt N2?\n\n**C.C. Wei** (Chairman and CEO)\nI already answered the question right because now the whole product is looking for low power consumption and high speed performance and our technology can provide that value. I also say that every year we improve. So every year they adopt the same, even the same name of the same node their product continue to improve. So that provides a value. If you say that the cost per transistor is increased, I saw the cost per transistor, the performance compared that called the CP value is increased, is much better. So that customer stick with the TSMC. Our headache right now, if I can call it headache is a demand and supply gap. We need to work hard to narrow the gap.\n\n**Sunny Lin** (Semiconductor Analyst)\nVery clear, thank you.\n\n**Jeff Su** (Director of Investor Relations)\nThank you. Operator, can we take the last call from the line and we'll take one last one from the floor?\n\n**Operator**\nNext one. Krish Sankar, TD Cowen. Go ahead, please.\n\n**Jeff Su** (Director of Investor Relations)\nHello? Okay Chris, are you there? I guess not. Then let's just take the last call. Sorry, the last question from Bruce Lu from Goldman Sachs. Thank you.\n\n**Bruce Lu** (Analyst)\nThank you for joining. Thank you for letting me ask the last question. Hopefully it's not that difficult. So I think one of the key. I understand that TSM is trying very hard to increase the capacity, you know. AI wafer fab is growing like 15% a year. 15% plus a year. But token consumption for last few quarters is 15x a quarter. So the gap is still there, right? That's why Elon Musk was talking about the chip shortage. So, C.C., can you share with us that in your assumption when you provide 50% plus AI revenue growth, what kind of token consumption you can support and how many gigawatts power in terms of the chips you can support in your assumption when you provide this kind of five-year revenue guidance for AI.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Bruce's first question is on our AI CAGR. Actually to be correct we have guided for the AI CAGR to grow mid- to high 50s CAGR in the five-year period from 2024 to 2029. So that is the official guidance we have provided just today. Bruce's question is in this guidance what is our assumption basically assuming about the token growth behind this type of CAGR, what is our assumption in terms of translating to how much gigawatts of data center can we support? And other specific assumptions behind our guidance?\n\n**C.C. Wei** (Chairman and CEO)\nBruce, you got me. I mean that's, I, I also try to understand what is the tokens growth but my customers their product improvement continue to increase. So from, it's a well known from Hopper to Blackwell to Rubin that almost double triple their performance. So the one they can support the tokens growth or the one they can continue to support the compute power is enormous and so I lost track to be frank with you. For gigawatt I want to see that how much of TSMC can make the money from the gigawatt rather than say that you know how much we can support today. From my point of view still the bottleneck is TSMC's wafer supply, not power consumption. Not yet.\n\n**C.C. Wei** (Chairman and CEO)\nWe also look at carefully to answer your question, say that TSMC's wafer can support how much of the gigawatt. Still not enough. They still have an abundant power supply in the U.S.\n\n**Bruce Lu** (Analyst)\nOkay, my next question is for the CapEx, right? I want to double-check with what I just heard that CC was talking about like 2027. The CapEx will be more for the productivity improvement when 2028-29 may be meaningfully higher. So I do recall that in 2021 TSMC provided three years for $100 billion CapEx to support our structural growth. Now the demand is even stronger. Based on that, can we do three years? $200 billion for CapEx for next three years. You know the math sounds doable.\n\n**Jeff Su** (Director of Investor Relations)\nFirst, a slight clarification because CC was talking about this year we have substantially, you know, stepping up our CapEx investment. But CC also mentioned it takes two to three years to build capacity. In terms of Bruce's question, is do we say 2027 significant step up in CapEx? I think we're saying it takes time for that capacity to come out. That is the first part.\n\n**Wendell Huang** (CFO)\nYeah, I think Bruce, what CC said was the productivity was our main focus in 2026 and 2027 because when we start to invest the fab, the volume production will not come out until 2028 and 2029. So the dollar amount invested today is for 2 years or even in the future. And CapEx dollar amount, as I said in the last 3 years, $101 billion in the next 3 years, significantly higher. I'm not going to share with you the number, but significantly higher.\n\n**Jeff Su** (Director of Investor Relations)\nYeah, so I think Wendell has addressed at least both parts of Bruce's question. Okay, so again, thank you. So again, thank you everyone. This does conclude our Q and A session. Before we conclude today's conference, please be advised that the replay of the conference will be accessible within 30 minutes from now. The transcript will become available 24 hours from now and both are available or will be available throughout TSMC's website at www.tsmc.com. So again, thank you everyone for taking the time to join us today. We certainly would like to wish everyone a happy New Year. We hope everyone continues to stay well and you will join us again next quarter. Thank you. Goodbye and have a good day.",
        "fetched_at": "2026-02-04T16:12:55.583Z"
      },
      {
        "ticker": "TSM",
        "title": "Yahoo Finance",
        "published_date": "Oct 16, 2025, 2:00 AM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/TSM/earnings/TSM-Q3-2025-earnings_call-363980.html",
        "content": "**Jeff Su** (Director of Investor Relations)\nGood afternoon, everyone, and welcome to TSMC's Third Quarter 2025 Earnings Conference call. This is Jeff Su, TSMC's Director of Investor Relations and your host for today. TSMC is hosting our earnings conference call via live audio webcast through the company's website at www.tsmc.com, where you can also download the earnings release materials. If you are joining us through the conference call, your dial-in lines are in listen-only mode. The format for today's event will be as follows. First, TSMC's Senior Vice President and CFO, Mr. Wendell Huang, will summarize our operations in the third quarter 2025, followed by our guidance for the fourth quarter 2025. Afterwards, Mr. Huang and TSMC's Chairman and CEO, Dr. C.C. Wei, will jointly provide the company's key messages. We will open the line for Q&A.\n\n**Jeff Su** (Director of Investor Relations)\nAs usual, I would like to remind everybody that today's discussions may contain forward-looking statements that are subject to significant risks and uncertainties, which could cause actual results to differ materially from those contained in the forward-looking statements. Please refer to the safe harbor notice that appears in our press release. I would like to turn the call over to TSMC CFO, Mr. Wendell Huang, for the summary of operations and the current quarter guidance.\n\n**Wendell Huang** (CFO and SVP)\nThank you, Jeff. Good afternoon, everyone. Thank you for joining us today. My presentation will start with financial highlights for the third quarter 2025. After that, I will provide the guidance for the fourth quarter 2025. Third quarter revenue increased 6% sequentially in NT, as our business was supported by a strong demand for our leading-edge process technologies. In U.S. dollar terms, revenue increased 10.1% sequentially to $33.1 billion, slightly ahead of our third quarter guidance. Gross margin increased 0.9% percentage point sequentially to 59.5%, primarily due to cost improvement efforts and a higher capacity utilization rate, partially offset by an unfavorable foreign exchange rate and dilution from our overseas fabs. Accordingly, operating margin increased 1.0 percentage point sequentially to 50.6%. Overall, our third quarter EPS was TWD 17.44, up 39% year-over-year, and ROE was 37.8%. Now, let's move on to revenue by technology.\n\n**Wendell Huang** (CFO and SVP)\n3 nm process technology contributed 23% of wafer revenue in the third quarter, while 5 nm and 7 nm accounted for 37% and 14% respectively. Advanced Technologies defined as 7 nm and below accounted for 74% of wafer revenue. Moving on to revenue contribution by platform, HPC remained flat quarter-over-quarter to account for 57% of our third quarter revenue. Smartphone increased 19% to account for 30%. IoT increased 20% to account for 5%. Automotive increased 18% to account for 5%. DCE decreased 20% to account for 1%. Moving on to the balance sheet, we ended the third quarter with cash and marketable securities of TWD 2.8 trillion, or $90 billion. On the liability side, current liability decreased by TWD 101 billion, quarter-over-quarter, mainly due to the decrease of TWD 112 billion in accrued liabilities and others, as we paid out 2025 provisional tax of TWD 136 billion.\n\n**Wendell Huang** (CFO and SVP)\nIn terms of financial ratios, accounts receivable turnover days increased two days to 25 days. Days of inventory decreased two days to 74 days due to strong shipment in N3 and N5. Regarding cash flow and CapEx, during the third quarter, we generated about TWD 427 billion in cash from operations, spent TWD 287 billion in CapEx, and distributed TWD 117 billion for Q2 2024 cash dividend. Overall, our cash balance increased TWD 106 billion to TWD 2.5 trillion at the end of the quarter. In U.S. dollar terms, our third quarter capital expenditures totaled $9.7 billion. I have finished my financial summary. Now, let's turn to our current quarter guidance. Based on the current business outlook, we expect our fourth quarter revenue to be between $32.2 billion and $33.4 billion, which represents a 1% sequential decrease or a 22% year-over-year increase at the midpoint.\n\n**Wendell Huang** (CFO and SVP)\nBased on the exchange rate assumption of $1 to TWD 30.6, gross margin is expected to be between 59% and 61%. Operating margin between 49% and 51%. This concludes my financial presentation. Now, let me turn to our key messages. I will start by talking about our third quarter 2025 and fourth quarter 2025 profitability. Compared to the second quarter, our third quarter gross margin increased by 90 basis points sequentially to 59.5%, primarily due to cost improvement efforts and a higher overall capacity utilization rate, partially offset by margin dilution from our overseas fabs and an unfavorable foreign exchange rate. Compared to our third quarter guidance, our actual gross margin exceeded the high end of the range provided three months ago by 200 basis points, mainly as the actual third quarter exchange rate was $1 to TWD 29.91, compared to our guidance of $1 to TWD 29.\n\n**Wendell Huang** (CFO and SVP)\nIn addition, we also delivered better than expected cost improvement efforts. We have just guided our fourth quarter gross margin to increase by 50 basis points to 60% at the midpoint, primarily driven by a more favorable foreign exchange rate, partially offset by continued dilution from our overseas fabs. While the cost of overseas fabs remains higher, thanks to the company's overall larger scale, we now expect the gross margin dilution from the ramp-up of our overseas fabs to be closer to 2% in the second half of 2025. For the full year 2025, we now expect it to be between 1%-2% as compared to 2%-3% previously.\n\n**Wendell Huang** (CFO and SVP)\nLooking ahead, we continue to forecast the gross margin dilution from the ramp-up of our overseas fabs in the next several years to be 2%-3% in the early stages and widen to 3%-4% in the latter stages. We will leverage our increasing size in Arizona and work on our operations to improve the cost structure. We will also continue to work closely with our customers and suppliers to manage the impact. Overall, with our fundamental competitive advantages of manufacturing technology leadership and large-scale production base, we expect TSMC to be the most efficient and cost-effective manufacturer in every region that we operate. Now, let me make some comments on our 2025 CapEx. As the structured AI-related demand continues to be very strong, we continue to invest to support our customers' growth.\n\n**Wendell Huang** (CFO and SVP)\nWe are narrowing the range of our 2025 CapEx to be between $40 billion and $42 billion, as compared to $38 billion-$42 billion previously. About 70% of the capital budget will be allocated for advanced process technologies. About 10%-20% will be spent for specialty technologies. About 10%-20% will be spent for advanced packaging, testing, mask making, and others. At TSMC, a higher level of capital expenditures is always correlated with higher growth opportunities in the following years. Even as we invest for the future growth with this higher level of CapEx spending in 2025, we remain committed to delivering profitable growth to our shareholders. We also remain committed to a sustainable and steadily increasing cash dividend per share on both an annual and quarterly basis. Now, let me turn the microphone over to C.C.\n\n**Che-Chia Wei** (CEO and Chairman)\nThank you, Wendell. Good afternoon, everyone. First, let me start with our near-term demand outlook. We concluded our third quarter with revenue of $33.1 billion, slightly above our guidance in U.S. dollar terms, mainly due to the strong demand for our leading-edge process technologies. Moving into the fourth quarter 2025, we expect our business to be supported by continued strong demand for our leading-edge process technologies. We continue to observe robust AI-related demand throughout 2025, while the non-AI end market segment has patterned out and is seeing a mild recovery. Supported by our strong technology differentiation and broad customer base, we now expect our full-year 2025 revenue to increase by close to mid-30% year-over-year in U.S. dollar terms.\n\n**Che-Chia Wei** (CEO and Chairman)\nWhile we have not observed any change in our customers' behavior so far, we understand there are uncertainties and risks from the potential impact of tariff policies, especially in the consumer-related and price-sensitive end market segments. As such, we will remain mindful of the potential impact and be prudent in our business planning going into 2026 while continuing to invest for the future megatrend. Amidst the uncertainty, we will also continue to focus on the fundamentals of our business, that is technology leadership, manufacturing excellence, and customer trust, to further strengthen our competitive position. Next, let me talk about the AI demand outlook and TSMC's capacity planning process disciplines. Recent developments in the AI market continue to be very positive. The explosive growth in token volume demonstrates increasing consumer AI model adoption, which means more and more computation is needed, leading to more leading-edge silicon demand.\n\n**Che-Chia Wei** (CEO and Chairman)\nCompanies such as TSMC are leveraging AI internally to drive greater productivity and efficiency to create more value. As such, enterprise AI is another source of demand. In addition, we continue to observe the rising emergence of sovereign AI. We are also happy to see continued strong outlook from our customers. In addition, we directly receive very strong signals from our customers' customers, requesting the capacity to support their business. Thus, our conviction in the AI megatrend is strengthening, and we believe the demand for semiconductors will continue to be very fundamental. As a key enabler of AI applications, TSMC's biggest responsibility is to prepare the most advanced technologies and necessary capacity to support our customers' growth. To address the structural increase in the long-term market demand profile, TSMC employs a disciplined and robust capacity planning system.\n\n**Che-Chia Wei** (CEO and Chairman)\nExternally, we work closely with our customers and our customers' customers to plan our capacity. We have more than 500 different customers across all the end market segments. In addition, as process technology complexity increases, the engagement lead time with customers is now at least two to three years in advance. Therefore, we probably get the deepest and widest loop possible in the industry. Internally, our planning system involves multiple teams across several functions to assess and evaluate the market demand from both top-down and bottom-up approaches to determine the appropriate capacity to build. This is especially important when we have such high forecasted demand from AI-related businesses. As the world's most reliable and effective capacity provider, we will continue to work closely with our customers to invest in leading-edge specialty and advanced packaging technologies to support their growth.\n\n**Che-Chia Wei** (CEO and Chairman)\nWe will also remain disciplined and robust in our capacity planning approach to ensure we deliver profitable growth for our shareholders. Now, let me talk about TSMC's global manufacturing footprint update. All our overseas decisions are based on our customers' needs, as they value some geographic flexibility and the necessary level of government support. This is also to maximize the value for our shareholders. With a strong collaboration and support from our leading U.S. customers and the U.S. federal, state, and city governments, we continue to speed up our capacity expansion in Arizona. We are making tangible progress and executing well to our plan. In addition, we are preparing to upgrade our technologies faster to end-to-end and more advanced process technologies in Arizona, given the strong AI-related demand from our customers.\n\n**Che-Chia Wei** (CEO and Chairman)\nFurthermore, we are close to securing a second large piece of land nearby to support our current expansion plans and provide more flexibility in response to the very strong multi-year AI-related demand. Our plan will enable TSMC to scale up to an independent gigafab cluster in Arizona to support the needs of our leading-edge customers in smartphone, AI, and HPC applications. Next, in Japan, thanks to the strong support from the Japan Central, Prefectural, and Local Government, our first specialty fab in Kumamoto has already started volume production in late 2024 with very good yield. The construction of our second fab has begun, and the ramp schedule will be based on our customers' needs and market conditions. In Europe, we have received strong commitment from the European Commission and the German federal, state, and city governments.\n\n**Che-Chia Wei** (CEO and Chairman)\nConstruction of our specialty fab in Dresden, Germany, has also started, and we are progressing smoothly with our plans. The ramp schedule will be based on our customers' needs and market conditions. In Taiwan, with support from the Taiwan government, we are preparing for multiple phases of 2 nm fab in both Xinchu and Kaohsiung Science Parks. We will continue to invest in leading-edge and advanced packaging facilities in Taiwan over the next several years. By expanding our global footprint while continuing to invest in Taiwan, TSMC can continue to be the trusted technology and capacity provider of the global logic IC industry for years to come. Finally, let me talk about our N2 and S16 status. Our 2 nm and S16 technologies lead the industry in addressing insatiable demand for energy-efficient computing, and almost all innovators are working with TSMC. N2 is well on track for volume production later this quarter.\n\n**Che-Chia Wei** (CEO and Chairman)\nWith good yield, we expect a faster ramp in 2026, fueled by both smartphone and HPC AI applications. With our strategy of continuous enhancement, we also introduce N2P as an extension of our N2 family. N2P features further performance and power benefits on top of N2 and volume production scheduled for the second half of 2026. We also introduced A16 featuring our best-in-class superpower rail, or SPR. A16 is best suited for a specific HPC product with a complex signal route and dense power delivery networks. Volume production is on track for the second half of 2026. We believe N2, N2P, A16, and its derivatives will propel our N2 family to be another large and long-lasting node for TSMC. This concludes our key message, and thank you for your attention.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, C.C. This concludes our prepared statements. Before we begin the Q&A session, I would like to remind everybody to please limit your questions to two at a time to allow all the participants an opportunity to ask their questions. Should you wish to raise your question in Chinese, I will translate it to English before our management answers your question. For those of you on the call, if you would like to ask a question, please press the star, then one on the telephone keypad now. If at any time you'd like to remove yourself from the questioning queue, please press star, then two. Now, let's begin the Q&A session. Operator, can we please proceed with the first caller on the line? Thank you.\n\n**Operator**\nYes. First one, Gokul Hariharan, JPMorgan. Go ahead, please.\n\n**Gokul Hariharan** (Analyst)\nYeah, thanks. Good afternoon, C.C., Wendell, and Jeff. Great result again. On the AI front, C.C., I think you have met with pretty much everybody who is driving the Gen AI revolution over the last couple of months. As you said, everybody seems to be a lot more positive. I think we gave a guidance of mid-40% data center AI growth CAGR earlier this year until 2029. Anything that you see which should kind of change that number? It definitely feels like the growth today seems to be much stronger. Related to that, you did talk about the very detailed capacity expansion planning that TSMC does. In past technology cycles, TSMC CapEx has gone up significantly to prepare for the next upgrade or next leading-edge node. In this cycle, TSMC revenues have grown 50% from the previous peak in 2022. CapEx has only grown about 10%.\n\n**Gokul Hariharan** (Analyst)\nHow should we think about the CapEx over the next couple of years? I know that you're not giving numerical guidance yet, but I just wanted to understand, like are we looking at much higher CapEx in the next couple of years given all these conversations you've had? I had a follow-up after that. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Gokul, first question. Sorry, Gokul. Let me summarize for everyone's benefit. Again, he wants to know firstly related to the AI-related demand that TSMC works with many, if not everyone, who is doing AI, and many of the customers seem to be even more positive today. I guess he would like to ask C.C., sort of what are we seeing or hearing from our customers? We had previously said that the next five years from 2024 to 2029, we expect AI accelerator to grow at a mid-40% CAGR. Is there any update to this? I think this is the first part. I'll get to the second part on CapEx.\n\n**Che-Chia Wei** (CEO and Chairman)\nWow. That's a long question, isn't it? Gokul, the AI demand actually continues to be very strong. It's more strong than we thought three months ago. In today's situation, we have talked to customers, and then we talk to customers' customers. The CAGR we previously announced is about the mid-40%, but it's still a little bit better than that. We will update you probably in the beginning of next year. We have a more clear picture. Today, the numbers are incentive.\n\n**Jeff Su** (Director of Investor Relations)\nThe second part of Gokul's question related to CapEx, he notes that in the past, when TSMC sees opportunities for higher growth, past cycles or past instances, we would step up the CapEx significantly to prepare to drive the future growth. He notes this cycle, actually, though while CapEx is increasing, the revenue is increasing even faster. His question really, I think, is how do we see this playing out over the next few years, both in terms of the CapEx spend and the growth relative to the revenue growth?\n\n**Wendell Huang** (CFO and SVP)\nOkay. Gokul, every year we spend the CapEx based on the business opportunity in the following few years. As long as we believe there are business opportunities, we will not hesitate to invest. If we do our job right, the growth of our business or of our revenue should outpace the growth of the CapEX. That is what we have been delivering in the past few years. Now, going forward, assuming we're still doing a very good job, we will continue to see that happening again. A company of our size, the CapEx number, it's unlikely to suddenly drop significantly in any given year. When we continue to invest and our growth is outpacing our CapEx growth, you'll see the growth like what we have done in the past few years.\n\n**Gokul Hariharan** (Analyst)\nUnderstood. I know that it is unlikely to drop, but it is also likely to grow quite a bit given what C.C. Wei mentioned in terms of every customer asking you and every customer's customer requesting you for capacity addition, right?\n\n**Wendell Huang** (CFO and SVP)\nYeah, as I said, a higher level of CapEx is always going to be correlated with a higher growth opportunity. As C.C. said, next year looks to be a healthy year and that we are confident on the megatrend, then we'll continue to invest.\n\n**Gokul Hariharan** (Analyst)\nOkay, got it. Yeah.\n\n**Gokul Hariharan** (Analyst)\nYeah, maybe one more follow-up question from me, C.C. I think last year also you gave us an indication of how much CoWoS capacity you would be building. I think you talked about 2x of doubling the CoWoS capacity. It clearly feels like even that is not enough. Could you give us some idea about how much capacity you would be building next year just to get some idea about what you are seeing in terms of AI demand? Also, just to get some understanding of TSMC's data center AI exposure, I think last year we talked about mid-teens revenues. Where do we end up this year? Do we end up close to like 30% of revenues coming from AI?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Gokul, your second question really, he wants to understand, can we provide any detail or colors on the CoWoS capacity plan for 2026 in terms of year-on-year increase? Also, in terms of our definition of AI accelerator revenue, the narrow definition, how much will it contribute for 2025 revenue? Is it 30%?\n\n**Che-Chia Wei** (CEO and Chairman)\nGokul, this is C.C. Wei again. Talking about the CoWoS capacity, all I can say is continuing the three months ago, we are working very hard to narrow the gap between the demand and supply. We are still working to increase the capacity in 2026. The real number, we probably update you next year. Today, all I want to say about the AI, everything related, like the front-end and back-end capacity, is very tight. We are working very hard to make sure that the gap will be narrow, but all I can say is we are working very hard.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, Gokul. I think we need to move on in the interest of time. Operator, can we move to the next participant, please?\n\n**Operator**\nYes. Next one, Charlie Chan, Morgan Stanley. Go ahead, please.\n\n**Charlie Chan** (Analyst)\nThanks for taking my question. Again, congratulations for very strong results, C.C., Wendell, and Jeff. My first question is really about your leading-edge demand. As C.C. just mentioned, your front-end demand is also very strong into next year. One of your major customers just said that more so is that. I think his point is that by doing maybe system-level innovation in the thermal, etc., can boost up more kind of performers. Just a kind of dumb question. How do we reconcile your very, very strong leading-edge demand and that customer continue to migrate to your most advanced nodes and also you continue to reflect value, whereas the customer continues to think that more so is that? Can we get some clarification from TSMC?\n\n**Jeff Su** (Director of Investor Relations)\nAll right. Charlie's question is very specific, although he wants us to comment on a customer saying more so is that. How do we reconcile this with a very strong leading-edge demand into 2026 and also with system-level innovations?\n\n**Che-Chia Wei** (CEO and Chairman)\nOkay. Charlie, this is C.C. Wei. Yeah, one of my customers, very important customer, say more so is that. What he means is it's not only relying on the chip technology anymore. Now we have to focus on the whole system's performance. He wants to emphasize the whole system's performance rather than just talking about the more so, which is not enough to meet his requirement. We work very closely with his people to design our technology, both in front-end and back-end, and also in all the packagings to meet his requirement. That's all I can say.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, C.C.\n\n**Che-Chia Wei** (CEO and Chairman)\nSure.\n\n**Charlie Chan** (Analyst)\nThanks, CC.\n\n**Jeff Su** (Director of Investor Relations)\nDo you have a second question, Charlie?\n\n**Charlie Chan** (Analyst)\nYes, I do. Thanks, Jeff. I would interpret that as Foundry 2.0, that your co-COO, Mr. Cliff, also kind of shared during the SEMICON Taiwan. Thanks, C.C., for your commentary. My second question is actually a follow-up from last quarter's same question. Back then, I consulted you about the China AI GPU demand, right? Whether you can seize the market opportunity because China says VDL is setting their AI infrastructure very rapidly. Given the recent kind of back and forth between the U.S. and China, whether China can really impose this NVIDIA GPU, would that kind of discount your potential long-term growth of the AI CAGR? Is that something that TSMC would worry about?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Charlie's second question is related around AI demand and specific to China. With the sort of the export control and restriction, his question is, does that impact our ability to address the market opportunity? Will this impact our AI CAGR growth if we're not allowed to fully serve China?\n\n**Charlie Chan** (Analyst)\nI think there will be both sides, meaning restriction from the U.S., but also China government's kind of discouragement to procure a U.S. chip. Sorry for the interruption.\n\n**Che-Chia Wei** (CEO and Chairman)\nCharlie, to speak the truth, I have a confidence in my customers. Both are in GPU or in ASIC. They all perform very well. If the China market is not available, I still think the AI's growth will be very dramatic and, as I said, very positive. I have confidence that our customers' performance and they will continue to grow, and we will support them.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, C.C.\n\n**Charlie Chan** (Analyst)\nEven with a limited opportunity from China for the time being, you are still confident that a 40% CAGR or even higher can be achieved in the coming years?\n\n**Che-Chia Wei** (CEO and Chairman)\nYou are right.\n\n**Charlie Chan** (Analyst)\nOkay, great. Thank you.\n\n**Charlie Chan** (Analyst)\nOkay.\n\n**Charlie Chan** (Analyst)\nThanks, gentlemen.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Charlie. Operator, can we move on to the next participant, please?\n\n**Operator**\nYes. Next one, Sunny Lin, UBS. Go ahead, please.\n\n**Sunny Lin** (Analyst)\nThank you very much. Good afternoon. Congrats on the very strong gross margin. My first question is, how should we think about 2026? I understand we should get better color maybe into January, but just want to get some directional major puts and takes for gross margin trending going into 2026. Especially, how should we think about the gross margin impact from 2 nm ramp for 2026?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Sonya's first question is regarding gross margin. She would like to know directionally how do we see the gross margin for next year, 2026, in terms of certain puts and takes, and also if Wendell is able to comment specifically. Sunni, sorry if I heard you right, on the N2 dilution impact, correct?\n\n**Sunny Lin** (Analyst)\nYeah, that's right. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. That's her first question.\n\n**Wendell Huang** (CFO and SVP)\nOkay, Sunni. Yeah, it's too early to talk about 2026. You already mentioned about the N2 dilution. As all the new nodes, when they just come out, the N2 will have dilution in our gross margin in 2026. At the same time, the N3 dilution is gradually coming down. We expect the N3 to catch up to the corporate average sometime in 2026. The other factors include overseas fabs dilution, which will continue, and which we said that it will be about 2%-3% dilution in the early stage of the next several years. That will also be there. We all saw the dramatic foreign exchange rate movement in the earlier part of this year. There's no control. We don't know where that will be. Every percentage move of dollar against TWD will affect our gross margin by 40 basis points. That just gives you some rough idea.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, thank you.\n\n**Sunny Lin** (Analyst)\nGot it. Sunni, if I may, a very quick follow-up. On 2 nm, would the typical 2%-3% dilution by new node for the first seven to eight quarters of mass production be a good reference for two-nanometer as well for 2026?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Sunni, a quick follow-up. She wants to know for the 2 nm dilution if we're able to provide any detail. Can she still think about it in terms of seven to eight quarters or six to eight quarters dilution to reach the time, sorry, to reach the corporate average?\n\n**Wendell Huang** (CFO and SVP)\nYeah, Sunni, let me share with you. N2 structure profitability is better than N3. Now, secondly, it's less meaningful nowadays to talk about how long it will take for a new node to reach the corporate average in terms of profitability. That's because the corporate profitability, the corporate gross margin moves, and generally, it has been moving upwards. Less meaningful to talk about that.\n\n**Sunny Lin** (Analyst)\nGot it. No problem. That's very helpful. My second question is maybe for C.C. Thanks a lot for sharing with us the details on how you think about the capacity expansions and planning. My question is, now Cloud AI is ramping a lot faster than the prior opportunities like smartphones and PCs. I think the demand for Cloud AI is also maybe harder to forecast. I just want to maybe get a bit more color from you. Compared to the prior rounds of capacity expansions, what is TSMC doing differently versus before? How do you ensure that while you are ramping up the capacities more quickly, you are still having a good risk control? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Sunni. Sonia's second question is regarding capacity planning and expansion in a capital-intensive business. She notes this is very important. In the past, smartphone and PC megatrends, today it's AI and Cloud AI. She's wondering, does that make this planning process more difficult to forecast? What are we doing differently? How do we forecast this to make sure that we are investing appropriately?\n\n**Che-Chia Wei** (CEO and Chairman)\nSunni, indeed, right now, because I believe we are just in the early stage of the AI application, it is very hard to make a right forecast at this moment. What do we do differently? There's a big difference because right now we pay a lot of attention to our customers' customers. We talk to and then discuss with them and look at their applications, be it in the search engine or in social media applications. We talk with them and see how they view the AI application to those functions. Then we make a judgment about what the AI is going to grow. This is quite different as compared with before. We only talked to our customers and had an internal study. This is different. Did I answer your question?\n\n**Sunny Lin** (Analyst)\nGot it. Thank you very much, C.C. Yeah, and looking forward to the [KPAC sky] in January. Thank you.\n\n**Che-Chia Wei** (CEO and Chairman)\nYou're welcome.\n\n**Jeff Su** (Director of Investor Relations)\nAll right. Thank you, Sunni. Operator, can we move on to the next participant, please?\n\n**Operator**\nNext one, Bruce Lu, Goldman Sachs. Go ahead, please.\n\n**Bruce Lu** (Analyst)\nHello. Thank you for taking my question. I think Jensen talked about like $3 trillion-$4 trillion AI infrastructure opportunities by 2030, right? This compared to like $600 billion CapEx recent of this year implies for about 40% CAGR. This is similar to TSMC guidance for the AI growth, right? For me, first of all, what I want to know is what's the TSMC view for the AI infrastructure growth for the next five years? What's TSMC's forecast for the token growth rate in the next few years? TSMC used to provide the same industry growth, foundry growth, and how much TSMC can outperform the industry, right? Given the context, can we assume like TSMC AI-related revenue can track or will track with the CapEx growth of AI or the major cloud service provider?\n\n**Bruce Lu** (Analyst)\nShould we expect an even higher growth rate for TSMC, considering you're potentially getting more value out of it?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Let me try to summarize your question, Bruce. He notes that one of our customers has highlighted a $3 trillion-$4 trillion infrastructure opportunity over the next few years compared to $600 billion current CapEx, implying a 40-something % CAGR growth rate, which is similar to ours. Bruce's question is he wants to know what is TSMC's forecast or view for AI infrastructure growth. He would also like to know what is TSMC's forecast or view for the token growth? What is TSMC's AI-related revenue growth? Can it track that of the cloud service providers? His question is, should it be even higher? Shouldn't it be even higher given the value that we capture? That's actually several questions, but is that correct, Bruce?\n\n**Bruce Lu** (Analyst)\nThat's right. Thank you.\n\n**Che-Chia Wei** (CEO and Chairman)\nBruce, essentially just want to know how accurate that we can predict that the AI is in demand. We give you a number, roughly 40% in the mid-40s is a CAGR, not including all the infrastructures built up and also aligned with our major customers' forecasts or their view. More than that, I think if we are talking about the tokens, the number of tokens increase, it's exponential. I believe that almost every three months, it will be exponentially increased. That's why we are still very comfortable that the demand on leading-edge semiconductors is real. As I continue to say, we look at all the demand and look at our capacity expansion, we need TSMC to work very hard to narrow the gap. That's what we are doing right now.\n\n**Che-Chia Wei** (CEO and Chairman)\nExactly the number that we probably will share with you in next year so that when we have a very better clear picture.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, C.C.\n\n**Bruce Lu** (Analyst)\nI think the question is that the token growth seems to be substantially higher than the AI-related revenue guidance from TSMC, right? The gap is actually enlarging if you compound in the outer years, right? That's why that's the difference between what we see for the current TSMC outlook and the potential token consumptions, right? The gap is continuing to see an enlarging. How do we solve this? Do we really see that as a major issue as well?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Bruce's second question, which is a follow-on from his first, is that the token growth is growing at a much higher rate or exponentially than TSMC's AI revenue growth. This gap will only widen in the next few years. He wants to know, Bruce, basically, what's the implication to TSMC or how do we see this? Is that correct?\n\n**Che-Chia Wei** (CEO and Chairman)\nOkay. Okay, Bruce. You are right. You are right. The tokens and the number of tokens that increase exponentially is much, much higher than TSMC's CAGR as we forecasted. Let me tell you that first, our technology continues to improve. Our customer is moving from one node to the next node so that they can handle much more tokens' number in their basic fundamental calculation. That's one thing. You know we progress very well from one node to the other node. Our customer is working with TSMC to continuously improve their performance. That's why when we say that we have about 40%, 45% CAGR, the token number exponentially increases because of our customer and TSMC's technology combined that can handle much more or much efficiently than before. Did I answer your question?\n\n**Bruce Lu** (Analyst)\nI see.\n\n**Bruce Lu** (Analyst)\nYou believe your node migration plus your customer design change can fulfill or can meet the exponential growth for the token consumption?\n\n**Che-Chia Wei** (CEO and Chairman)\nExactly.\n\n**Bruce Lu** (Analyst)\nIs that the conclusion?\n\n**Che-Chia Wei** (CEO and Chairman)\nYes.\n\n**Bruce Lu** (Analyst)\nI understand.\n\n**Bruce Lu** (Analyst)\nOkay. Quick follow-up for the market.\n\n**Jeff Su** (Director of Investor Relations)\nBruce, that was your second question. Operator, we need to move on. Thank you, Bruce.\n\n**Operator**\nYes. Next one, Laura Chen, Citi. Go ahead, please.\n\n**Laura Chen** (Analyst)\nYeah. Thank you very much for taking my questions. I appreciate C.C. sharing your view on TSMC's strategy on the AI capacity planning. I think along with the very strong advanced node demand, I believe that advanced packaging like CoWoS is also one of the focuses for your AI clients they are now looking for. I recall that TSMC previously also planned to expand advanced packaging in Arizona. Can you give us updates here? Also, for the time being, the very stretched demands at the moment, would TSMC work more closely with your OSAT partner to fulfill the strong demand at the same time? That's my first question. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Lora. Her first question is on capacity planning. We have talked earlier on the call about the planning for leading nodes. She wants to understand also on the cohort capacity, and specifically, I guess, advanced packaging in Arizona. How do we work with our all-set partners?\n\n**Che-Chia Wei** (CEO and Chairman)\nOkay. We have announced our plan to build two advanced packaging fabs in Arizona to support our customers. At the same time, right now we are working with one all-set big company and our good partner, and they are going to build their fab in Arizona. We are working with them because they are already breaking ground, and the schedule is earlier than TSMC's two advanced packaging fabs. We are working with them. Our main purpose is to support our customers, so we can marry in the U.S.\n\n**Jeff Su** (Director of Investor Relations)\nLaura, do you have a second question?\n\n**Laura Chen** (Analyst)\nYes, yes, certainly. I mean, obviously, we see that the advanced node, advanced packaging is quite strong. Also, at the same time, we are also seeing that the migration is also happening for N2 and N3. Just wondering, from the revenue growth perspective, I know it's still early to predict next year based on your guidance. I'm just wondering, will it be more driven by the ASP increase because of the technology migration? TSMC will be able to sell in your value or more that will be driven by the capacity or volume growth on both N2 ramp-up? Also, C.C, you mentioned some of the mild silico recovery. That may also drive some of the volume growth into next year. Just wondering, if you look at the growth outlook, would that be more driven by the technology upgrade ASP increase or also more like a volume?\n\n**Laura Chen** (Analyst)\nThat's my second question. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Laura's, again, second question is looking at 2026. She would like to understand what will be the key drivers of the growth. Is it more from the technology mix migration, things like N2? Is it more from ASP upgrade, or is it more from just pure wafer volume growth?\n\n**Che-Chia Wei** (CEO and Chairman)\nLaura, all the above. All right?\n\n**Laura Chen** (Analyst)\nOkay. Okay.\n\n**Che-Chia Wei** (CEO and Chairman)\nYou knew it, right? I mean, that's it.\n\n**Che-Chia Wei** (CEO and Chairman)\nIt's growing.\n\n**Laura Chen** (Analyst)\nYeah.\n\n**Laura Chen** (Analyst)\nThere are also follow-ups because we see that actually N3 is very tight. At the same time, we are also kind of expanding on N2. C.C., you previously mentioned that you will migrate some of the even N7, N6, and also N5 to like N3. Specifically on N3, do we also need to add more capacity into next year for newly added capacity?\n\n**Jeff Su** (Director of Investor Relations)\nLaura, if I understand correctly, will we need to add new capacity? Will we continue to do conversion? What will we do to support the very strong demand we see at leading edge next year?\n\n**Laura Chen** (Analyst)\nYes, thank you.\n\n**Wendell Huang** (CFO and SVP)\nLet me answer that question. We continue to optimize the N5, N3 capacity to support our customer. For the new building for the N3 capacity to expand, we put the new building for the N2 technology. That's today's plan.\n\n**Laura Chen** (Analyst)\nOkay.\n\n**Wendell Huang** (CFO and SVP)\nOkay?\n\n**Laura Chen** (Analyst)\nOkay. Thank you. Thank you. Very clear.\n\n**Wendell Huang** (CFO and SVP)\nThank you.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Laura. Operator, in the interest of time, we'll take the questions from the last two participants, please. Thank you.\n\n**Operator**\nYes. Next one, Krish Sankar, TD Cowen. Go ahead, please.\n\n**Krish Sankar** (Analyst)\nYeah, hi. Thanks for taking my question. My first one is C.C. About 10 years ago, back in the smartphone days, TSMC would talk about the revenue opportunity for TSMC per phone. I was wondering, in today's world, can you talk about how much one gigawatt of AI data center capacity could translate in terms of wafer demand or revenue for TSMC? I have a follow-up.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Krish's first question, you noted in the past in the smartphone megatrend, we talked about the content per phone opportunity for TSMC. Now with AI, is there a way to frame or quantify one gigawatt of data center capacity? What is the revenue opportunity for TSMC?\n\n**Che-Chia Wei** (CEO and Chairman)\nRecently, as I said, the AI demand continues to increase. My customers say that 1 GW, they need to invest about $50 billion. How much of TSMC is a wafer inside? We are not ready to share with you yet because of different approaches. Okay?\n\n**Krish Sankar** (Analyst)\nNo worries. A quick follow-up.\n\n**Che-Chia Wei** (CEO and Chairman)\nExcuse me. I just want to say that you know right now it's not only one chip. Actually, it's many chips together to form a system. All right?\n\n**Krish Sankar** (Analyst)\nGot it. Very helpful for that. A little quick follow-up. You know, obviously, you folks forecast long-term trends and then build capacity towards that. I'm kind of curious, when you look at the AI demand over the next several years, from a TSMC angle, does it matter whether that demand is coming through a GPU or an ASIC? Does it have an impact on your revenue or gross margin mix?\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Krish. His second question is, again, with our business outlook. We forecast the long-term trends. We plan our capacity, as C.C. said, in a thorough and disciplined manner. His question is, what are the implications, for example, of, I believe you said GPU versus ASIC in terms of the AI market? Do we have a preference or is there a difference for TSMC? Is that correct, Krish?\n\n**Krish Sankar** (Analyst)\nThat's right. The impact to revenue and gross margin, whether it's a GPU or an ASIC.\n\n**Jeff Su** (Director of Investor Relations)\nRight. Okay.\n\n**Che-Chia Wei** (CEO and Chairman)\nKrish, no matter if it's a GPU or it's an ASIC, it's all using our leading-edge technologies. From our perspective, we are working with our customer, and we all know that they are going to grow strongly in the next several years. There is no differentiation in front of TSMC. We support all kinds of types.\n\n**Krish Sankar** (Analyst)\nThank you very much.\n\n**Jeff Su** (Director of Investor Relations)\nThank you. Operator, can we take?\n\n**Krish Sankar** (Analyst)\nThank you.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Krish. We'll take the question from the final participant, please.\n\n**Operator**\nYes. Last one off the line, Macquarie. Go ahead, please.\n\n**Arthur Lai** (Analyst)\nHi, C.C., Wendell, and Jeff. Congrats on a strong outlook. Asalai from Macquarie. My question is about competition. C.C., you define the Foundry 2.0 market. I wonder what's the strategic initiative that TSMC is undertaking to further strengthen your competitive landscape and also in this broader ecosystem? For some context, I got the question from the U.S. investor as your clients announced they invest in Intel. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Arthur's question is around competition. In the Foundry 2.0 landscape, what strategic initiatives, what things are TSMC focusing on to further strengthen our competitive advantage? I think the last part, Arthur, you're asking in the environment where one of our competitors in the U.S., how do we focus on the competition? Is that correct?\n\n**Arthur Lai** (Analyst)\nYes. Thank you, Jeff.\n\n**Che-Chia Wei** (CEO and Chairman)\nOkay. Let me answer that one. When we introduce Foundry 2.0, we set the purpose that, as I said, one of my customers said that the system performance is very important in these days, not only a single chip. Also, let me share with you that our advanced packaging revenue is approaching close to 10%. It's significant in our revenue, and it's important for our customer. That's why we introduce Foundry 2.0 to categorize this foundry business, not as usual. Previously, we only looked at the front-end portion. Now it's the whole thing, the front-end, the back-end, and also important for our customer. That's why we introduce 2.0. Talking about our competition in the U.S., that competitor happens to be our customer, a very good customer. In fact, we are working with them for their most advanced product. Other than that, I don't want to make any more comments.\n\n**Arthur Lai** (Analyst)\nYeah. Thank you, C.C. Can I ask one more question?\n\n**Jeff Su** (Director of Investor Relations)\nYes, you have two. Your second question, sure.\n\n**Arthur Lai** (Analyst)\nYeah. My second question is very quick on the end demand. Recall, C.C., you last time mentioned that we should also monitor and worry about the prebuilt, especially in the consumer electronics. This quarter, our numbers suggest that there's a QoQ 19% growth in the smartphone. My question is, do you still worry about the prebuilt? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Arthur, the second question is on smartphone. Are we concerned about prebuilt or sort of, I guess, pulling prebuilt from customers in that regard?\n\n**Che-Chia Wei** (CEO and Chairman)\nNo. We don't worry about the prebuilt because when you have a prebuilt, you have an inventory. These days, the inventory already goes to the very seasonal level and very healthy. So no prebuilt.\n\n**Arthur Lai** (Analyst)\nThank you very much.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, C.C. Thank you, Arthur. Thank you, everyone. This concludes our Q&A session. Before we conclude today's conference, please be advised that the replay of the conference will be accessible within 30 minutes from now. The transcript will become available 24 hours from now. Both are going to be available through TSMC's website at www.tsmc.com. Thank you, everyone, for joining us today. We hope you all continue to stay well, and we hope you will join us again next quarter in early 2026. Thank you and have a good day.",
        "fetched_at": "2026-02-04T16:12:59.327Z"
      },
      {
        "ticker": "TSM",
        "title": "Yahoo Finance",
        "published_date": "Jul 17, 2025, 2:00 AM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/TSM/earnings/TSM-Q2-2025-earnings_call-336686.html",
        "content": "**Jeff Su** (Director of Investor Relations)\nGood afternoon, everyone, and welcome to TSMC's Second Quarter twenty twenty five Earnings Conference and Conference Call. This is Jeff Su, TSMC's Director of Investor Relations and your host for today. Today's event is being webcast live through TSMC's website at www.psmc.com, where you can also download the earnings release materials if you are joining us through the conference call. Your dial in lines are in listen only mode. The format for today's event will be as follows.\n\n**Jeff Su** (Director of Investor Relations)\nFirst, TSMC's Senior Vice President and CFO, Mr. Wendell Huang, will summarize our operations in the second quarter twenty twenty five, followed by our guidance for the third quarter twenty twenty five. Afterwards, Mr. Huang and TSMC's Chairman and CEO, Doctor. C.\n\n**Jeff Su** (Director of Investor Relations)\nC. Wei, will jointly provide the company's key messages. Then we will open both the floor and the line for the question and answer session. As usual, I would like to remind everybody that today's discussions may contain forward looking statements that are subject to significant risks and uncertainties, which could cause actual results to differ materially from those contained in the forward looking statements. Please refer to the Safe Harbor notice that appears on our press release.\n\n**Jeff Su** (Director of Investor Relations)\nAnd now I would like to turn the microphone over to TSMC's CFO, Mr. Wendell Huang, for the summary of operations and the current quarter guidance.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nThank you, Jeff. Good afternoon, everyone. Thank you for joining us today. My presentation will start with financial highlights for the second quarter twenty twenty five. After that, I will provide the guidance for the third quarter of twenty twenty five.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nSecond quarter revenue increased 11.3% sequentially in '20 as our business was supported by strong demand for our industry leading three nanometer and five nanometer technologies, partially offset by an unfavorable foreign exchange rate. In U. S. Dollar term, revenue increased 17.8% sequentially to billion and exceeded our second quarter guidance. Gross margin decreased 0.2 percentage points sequentially to 58.6%, primarily due to an unfavorable foreign exchange rate and margin dilution from our overseas fab, partially balanced by higher capacity utilization and cost improvement efforts.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nDue to operating leverage, operating margin increased 1.1 percentage points sequentially to 49.6%. Overall, our second quarter EPS was dollars up 60.7% year over year and ROE was 34.8%. Now let's move on to revenue by technology. Three nanometer process technology contributed to 24% of wafer revenue in the second quarter, while five nanometer and seven nanometer accounted for 3614% respectively. Advanced technologies defined as seven nanometer and below accounted for 74% of wafer revenue.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nMoving on to revenue contribution by platform. HPC increased 14% quarter over quarter to account for 60% of our second quarter revenue. Smartphone increased 7% to account for 27%. IoT increased 14% to account for 5%. Automotive stayed flat and accounted for 5% and DCE increased 30% to account for 1%.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nMoving on to the balance sheet. We ended the second quarter with cash and marketable securities of NT2.6 trillion or US90 billion dollars On the liability side, current liabilities decreased by billion dollars quarter over quarter, mainly due to the decrease of NT38 billion dollars in accrued liabilities and others. The decrease in accrued liabilities and others was mainly due to the payment of income tax. Our financial ratios, accounts receivable turnover days decreased five days to twenty three days. The decrease in accounts receivable was mainly due to anti dollar appreciation as almost all of our accounts receivables are in U.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nS. Dollars. Days of inventory decreased seven days to seventy six days, primarily due to higher N3 and N5 wafer shipments. Regarding cash flow and CapEx, during the second quarter, we generated about $497,000,000,000 in cash from operations, spent TWD $297,000,000,000 in CapEx and distributed TWD 117,000,000,000 for third quarter twenty twenty four cash dividend. Taking the unfavorable exchange rate into consideration, our cash balance decreased billion dollars to NT2.36 trillion dollars at the end of the quarter.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nIn U. S. Dollar terms, our second quarter capital expenditures totaled CNY 9,600,000,000.0. I finished my financial summary. Now let's turn to our current quarter guidance.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nBased on the current business outlook, we expect our third quarter revenue to be between US31.8 billion dollars and US33 billion dollars which represents an 8% sequential increase or a 38% year over year increase at the midpoint. Based on the exchange rate assumption of NT1 to NT29 dollars gross margin is expected to be between 55.557.5%. Operating margin between 45.547.5%. In addition, we maintain our 2025 capital budget to be between US38 billion dollars and US42 billion dollars This concludes my financial presentation. Now let me turn to our key messages.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nI will start by talking about our second quarter twenty twenty five and third quarter twenty twenty five profitability. Compared to first quarter, our second quarter gross margin slightly decreased by 20 basis points sequentially to 58.6. This was primarily due to an unfavorable foreign exchange rate and margin dilution from our overseas fab, partially offset by higher than expected overall capacity utilization and cost improvement efforts. Compared to the first quarter, foreign exchange rate of $1 to dollars The actual second quarter exchange rate was $1 to NT31.05 dollars This created about two twenty basis points margin headwind to our actual second quarter gross margin. We also experienced slightly more than 100 basis points impact from the ramp up of our overseas fabs, mainly as the margin dilution from our Arizona fabs started to kick in.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nWe have just guided our third quarter gross margin to decrease by two ten basis points to 56.5% at the midpoint, primarily due to the continued unfavorable foreign exchange rate and more pronounced dilution from overseas fabs as we ramp up further in Kuevamoto and Arizona. We continue to forecast the gross margin dilution from the ramp up of our overseas fabs in the next five years, starting from 2025 to be between 2% to 3% every year in the early stages and widen to three percent to 4% in the latter stages. Despite the higher cost of overseas fabs, we will leverage our increasing size in Arizona and work on our operations to improve the cost structure. We will also continue to work closely with our customers and suppliers to manage the impact. Overall, with our fundamental competitive advantages of manufacturing technology leadership and large scale production base, we expect TSMC to be the most efficient and cost effective manufacturer in every region that we operate.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nNow let me make some comments on the impact of foreign exchange rate on TSMC's revenue and profitability. NT dollar is the reporting currency of our financial statements. Nearly all of our revenue is in U. S. Dollars, while about 75% of cost of goods sold is in NT.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nTherefore, fluctuations in the exchange rate between U. S. Dollar and NT will have a sizable impact to our reported revenue and gross profit margin. The sensitivity of the revenue to dollar NT exchange rate is nearly 100%. That is every 1% appreciation of NT against U.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nS. Dollars will reduce our reported NT revenue by 1%. The sensitivity of our gross margin to the same 1% exchange rate change is about 40 basis points. That is if NT appreciate 1% against the dollar, our gross margin will come down by about 40 basis points. Compared with our second quarter exchange rate guidance of dollars to NT32.5 dollars provided on April 17, the NT dollar has appreciated by an average of about 4.4% sequentially, which negatively impacted our second quarter revenue by about 4.4% in NT and our gross margin by about 180 basis points.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nFor third quarter of twenty twenty five, based on the current exchange rate of NT1 dollars to NT29 dollars the average NT dollar will appreciate by another 6.6% sequentially, which will negatively impact our third quarter revenue by 6.6% in NT and reduce our gross margin by about two sixty basis points. As a reminder, six factors determining TSMC's profitability, leadership technology development and ramp up, pricing, capacity utilization, cost reduction, technology mix and foreign exchange rate which is not in our control. When the foreign exchange rate is unfavorable as it is currently, we will focus on the fundamentals of our business and being on the other five factors to manage through it and we have successfully done in the past. Thus, even with the unfavorable foreign exchange rate, we believe our long term gross margin of 53% and higher remains well achievable. Now let me turn the microphone over to Cici.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThank you, Wendell. Good afternoon, everyone. First, let me start with our near term demand outlook. We concluded our second quarter with revenue of US30.1 billion dollars above our guidance in US dollar term mainly due to continue the robust AI and HPC related demand. Moving into the third quarter twenty twenty five, we expect our business in the third quarter to be driven by strong demand for our leading edge process technologies.\n\n**C.C. Wei** (Chairman &amp; CEO)\nLooking into second half of twenty twenty five, we have not seen any change in our customers' behavior so far. However, we understand there are uncertainties and risk from the potential impact of tariff policies, especially on consumer related and the price sensitive end market segment. While we observe rebate program in China are stimulating some near term demand upside, We believe this is a short term in nature and continue to expect a mild recovery in overall non AIM market segment in 2025. Having said that, we believe that demand for semiconductor is very fundamental and will continue to be robust. Recent developments are also positive to AI's long term demand outlook.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThe explosive growth in token volume demonstrate increasing AI model usage and adoption, which means more and more computation is needed, leading to more leading and silicon demand. We also see AI demand continuing to be strong, including the rising demand from sovereign AI. Therefore, we now expect our full year 2025 revenue to increase by around 30% in US dollar term, supported by strong demand for our industry leading three nanometer and five nanometer technologies underpinned by working our HPC platform. Amidst the uncertainties, we want to remain mindful of the potential tariff related impact and be prudent in our business planning going into second half twenty twenty five and 2026, while continuing to invest for the future makeup trend. We are also focused on the fundamentals of our business, technology leadership, manufacturing excellence and customer trust to further strengthen our competitive position.\n\n**C.C. Wei** (Chairman &amp; CEO)\nNext, let me talk about TSMC's global manufacturing footprint update. All our overseas decision are based on customers' need, the value some traffic flexibility and the necessary level of government support. This is also to maximize the value of our shareholders. With a strong collaboration and support from our leading U. S.\n\n**C.C. Wei** (Chairman &amp; CEO)\nCustomers and The U. S. Federal State And City Government, we announced our intention to invest a total of U. S. US165 billion dollars in advanced semiconductor manufacturing in The United States.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThis expansion includes plans for six advanced wafer manufacturing fab in Arizona, two advanced packaging fabs and a major R and D center to support the stronger multiyear demand from our customers. Our first fab in Arizona has already successfully entered into high volume production in 4Q twenty twenty four, utilizing the N4 process technology with a yield comparable to our fab in Taiwan. The construction of our second fab, which will utilize three nanometer process technology, is already complete. We are seeing strong interest from our leading U. S.\n\n**C.C. Wei** (Chairman &amp; CEO)\nCustomers and are working on speeding up the volume production schedule by several quarters to support their needs. Construction of our server, which will utilize two nanometer and the eight sixteen process technologies has already begun and we want to get to speeding up the production schedule as well based on the strong AI related demand from our customers. Our fourth wave will utilize Gen2 and A16 process technology and our fifth and sixth wave will use even more advanced technologies. The construction and ramp schedule for those fabs will be based on our customers' need. Our expansion plan will enable TSMC to scale up to a detailed fab faster in Arizona to support the needs of our leading edge customers in smartphone, AI and HPC applications.\n\n**C.C. Wei** (Chairman &amp; CEO)\nWe also plan to build two new advanced packaging facilities and establish an R and D center to complete the AI supply chain. After completion, around 30% of our two nanometer and more advanced capacity will be located in Arizona, creating an independent leading edge semiconductor manufacturing cluster in The US. Thus, TSMC continued to play a critical and integral role in enabling our customers' success. We also maintained a key partner and enabler of The U. S. Semiconductor industry. Next, in Japan, thanks to the strong support from the Japan Central Prefecture and Noble Government, our first specialty technology fab in Komodo has already started rolling production in late twenty twenty four with very good yield. The construction of our second specialty fab is scheduled to start later this year subject to the readiness of the local infrastructure. The ramp schedule will be based on our customers' need and market conditions. In Europe, we have received strong commitment from the European Commission and the German Federal, State and City Government and are progressing smoothly with our plans to build a specialty technology fab in Dresden, Germany. The ramp schedule was also based upon customers' need and market conditions.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIn Taiwan, we support from the Taiwan government. We plan to build 11 wafer manufacturing fab and four advanced packaging facility over the next several years. We are preparing for multiple phases of two nanometer fab in both Q2 and Gaucho sized cars to support the strong structural demand from our customers. By expanding our global footprint while continuing to invest in Taiwan, TSMC can continue to be the trusted technology and capacity provider of the global IC industry for years to come while delivering profitable growth for our shareholders. Now let me talk about our N2 and N16 status.\n\n**C.C. Wei** (Chairman &amp; CEO)\nOur N2 and N16 technologies lead the industry in addressing the infeasible demand for energy efficient computing, and almost all the innovators are working with TSMC. We expect the number of new take outs for two nanometer technology in the first two years to be higher than both three nanometer and five nanometer in the first two years, fueled by both smartphone and HPC applications. N2W deliver four node performance and power benefit with 10 to 15 speed improvement at the same power or 20 to 30% power improvement at the same speed and more than 15% chip density increase as compared with N3E. N2 is well on track for volume production in the 2025 as scheduled with a ramp profile similar to N3. With our strategy of continuous enhancement, we also introduced N2P as an extension of our N2 family.\n\n**C.C. Wei** (Chairman &amp; CEO)\nN2P features a further performance and power benefits on top of the N2, then volume production is scheduled for second half twenty twenty six. We also introduced A16 featuring our best in class superpower rail or SPR. Compared with the N2P, A16 provides a four zero eight to 10% speed improvement at the same power or 15 to 20 power improvement at the same speed and additional seven to 10% chip density band. A16 is best suitable suited for specific HPC products with complex signal route and dense power delivery network. Volume production is on track for second half twenty twenty six. We believe N2, N2P eight sixteen and its derivatives will fuel our N2 family to be another large and long lasting node for TSMC. Finally, let me talk about our A14 status.\n\n**C.C. Wei** (Chairman &amp; CEO)\nFeaturing our second generation DarioSphere transistor structure, A14W delivers another four node stride from M2 with performance and power benefits to address the increasing structural demand for high performance and energy efficient computing. Compared with the M2, A16 will provide 10 to 15 speed improvement at the same power or 20 to 30% power improvement at the same speed and about 20% chip density gain. Our A14 technology development is on track and progressing well with device performance and year improvement on or ahead of schedule. Volume production is scheduled for 2028. We will continue our strategy of continuously enhancement with A14, including a superpower rail offering planned for 2029.\n\n**C.C. Wei** (Chairman &amp; CEO)\nWe believe A14 and its derivative will further extend our technology leadership position and enable TSMC to capture the growth opportunities way into the future. This concludes our key message and thank you for your attention.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Cici. This does conclude our prepared statements. So before we begin the question and answer session, I would like to remind everybody to please limit your questions to two at a time so that we can allow all the participants an opportunity to ask their questions.\n\n**Jeff Su** (Director of Investor Relations)\nQuestions will be taken both from the floor and from the call. Should you wish to raise your question in Chinese, I will translate it to English before our management answers your question. For those of you on the call, if you'd like to ask a question, please press the star then one on your telephone keypad now. If at any time you'd like to remove yourself from the question queue, please press star then 2. So now let's begin question and answer session.\n\n**Jeff Su** (Director of Investor Relations)\nWe'll take the first few questions from the floor, then we'll flip and alternate to those on the line. Maybe we'll go left, center, and then right, sort of a sequence. And we'll start here with go call Harry Haran from JPMorgan.\n\n**Gokul Hariharan** (Managing Director)\nThanks, Jeff, and good afternoon, Siti and Vindal. First question on demand. I think T. V, you mentioned data center AI demand certainly looks better than maybe three months back. Last quarter, you also mentioned cohort capacity will probably come into balance by 2026.\n\n**Gokul Hariharan** (Managing Director)\nIs that still our view? Or you think that the capacity now starts to look tighter? Second, I think you talked about on device AI as a potential future driver. Are you seeing more development on the on device AI part? Is it better compared to the three, six months back?\n\n**Gokul Hariharan** (Managing Director)\nAnd lastly, near term, your 4Q looks like you're expecting revenue to decline. Is that based on what your customers are telling, especially on the consumer side? Or is it just TSMC being cautious and conservative in terms of the guidance?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Gokul, thank you. Again, for the benefit of those, of course, here in person on the line, please allow me to summarize your questions. So maybe we'll take them one by one. His first question is on the demand, particularly data center and AI related demand.\n\n**Jeff Su** (Director of Investor Relations)\nAs Fiji said in his remarks, it is certainly still even stronger. So his question is about the advanced packaging and cobots demand into 2026. How do we see the supply demand gap narrowing or becoming more balanced for cobots specifically?\n\n**C.C. Wei** (Chairman &amp; CEO)\nKoku, the demand from the AI getting stronger and stronger if you pay attention to what for treating companies as CEO say. And so the makeup trend for the AI is continued to be strong and so is the cohort.\n\n**C.C. Wei** (Chairman &amp; CEO)\nAnd so now we are again, we are in a a mode trying to narrow the gap. I don't want to use the balance. The last time you guys misunderstood what I said, you saw the bad wording. So I wanna say, we try to narrow the gap.\n\n**Jeff Su** (Director of Investor Relations)\nAlright.\n\n**C.C. Wei** (Chairman &amp; CEO)\nSo momentum is still there and very healthy.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. And then the second question or second part is on on device or edge AI. Gokul wants to know how is the development of customers to work on on device AI compared to maybe three to six months ago. What is the interest or activity level and how do we see this?\n\n**C.C. Wei** (Chairman &amp; CEO)\nThe last time I say it, I say that it takes one to two years for my customer to complete the new design and the product. The momentum is still going. They are still continuing to, as time goes by, as I said, the increase on the edge device, the number of the units is actually mild. But then the die size increased. We continue to see that.\n\n**C.C. Wei** (Chairman &amp; CEO)\nAnd the die size increased by about 5% to 10% and that kind of trend continued. You have to wait another probably six months or to one year to see a explosion.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. And then go with the second question on the final part on the near term. I think, Gokul, your question is with our third quarter guidance implies fourth quarter, is there any particular reason or any comment that we want to make about the implied fourth quarter business momentum?\n\n**C.C. Wei** (Chairman &amp; CEO)\nI think you did not mention Gokul's company and said or you are become conservative. That company is more real. We are are a company that but we say that you are achieved and achieved the high target. So your calculation, I think, also is nothing. But a lot of you is calculating our reported numbers so that you can easily see that our fourth quarter is decreasing.\n\n**C.C. Wei** (Chairman &amp; CEO)\nWe take into the consideration of the possible impact of tariff and a lot of other uncertainties. So we become more conservative. That's our current attitude. But I guarantee you with our technology leadership position and excellent manufacturing, if there are any opportunities we want to catch and be expected that we achieve our high end target.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, C.\n\n**Jeff Su** (Director of Investor Relations)\nC. Thank you, Gokul. Sorry, let's go one by one. The second question that may be Charlie Chan from Morgan Stanley.\n\n**Charlie Chen** (VP - Investment Banking)\nThanks for taking my question. Good afternoon, Cici and Jeff. So first of all, congrats for very strong results and especially on the gross margin side, a very good execution indeed. So my first question is really also on the gross margin because the accumulated effect in pay is almost like 4.4 percentage points, right? So too big to ignore.\n\n**Charlie Chen** (VP - Investment Banking)\nSo when TSMC consider your 2,026, the wafer pricing, so called the impacting your value, would you consider this effective impact? And it's company confident to keep your margin similar to this year's label. Feel like a 53% is low bar. So just want to admit a little bit high and see about that effect that can be considered to reflect to your value. Thank you.\n\n**C.C. Wei** (Chairman &amp; CEO)\nOkay. So Charlie's first question is on margin and I guess pricing. He knows obviously as Wendell said the big move in the exchange rate and therefore, a big impact to our profitability and gross margin. So his question is, looking ahead to 2026, can we reflect or earn our value from the including the FX impact into the pricing? And therefore, what is our confidence level on the gross margin for next year?\n\n**C.C. Wei** (Chairman &amp; CEO)\nCan it keep a similar level as this year? Well, let me assure you that, yes, the impact from the exchange rate is huge. But you try to imply that whether we are still our value. Let me answer that. We are working on it and we have confidence that the 53% gross margin and higher, I still want you guys to take more attention to and higher. Thank you.\n\n**Charlie Chen** (VP - Investment Banking)\nOkay. Thanks. Hopefully, it will work out well. My second question is also a very hot topic recently about the H20 chip shipping to China. I remember a few months ago, there was another question on this matter, right?\n\n**Charlie Chen** (VP - Investment Banking)\nMeaning that back then, I believe that chip was a suspend, but you're still very confident about your mid-forty percent CAGR for cloud saving growth in the coming five years. Right now China becomes your addressable market again. Do you think that mid-forty percent CAGR target can be revised up?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, Charlie. So Charlie, second question is around the AI accelerator demand. He knows, of course, our customers' product, H20 recently is now seems to be able to ship to China versus three months ago, it was not. So his question really is our long term AI accelerator growth CAGR to grow close to mid-40s.\n\n**Jeff Su** (Director of Investor Relations)\nCan it be higher? Do we think it will be higher? Is there upside to this?\n\n**C.C. Wei** (Chairman &amp; CEO)\nCharlie, the S20 now is again according to local trading companies and CEO. We did not receive the signal yet, so it's too early to give you an estimate, but certainly this is a good news, right?\n\n**C.C. Wei** (Chairman &amp; CEO)\nI mean that's a China is a big market and my customer can still continue to supply the chip to the big market and it's a very positive news for them and in return is a very positive news for TSMC. We know we are ready to increase our forecast, not yet, another quarter probably will be more appropriate to answer your question.\n\n**Charlie Chen** (VP - Investment Banking)\nThanks for your comments, very helpful.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThanks.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Charlie. Okay, then we'll move on to the right side of the room for us, Bruce Lu from Goldman Sachs.\n\n**Bruce Lu** (VP Asia Technology)\nThank you for taking my question.\n\n**Bruce Lu** (VP Asia Technology)\nI think Charlie already asked the profitability question already. So I just move on to your end to mid rent. So what's the revenue contribution can make for the N2 RED for next year? I'm not a bit surprised to hear that N2 RED is similar rated with N3 with N2, you have both HPC and smartphone customer ramping on the same stage or in the first year one or year two, right? Can we expect like 15% revenue contribution coming from N2 for next year or similar level compared to N2 which is around 10%, 11% for the year two.\n\n**C.C. Wei** (Chairman &amp; CEO)\nBruce's first question is around the N2 ramp. His question is about the ramp and the ramp profile because we said the N2 ramp profile is the N3. So what does that mean? And then also, of course, what revenue contribution do we expect or can we share for N2 in 2026? Bruce, do you have a good argument?\n\n**C.C. Wei** (Chairman &amp; CEO)\nUsually, we ramp up a new node using the smartphone. If you that, everybody knew it. Now it's not only a smartphone but also HPC product. However, the ranking profile I just reported say similar to three nanometer. It's limited by our capability to build a new fab to ramp it up and also a little bit it's straightforward.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIt's constrained by the capacity. So we say the ramp profile is similar to m three, but the revenue contribution certainly will be bigger because you don't expect our m two is the same price as the m three. Right?\n\n**Bruce Lu** (VP Asia Technology)\nOf course.\n\n**C.C. Wei** (Chairman &amp; CEO)\nGood. Thank you.\n\n**Bruce Lu** (VP Asia Technology)\nIf that is the case, we should assume that in '27, the N2 ramp up will be faster, right? Because it twelve, eighteen months for you to build new fab, you should be able to achieve the even higher growth in '27.\n\n**C.C. Wei** (Chairman &amp; CEO)\nSo Bruce is asking if the revenue contribution is much higher than '26 then should it be even greater than '27? Who do I answer that question in '26? Thank you.\n\n**Bruce Lu** (VP Asia Technology)\nOkay. The next question is for M5 and M3, right? So I want to understand the supply demand for M5 N3 in the coming two years. Most of the AI will migrate to N3 next year. But it seems to me that the N5 conversion is mostly done, N5, N3 conversion is mostly done.\n\n**Bruce Lu** (VP Asia Technology)\nAnd we don't really see like going to your capacity expansion N3. So it becomes like super like tightness for the N3 for the coming years. Does that mean that N5 will be low in terms or we try to build more N3 in the future or what kind of or we should see we can fill out more value for N3, N5 next year?\n\n**C.C. Wei** (Chairman &amp; CEO)\nOkay. Bruce's second question is around N5 and N3. He wants to know what is the outlook for the supply demand at these two advanced nodes in the coming two years. His observation, AI products will migrate to N3 and the N5, N3 conversion is mostly done. So his question is, will three nanometer supply be very tight the next three years?\n\n**C.C. Wei** (Chairman &amp; CEO)\nI think the last part, therefore, can we earn our value or price for that tightness? And then on the flip side, what about five nanometer? Will it become lower utilization? I like your comment, we had to share our value because of very tight in N3 capacity. It will be continued for couple of years, very tight in fact, N5 also very tight.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThe demand is high because of a lot of AI product still in the four nanometer technology node. They are transitioning to three nanometer probably in the next two years. In the meanwhile, n five are still very tight in capacity. N three even tighter. And so we are working hard.\n\n**C.C. Wei** (Chairman &amp; CEO)\nOne of the TSMC's advantage is that we have peak of that cluster. And so we have between n seven, n five, n three, even the future n two, we have almost for each node, have about 85 to 90% common tools. So it's it's not free, but it's much easier for TSMC to adjust or convert the capacity between those node. And today, let me share with you, we are using the n seven capacity to support n five because the n five is too tight. And then we are converting n five to n three as you just pointed out.\n\n**C.C. Wei** (Chairman &amp; CEO)\nWe'll continue to do that. And so today, we are our leading edge technology is a capacity. We define n seven and below are all very tight. Same time, we are working very hard to, again, my my sentence and narrow the gap between the demand and the capacity.\n\n**Jeff Su** (Director of Investor Relations)\nOkay.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Bruce. Let's go to the participants online. We'll maybe we'll take two questions from the online and then we'll come back to the floor. Thank you. Operator?\n\n**Operator**\nYes. Now asking question, Brett Simpson, Arete.\n\n**Brett Simpson** (Senior Analyst)\nThanks very much. I had a question for Wendell on gross margins. And it's always helpful you've laid out a framework for some of the puts and takes to TSMC's gross margins. But my question is really some of these headwinds like FX and the dilution from overseas fabs are more structural cost increases. And to what extent can TSMC adjust wafer pricing higher to neutralize these cost increases in your business?\n\n**Brett Simpson** (Senior Analyst)\nAnd I guess, secondly, on this point, how much economic benefits are you seeing from applying AI across the fabs? I think NVIDIA has mentioned that they're working with TSMC closely strategically in areas like computational lithography to try to drive further fab efficiencies. So can you maybe just give us some examples where you're seeing real gains in your cost structure? And are we at a point where you're starting to see several points of gross margin benefit from AI efficiencies? Thanks.\n\n**Jeff Su** (Director of Investor Relations)\nAlright, Brett. So Brett, first question is little bit involved, but looking at our gross margin and profitability. He knows that the unfavorable exchange rate and the dilution from the overseas due to the higher cost, these are structural headwinds. So his question is, can we how can we or can we earn our value or adjust our wafer price to help offset some of these? And also how much we've talked about before about using AI ourselves in our operations, how much economic benefit are we deriving from things such as the legal with our customers such as and other other examples of using AI where it's helping our cost structure and can we quantify that quantify the benefit, sorry. That's your question. Right? Right?\n\n**Brett Simpson** (Senior Analyst)\nThat's right. Thanks, Jeff.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nOkay, Brad. The first question, gross margin. That's the reason why we've been talking about the six factors affecting our profitability. I don't think I need to repeat those six factors but whenever, for example, using foreign exchange rate example, a few years ago there were also periods of time that foreign exchange rates were against us. So we are able to lean on the other factors to help us mitigate the negative impact from certain factors and therefore still achieve our gross margin targets.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nAnd you specifically asked about ASP, raising the price, but the price is just one of the factors. And I believe C. C. Just elaborate a lot on earning our value. And at the same time, there are other factors that we can leverage on.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nSo all in all, that's why we're saying 53% and higher and higher gross margin is still achievable. Your second question on AI benefits. I think we also talked about that before. We use that in operation, in manufacturing. We also use that in R and Ds.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nAnd just think about if we are able to produce 1% of productivity gains in a company of our size that equals to US1 billion dollars So that's the number we can share with you without going into too much other details.\n\n**Jeff Su** (Director of Investor Relations)\nDoes that answer your question, Frank?\n\n**Brett Simpson** (Senior Analyst)\nYes.\n\n**Brett Simpson** (Senior Analyst)\nYes, that's great. Thanks very much, Wendell. I guess my follow-up question, I guess just digesting your prepared remarks, Sisi, you mentioned 11 fabs in Taiwan. I think that counts eight fabs for overseas that you're planning that aren't commercially online yet. You maybe just talk a bit about I mean, I've never seen that type of constructing that type of roadmap before from TSMC.\n\n**Brett Simpson** (Senior Analyst)\nIt's quite big. Can you maybe share with us if you're planning a bigger expansion of new capacity next year? And I say this because, you know, in the last few months, we've seen so many gigawatts data center announcements. I think this week, we had one from Meta that was significant. So are you the demand looks very strong and I'm just wondering whether you have enough capacity to satisfy demand next year and whether you plan to convert further five nanometer to three nanometer And how you see the M2 capacity planned for 2026? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Brett's second question, he notes that we are building many fabs both in Taiwan and also overseas. He's never seen this size or scale of capacity expansion from TSMC before. So it's very and he also knows that the demand from data centers continues to be very strong. So his question is basically very simply, do we have enough capacity to support the strong demand specific to next year and also very specifically to two nanometer and will we further also convert more five nanometer to three? That's I think all of his question.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThank you. Greg, your observation is right. Recently we saw a lot of announcement of the AI data center around the world and the demand on three nanometer, actually on five nanometer, three nanometer and the future of two nanometer are very high. We did not see this kind of a strong demand for a long time, but what be enough to support them, I still want to use my word, say that we try very hard to narrow the gap between the demand and the supply. We're working very hard.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, Brett. Let's go to the next participant on the call.\n\n**Operator**\nNow it's Arthur Lai from Macquarie. Your line is open now.\n\n**Arthur Lai** (Asia Equity Research - Technology)\nHi, thank you, C. C, Wendell and Jeff. Arthur Lai from Macquarie. Again, congrats on strong results. I would like to follow-up on the M2.\n\n**Arthur Lai** (Asia Equity Research - Technology)\nI think as Sisi highlight, this is a very exciting note we are all heard. And then I want to follow on the return on investment. Can you compare to the N2 and N3, the return on investment and then give us some more color? Second one is the reason we ask this question is because the CapEx per day we actually until it's higher, right? And then we also heard from industry like the companies yield on the end to is also pretty good.\n\n**Arthur Lai** (Asia Equity Research - Technology)\nSo can you give us some put and take on how we think of the N2's future development? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. So Arthur's question, both questions I think are around N2. N2, as you said, is a very exciting note. He wonder if we would like to know, understand what is the return or the return on investment that we see from N2 compared to N3? And also, can we talk a little bit into the CapEx is higher, but the yield is still very good.\n\n**Jeff Su** (Director of Investor Relations)\nWhat is the developments that we're seeing for two nanometer? I think that's is that your question, Arthur?\n\n**Arthur Lai** (Asia Equity Research - Technology)\nYes, yes. Yeah, exactly.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nHey, Arthur. N2 return, as we said before, N2 profitability is better than N3. Now there were questions asking how many quarters to catch up with the corporate before and N3 was it took N3 longer. But for N2, we think it will be back to the old days. Having said that, I need to remind everyone that in the old days, we're talking about corporate average of, say, 50% gross margin.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nNowadays, we're talking about 53% gross margin. So it becomes less meaningful to talk about how much time it takes to catch up with corporate nowadays. But having said that, structurally M2 does have a better profitability than M3. Okay. And N2 development is right on track.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nWe're ramping it in the second half of this year. We expect the revenue to come up in the first half of next year.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, Wendell. Thank you, Arthur. Let's come back to the floor. We'll go left, middle, right. So maybe Sunny Lin from UBS.\n\n**Sunny Lin** (Analyst)\nGood afternoon. Thank you for taking my question. Very good results and congrats. So my first question is a follow-up on CapEx. So obviously, full year sales guidance is stronger.\n\n**Sunny Lin** (Analyst)\nYou are turning more constructive on high performance compute and AI. Yet you are keeping your CapEx guidance. So is it fair to assume that you are considering some conservatism for CapEx for this year, given the ongoing macro uncertainty? Or is it because in the short term, your capacity expansion is somewhat constrained by the ability that you can ramp up more capacity? And therefore, maybe in 2026 and 2027, we should expect some acceleration of your CapEx spending.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. So Sunny's first question is around CapEx. She notes, of course, that we raised our 2025 revenue guidance this year and we certainly still see a very robust demand from AI, yet we kept CapEx guidance in the same range of 30 to 42. So she wants to understand why. Is it because of macro uncertainty?\n\n**Jeff Su** (Director of Investor Relations)\nIs it because of constraints in the construction? And her other part of this question is what is the CapEx outlook for 2026 and 2027, I guess?\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nSami, the CapEx, as we said before, the CapEx invested in the given year is for the business opportunities in the following years. And as long as the business opportunities, we will not hesitate to invest. Having said that, nowadays, as Cici also said, with all these macro uncertainties, we are mindful of these uncertainties. So we also take that into considerations in our capacity and CapEx plan. Going forward, it's too early to talk about future years CapEx, but I can share with you a company of our size.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nIt's unlikely that you see CapEx dollar amount suddenly drop a lot in any given years. That's all I can share with you.\n\n**Sunny Lin** (Analyst)\nGot it. Sounds like CapEx could be going higher in the coming years. My second question is on Cloud AI. And so you are things like earlier achieved you most of the sales upside for 2025 to Cloud AI. And therefore, I wonder if you have an update on the Cloud AI growth in 2025.\n\n**Sunny Lin** (Analyst)\nWould you guide it before to be about 100% for 2025? And the implication to your co op capacity expansion, would you be are you able to maybe expect a bit more co op capacity for Fisher to support a stronger call AI growth for Fisher? And any other early insights that you could share with us for your co op capacity expansion for 2026? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. So Sunny's second question is asking about our AI, well, she said cloud AI, basically our AI accelerated growth in 2025 and related the co ops capacity. So her question is, what is the AI accelerator revenue growth we expect in 2025? And then what is our co ops capacity expansion plan for 2025? And she asked a similar question to Charlie or someone earlier. What is the plan for COWAS capacity in 2026?\n\n**C.C. Wei** (Chairman &amp; CEO)\nWell, my answer stays the same. We are trying very hard to narrow the gap. For now and for 2026. The demand, the momentum of our ATRC and we shrunk and so we we are building many new facilities in the back end to increase the AI increase the cobwebs capacity to support our customer.\n\n**C.C. Wei** (Chairman &amp; CEO)\nAI demand is very strong and so this cobwebs capacity, the demand is very strong.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, Sonny. Then we'll move on to Laura Chen from Citi.\n\n**Laura Chen** (Research Analyst)\nYou for taking my question and congrats for the good result and outlook. My question is also about the AI chip. You mentioned that AI chip is getting bigger and bigger and also the power consumption is getting much more. So I'm just wondering that among like your advanced technology, including like the advanced node, we also noted that during the symposium, TSMC also announced some of the new technology in advanced packaging as well. So I'm just wondering how do you kind of prioritize your leading edge advanced packaging?\n\n**Laura Chen** (Research Analyst)\nDuring the symposium, we see that system now wait for that kind of a new design. Do you have any like plan or like timeline for the new technology? And should we think about that, that should be kind of aligned with our most of the business know process like N2 or X16 going forward?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. So Laura's first question is on advanced packaging. She notes AI, the die sizes are increasing, the need for power consumption or energy efficiency is rising. So she wants to understand how our strategy for advanced packaging along with the advanced node development. Are there any specific packaging solutions that we're prioritizing?\n\n**Jeff Su** (Director of Investor Relations)\nWhat about the timeline and roadmap? How does that match up with our advanced node roadmap?\n\n**C.C. Wei** (Chairman &amp; CEO)\nI think TSMC's philosophy to develop a technology is working with customer. The customer has such demand. We develop the technology, we increase the capacity for JET.\n\n**C.C. Wei** (Chairman &amp; CEO)\nSo priorities, every customer is important to TSMC. So and in the advanced packaging side, a lot of customers use the different approaches. So we are developing a variety of different back end packaging, advanced technology for all the customers. Further is related to the advanced DTS technology. The answer is yes.\n\n**C.C. Wei** (Chairman &amp; CEO)\nOkay. So we have a system integration. We have a code words error. That's a terminology. We have a lot of different name that I cannot even remember, but it's a lot of varieties and we work with our customer to meet their demand. Now I can answer you.\n\n**Laura Chen** (Research Analyst)\nIs that easy to kind of leverage or transfer different kind of technologies from your perspective?\n\n**Jeff Su** (Director of Investor Relations)\nSo Laura is asking how fungible are these different packaging technologies? How interchangeable or easy to transfer the technology between different packaging solutions?\n\n**C.C. Wei** (Chairman &amp; CEO)\nOf course. There are some similarities in between. Otherwise, we are going take too much of the effort and did not get the return.\n\n**C.C. Wei** (Chairman &amp; CEO)\nYes, there's a lot of similarities but a lot of varieties also. Okay.\n\n**Laura Chen** (Research Analyst)\nThank you. And my second question is, we know that obviously the AI demand and advanced nodes and advanced leading edge packaging is very tight. And but I'm just wondering that industry wise, still see probably overcapacity in mature nodes. TSMC also has like more mature 16 nanometer or more above that kind of process. So can we kind of consolidate our mature nodes to kind of make better efficiency and probabilities to enhance the like those capacity to fulfill the demands across the board?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. So Nora's second question is on mature nodes. She notes there is overcapacity on the industry wide in older nodes. So she wants to understand for TSMC specifically, if we take, for example, 16 nanometer and older nodes, what is our strategy, can we consolidate amongst the different nodes, how do we protect our profitability?\n\n**C.C. Wei** (Chairman &amp; CEO)\nGood question.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIf you read the newspaper, there are so much of mature node capacity. At TSMC's strategy actually is on the mature node technologies, we give it up kind of specialties. For example, that RF technology or CMOS image sensor or the high voltage. So we develop the technology at the request of our customer. So we don't worry too much about it, what you say, the overcapacity.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIf it is really overcapacity, we will not build a fab in Japan, We will not build a fab in Germany. So this is not overcapacity. It's all related to customers that need customers that demand and those are all specialty technologies. Did I answer your question?\n\n**Jeff Su** (Director of Investor Relations)\nThank Okay.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Laura. I think in the interest time, we'll go to Brad Lin from Bank of America. Then we'll take one more from the line and then if there's one more from the floor.\n\n**Brad Lin** (Director)\nThank you for taking my question.\n\n**Brad Lin** (Director)\nI have two questions. My first one is on the human robot. So we have learned that human robot started to contribute to TSMC and it is gaining momentum as the next frontier of the AI hardware. How does TSMC evaluate the market size of humanoid robot in the semiconductor and in terms of potential market cap, compute and also sensor requirements? Thank you.\n\n**Brad Lin** (Director)\nAnd do you think that might be another driver potentially for mature nodes too? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Thank you, Brad. So Brad, first question is around humanoid robot. We're starting to see some contribution. He wants to understand how do we evaluate the market size, what is the addressable opportunities for TSMC in the long term at the leading edge and also on the mature nodes with certain type of specialty.\n\n**C.C. Wei** (Chairman &amp; CEO)\nBrett, it's too early. Actually, it's too early to say that he will know the robot will play a role in this year. Next year, probably still too early because of it's so complicated. You know that human know it's a robot. Well, most of the time what we use, I think the first one will be used in in medical industry to take care of the people getting older like me.\n\n**C.C. Wei** (Chairman &amp; CEO)\nProbably some days I needed some human knowledge robot to help me, But, you know, it's very complicated because it's not we are talking about a brain only. Actually, you're talking about a lot of sensor sensor technology. That's the image sensor, the pressure sensor, the temperature sensor, and all the feedback to the CPU and so it's very complicated and since it's dealing with human being directly, I should be very very careful. But then once you start to fly, you are a big big class. I talked to one of my customer and he said that the EV car is nothing.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIt's it's a robot what the 10 times of that. I'm waiting for that. Okay. Did I answer your question?\n\n**Brad Lin** (Director)\nYes. Yes. I believe the client definitely owns EV cars and robots too, so he knows it well. So my second question will be on the potential point ahead of the so called recycling of value into 2026. So we know well, normally, we continue to recycle value into our pricing.\n\n**Brad Lin** (Director)\nSo even the potentially higher pricing in 2026, are you observing any signs of demand pulling from their customers in the second half of the year and potentially, well, given the tight pipeline of M3 and M5, which we see a continuous trend into 4Q, even though we already guided potential decline, but yes, any point potentially.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Brad, second question very specifically, he's asking as we C. C. Talked about that we will continue to earn our value. Do we see any customers trying to pull in their demand ahead of 2026 into the second half of this year?\n\n**Jeff Su** (Director of Investor Relations)\nAnd do we have any additional comments to offer on the fourth quarter besides what we have already shared?\n\n**C.C. Wei** (Chairman &amp; CEO)\nWell, the answer is no. We did not see any different customers of the heaviest so far. Okay. But let me share with you, I add more color.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIf you are talking about the three millimeters demand, for example, the cycle time is here, what takes about the four months. So there's no way you can pull in anything. I mean, that's a yeah. And we have a as I said, our capacities are very, very tight. So we already have all the schedules and so we'll review room for for you.\n\n**C.C. Wei** (Chairman &amp; CEO)\nLet me say that. Even they want it. No. The answer is no. So 2026 is 2026. We will share with you.\n\n**Brad Lin** (Director)\nThank you very much.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Siti. Thank you, Brad. All right. Operator, let's go to the we'll take questions from the last participant on the line.\n\n**Operator**\nYes.\n\n**Operator**\nThe last one to ask question, Matiji Husseini from SIG.\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nYes, sir. Thanks for taking my question. The first one has to do with capital intensity. When I look at the past five years when you were ramping N3 and N5, the capital intensity was at or above 40%. And you also highlighted how N3 tape out is tracking better than n three and n five combined.\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nDoes that imply that the capital intensity would need to go back up to 40? And in other words, an initial investment for MT to accommodate these flip outs? Is that the level of thinking about how investments are going to play out and have fun?\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Mehdi. Sorry. We couldn't hear you exactly clearly. Let me try to summarize your question, all right, which is some of these questions around capital intensity. He knows that in the past when we invest in new nodes or structural, the megatrends like we have with N3 and N5, our capital intensity has jumped up to greater than 40%.\n\n**Jeff Su** (Director of Investor Relations)\nSo if I heard you correctly, Madi, your question is this time we talked about the strong demand for two nanometer multiyear upcoming. What is our expectation on capital intensity? Is that correct, Nadeep?\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nYes, that's correct.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nNadeep, let me answer this question. As we just said, the capital expenditure invested in any year is the future growth opportunities. So if we do our job right, the growth in the next few years is likely to exceed the growth in CapEx dollars, even though as I said, if CapEx dollars is unlikely to drop significantly in any given year. So you'll see a higher growth in revenue than the growth in capital expenditure, then you don't have it such a high capital intensity. We actually demonstrated that in the past few years.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nAnd also let me just share with you that because of this, we're not operating setting a capital intensity as a goal. It's the dollar amount invested is really on the structure demand growth in the following years. So talking about capital intensity is also less meaningful than before.\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nOkay. Thank you. And a follow-up for me. You highlighted NTP I'm I'm sorry. You highlighted a 16, which will be very applicable for hyperthermal compute.\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nIs that is that the node where AI and HPC would actually be at power with a smartphone as an end market that would drive demand for the most mini range node?\n\n**Jeff Su** (Director of Investor Relations)\nSorry, Madhee. Again, I apologize. We apologize. I could not hear you clearly, but I think his question is about on a 16, where we said it's more for specific HPC related offerings. So his question is, I think, maybe your question is, is that where the AI demand also comes in for the two nanometer family?\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nYes. I don't know.\n\n**Mehdi Hosseini** (Senior Equity Research Analyst)\nAnswer because so far, AI has been n plus one, n plus two. Is that node a 16 the first node where AI would move to the leading edge?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. His question okay. Maybe let me rephrase it. I think I understand better. His question is really about AI adoption of the leading edge node, the end node.\n\n**Jeff Su** (Director of Investor Relations)\nYou know, we see smartphone, we see HPC. This question very specifically, how do we see the AI adoption of the most leading node for TSMC? He observed in the past, it is generally been one node behind. So how do we see that going forward with things such as a 16?\n\n**C.C. Wei** (Chairman &amp; CEO)\nWell, you're right.\n\n**C.C. Wei** (Chairman &amp; CEO)\nUsually, the HPC's customer always one step behind using m plus one or m plus two technologies. Now because of our AI demand is so strong, that's one thing, but the most important thing is we need some kind of performance but the power consumption is very, very important. When we talk about A16, we have another power efficiency improvement across to 20%. That's a big value for all the AI data centers applications. So that help my customer moving faster because of every time when we talk about AI data center, if you notice that, the first thing they talk about is power supply, electricity, right?\n\n**C.C. Wei** (Chairman &amp; CEO)\nSo they did not tell you say the power efficiency is very important, but they tell you that we have to build a very big electricity power plant to support the AI data center. So that tell you how important it is. And TSMC is the technology, by the way, on 08/16, it's a further improvement of the N2 node. So it's not a surprise for TSMC to expect for those people in AI data centers industry. They want to use in a 16.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Cici. Thanks, We'll take the last question from the floor. We have one participant here, Felix Chan from KGI.\n\n**Felix Pan** (EVP, Head of Semiconductor)\nHi. Thanks, Jeff. Good afternoon, Sisi and Wendell. I only have one question about the overseas expansion. I think Sisi earlier mentioned that the second fab for the M3, there's a strong demand.\n\n**Felix Pan** (EVP, Head of Semiconductor)\nSo you guys need to speed up several quarters for that. Together with, I think, the U. S. Government also raised the investment tax credit cap for next year. So I wonder how this shape or how this speed up your ramping schedule for the second fab?\n\n**Felix Pan** (EVP, Head of Semiconductor)\nAnd how this impact to the overseas fab dilution for the guidance windows given earlier? Okay. I'm sorry. Know that I think the follow-up question will be, if you guys speed up The U. S.\n\n**Felix Pan** (EVP, Head of Semiconductor)\nInvestment, how is that impact to other regional investment like Japan and Germany as well? And lastly, is that possible to break down the overseas CapEx and domestic CapEx going forward? That's all my questions.\n\n**Jeff Su** (Director of Investor Relations)\nYes, that's pretty much two questions. But okay. Felix's question on our overseas expansion plans, he notes that yes, he said we're speeding up the schedule for the second fab in The U. S. So how and he also notes the recent passage of The U.\n\n**Jeff Su** (Director of Investor Relations)\nS. ITC bill. So how does this impact or affect our rent schedules in our US expansion and what is the implication or impact to the overseas dilution? That's number one.\n\n**C.C. Wei** (Chairman &amp; CEO)\nWow.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThat's two questions. Okay. Let me share with you about our ramp up schedule. It's totally because of our customers' demand. And we appreciate the US government in create the ITC from 25% to 35%.\n\n**C.C. Wei** (Chairman &amp; CEO)\nWe appreciate that. It help, but the real schedule is because of our customers' demand. So we have to prepare the capacity to meet their demand. That's the number one consideration.\n\n**Wendell Huang** (SVP - Finance &amp; CFO)\nYes. The margin impact, it is positive, although not that significant in the five year period. Think about this, the ITC is used to offset the asset value and the benefit comes when depreciation starts. So it gets amortized.\n\n**C.C. Wei** (Chairman &amp; CEO)\nThen, David, to the second question is how does the ramp and speed up of The U. S. Expansion, how is this impacting our expansion plans in Japan and Europe, if it does at all? Well, you think about TSMC expansion, the oversea fab. In The US it's a leading edge.\n\n**C.C. Wei** (Chairman &amp; CEO)\nIn Japan it's specialty technology. To be specific, most of the time, it's for the CMOS image sensor. For Germany, it's automotive industry. So they are all not in the same field. So actually it's not affect the investment in The U.\n\n**C.C. Wei** (Chairman &amp; CEO)\nS. Or investment on the leading edge does not affect the investment in Japan or in Germany.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Cece. Thank you, Felix. Okay, everyone.\n\n**Jeff Su** (Director of Investor Relations)\nSo this concludes our question and answer session. Before we conclude today's conference, please be advised that the replay of the conference will be accessible within thirty minutes from now. The transcript will become available twenty four hours from now and both are going to be available through TSMC's website at www.ksmg.com. So thank you very much for joining us today. We hope everyone continues to stay well and we hope you will join us again next quarter. Goodbye and have a good day. Thank you.",
        "fetched_at": "2026-02-04T16:13:03.140Z"
      },
      {
        "ticker": "TSM",
        "title": "Yahoo Finance",
        "published_date": "Apr 17, 2025, 2:00 AM EDT",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/TSM/earnings/TSM-Q1-2025-earnings_call-306364.html",
        "content": "**Jeff Su** (Director of Investor Relations)\nGood afternoon, everyone, and welcome to TSMC's First Quarter 2025 Earnings Conference Call. This is Jeff Su, TSMC's Director of Investor Relations and your host for today. TSMC is holding our Earnings Conference Call via live audio webcast through the company's website at www.tsmc.com, where you can also download the earnings release materials. If you are joining us through the conference call, your dial-in lines are in listen-only mode. The format for today's event will be as follows. First, TSMC's Senior Vice President and CFO, Mr. Wendell Huang, will summarize our operations in the first quarter 2025, followed by our guidance for the second quarter 2025. Afterwards, Mr. Huang and TSMC's Chairman and CEO, Dr. C.C. Wei, will jointly provide the company's key messages. We will open the line for questions-and-answers.\n\n**Jeff Su** (Director of Investor Relations)\nAs usual, I would like to remind everybody that today's discussions may contain forward-looking statements that are subject to significant risk and uncertainties, which could cause actual results to differ materially from those contained in the forward-looking statements. Please refer to the safe harbor notice that appears in our press release. I would like to turn the call over to TSMC's CFO, Mr. Wendell Huang, for the summary of operations and the current quarter guidance.\n\n**Wendell Huang** (Senior VP and CFO)\nThank you, Jeff. Good afternoon, everyone. Thank you for joining us today. My presentation will start with financial highlights for the first quarter 2025. After that, I will provide the guidance for the second quarter of 2025. First quarter revenue decreased 3.4% sequentially in NT dollar, or 5.1% in U.S. dollars, as our business was impacted by smartphone seasonality, partially offset by continued growth in AI-related demand. In spite of the January 21 earthquake and several aftershocks, we worked diligently to recover much of the lost production. Thus, our revenue in the first quarter was slightly above the midpoint of our guidance. Gross margin decreased 0.2 percentage points sequentially to 58.8%, primarily due to the earthquake impact as well as the start of overseas dilution, partially offset by the cost improvement efforts. Total operating expenses accounted for 10.2% of net revenue. Operating margin decreased 0.5 percentage points sequentially to 48.5%.\n\n**Wendell Huang** (Senior VP and CFO)\nOverall, our first quarter EPS was NT 13.94, and ROE was 32.7%. Now, let's move on to revenue by technology. Three-nanometer process technology contributed 22% of wafer revenue in the first quarter, while five-nanometer and seven-nanometer accounted for 36% and 15% respectively. Advanced technologies, defined as seven-nanometer and below, accounted for 73% of wafer revenue. Moving on to revenue contribution by platform. HPC increased 7% quarter-over-quarter to account for 59% of our first quarter revenue. Smartphone decreased 22% to account for 28%. IoT decreased 9% to account for 5%. Automotive increased 14% and accounted for 5%. DCE increased 8% to account for 1%. Moving on to the balance sheet, we ended the first quarter with cash and marketable securities of NT 2.7 trillion, or $81 billion.\n\n**Wendell Huang** (Senior VP and CFO)\nOn the liabilities side, current liabilities increased by TWD 135 billion quarter-over-quarter, mainly due to the increase of TWD 111 billion in accrued liabilities and others. The increase in accrued liabilities and others was mainly due to the accrual of income tax payables. On financial ratios, accounts receivable turnover days increased one day to 28 days. Days of inventory increased three days to 83 days, primarily due to the ramping of new overseas fabs. Regarding cash flow and CAPEX, during the first quarter, we generated about TWD 626 billion in cash from operations, spent TWD 331 billion in CAPEX, and distributed TWD 104 billion for second quarter 2024 cash dividend. In addition, we raised TWD 16 billion in cash from bond issuances. Overall, our cash balance increased TWD 267 billion-TWD 2.4 trillion at the end of the quarter. In U.S. dollar terms, our first quarter capital expenditures totaled $10.06 billion.\n\n**Wendell Huang** (Senior VP and CFO)\nI've finished my financial summary. Now, let's turn to our current quarter guidance. Based on the current business outlook, we expect our second quarter revenue to be between $28.4 billion and $29.2 billion, which represents a 13% sequential increase or a 38% year-over-year increase at the midpoint. Based on the exchange rate assumption of $1 -NT 32.5, gross margin is expected to be between 57-59%. Operating margin between 47-49%. Also, in the second quarter, we will need to accrue the tax on the undistributed retained earnings. As a result, our second quarter tax rate will be around 20%. The tax rate will then fall back to the 14-15% level in the third and fourth quarter, and the full year tax rate will be between 16% and 17%. This concludes my financial presentation. Now, let me turn to our key messages.\n\n**Wendell Huang** (Senior VP and CFO)\nI will start by talking about our first quarter 2025 and second quarter of 2025 profitability. Compared to fourth quarter, our first quarter gross margin slightly decreased by 20 basis points sequentially to 58.8%. This was primarily due to 60 basis points impact from the January 21 earthquake and its aftershocks, as well as the start of dilution from our Kumamoto fab, partially offset by cost improvement efforts. We have just guided our second quarter gross margin to decrease by 80 basis points to 58% at the midpoint, primarily as the margin dilution impact from our Arizona fab starts to kick in. We expect the impact from overseas fab to grow more pronounced throughout the year as we ramp up further in Kumamoto and Arizona and forecast 2-3% margin dilution impact for the full year 2025.\n\n**Wendell Huang** (Senior VP and CFO)\nAs we have said before, under today's fragmented globalization environment, overseas fabs' costs are higher for everyone, including TSMC and all other semiconductor manufacturers. With our additional $100 billion investment planned in Arizona, we forecast the gross margin dilution from the ramp-up of our overseas fabs in the next five years to start from 2-3% every year in the early stages and widen to 3-4% in the latter stages. We will leverage our increasing size in Arizona and work on our operations to improve the cost structure. We will also continue to work closely with our customers and suppliers to manage the impact. Overall, with our fundamental competitive advantages of manufacturing technology leadership and large-scale production base, we expect TSMC to be the most efficient and cost-effective manufacturer in the region that we operate.\n\n**Wendell Huang** (Senior VP and CFO)\nThus, even considering our global manufacturing expansion plans, we believe a long-term gross margin of 53% and higher is achievable. Next, let me talk about our 2025 capital budget. At TSMC, a higher level of capital expenditures is always correlated with higher growth opportunities in the following years. We reiterate our 2025 capital budget is expected to be between $38 billion and $42 billion as we continue to invest to support customers' growth. About 70% of the capital budget will be allocated for advanced process technologies. About 10%-20% will be spent for specialty technologies, and about 10%-20% will be spent for advanced packaging, testing, mask making, and others. Our 2025 CAPEX also includes a small amount related to our recently announced additional $100 billion investment plan to expand our capacity in Arizona.\n\n**Wendell Huang** (Senior VP and CFO)\nEven as we invest for the future growth with this level of CAPEX spending in 2025, we remain committed to delivering profitable growth to our shareholders. We also remain committed to a sustainable and steadily increasing cash dividend per share on both an annual and quarterly basis. Now, let me turn the microphone over to C.C. Wei.\n\n**Che-Chia Wei** (Chairman and CEO)\nThank you, Wendell. Good afternoon, everyone. First, let me start with our near-term demand outlook. Before that, I would like to mention the earthquake during Lunar New Year. On January 21, Taiwan experienced a 6.4 magnitude earthquake on the Richter scale, followed by several significant aftershocks. Although a certain number of wafers in process were impacted and had to be scrapped, we worked tirelessly and were able to recover much of the lost production, demonstrating the resilience of our operation in Taiwan. I want to recognize and deeply thank all of our employees and our suppliers for their dedication and hard effort over the Lunar New Year holidays. I would also like to extend our great appreciation to our customers for their understanding and support during this time. Now, let me talk about the first quarter's result. We concluded our first quarter with revenue of $25.5 billion.\n\n**Che-Chia Wei** (Chairman and CEO)\nOur business in the fourth quarter was impacted by smartphone seasonality, partially offset by continued growth in AI-related demand. Moving into second quarter 2025, we expect our business to be supported by strong growth of our 3-nanometer and 5-nanometer technologies. Looking at the full year of 2025, we expect Foundry 2.0 industry growth to be supported by robust AI-related demand and a mild recovery in other market segments. In January, we had forecast the Foundry 2.0 industry to grow 10 percentage points year-over-year in 2025, which is consistent with IDC's forecast of 11% year-over-year growth for Foundry 2.0. Now, let me talk about the recent tariffs. We understand there are uncertainties and risks from the potential impact of tariff policies. However, we have not seen any change in our customers' behavior so far.\n\n**Che-Chia Wei** (Chairman and CEO)\nTherefore, we continue to expect our full year 2025 revenue to increase by close to mid-20% in U.S. dollar terms. We might get a better picture in the next few months, and we will continue to closely monitor the potential impact to the end market demand and manage our business prudently. Amidst the uncertainties, we continue to focus on fundamentals of our business, which are technology leadership, manufacturing excellence, and customer trust, to further strengthen our competitive position. As such, we are confident TSMC can continue to outperform the Foundry 2.0 industry growth in 2025. Now, I will talk about our AI demand outlook. We continue to observe robust AI-related demand from our customers throughout 2025. We reaffirm our revenue from AI accelerators to double in 2025. The AI accelerators we define as AI GPU, AI ASIC, and HBM controllers for AI training and inference in the data center.\n\n**Che-Chia Wei** (Chairman and CEO)\nBased on our customers' strong demand, we are also working hard to double our CoWoS capacity in 2025 to support their needs. Recent developments are also positive to AI's long-term demand outlook. In our assessment, the impact from AI reasoning models, including DeepSeek, will drive greater efficiency and help lower the barrier to future AI development. This will lead to wider usage and greater adoption of AI models, which all require use of leading-edge silicon. Thus, these developments only serve to strengthen our conviction in the long-term growth opportunities from the industry mega trend of 5G, AI, and HPC. To address the structural increase in the long-term market demand profile, TSMC employs a disciplined and robust capacity planning system. This is especially important when we have such high forecasted demand from AI-related business. Externally, we work closely with our customers and our customers' customers to plan our capacity.\n\n**Che-Chia Wei** (Chairman and CEO)\nInternally, our planning system involves multiple teams across several functions to assess and evaluate the market demand from both a top-down and bottom-up approach to determine the appropriate capacity to build. Based on our planning framework, we are confident that our revenue growth from AI accelerators will approach a mid-40s-percentage CAGR for the next five years' period starting from 2024. Next, let me talk about TSMC's additional $100 billion investment planned to expand in Arizona. All our overseas decisions are based on our customers' needs. They value some geographic flexibility and necessary level of government support. This is also to maximize the value for our shareholders. With the strong collaboration and support from our leading U.S. customers and the U.S. federal, state, and city governments, we recently announced our intention to invest an additional $100 billion in advanced semiconductor manufacturing in the United States.\n\n**Che-Chia Wei** (Chairman and CEO)\nThis expansion includes plans for three additional wafer manufacturing fabs, two advanced packaging fabs, and a major R&D center. Combined with our previously announced plan to build three advanced semiconductor manufacturing fabs in Arizona, this brings our total investment in the U.S. to $165 billion to support the strong multi-year demand from our customers. Our first fab in Arizona has already successfully entered high-volume production in Q4 2024, utilizing N4 process technology with a yield comparable to our fab in Taiwan. The construction of our second fab, which will utilize a 3-nanometer process technology, is already complete, and we are working on speeding up the volume production schedule based on the strong AI-related demand from our customers. Our third and fourth fab will utilize N2 and A16 process technologies, and with the expectation of receiving all the necessary permits, are scheduled to begin construction later this year.\n\n**Che-Chia Wei** (Chairman and CEO)\nOur fifth and sixth fab will use even more advanced technologies. The construction and ramp schedule for these fabs will be based on our customers' demand. We also plan to build two new advanced packaging facilities and establish an R&D center in Arizona to complete the AI supply chain. Our expansion plan will enable TSMC to scale up to a GIGAFAB cluster to support the needs of our leading-edge customers in smartphone, AI, and HPC applications. With this additional $100 billion investment planned to expand our leading-edge capacity in Arizona, I would also like to mention that TSMC is not engaged in any discussion with other companies regarding any joint venture, technology licensing, or technology transfer and sharing. After completion, around 30% of our two-nanometer and more advanced capacity will be located in Arizona, creating an independent leading-edge semiconductor manufacturing cluster in the U.S.\n\n**Che-Chia Wei** (Chairman and CEO)\nIt will also create greater economies of scale and help foster a more complete semiconductor supply chain ecosystem in the U.S. Thus, TSMC will continue to play a critical and integral role in enabling our customers' success while remaining a key partner and enabling all the strength and leadership of the U.S. semiconductor industry. Next, in Japan, thanks to the strong support from the Japan Central Prefecture and local government, our first specialty technology fab in Kumamoto has already started volume production in late 2024 with very good yield. The construction of our second specialty fab is scheduled to start later this year, subject to the readiness of the local infrastructure. In Europe, we have received strong commitment from the European Commission and the German federal, state, and city governments. We are on track with our plan to build a specialty technology fab in Dresden, Germany.\n\n**Che-Chia Wei** (Chairman and CEO)\nIn Taiwan, with support from the Taiwan government, we plan to build 11 wafer manufacturing fabs and four advanced packaging facilities over the next several years. Volume production of N2 is expected to start in the second half of 2025, and we are preparing for multiple phases of two-nanometer fabs in both Hsinchu and Kaohsiung science parks to support the strong structural demand from our customers. By expanding our global footprint while continuing investment in Taiwan, TSMC can continue to be the trusted technology and capacity provider of the global logic IC industry for years to come while delivering profitable growth for our shareholders. Finally, I will talk about our N2 status and A16 introduction. Our two-nanometer and A16 technology leads the industry in addressing the insatiable need for energy-efficient computing, and almost all the innovators are working with us.\n\n**Che-Chia Wei** (Chairman and CEO)\nWe expect the number of new tape outs for two-nanometer technology in the first two years to be higher than both three-nanometer and five-nanometer in their first two years, fueled by both smartphone and HPC applications. N2 will deliver full-on performance and power benefits, with 10-15% speed improvement at the same power or 20-30% power improvement at the same speed, and more than 15% chip density increase as compared with N3e. N2 is well on track for volume production in the second half of 2025 as scheduled, with a ramp profile similar to N3. With our strategy of continuous enhancement, we also introduce N2P as an extension of N2 family. N2P features further performance and power benefits on top of N2, and volume production is scheduled for the second half of 2026. We also introduce A16 featuring Super Power Rail or SPR as a separate offering.\n\n**Che-Chia Wei** (Chairman and CEO)\nCompared with N2P, A16 provides a further 8-10% speed improvement at the same power, or 15-20% power improvement at the same speed, and additional 7-10% chip density gain. A16 is best suited for specific HPC products with complex signal route and dense power delivery network. Volume production is scheduled for the second half of 2026. We believe N2, N2P, A16, and its derivatives will further extend our technology leadership position and enable TSMC to capture the growth opportunities well into the future. This concludes our key message, and thank you for your attention.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, C.C. This concludes our prepared statements. Before we begin the Q&A session, I would like to remind everybody to please limit your questions to two at a time to allow all the participants an opportunity to ask their questions.\n\n**Jeff Su** (Director of Investor Relations)\nShould you wish to raise your question in Chinese, I will translate it to English before our management answers your question. For those of you on the call, if you would like to ask a question, please press the star then one on your telephone keypad now. If at any time you'd like to remove yourself from the questioning queue, please press star two. Now, let's begin the Q&A session. Operator, can we please proceed with the first caller on the line?\n\n**Operator**\nThe first one to ask a question, Gokul Hariharan from JPMorgan.\n\n**Gokul Hariharan** (Managing Director)\nThank you very much. Good afternoon. First of all, thanks for clearing the air on all those JV-related news reports. I think a lot of people needed that. Thank you. My first question is on AI demand. C.C., there has been a lot of talks about CoWoS order adjustments and some concerns about AI demand.\n\n**Gokul Hariharan** (Managing Director)\nYou did talk about CoWoS capacity doubling. Could you talk a little bit about how you see demand versus supply? I think last time we talked about this, you did indicate CoWoS demand is still well above supply. Could you talk a little bit about how the situation is looking for CoWoS demand versus supply this year? Maybe a little bit of early color on 2026 also as you plan for the capacity?\n\n**Jeff Su** (Director of Investor Relations)\nAll right. Thank you, Gokul. For everyone's benefit, let me try to summarize your first question. Gokul's first question is on the AI-related demand. He notes there's been a lot of noise around CoWoS and order cuts and such. He would like to ask C.C., what is the thinking or strategy for TSMC? CoWoS still doubling this year? Is the demand still exceeding the supply?\n\n**Jeff Su** (Director of Investor Relations)\nHow is the CoWoS capacity and supply, or supply and demand, I should say, look like going into 2026 if C.C. is able to provide any color?\n\n**Che-Chia Wei** (Chairman and CEO)\nOkay, Gokul. I know there is a lot of rumors about the CoWoS. The last time when we talked about the CoWoS, the demand is almost insane and much, much higher than we can prepare. Now it is a little bit better. I think still we need to build a lot of capacity to meet the demand. As I said, we have to double our CoWoS capacity. Still fully loaded. For 2026, I cannot say the number, but it is still a heresy momentum while we continue. Okay? Did that answer your question?\n\n**Gokul Hariharan** (Managing Director)\nDo you still think 2026 is going to be supply limited still? That demand is still going to be much more than supply even in 2026?\n\n**Gokul Hariharan** (Managing Director)\nIs that your current expectation, C.C.?\n\n**Jeff Su** (Director of Investor Relations)\nGokul is asking, do we still see demand exceeding supply for CoWoS in 2026?\n\n**Che-Chia Wei** (Chairman and CEO)\nWe will work very hard to make sure that we do not have this kind of demand being much, much higher than the capacity. We are working very hard, and I believe that it will be more balanced next year.\n\n**Gokul Hariharan** (Managing Director)\nThank you. My second question is on the U.S. investment and all these persistent rumors about involvement in your competitors' operations, etc. You have interacted with the U.S. government, the new administration for the last several months, and C.C. made the big announcement at the White House as well. I just wanted to understand what is TSMC's impression in terms of what is required now that there is also the semiconductor tariff litigation going on?\n\n**Gokul Hariharan** (Managing Director)\nWhat is TSMC's impression of what is required over the next two, three years in terms of reassuring of capacity, both from a U.S. administration perspective, also from your U.S. customers' perspective? I think Wendell also indicated that the margin dilution may be slightly bigger as we go along. Could you talk a little bit about how much of the value can you pass on to the customers as the expansion becomes a little bit more accelerated? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Gokul's second question is a bit involved, but he's asking about, again, a lot of talk about our recent announcement for an additional $100 billion expansion in the U.S. Again, talk about this involving the competitors. C.C. has been speaking to the U.S. government. There's still potential semiconductor tariffs.\n\n**Jeff Su** (Director of Investor Relations)\nHis question is really from TSMC's point of view, what do we think is required for more onshoring in the U.S.? Can we share the perspective from the U.S. government, or more directly, what our customers are asking us to do in terms of reshoring? That's the first part. The second part, maybe Wendell can address on the margin.\n\n**Che-Chia Wei** (Chairman and CEO)\nReally? Okay. I saw that's a very long, long question. Let me answer that. Yes, indeed, we have talked with U.S. government officials. The reason we are expanding in Arizona, actually, let me say again, is all because of our customers' request. That's because of their very high, high demands. I announced it in other occasions, said that very strong AI demand from U.S. customers such as Apple, Nvidia, AMD, Qualcomm, and Broadcom.\n\n**Che-Chia Wei** (Chairman and CEO)\nWe need to expand our capacity in the U.S. to support them. We talked with the U.S. government to ask for their help in getting the necessary permits so we can start the fab. As a result, I would expect our two-nanometer capacity, around 30%, will be in Arizona. That will be also an independent leading-edge semiconductor manufacturing cluster. Okay?\n\n**Jeff Su** (Director of Investor Relations)\nGokul, the second part of your question is related to, sorry, Wendell had mentioned that the margin may widen. Gokul's second part of the question, I think, was related to pricing and what is our strategy or approach here as we expand overseas. Is that correct?\n\n**Gokul Hariharan** (Managing Director)\nYeah, that's right. Yeah.\n\n**Wendell Huang** (Senior VP and CFO)\nHey, Gokul. You're asking about the pricing. As we always said, reflecting our value is a continuous and ongoing process for TSMC, as we're in a very capital-intensive business.\n\n**Che-Chia Wei** (Chairman and CEO)\nWe need to have a very high gross margin to earn the sustainable and healthy return. That is why we set up our pricing strategy. Geographic manufacturing flexibility is an important part of our value proposition to the customers. We are already discussing this with our major customers, and the progress is so far so good.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Gokul?\n\n**Gokul Hariharan** (Managing Director)\nOkay, understood. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nAll right, thank you. Operator, can we move on to the next participant, please?\n\n**Operator**\nThe next to ask question, Bruce Lu from Goldman Sachs. Please ask a question.\n\n**Bruce Lu** (VP and Equity Analyst)\nOkay, thank you for taking my question. I think the geopolitical micro concerns is one of the major uncertainties nowadays. The last two days, we have H20 being banned in China, blah, blah, blah. How does that impact TSMC's forecast and production planning?\n\n**Bruce Lu** (VP and Equity Analyst)\nDo we have enough other customers and demand to keep our advanced node capacity fully utilized? Or how does that change our long-term production planning moving forward?\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Bruce, thank you. Your first question is related. He's talking about geopolitical risk or, I guess, some of the recent rules and announcements, specifically the ban on H20. So his question is, how does this impact TSMC's business? How does this impact our capacity planning and our strategies?\n\n**Che-Chia Wei** (Chairman and CEO)\nBruce, let me answer this question. Of course, we do not comment on specific customers' products, but let me assure you that we have taken this into consideration when providing our four-year gross outlook. Did I answer the question?\n\n**Bruce Lu** (VP and Equity Analyst)\nYes, but I want a little bit more about, you know, I'm sure you guys did a lot of sensitive analysis, like what kind of impact it's going to be.\n\n**Bruce Lu** (VP and Equity Analyst)\nCan you share with us how much buffer we got that you've assumed, like how comfortable we have to maintain our current capacity planning moving forward or current utilization right now?\n\n**Jeff Su** (Director of Investor Relations)\nBruce is asking for some more color in terms of what type of buffer or what type of room we have in making our decisions for the long-term capacity planning.\n\n**Che-Chia Wei** (Chairman and CEO)\nActually, we know a lot of people right now speculate a lot of things. Again, we certainly are mindful of the potential impact from all the recent tariff announcements, especially the potential impact to the end market demand. We will continue to watch it carefully. Having said that, we have not seen any change in our customers' behavior so far. We stick on our forecast.\n\n**Bruce Lu** (VP and Equity Analyst)\nI see. Thank you. Let me switch gears a little bit for the non-U.S. capacity expansion.\n\n**Bruce Lu** (VP and Equity Analyst)\nI think, as we understand that the current capacity utilization for mature node is underutilized, right? Do we consider to slow down the capacity expansion in Japan or Europe, or just relocate the current equipment from Taiwan to Japan or Europe instead of building the new one? We do not wantwhy do we want to expand the capacity for the mature node, which management already mentioned that it is an oversupply industry, though? If we relocate them, we can squeeze more space, clean room in Taiwan for more advanced nodes.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Bruce's second question is around mature node and our expansion into Europe and Japan. His question really is, given that the capacity of mature node and 7-nanometer are underutilized, number one, are we concerned to slow down our expansions in these places?\n\n**Jeff Su** (Director of Investor Relations)\nNumber two, would we consider using current relocate equipment from Taiwan to overseas rather than just the pure new expansion or greenfield expansion?\n\n**Che-Chia Wei** (Chairman and CEO)\nBruce? Let me answer the first part of the question. Are we considering slowing down? The answer is no. We execute our plan as scheduled. The reason is very simple because of this kind of mature node is a specialty technology that demand, which my competitor did not have capacity or capability to support. It is kind of free from, you mentioned, the underloading of the mature node. Again, I would emphasize, no, we are not going to slow down our plan in Japan or in Germany. The second question is how to do it. We have a good idea, but it is TSMC's confidential information. I'll let you know later.\n\n**Bruce Lu** (VP and Equity Analyst)\nThank you.\n\n**Jeff Su** (Director of Investor Relations)\nAll right, thanks, Bruce.\n\n**Jeff Su** (Director of Investor Relations)\nOperator, can we move on to the next participant, please?\n\n**Operator**\nNow the line is open to Charlie Chan, Morgan Stanley.\n\n**Charlie Chan** (Managing Director)\nHi, good afternoon, gentlemen. Thanks for taking my question. My first question is really very specific on the semiconductor tariff on either Taiwan or TSMC's leading edge. I am wondering, first of all, does TSMC get involved in all those tariff negotiations between Taiwan government and the U.S. government? Secondly, do you believe that your commitment of $165 billion U.S. dollars investments can get a spare on this semiconductor tariff? In your previous comment, you seem to only concern about the tariff impact on consumer tech demand. I think global investors are also very concerned about additional tariffs on this semiconductor category. Can you give us some color?Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, let me summarize your question. First question, Charlie.\n\n**Jeff Su** (Director of Investor Relations)\nCharlie's first question is on semiconductor tariffs. He wants to know what is our comment or view on potential tariffs on Taiwan, reciprocal tariffs, or semiconductor-specific tariffs. His question specifically, is TSMC getting involved in the negotiations between the Taiwan government and the U.S. government?\n\n**Che-Chia Wei** (Chairman and CEO)\nCharlie, this kind of tariff discussion is between countries. We are a private company. Certainly, no, we are not getting involved. What is the second question?\n\n**Charlie Chan** (Managing Director)\nYeah, actually, do you have any visibility that semiconductor-specific tariffs can be exempt?\n\n**Jeff Su** (Director of Investor Relations)\nCharlie is saying thatsorry, Charlie, I think your question was with our total investment of $165 billion in Arizona. Do we believe, does TSMC believe semiconductors will be exempt from these tariffs?\n\n**Che-Chia Wei** (Chairman and CEO)\nYes. Yes. Charlie, all policy, especially these tariff decisions, are government's responsibility to decide.\n\n**Che-Chia Wei** (Chairman and CEO)\nAs a private company, we are fully respectful of this, but we are not getting involved.\n\n**Charlie Chan** (Managing Director)\nOkay, got you. I think you're too moderate, but let's move on to my second question. Based on your second quarter guidance, which is very strong at 13% quarter-on-quarter, I can't help to think whether there are customers pulling given tariffs, or is there really demand? Also, based on your full-year guidance, so-called ME 20%, it seems like the second half recovery will be very, very gradual or flat-ish. I'm wondering if you're already baking those kinds of consumer tech demand impacts. If a tariff has some kind of turnaround, meaning some exemption on, for example, major smartphone brands, is there a chance for you to revise your full-year revenue guidance? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Charlie's second question is on the revenue outlook.\n\n**Che-Chia Wei** (Chairman and CEO)\nHis first part is on the second quarter. He notes second quarter 13% at the midpoint in U.S. dollar terms, Q on Q is very strong. He wonders, are we seeing already some tariff pulling impact, or is this part of that guidance? I'll stop here first.\n\n**Wendell Huang** (Senior VP and CFO)\nYeah, Charlie, as we said in the prepared remarks, we haven't seen any changes in customers' behavior so far. Our second quarter growth is driven mainly by strong demand for the 3-nanometer and 5-nanometer technologies, underpinned by the growth in our HPC platform. As I said, we haven't observed any changes in customer behavior in terms of pulling or due to tariffs. It's probably better to ask them directly.\n\n**Jeff Su** (Director of Investor Relations)\nThe second part then, Charlie, is asking about what the second quarter guidance implies of limited half-on-half growth.\n\n**Jeff Su** (Director of Investor Relations)\nIs that also because we are assuming something from a tariff impact to consumer demand, or why is that?\n\n**Wendell Huang** (Senior VP and CFO)\nCharlie, as we also said in the prepared remarks, there are uncertainties and potential risks from tariffs exist. So far, what we are able to share with you is we stick to the mid-20% or close to mid-20% year-over-year growth, no different from the previous quarter.\n\n**Charlie Chan** (Managing Director)\nI see. I think that's really what we want. I think your answer to Gokul's previous question on long-term margin dilution was a little bit unclear because we thought that the 2-3% margin dilution from overseas staff should remain to be the case, but it seems like it's widening.\n\n**Charlie Chan** (Managing Director)\nI'm not sure if it is because you are further accelerating your U.S. staff expansion or some cost item or pricing item are not in your expectations versus maybe one or two months ago.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, I think so. Charlie is asking basically how come the dilution in the latter period widens to 3-4%. What are the drivers or reasons behind it?\n\n**Wendell Huang** (Senior VP and CFO)\nYeah, Charlie, the widening of dilution on the gross margin in the later part of the five-year period is mainly from inflation in cost and also potential tariff-related cost increases. Those are the reasons. Okay.\n\n**Charlie Chan** (Managing Director)\nOh, I see. Okay, thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, thank you, Charlie. Okay, Operator, let's move on to the next participant, please.\n\n**Operator**\nNext one, Charles Shi from Needham. Go ahead, please.\n\n**Charles Shi** (Analyst)\nThanks for taking my questions. Maybe I'll ask a relatively higher-level question. It's a two-part question.\n\n**Charles Shi** (Analyst)\nBoth are regarding your expansion plan in the U.S. I think management, another occasion that what TSMC wants the most is really fairness. Nothing monetary, nothing about tariffs, but fairness. Can management kind of elaborate a little bit what fairness means? Give us a little bit more specifics. The other part of the question regarding the U.S. expansion is about the R&D team center you announced. We understand, yes, the TSMC's R&D in the U.S. does need to start from somewhere, right? You said it's more about the production improvements related to R&D on derivative nodes.\n\n**Che-Chia Wei** (Chairman and CEO)\nSince this seems to be something the U.S. really cares about, that the R&D capability on U.S. soil, on the leading edge, is there any longer-term plan to have the U.S. R&D center to be involved, let's say, in the primary R&D, let's say, brand new processes, the major nodes development? That is my two-part question. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nAll right. Thank you, Charles. Again, to summarize, both questions are related to the expansion in the U.S. The first part of the question is, C.C. has mentioned all we want is fair treatment. What do we mean by fair or fairness?\n\n**Che-Chia Wei** (Chairman and CEO)\nLet me answer this question. What we mean by fair treatment is very simple. If anybody gets the subsidy or gets the incentive, everybody should get the same. Either we get all or we get zero, all right?\n\n**Che-Chia Wei** (Chairman and CEO)\nThat is what we call fair. Again, I would like to assure you that we will be very competitive in either condition.\n\n**Jeff Su** (Director of Investor Relations)\nThe second part of the question is regarding the R&D. Charles is saying he understands the R&D needs to start from somewhere, but with our major R&D center in Arizona, what will be the purpose or the focus, and will it be involved at some point in ramping new technologies?\n\n**Che-Chia Wei** (Chairman and CEO)\nAs I said before, TSMC's fair will never be stagnant. We always continue to improve it. We need to establish a major R&D center in Arizona with about 1,000 engineers. That is a big amount. The focus will be to support our manufacturing cluster, improve its technology, and allow it to operate independently. Did I answer the question?\n\n**Charles Shi** (Analyst)\nMaybe let me just really follow up because there has been a good amount of chatters about the U.S. R&D center more supporting manufacturing rather than doing major R&D on the brand new nodes. It looks like that's not the plan. Over the longer term, is there any thoughts of our management? Maybe they will get involved in brand new nodes development one way or the other. I think that's a question people have been discussed about over the last quarter.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Charles is asking, will the R&D center over the mid to long term can it also focus on things like new node development or pathfinding opportunities, long-term research, these types of things?\n\n**Che-Chia Wei** (Chairman and CEO)\nActually, the first purpose is to let Arizona's fab we can operate independently. Of course, we have done and we are doing it right now.\n\n**Che-Chia Wei** (Chairman and CEO)\nWe'll do some kind of pest funding, exploratory work, and cooperate with university, blah, blah, blah. It actually a lot of activities. 1,000 engineers is not a small amount. Of course, it's not comparable to TSMC's right now. It's a 10,000 R&D people, but it's a beginning. Okay, so we do a lot more.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Charles, do you have a second question?\n\n**Charles Shi** (Analyst)\nNo, I don't. Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, great. Thank you. Operator, the next participant, please.\n\n**Operator**\nNext one to ask questions, Sunny Lin from UBS.\n\n**Sunny Lin** (Analyst)\nGood afternoon. Thank you very much for taking my questions. My first question is to follow up on the Arizona expansions. First part is on the timeline or the pace of your expansions. Now, given the stronger demand for your U.S. capacities, to what extent could you pull in the rep of the original second and third phase?\n\n**Sunny Lin** (Analyst)\nFor your fourth phase, you earlier mentioned that you will be constructing the fascial layer lister. Would that be possible that you start to wrap the fourth phase at the same time as the third phase?\n\n**Jeff Su** (Director of Investor Relations)\nSunny's first question is regarding our GIGAFAB cluster in Arizona. She wants to understand the timeline of expansion, particularly given the strong AI-related demand. Can we pull in the timing for both the second fab and the third fab? Also, can we at the same time start the production of the third and fourth fab simultaneously?\n\n**Che-Chia Wei** (Chairman and CEO)\nSunny, we are working very hard to speed it up of our production in the second fab and the construction on the third fab. All I can say now is customers' demand is strong. We have to really do speed it up.\n\n**Che-Chia Wei** (Chairman and CEO)\nThe following, all the fab definitely will depend on our customers' demand, of course.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Sunny?\n\n**Sunny Lin** (Analyst)\nSorry, just to clarify. The second phase originally is planning for production in 2028. Now should we assume it to be from maybe mid-2027 or even first of 2027? For the third phase, since you are building the fascial this year, will the production start maybe one year ahead versus the original timeline of 2030?\n\n**Jeff Su** (Director of Investor Relations)\nSunny, specifically, the second one, we said we're speeding up. Can we give some context of a timeframe? For the third fab, will we also speed it up? Could that also be moved forward?\n\n**Che-Chia Wei** (Chairman and CEO)\nYes, we are speeding it up. How fast? The second fab, as you said, it should be pulling.\n\n**Che-Chia Wei** (Chairman and CEO)\nThis one, we are working hard to pull in at least a couple of quarters. That's at least. On the third fab, actually, I did not speak the whole thing. It is also being constrained by the labor shortage over Arizona, and we need to get all the permits, everything, etc. I cannot give you a very definite date yet, but we are going to update you probably in the next quarter or one quarter after that.\n\n**Sunny Lin** (Analyst)\nGot it. No problem. My second question is on the pricing and margin of the overseas expansions. Now with the especially stronger demand for the U.S capacities, would you be able to sell more value given the stronger onshoring requirements?\n\n**Sunny Lin** (Analyst)\nFor margin, earlier you mentioned this 2-3% margin dilution for the coming two to three years, and then expanding to 3-4% maybe into 2029 to 2030. I just wondered what the underlying wafer price assumption for that gross margin dilution estimates is. If you are able to raise the Arizona pricing a bit, would the gross margin dilution be less?\n\n**Jeff Su** (Director of Investor Relations)\nSunny's question is on the overseas expansion in both pricing and margin. Given the strong demand in terms of pricing, can we reflect even greater value to our customers? Also, her question is given that the dilution from overseas will widen to 3-4% in the latter stages of the five-year period. She wants to know what is our underlying wafer price assumption behind this.\n\n**Wendell Huang** (Senior VP and CFO)\nSunny, let me answer that. These two things actually go together.\n\n**Wendell Huang** (Senior VP and CFO)\nAs we said, reflecting our value is a continuous and ongoing process. Because of our business nature, we need very high gross margin to earn a sustainable and healthy return. Now, geographic manufacturing flexibility is an important part of our value proposition to the customers. Therefore, we are already discussing this with our major customers, and the progress is so far so good. At the same time, the margin dilution from the overseas fabs, the additional dilutions come from the cost inflation as well as potential cost increases from the tariff policies. Of course, with that, we also want to reflect the value, and therefore the discussion with the customers are continuous.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Sunny?\n\n**Sunny Lin** (Analyst)\nGot it.\n\n**Jeff Su** (Director of Investor Relations)\nAll right. Thank you.\n\n**Sunny Lin** (Analyst)\nAll right. Very clear. Thank you very much.\n\n**Jeff Su** (Director of Investor Relations)\nThank you. Operator, can we move on to the next participant, please?\n\n**Operator**\nNext one to ask question, Brett Simpson, Arete Research\n\n**Brett Simpson** (Partner and Co-Founder)\nYes, thanks very much. I have a two-part question on this year's guidance for C.C. First, C.C., you mentioned that AI is still expected to double this year despite the U.S. ban on AI GPUs into China. I guess China was a meaningful portion of accelerator shipments, well over 10% of volumes. Factoring this in, it would imply your AI outlook this year still doubling would mean that the AI orders have improved meaningfully outside of China in the last three months. Is that how we should interpret your comment about you still expect the business to double? Second, we're in a June quarter where tariffs have been paused for 90 days. To what extent does your above-seasonal June quarter guidance reflect customer pullings ahead of potential tariffs being applied in the September quarter? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Brett, his question is on, again, the one part is on the AI demand that although there's a ban in China on certain AI chips or products, that we reiterated our AI accelerator growth will double this year. His assumption is that implies a strong non-China AI-related demand and wondering what is the mechanics or can we comment behind that?\n\n**Che-Chia Wei** (Chairman and CEO)\nBrett, three months ago, now I can tell you that three months ago, we just cannot supply enough wafer to our customer. Now it's a little bit balanced, but still, the demand is very strong. You are right. Other than China, the demand is still very strong, especially in the U.S. We are confident that we are going to double our AI revenue this year.\n\n**Brett Simpson** (Partner and Co-Founder)\nYeah.\n\n**Brett Simpson** (Partner and Co-Founder)\nThen very quickly, he was asking about the second quarter revenue guidance and do we see any tariff-related pulling? I think Wendell answered this earlier.\n\n**Wendell Huang** (Senior VP and CFO)\nYeah, I think that we have, as C.C. Wei said in the prepared remarks, we haven't seen any changes in customer behavior. The growth in second quarter was primarily due to the demand from our 3-nanometer and 5-nanometer technologies underpinned by the demand from the HPC platform.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, do you have a second question, Brett? Sorry.\n\n**Brett Simpson** (Partner and Co-Founder)\nYeah, yeah, thanks, Jeff. My second question was for Wendell, and thanks for clarifying that, Wendell. Follow-up is on shareholder returns. TSMC traditionally has always favored growing the dividends as the main policy. Many shareholders would argue that the dividend payouts are not having that much of an impact on the discounted multiple that TSMC trades at versus some of your U.S. big tech peers.\n\n**Brett Simpson** (Partner and Co-Founder)\nMy question is, why does TSMC management not adopt a buyback framework, particularly with the strength of the cash position on your balance sheet at the moment? Thank you.\n\n**Jeff Su** (Director of Investor Relations)\nThank you, Brett. Brett's second question is circulated on shareholder return. He notes TSMC's policy has always been a stable and steadily increasing cash dividend and focused on cash dividend payout. His question is, why do we consider? Why do we not consider adopting more of a buyback policy, share buyback policy?\n\n**Wendell Huang** (Senior VP and CFO)\nBrett, we've done studies a long time ago, and we continue to revisit that. We also talked to investors. Our conclusion stays the same. The sustainable and steadily increasing dividends is a better way of returning cash to the shareholders. We're maintaining the policy.\n\n**Brett Simpson** (Partner and Co-Founder)\nThank you.\n\n**Jeff Su** (Director of Investor Relations)\nAll right.\n\n**Jeff Su** (Director of Investor Relations)\nOperator, in the interest of time, can we take the questions from the last two participants, please?\n\n**Operator**\nYes. Now the line is open to Laura Chen, Citi.\n\n**Laura Chen** (Research Analyst)\nHello, hi. Thank you very much for taking my question. Can you hear me clearly?\n\n**Jeff Su** (Director of Investor Relations)\nYes.\n\n**Laura Chen** (Research Analyst)\nYeah, thank you. My question is also about the AI and also the U.S. expansion. C.C., you just mentioned that the core supply demand will be more balanced into 2026. Do you see any structural change in the future AI chip design when moving to N3, such as a chip like that kind of a design? Also, in that kind of new trend, what is TSMC's view on the new technology, such as CPO or PLP panel base? Will that still start from Taiwan first, or would you also consider to further invest the new backend technology in Arizona?\n\n**Laura Chen** (Research Analyst)\nSince C.C., you just mentioned that you would also start to build up the fab in advanced packaging in Arizona.\n\n**Che-Chia Wei** (Chairman and CEO)\nOkay, Laura, first question. Thank you. First question is a very broad question, but basically, if I just try to distill, she wants to know, do we see any changes in the chip design, particularly moving to chiplets with N3? Do we see this more and more? What about the role of things like co-package optics and panel-level packaging? I think the essence of her question, will we continue to use our leading or, sorry, advanced packaging technologies like CoWoS or SRIC in Taiwan first, or is this also part of the plan for the expansion in Arizona?\n\n**Che-Chia Wei** (Chairman and CEO)\nThat is a long question. Laura, yes. Our customers, they continue to use TSMC's leading-edge technology, and they also adopt the advanced packaging technologies more and more, and also are more advanced.\n\n**Che-Chia Wei** (Chairman and CEO)\nThis year is probably most of CoWoS S, then next year, CoWoS Europe, etc. We can see that customers start to pick up the SRIC and the more advanced packaging technologies. As for what we call panel-level packaging, we are aggressively developing it. Today it still is a feasibility study stage. Too early to say it will be in Taiwan or in the U.S., but most likely it will be in Taiwan first. We ramp it up and then bring it to the U.S.\n\n**Laura Chen** (Research Analyst)\nThank you very much. That is very clear. Also, my second question is about the capacity allocation between Taiwan and also Arizona. C.C., you just shared with us that about 30% of N2 capacity will be in Arizona. We know it will be starting from when or what kind of a timeframe you are looking for.\n\n**Laura Chen** (Research Analyst)\nCan we also assume that the same scale, like 30% of your Arizona fab for the advanced node in the longer term?\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Laura's second question is about the capacity allocation between how do we allocate between Taiwan and the U.S.? Maybe is it duplicative or extra capacity? Then very specific, C.C. had mentioned that N2 and more advanced capacity, 30%, around 30% will be in Arizona once we scale up to the cluster. Will that be kind of the percentage for the leading node in the future?\n\n**Che-Chia Wei** (Chairman and CEO)\nWe have right now we plan a six fab in Arizona. And in that six fab, the two nanometer will be a major node. That is what I say, 30% will be there. As time goes by, after the two nanometer will be 1.4 and 1.0. That has not been discussed yet.\n\n**Laura Chen** (Research Analyst)\nOkay, thank you. Thank you very much.\n\n**Laura Chen** (Research Analyst)\nThat's very clear.\n\n**Jeff Su** (Director of Investor Relations)\nAll right, thanks, Laura. Operator, can we take the last questions from the last participant, please?\n\n**Operator**\nThe last one to ask questions, Chris Asankar Cohen. Go ahead, please.\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nYeah, thanks for taking my question. My first one is, it's very impressive given uncertainty, you're still maintaining full revenue guidance and also your N2 capacity plan for this year and next year. Kind of curious, what is your visibility on second-half revenues and also N2 demand for wafers into next year? And then I have a follow-up.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, so Chris's first question is sort of in the near term, what is our visibility into the second-half business outlook? And then also, how do we see the demand for N2 progressing this year and also next year?\n\n**Wendell Huang** (Senior VP and CFO)\nOkay, let me talk about the first one. We're only at second quarters.\n\n**Wendell Huang** (Senior VP and CFO)\nI think it's too early to talk about the second half. We did mention that the uncertainties and risks from tariffs exist, and we might get a better picture in the next few months. We can probably update you in the next earnings call.\n\n**Jeff Su** (Director of Investor Relations)\nThe second part of it is on the demand visibility of our two nanometer.\n\n**Che-Chia Wei** (Chairman and CEO)\nSo far, actually, so far is very strong, as we said. All the new tape-out customers, the number of the tape-outs is exceeding what we expected. As we said, the number of the new tape-outs is much higher than the three nanometer and five nanometer in the same period of time.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, did you have a second question, Chris?\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nGot it. Very helpful. Yes, Jeff, yeah. Just one quick follow-up. You spoke about the Japan fab. I'm curious, what is the capacity installed in Japan today?\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nHow do you think about the revenue contribution this year from Japan?\n\n**Jeff Su** (Director of Investor Relations)\nOkay. Chris's second question is related to our first specialty technology fab in Japan. He wants to know what is the capacity installment for this specialty technology fab and also the revenue contribution from JASM.\n\n**Wendell Huang** (Senior VP and CFO)\nThe capacity for the fab will be 40K when it is ramped up. The revenue for this year compared to the whole company is really not significant at this moment.\n\n**Jeff Su** (Director of Investor Relations)\nOkay, Chris?\n\n**Krish Sankar** (Managing Director and Senior Research Analyst)\nGot it. Thank you, Wendell. Thank you, Jeff.\n\n**Jeff Su** (Director of Investor Relations)\nThank you very much. No problem. Thank you, everyone. This concludes our question and answer session. Before we conclude today's conference, please be advised that the replay of the conference call will be accessible within 30 minutes from now. The transcript will become available 24 hours from now, and both will be available through TSMC's website at www.tsmc.com.\n\n**Jeff Su** (Director of Investor Relations)\nThank you again for joining us today. We hope everyone continues to stay well and hope you will join us again next quarter. Goodbye and have a good day. Take care. Thank you.",
        "fetched_at": "2026-02-04T16:13:07.004Z"
      }
    ]
  },
  "AVGO": {
    "ticker": "AVGO",
    "last_updated": "2026-02-04T16:13:42.676Z",
    "total_transcripts": 4,
    "transcripts": [
      {
        "ticker": "AVGO",
        "title": "Yahoo Finance",
        "published_date": "Dec 11, 2025, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/AVGO/earnings/AVGO-Q4-2025-earnings_call-382934.html",
        "content": "**Operator**\nWelcome to Broadcom Inc.'s Fourth Quarter and Fiscal Year 2025 Financial Results Conference Call. At this time, for opening remarks and introductions, I would like to turn the call over to Ji Yoo, Head of Investor Relations of Broadcom Inc.\n\n**Ji Yoo** (Head of Investor Relations)\nThank you, Cherie, and good afternoon, everyone. Joining me on today's call are Hock Tan, President and CEO, Kirsten Spears, Chief Financial Officer, and Charlie Kawwas, President, Semiconductor Solutions Group. Broadcom distributed a press release and financial tables after the market closed, describing our financial performance for the fourth quarter and fiscal year 2025. If you did not receive a copy, you may obtain the information from the investor section of Broadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the call can be accessed for one year through the investor section of Broadcom's website. During the prepared remarks, Hock and Kirsten will be providing details of our fourth quarter and fiscal year 2025 results, guidance for our first quarter of fiscal year 2026, as well as commentary regarding the business environment. We'll take questions after the end of our prepared comments.\n\n**Ji Yoo** (Head of Investor Relations)\nPlease refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our actual results to differ materially from the forward-looking statements made on this call. In addition to U.S. GAAP reporting, Broadcom reports certain financial measures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release. Comments made during today's call will primarily refer to our non-GAAP financial results. I'll now turn the call over to Hock.\n\n**Hock Tan** (President and CEO)\nThank you, Ji. And thank you, everyone, for joining us today. We just ended our Q4, fiscal 2025, and before I get into details of that quarter, let me recap the year. In our fiscal 2025, consolidated revenue grew 24% year over year to a record $64 billion, and it's driven by AI semiconductors and VMware. AI revenue grew 65% year over year to $20 billion, driving the semiconductor revenue for this company to a record $37 billion for the year. In our infrastructure software business, strong adoption of VMware Cloud Foundation, or VCF, as we call it, drove revenue growth of 26% year on year to $27 billion. In summary, 2025 was another strong year for Broadcom, and we see the spending momentum by our customers for AI continuing to accelerate in 2026. Now, let's move on to the results of our fourth quarter 2025.\n\n**Hock Tan** (President and CEO)\nTotal revenue was a record $18 billion, up 28% year on year, and above our guidance on better-than-expected growth in AI semiconductors, as well as infrastructure software. Q4 consolidated adjusted EBITDA was a record $12.12 billion, up 34% year on year. So let me give you more color on our two segments. In semiconductors, revenue was $11.1 billion, as year-on-year growth accelerated to 35%. And this robust growth was driven by the AI semiconductor revenue of $6.5 billion, which was up 74% year on year. And this represents a growth trajectory exceeding 10 times over the 11 quarters we have reported this line of business. Our custom-accelerated business more than doubled year over year, as we see our customers increase adoption of XPUs, as we call those custom accelerators, in training their LLMs and monetizing their platforms through inferencing APIs and applications.\n\n**Hock Tan** (President and CEO)\nThese XPUs, I might add, are not only being used to train and inference internal workloads by our customers. The same XPUs, in some situations, have been extended externally to other LLM peers. Best exemplified at Google, where the TPUs used in creating Gemini are also being used for AI cloud computing by Apple, Cohere, and SSI as a sample, and the scale at which we see this happening could be significant, and as you are aware, last quarter, Q3 2025, we received a $10 billion order to sell the latest TPU, Ironwood Rex, to Anthropic, and in this quarter, Q4, we received an additional $11 billion order from this same customer for delivery in late 2026, but that does not mean our other two customers are using TPUs.\n\n**Hock Tan** (President and CEO)\nIn fact, they prefer to control their own destiny by continuing to drive their multi-year journey to create their own custom AI accelerators, or XPU Rex, as we call them. I'm pleased today to report that during this quarter, we acquired a fifth XPU customer through a $1 billion order placed for delivery in late 2026. Now, moving on to AI networking. Demand here has even been stronger as we see customers build out their data center infrastructure ahead of deploying AI accelerators. Our current order backlog for AI switches exceeds $10 billion, as our latest 102 terabit per second Tomahawk 6 switch, the first and only one of its capability out there, continues to book at record rates. This is just a subset of what we have.\n\n**Hock Tan** (President and CEO)\nWe have also secured record orders on DSPs, optical components like lasers, and PCI Express switches to be deployed in AI data centers, and all these components, combined with our XPUs, bring our total order on hand in excess of $73 billion today, which is almost half Broadcom's consolidated backlog of $162 billion. We expect these $73 billion in AI backlog to be delivered over the next 18 months, and in Q1, fiscal 2026, we expect our AI revenue to double year on year to $8.2 billion. Turning to non-AI semiconductors, Q4 revenue of $4.6 billion was up 2% year on year and up 16% sequentially based on favorable wireless seasonality. Year on year, broadband showed solid recovery. Wireless was flat, and all the other end markets were down as enterprise spending continued to show limited signs of recovery.\n\n**Hock Tan** (President and CEO)\nAccordingly, in Q1, we forecast non-AI semiconductor revenue to be approximately $4.1 billion, flat from a year ago, down sequentially due to wireless seasonality. Let me now talk about our infrastructure software segment. Q4 infrastructure software revenue of $6.9 billion was up 19% year on year, and above our outlook of $6.7 billion. Bookings continued to be strong as total contract value booked in Q4 exceeded $10.4 billion versus $8.2 billion a year ago. We ended the year with $73 billion of infrastructure software backlog, up from $49 billion a year ago. We expect renewals to be seasonal in Q1 and forecast infrastructure software revenue to be approximately $6.8 billion. We still expect, however, that for fiscal 2026, infrastructure software revenue to grow low double-digit percentage. Here's what we see in 2026.\n\n**Hock Tan** (President and CEO)\nDirectionally, we expect AI revenue to continue to accelerate and drive most of our growth, and non-AI semiconductor revenue to be stable. Infrastructure software revenue will continue to be driven by VMware growth at low double digits. And for Q1 2026, we expect consolidated revenue of approximately $19.1 billion, up 28% year on year. And we expect adjusted EBITDA to be approximately 67% of revenue. And with that, let me turn the call over to Kirsten.\n\n**Kirsten Spears** (CFO)\nThank you, Hock. Let me now provide additional detail on our Q4 financial performance. Consolidated revenue was a record $18 billion for the quarter, up 28% from a year ago. Gross margin was 77.9% of revenue in the quarter, better than we originally guided on higher software revenues and product mix within semiconductors. Consolidated operating expenses were $2.1 billion, of which $1.5 billion was research and development. Q4 operating income was a record $11.9 billion, up 35% from a year ago. Now, on a sequential basis, even as gross margin was down 50 basis points on semiconductor product mix, operating margin increased 70 basis points sequentially to 66.2% on favorable operating leverage. Adjusted EBITDA of $12.12 billion, or 68% of revenue, was above our guidance of 67%. This figure excludes $148 million of depreciation. Now, a review of the P&L for our two segments, starting with semiconductors.\n\n**Kirsten Spears** (CFO)\nRevenue for our semiconductor solution segment was a record $11.1 billion, with growth accelerating to 35% year on year, driven by AI. Semiconductor revenue represented 61% of total revenue in the quarter. Gross margin for our semiconductor solution segment was approximately 68%. Operating expenses increased 16% year on year to $1.1 billion on increased investment in R&D for leading-edge AI semiconductors. Semiconductor operating margin of 59% was up 250 basis points year on year. Now, moving to infrastructure software. Revenue for infrastructure software of $6.9 billion was up 19% year on year and represented 39% of total revenue. Gross margin for infrastructure software was 93% in the quarter, compared to 91% a year ago. Operating expenses were $1.1 billion in the quarter, resulting in infrastructure software operating margin of 78%. This compares to operating margin of 72% a year ago, reflecting the completion of the integration of VMware.\n\n**Kirsten Spears** (CFO)\nMoving on to cash flow. Free cash flow in the quarter was $7.5 billion and represented 41% of revenue. We spent $237 million on capital expenditures. Day sales outstanding were 36 days in the fourth quarter, compared to 29 days a year ago. We ended the fourth quarter with inventory of $2.3 billion, up 4% sequentially. Our days of inventory on hand were 58 days in Q4, compared to 66 days in Q3, as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the fourth quarter with $16.2 billion of cash, up $5.5 billion sequentially on strong cash flow generation. The weighted average coupon rate in years to maturity of our gross principal fixed rate debt of $67.1 billion is 4% at 7.2 years, respectively. Turning to capital allocation.\n\n**Kirsten Spears** (CFO)\nIn Q4, we paid stockholders $2.8 billion of cash dividends based on a quarterly common stock cash dividend of $0.59 per share. In Q1, we expect the non-GAAP diluted share count to be approximately 4.97 billion shares, excluding the potential impact of any share repurchases. Now, let me recap our financial performance for fiscal year 2025. Our revenue hit a record $63.9 billion, with organic growth accelerating to 24% year on year. Semiconductor revenue was $36.9 billion, up 22% year over year. Infrastructure software revenue was $27 billion, up 26% year on year. Fiscal 2025 adjusted EBITDA was $43 billion and represented 67% of revenue. Free cash flow grew 39% year on year to $26.9 billion. For fiscal 2025, we returned $17.5 billion of cash to shareholders in the form of $11.1 billion of dividends and $6.4 billion in share repurchases and elimination.\n\n**Kirsten Spears** (CFO)\nAligned with our ability to generate increased cash flows in the preceding year, we are announcing an increase in our quarterly common stock cash dividend in Q1 fiscal 2026 to $0.65 per share, an increase of 10% from the prior quarter. We intend to maintain this target quarterly dividend throughout fiscal 26, subject to quarterly board approval. This implies our fiscal 2026 annual common stock dividend to be a record $2.60 per share, an increase of 10% year on year. I would like to highlight that this represents the 15th consecutive increase in annual dividends since we initiated dividends in fiscal 2011. The board also approved an extension of our share repurchase program, of which $7.5 billion remains through the end of calendar year 2026. Now, moving to guidance. Our guidance for Q1 is for consolidated revenue of $19.1 billion, up 28% year on year.\n\n**Kirsten Spears** (CFO)\nWe forecast semiconductor revenue of approximately $12.3 billion, up 50% year on year. Within this, we expect Q1 AI semiconductor revenue of $8.2 billion, up approximately 100% year on year. We expect infrastructure software revenue of approximately $6.8 billion, up 2% year on year. For your modeling purposes, we expect Q1 consolidated gross margin to be down approximately 100 basis points sequentially, primarily reflecting a higher mix of AI revenue. As a reminder, consolidated gross margins through the year will be impacted by the revenue mix of infrastructure software and semiconductors, and also product mix within semiconductors. We expect Q1 adjusted EBITDA to be approximately 67%. We expect the non-GAAP tax rate for Q1 and fiscal year 2026 to increase from 14% to approximately 16.5% due to the impact of the global minimum tax and shift in geographic mix of income compared to that of fiscal year 2025.\n\n**Kirsten Spears** (CFO)\nThat concludes my prepared remarks. Operator, please open up the call for questions.\n\n**Operator**\nThank you. To ask a question, you will need to press star 11 on your telephone. To withdraw your question, press star 11 again. Due to time restraints, we ask that you please limit yourself to one question. Please stand by while we compile the Q&A roster. Our first question will come from the line of Vivek Arya with Bank of America. Your line is open.\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nThank you. Just wanted to clarify. Hock, you said $73 billion over 18 months for AI. That's roughly $50-ish billion plus for fiscal 26 for AI. I just wanted to make sure I got that right. And then the main question, Hock, is that there is sort of this emerging debate about customer-owned tooling, your hyperscale customers potentially wanting to do more things on their own. How do you see your XPU content and share at your largest customer evolve over the next one or two years? Thank you.\n\n**Hock Tan** (President and CEO)\nTo answer your first question, what we said is correct that as of now, we have $73 billion of backlog in place of XPUs, switches, DSPs, lasers for AI data centers that we anticipate shipping over the next 18 months. Obviously, this is as of now. I mean, we fully expect more bookings to come in over that period of time. So don't take that $73 billion as that's the revenue we ship over the next 18 months. We're just saying we have that now, and the bookings have been accelerating. Frankly, we see that bookings not just in XPUs, but in switches, DSPs, all the other components that go into AI data centers. We have never seen bookings of the nature that what we have seen over the past three months, particularly with respect to Tomahawk 6 switches.\n\n**Hock Tan** (President and CEO)\nThis is one of the fastest-growing products in terms of deployment that we have ever seen of any switch product that we put out there. It is pretty interesting, and partly because it's the only one of its kind out there at this point at 102 terabits per second, and that's the exact product needed to expand the clusters of the latest GPU and XPUs out there. Oh, that's great, but as far as what is the future, is XPU your broader question? My answer to you is don't follow what you hear out there as gospel. It's a trajectory. It's a multi-year journey, and many of the players, and not too many players doing LLMs, want to do their own custom AI accelerator for very good reasons. You can put in hardware what, if you use a general-purpose GPU, you can only do in software and kernels and software.\n\n**Hock Tan** (President and CEO)\nYou can achieve performance-wise so much better in the custom-purpose designed hardware-driven XPU. And we see that in the TPU, and we see that in all the accelerators we are doing for our other customers. Much, much better in areas of Sparse Core, training, inference, reasoning, all that stuff. Now, will that mean that over time they all want to go do it themselves? Not necessarily. And in fact, because the technology in silicon keeps updating, keeps evolving. And if you are an LLM player, where do you put your resources in order to compete in this space, especially when you have to compete at the end of the day against merchant GPUs who are not slowing down in their rate of evolution? So I see that as this concept of customer tooling is an overblown hypothesis, which frankly, I don't think will happen.\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nThank you.\n\n**Operator**\nMoment for our next question, and that will come from the line of Ross Seymour with Deutsche Bank. Your line is open.\n\n**Ross Seymore** (Managing Director)\nHi. Thanks for asking the question. Hock, I wanted to go to something you touched on earlier about the TPUs going a little bit more to a merchant go-to-market to other customers. Do you believe that's a substitution effect for customers who otherwise would have done ASICs with you, or do you think it's actually broadening the market? And so what are kind of the financial implications of that from your perspective?\n\n**Hock Tan** (President and CEO)\nThat's a very good question, Ross. What we see right now is the most obvious move it does is it goes to the people who use TPUs. The alternative is GPUs on a merchant basis. That's the most common thing that happens. Because to do that substitution for another custom, it's different. To make an investment in custom accelerator is a multi-year journey. It's a strategic directional thing. It's not necessarily a very transactional or short-term move. Moving from GPU to TPU is a transactional move. Going into AI accelerator of your own is a long-term strategic move, and nothing will deter you from that to continue to make that investment towards that end goal of successfully creating and deploying your own custom AI accelerator. That's the motion we see.\n\n**Ross Seymore** (Managing Director)\nThank you.\n\n**Operator**\nAnd that will come from the line of Harlan Sur with J.P. Morgan.\n\n**Harlan Sur** (Executive Director of Equity Research)\nYeah. Good afternoon. Thanks for taking my question and congratulations on the strong results, guidance, and execution, Hock. Again, I just want to reiterate I just want to sort of verify this, right? So you talked about total AI backlog of $73 billion over the next six quarters, right? This is just a snapshot of your order book right now. But given your lead times, I think customers can and still will place orders for AI in quarters four, five, and six. So as time moves forward, that backlog number for more shipments in the second half of 2026 will probably still go up, right? Is that the correct interpretation? And then given the strong and growing backlog, right, the question is, does the team have 3-nanometer, 2-nanometer wafer supply, CoWoS, substrate, HBM supply commitments to support all of the demand in your order book?\n\n**Harlan Sur** (Executive Director of Equity Research)\nAnd I know one of the areas where you are trying to mitigate this is in advanced packaging, right? You're bringing up your Singapore facility. Can you guys just remind us what part of the advanced packaging process the team is focusing on with the Singapore facility? Thanks.\n\n**Hock Tan** (President and CEO)\nThanks. Well, to answer your first simpler question, you're right. You can say that $73 billion is the backlog we have today to ship over the next six quarters. You might also say that, and given our lead time, we expect more orders to be able to be absorbed into our backlog for shipments over the next six quarters. So take it that we expect revenue, a minimum revenue, one way to look at it, of $73 billion over the next six quarters, but we do expect much more as more orders come in for shipments within that next six quarters. Our lead time, depending on the particular product it is, can be anywhere from six months to a year. With respect to supply chain, is what you're asking, critical supply chain on silicon and packaging?\n\n**Harlan Sur** (Executive Director of Equity Research)\nYes.\n\n**Hock Tan** (President and CEO)\nYeah. That's an interesting challenge that we have been addressing constantly and continue to, and with the strength of the demand and the need for more innovative packaging, advanced packaging, because you're talking about multi-chips, multi-chips in creating every custom accelerator now, the packaging becomes a very interesting and technical challenge. Building our Singapore fab is to really talk about partially insourcing those advanced packaging. We believe that we have enough demand. We can literally insource not from the viewpoint of not just cost, but in the viewpoint of supply chain security and delivery. We're building up a fairly substantial facility for packaging, advanced packaging in Singapore, as you indicated, purely for that purpose to address the advanced packaging side. Silicon-wise, no, we go back to the same process source in TSMC, and so we keep going for more and more capacity in 2 nanometers, 3 nanometers.\n\n**Hock Tan** (President and CEO)\nAnd so far, we do not have that constraint. But again, time will tell as we progress and as our backlog builds up.\n\n**Harlan Sur** (Executive Director of Equity Research)\nThank you, Hock.\n\n**Operator**\nOne moment for our next question. The next question will come from the line of Blaine Curtis with Jefferies. Your line is open.\n\n**Blayne Curtis** (Managing Director)\nHey, good afternoon. Thanks for taking my question. I wanted to ask, with the original $10 billion deal, you talked about a rack sale. I just wanted to, with the follow-on order as well as the fifth customer, can you just maybe describe how you're going to deliver those? Is it an XPU, or is it a rack? And then maybe you can kind of just walk us through the math and kind of what the deliverable is. Obviously, Google uses its own networking. So I'm kind of curious too, would it be a copy exact of what Google does now that you could talk to it to name? Or would you have your own networking in there as well? Thanks.\n\n**Hock Tan** (President and CEO)\nThat's a very complicated question, Blaine. Let me tell you what it is. It's a system sale. Hock, about that. It's a real system sale. We have so many components beyond XPUs, custom accelerators in any system, in AI system, any AI system used by hyperscalers that, yeah, we believe it began to make sense to do it as a system sales and be responsible, be fully responsible for the entire system or rack, as you call it. I think people understand it as a system sale better. And so on this customer number four, we are selling it as a system with our key components in it. And that's no different than selling a chip. We certify and final ability to run as part of the whole selling process.\n\n**Blayne Curtis** (Managing Director)\nOkay. Thanks, Hock.\n\n**Operator**\nOne moment for our next question, and that will come from the line of Stacy Rasgon with Bernstein. Your line is open.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nHi, guys. Thanks for taking my question. I wanted to touch on gross margins, and maybe it feeds into a little bit the prior question. So I understand why the AI business is somewhat diluted to gross margins. We have the HBM pass-through, and then presumably with the system sales, that will be more diluted. And you've hinted at this in the past, but I was wondering if you could be a little more explicit. As this AI revenue starts to ramp, as we start to get system sales, how should we be thinking about that gross margin number, say if we're looking out four quarters or six quarters? Is it low 70s? I mean, could it start with a 6 at the corporate level? And I guess I'm also wondering, I understand how that comes down, but what about the operating margins?\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nDo you think you get enough operating leverage on the OpEx side to keep operating margins flat, or do they need to come down as well?\n\n**Hock Tan** (President and CEO)\nI'll let Kirsten give you the details, but enough for me to broadly high-level explain to you, Stacy, and good question, phenomenal. You don't see that impacting us right now, and we have already started that process of some system sales. You don't see that in our numbers, but it will, and we have said that openly. The AI revenue has a lower gross margin than our, obviously, the rest of our business, including software, of course, but we expect the rate of growth as we do more and more AI revenue to be so much that we get the operating leverage on our operating spending, that operating margin will deliver dollars that are still a high level of growth from what it has been. So we expect operating leverage to benefit us at the operating margin level, even as gross margin will start to deteriorate. High level.\n\n**Kirsten Spears** (CFO)\nYeah. I think Hock said that fairly, and the second half of the year, when we do start shipping more systems, the situation is straightforward. We'll be passing through more components that are not ours, so think of it similar to the XPUs where we have memory on those XPUs, and we're passing through those costs. We'll be passing through more costs within the rack, and so those gross margins will be lower. However, overall, the way Hock said it, gross margin dollars will go up, margins will go down. Operating margins, because we have leverage, operating margin dollars will go up, but the margin itself as a percentage of revenues will come down a bit, but we're not, I mean, we'll guide closer to the end of the year for that.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nGot it. Thank you, guys.\n\n**Operator**\nOne moment for our next question. That will come from the line of Jim Schneider with Goldman Sachs. Your line is open.\n\n**Jim Schneider** (Senior Equity Analyst)\nGood afternoon. Thanks for taking my question. Hock was wondering if you might care to calibrate your expectations for AI revenue in fiscal 2026 a little bit more closely. I believe you talked about acceleration in fiscal 2026 off of the 65% growth rate you did in fiscal 2025, and then you're guiding to 100% growth for Q1. So I'm just wondering if the Q1 is a good jumping-off point for the growth rate you expect for the full year or something maybe a little bit less than that. And then maybe if you could separately clarify whether your $1 billion of orders for the fifth customer is indeed OpenAI, which you made a separate announcement about. Thank you.\n\n**Hock Tan** (President and CEO)\nWow. There's a lot of questions here. But let me start off with 2026. Our backlog is very dynamic these days, as I said. It's continuing to ramp up. And you're right. We originally, six months ago, said maybe year on year, AI revenues would grow in 2026 60%-70%. Q1, we doubled. And Q1 2026, today, we're saying it doubled. And we're looking at it because all the fresh orders keep coming in, and we give you a milestone of where we are today, which is $73 billion of backlog to be shipped over the next 18 months. And we do fully expect, as I answered the earlier question, for that $73 billion over the 18 months to keep growing. Now, it's a moving target. It's a moving number as we move in time, but it will grow.\n\n**Hock Tan** (President and CEO)\nIt's hard for me to pinpoint what 2026 is going to look like precisely. So I'd rather not give you guys any guidance. That's why we don't give you guidance, but we do give it for Q1. Give it time. We'll give it for Q2. You're right. It's in that to us, is it an accelerating trend? My answer is it's likely to be an accelerating trend as we progress through 2026. Hope that answers your question.\n\n**Jim Schneider** (Senior Equity Analyst)\nYes. Thank you.\n\n**Operator**\nOne moment for our next question, and that will come from the line of Ben Reitzes with Melius Research. Your line is open.\n\n**Ben Reitzes** (Managing Director)\nYeah. Hey, guys. Thanks a lot. Hey, Hock. I wanted to ask. I'm not sure if the last caller said something on it, but I didn't hear it in the answer. What I wanted to ask about the OpenAI contract that it's supposed to start in the second half of the year and go through 2029 for 10 gigawatts. I'm going to assume that that's the fifth customer order there. And I was just wondering if you're still confident in that being a driver. Are there any obstacles to making that a major driver? And when you expect that to contribute and your confidence in it? Thanks so much, Hock.\n\n**Hock Tan** (President and CEO)\nYou didn't hear that answer from my last caller, Jim's questions, because I didn't answer it. I did not answer it, and I'm not answering it either. It's the fifth customer, and it's a real customer, and it will grow. They are on their multi-year journey to their own XPUs. And let's leave it at that. As far as the OpenAI view that you have, we appreciate the fact that it is a multi-year journey that will run through 2029, as our press release with OpenAI showed. 10 gigawatts between 2026, more like 2027, 2028, 2029, Ben, not 2026. It's more like 2027, 2028, 2029, 10 gigawatts. That was the OpenAI discussion. And I call it an agreement, an alignment of where we're headed with respect to a very respected and valued customer, OpenAI. But we do not.\n\n**Ben Reitzes** (Managing Director)\nOkay. That's real interesting.\n\n**Hock Tan** (President and CEO)\nWe do not expect much in 2026.\n\n**Ben Reitzes** (Managing Director)\nOkay. Thanks for clarifying that. That's real interesting. Appreciate it.\n\n**Operator**\nOne moment for our next question. That will come from the line of C.J. Muse with Cantor Fitzgerald. Your line is open.\n\n**CJ Muse Senior** (Managing Director)\nYeah. Good afternoon. Thank you for taking the question. I guess, Hock, I wanted to talk about custom silicon and maybe speak to how you expect compute to grow for Broadcom generation to generation. And as part of that, your competitor announced XPU offering essentially accelerator for an accelerator for massive context windows. I'm curious if you see it broadening opportunity for your existing five customers to have multiple XPU offerings. Thanks so much.\n\n**Hock Tan** (President and CEO)\nThank you. No. Yeah. You hit it right on. I mean, the nice thing about a custom accelerator is you try not to do one size fits all and generationally. Each of these five customers now can create their version of an XPU custom accelerator for training and inference. And basically, it's almost two parallel tracks going on almost simultaneously for each of them. So I would have plenty of versions to deal with. I don't need to create any more versions. We got plenty of different content out there just on the basis of creating these custom accelerators. And by the way, when you do custom accelerators, you tend to put more hardware in that are unique, differentiated versus trying to make it work on software and creating kernels into software.\n\n**Hock Tan** (President and CEO)\nI know that's very tricky too, but thinking about the difference where you can create in hardware those Sparse Core data routers versus the dense matrix multipliers, all in one same chip. And that's just one example of what creating custom accelerators is letting us do. Or for that matter, a variation in how much memory capacity or memory bandwidth for the same customer from chip to chip, just because even in inference, you want to do more reasoning versus decoding versus something else like prefill. So you literally start to create different hardware for different aspects of how you want to train or inference and run your workloads. It's a very fascinating area, and we are seeing a lot of variations and multiple chips for each of our customers.\n\n**CJ Muse Senior** (Managing Director)\nThank you.\n\n**Operator**\nOne moment for our next question, and that will come from the line of Harsh Kumar with Piper Sandler. Your line is open.\n\n**Harsh Kumar** (Managing Director and Senior Research Analyst)\nYeah. Hock and team, first of all, congratulations on some pretty stunning numbers. I've got an easy one and a more strategic one. The easy one is your guide in AI, Hock and Kirsten, is calling for almost $1.7 billion of sequential growth. I was curious, maybe you could talk about the diversity of the growth between the three existing customers. Is it pretty well spread out, all of them growing, or is one sort of driving much of the growth? And then, Hock, strategically, one of your competitors bought a photonic fabric company recently. I was curious about your take on that technology and if you think it's disruptive or you think it's just gimmickery at this point in time.\n\n**Hock Tan** (President and CEO)\nI like the way you address this question, the way that you address the question to me. It's almost hesitant. Thank you. I appreciate that. But on your first part, yeah, we are driving growth, and it began to feel like this thing never ends. And it's a real mixed bag of existing customers and on existing XPUs. And a big part of it is XPUs that we're seeing. And that's not to slow down the fact that, as I indicated in my remarks and commented on, the demand for switches, not just Tomahawk 6, Tomahawk 5 switches, the demand for our latest 1.6 terabit per second DSPs that enables optical interconnects for scale-out, particularly. It's just very, very strong. And by extension, demand for the optical components like lasers, PIN diodes, just going nuts. All that come together.\n\n**Hock Tan** (President and CEO)\nNow, all that is smaller on relatively lesser dollars when it comes to XPUs, as you probably guess. I mean, to give you a sense, maybe let me look at it on a backlog side. Of the $73 billion of AI revenue backlog over the next 18 months I talked about, maybe $20 billion of it is everything else. The rest is XPUs. Hope that gives you a sense of what the mix is. But that's not to say that the rest is still $20 billion. That's not small by any means. So we value that. So when you talk about your next question of silicon photonics as a means to create basically much better, more efficient, lower power interconnects in not just scale-out, but hopefully scale-up, yeah, I could see a point in time in the future when silicon photonics matters as the only way to do it.\n\n**Hock Tan** (President and CEO)\nWe're not quite there yet, but we have the technology, and we continue to develop the technology. Even at each time, we develop it first for 400 gigabit bandwidth, going on to 800 gigabit bandwidth. Not ready for it yet. And even we have the product, and we're now doing it for 1.6 terabit bandwidth to create silicon photonics switches, silicon photonics interconnects. Not even sure it will get fully deployed because our engineers, our peers, and the peers we have out there will somehow try to find a way to still try to do scale-up within a rack in copper as long as possible and in scale-up in pluggable optics. The final, final straw is when you can't do it well in pluggable optics. And of course, when you can't do it even in copper, then you're right. You go to silicon photonics, and it will happen.\n\n**Hock Tan** (President and CEO)\nWe're ready for it. Just saying not anytime soon.\n\n**Harsh Kumar** (Managing Director and Senior Research Analyst)\nThank you, Hock.\n\n**Operator**\nOne moment for our next question. That will come from the line of Carl Ackerman with BNP Paribas. Your line is open.\n\n**Karl Ackerman** (Managing Director)\nYes. Thank you. Hock, could you speak to the supply chain resiliency and visibility you have with your key materials suppliers, particularly CoWoS, as you not only support your existing customer programs but the two new custom compute processors that you announced this quarter? I guess what I'm getting at is you also happen to address the very large subset of networking and compute AI supply chains. You talked about record backlog. If you were to pinpoint some of the bottlenecks that you have and areas that you're aiming to address and mitigate from supply chain bottlenecks, what would they be, and how do you see that ameliorating into 2026? Thank you.\n\n**Hock Tan** (President and CEO)\nIt's across the board, typically. I mean, we are very fortunate in some ways that we have the product technology and the operating business lines to create multiple key leading-edge components that enables today's state-of-the-art AI data centers. I mean, our DSP, as I said earlier, is now at 1.6 terabit per second. That's the leading-edge connectivity for bandwidth for the top of the heap XPU and even GPU. And we intend to be that way. And we have the lasers, EMLs, VCSELs, CW lasers that goes with it. So it's fortunate that we have all this and the key active components that go with it. And we see it very early, and we expand the capacity as we do the design to match it.\n\n**Hock Tan** (President and CEO)\nThis is a long answer to what I'm trying to get at, which is I think we are of any of these data center suppliers of the system racks, not counting the power shell and all that. Now, that starts to get beyond us on the power shell and the transformers and the gas turbines. If you just look at the racks, the systems on AI, we probably have a good handle on where the bottlenecks are because sometimes we are part of the bottlenecks, which we then work to get to resolve. We feel pretty good about that through 2026.\n\n**Karl Ackerman** (Managing Director)\nThank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Christopher Rolland with Susquehanna. Your line is open.\n\n**Christopher Rolland** (Semiconductor Analyst)\nHi. Thanks for the question. Just first a clarification and then my question. And sorry to come back to this issue, but if I understand you correctly, Hock, I think you were saying that OpenAI would be a general agreement, so it's not binding, maybe similar to the agreements with both NVIDIA and AMD. And then secondly, you talked about flat non-AI semiconductor revenue. Maybe what's going on there is there still an inventory overhang, and what do we need to get that going again? Do you see growth eventually in that business? Thank you.\n\n**Hock Tan** (President and CEO)\nOn the non-AI semiconductor, we see broadband literally recovering very well. We don't see the others. No, we see stability. We don't see a sharp recovery that is sustainable yet. I guess give it a couple more quarters. We don't see any further deterioration in demand. It's more, I think, maybe the AI is sucking the oxygen a lot out of enterprise spending elsewhere and hyperscaler spending elsewhere. We don't see it getting any worse. We don't see it recovering very quickly with the exception of broadband. That's a simple summary of non-AI. With respect to OpenAI, without diving into depth, I'm just telling you what that 10-gigawatt announcement is all about. Separately, the journey with them on the custom accelerator progresses at a very advanced stage and will happen very, very quickly. We will have a committed element to this whole thing.\n\n**Hock Tan** (President and CEO)\nAnd that will. But what I was articulating earlier was the 10-gigawatt announcement. And that 10-gigawatt announcement is an agreement to be aligned on developing 10 gigawatts for OpenAI over 2027 to 2029 timeframe. That's it. That's different from the XPU program we're developing with them.\n\n**Christopher Rolland** (Semiconductor Analyst)\nI see. Thank you very much.\n\n**Operator**\nThank you. And we do have time for one final question. And that will come from the line of Joe Moore with Morgan Stanley. Your line is open.\n\n**Joe Moore** (Semiconductor Industry Analyst)\nGreat. Thank you very much. So if you have $21 million of rack revenue in the second half of 2026, I guess, do we stay at that run rate? Beyond that, are you going to continue to sell racks, or does that sort of that type of business make shift over time? And I'm really just trying to figure out the percentage of your 18-month backlog that's actually full systems at this point.\n\n**Hock Tan** (President and CEO)\nWell, it's an interesting question. And that question basically comes to how much compute capacity is needed by our customers over the next, as I say, over the period beyond 18 months. And your guess is probably as good as mine based on what we all know out there, which is really what it relates to. But if they need more, then you see that continuing even larger. If they don't need it, then probably it won't. But what we're trying to indicate is that's the demand we're seeing over that period of time right now.\n\n**Joe Moore** (Semiconductor Industry Analyst)\nThank you.\n\n**Operator**\nI would now like to turn the call back over to Ji Yoo for any closing remarks.\n\n**Ji Yoo** (Head of Investor Relations)\nThank you, operator. This quarter, Broadcom will be presenting at the New Street Research Virtual AI Big Ideas Conference on Monday, December 15th, 2025. Broadcom currently plans to report its earnings for the first quarter of fiscal year 2026 after close of market on Wednesday, March 4th, 2026. A public webcast of Broadcom's earnings conference call will follow at 2:00 P.M. Pacific. That will conclude our earnings call today. Thank you all for joining. Operator, you may end the call.\n\n**Operator**\nThis concludes today's program. Thank you all for participating. You may now disconnect.",
        "fetched_at": "2026-02-04T16:13:20.847Z"
      },
      {
        "ticker": "AVGO",
        "title": "Yahoo Finance",
        "published_date": "Sep 4, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/AVGO/earnings/AVGO-Q3-2025-earnings_call-353878.html",
        "content": "**Operator**\nWelcome to Broadcom Inc.'s third quarter, fiscal year 2025 financial results conference call. At this time, for opening remarks and introductions, I would like to turn the call over to Ji Yoo, Head of Investor Relations of Broadcom Inc. Please go ahead.\n\n**Ji Yoo** (Investor Relations)\nThank you, Cheri, and good afternoon, everyone. Joining me on today's call are Hock Tan, President and CEO; Kirsten Spears, Chief Financial Officer; and Charlie Kawwas, President, Semiconductor Solutions Group. Broadcom distributed a press release and financial tables after the market close, describing our financial performance for the third quarter of fiscal year 2025. If you did not receive a copy, you may obtain the information from the Investor section of Broadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the call can be accessed for one year through the Investor section of Broadcom's website. During the prepared comments, Hock and Kirsten will be providing details of our third quarter fiscal year 2025 results, guidance for our fourth quarter of fiscal year 2025, as well as commentary regarding the business environment. We'll take questions after the end of our prepared comments.\n\n**Ji Yoo** (Investor Relations)\nPlease refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our actual results to differ materially from the forward-looking statements made on this call. In addition to U.S. GAAP reporting, Broadcom reports certain financial measures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release. Comments made during today's call will primarily refer to our non-GAAP financial results. I will now turn the call over to Hock.\n\n**Hock Tan** (President, CEO &amp; Director)\nThank you, Ji, and thank you, everyone, for joining us today. In our fiscal Q3 2025, total revenue was a record $16 billion, up 22% year-on-year. Revenue growth was driven by better-than-expected strength in AI semiconductors and our continued growth in VMware. Q3 consolidated adjusted EBITDA was a record $10.7 billion, up 30% year-on-year. Looking beyond what we're just reporting this quarter, with robust demand from AI, bookings were extremely strong, and our current consolidated backlog for the company hit a record of $110 billion. Q3 semiconductor revenue was $9.2 billion, as year-on-year growth accelerated to 26% year-on-year. This accelerated growth was driven by AI semiconductor revenue of $5.2 billion, which was up 63% year-on-year, and extended the trajectory of robust growth to 10 consecutive quarters. Let me give you more color on our XPU business, which accelerated to 65% of our AI revenue this quarter.\n\n**Hock Tan** (President, CEO &amp; Director)\nDemand for custom AI accelerators from our three customers continued to grow, as each of them journeys at their own pace towards compute self-sufficiency. Progressively, we continue to gain share with these customers. Further to these three customers, as we had previously mentioned, we have been working with other prospects on their own AI accelerators. Last quarter, one of these prospects released production orders to Broadcom, and we have accordingly characterized them as a qualified customer for XPUs and, in fact, have secured over $10 billion of orders of AI racks based on our XPUs. Reflecting this, we now expect the outlook for our fiscal 2026 AI revenue to improve significantly from what we had indicated last quarter. Turning to AI networking, demand continued to be strong because networking is becoming critical as LLMs continue to evolve in intelligence, and compute clusters have to grow bigger.\n\n**Hock Tan** (President, CEO &amp; Director)\nThe network is the computer, and our customers are facing challenges as they scale to clusters beyond 100,000 compute nodes. For instance, scale-up, which we all know about, is a difficult challenge when you're trying to create substantial bandwidth to share memory across multiple GPUs or XPUs within a rack. Today's AI rack scales up a mere 72 GPUs at 28.8 terabits per second bandwidth using a proprietary NVLink. On the other hand, earlier this year, we have launched Tomahawk 5 with Open Ethernet, which can scale up 512 compute nodes for customers using XPUs. Moving on to scaling out across racks, today the current architecture using 51.2 terabits per second requires three tiers of networking switches. In June, we launched Tomahawk 6 and our Ethernet-based 102 terabit per second switch, which flattens the network to two tiers, resulting in lower latency, much less power.\n\n**Hock Tan** (President, CEO &amp; Director)\nWhen you scale to clusters beyond a single data center footprint, you now need to scale computing across data centers. Over the past two years, we have deployed our Jericho 3 Ethernet router with hyperscale customers to just do this. Today, we have launched our next-generation Jericho 4 Ethernet fabric router with 51.2 terabit per second deep buffering intelligence, intelligent congestion control to handle clusters beyond 200,000 compute nodes crossing multiple data centers. We know the biggest challenge to deploying larger clusters of compute for generative AI will be in networking. For the past 20 years, what Broadcom has developed for Ethernet networking is entirely applicable to the challenges of scale-up, scale-out, and scale across in generative AI. Turning to our forecast, as I mentioned earlier, we continue to make steady progress in growing our AI revenue.\n\n**Hock Tan** (President, CEO &amp; Director)\nFor Q4 2025, we forecast AI semiconductor revenue to be approximately $6.2 billion, up 66% year-on-year. Now, turning to non-AI semiconductors, demand continues to be slow to recover, and Q3 revenue of $4 billion was flat sequentially. While broadband showed strong sequential growth, enterprise networking and server storage were down sequentially. Wireless and industrial were flat quarter on quarter, as we expect. In contrast, in Q4, driven by seasonality, we forecast non-AI semiconductor revenue to grow low double digits sequentially to approximately $4.6 billion. Broadband, server storage, and wireless are expected to improve, while enterprise networking remains down quarter on quarter. Now, let me talk about our infrastructure software segment. Q3 infrastructure software revenue of $6.8 billion was up 17% year-on-year, above our outlook of $6.7 billion as bookings continued to be strong during the quarter. We booked, in fact, total contract value over $8.4 billion during Q3.\n\n**Hock Tan** (President, CEO &amp; Director)\nHere is what I'm most excited about. After two years of engineering development by over 5,000 developers, we delivered on a promise when we acquired VMware. We released VMware Cloud Foundation 9.0, a fully integrated cloud platform which can be deployed by enterprise customers on-prem or carried to the cloud. It enables enterprises to run any application workload, including AI workloads, on virtual machines and on modern containers. This provides the real alternative to public cloud. In Q4, we expect infrastructure software revenue to be approximately $6.7 billion, up 15% year-on-year. In summary, continued strength in AI and VMware will drive our guidance for Q4 consolidated revenue to approximately $17.4 billion, up 24% year-on-year. We expect Q4 adjusted EBITDA to be 67% of revenue. With that, let me turn the call over to Kirsten.\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nThank you, Hock. Let me now provide additional detail on our Q3 financial performance. Consolidated revenue was a record $16 billion for the quarter, up 22% from a year ago. Gross margin was 78.4% of revenue in the quarter, better than we originally guided on higher software revenues and product mix within semiconductors. Consolidated operating expenses were $2 billion, of which $1.5 billion was research and development. Q3 operating income was a record $10.5 billion, up 32% from a year ago. On a sequential basis, even as gross margin was down 100 basis points on revenue mix, operating margin increased 20 basis points sequentially to 65.5% on operating leverage. Adjusted EBITDA of $10.7 billion, or 67% of revenue, was above our guidance of 66%. This figure excludes $142 million of depreciation. Now a review of the P&L for our two segments, starting with semiconductors.\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nRevenue for our semiconductor solution segment was $9.2 billion, with growth accelerating to 26% year-on-year, driven by AI. Semiconductor revenue represented 57% of total revenue in the quarter. Gross margin for our semiconductor solution segment was approximately 67%, down 30 basis points year-on-year on product mix. Operating expenses increased 9% year-on-year to $951 million on increased investment in R&D for leading-edge AI semiconductors. Semiconductor operating margin of 57% was up 130 basis points year-on-year and flat sequentially. Now moving on to infrastructure software. Revenue for infrastructure software of $6.8 billion was up 17% year-on-year and represented 43% of revenue. Gross margin for infrastructure software was 93% in the quarter compared to 90% a year ago. Operating expenses were $1.1 billion in the quarter, resulting in infrastructure software operating margin of approximately 77%. This compares to operating margin of 67% a year ago, reflecting the completion of the integration of VMware.\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nMoving on to cash flow. Free cash flow in the quarter was $7 billion and represented 44% of revenue. We spent $142 million on capital expenditures. Day sales outstanding were 37 days in the third quarter compared to 32 days a year ago. We ended the third quarter with inventory of $2.2 billion, up 8% sequentially in anticipation of revenue growth next quarter. Our days of inventory on hand were 66 days in Q3 compared to 69 days in Q2, as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the third quarter with $10.7 billion of cash and $66.3 billion of gross principal debt. The weighted average coupon rate and years to maturity of our $65.8 billion in fixed-rate debt is 3.9% and 6.9 years, respectively.\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nThe weighted average interest rate and years to maturity of our $500 million in floating rate debt is 4.7% and 0.2 years, respectively. Turning to capital allocation, in Q3, we paid stockholders $2.8 billion of cash dividends based on a quarterly common stock cash dividend of $0.59 per share. In Q4, we expect the non-GAAP diluted share count to be approximately 4.97 billion shares, excluding the potential impact of any share repurchases. Now moving to guidance, our guidance for Q4 is for consolidated revenue of $17.4 billion, up 24% year-on-year. We forecast semiconductor revenue of approximately $10.7 billion, up 30% year-on-year. Within this, we expect Q4 AI semiconductor revenue of $6.2 billion, up 66% year-on-year. We expect infrastructure software revenue of approximately $6.7 billion, up 15% year-on-year.\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nFor your modeling purposes, we expect Q4 consolidated gross margin to be down approximately 70 basis points sequentially, primarily reflecting a higher mix of XPUs and also wireless revenue. As a reminder, consolidated gross margins through the year will be impacted by the revenue mix of infrastructure software and semiconductors and product mix within semiconductors. We expect Q4 adjusted EBITDA to be 67%. We expect the non-GAAP tax rate for Q4 and fiscal year 2025 to remain at 14%. I will now pass the call back to Hock for some more exciting news.\n\n**Hock Tan** (President, CEO &amp; Director)\nI don't know about exciting, Kirsten, but I do. I thought before we move to questions, I should share an update. The board and I have agreed that I will continue as the CEO of Broadcom through 2030, at least. These are exciting times for Broadcom, and I'm very enthusiastic to continue to drive value for our shareholders. Operator, please open up the call for questions.\n\n**Operator**\nThank you. To ask a question, you will need to press *11 on your telephone. To withdraw your question, press *11 again. Due to time restraints, we ask that you please limit yourself to one question. Please stand by while we compile the Q&A roster. Our first question will come from the line of Ross Seymore with Deutsche Bank. Your line is open.\n\n**Ross Seymore** (Managing Director)\nHi, guys. Thanks for having me ask the question. Hock, thank you for sticking around for a few more years. I just wanted to talk about the AI business and specifically the XPU. When you said you're going to grow significantly faster than what you had thought a quarter ago, what's changed? Is it just the impressive prospect moving to a customer definition, that $10 billion backlog that you mentioned? Is it stronger demand across the existing three customers? Any detail on that would be helpful.\n\n**Hock Tan** (President, CEO &amp; Director)\nI think it's both, Ross, but to a large extent, it's the fourth customer that we now add on to our roster, which we will ship pretty strongly in 2026, beginning 2026, I should say. It's a combination of increasing volumes from our existing three customers, and we move through that very progressively and steadily. The addition of a fourth customer with immediate and fairly substantial demand really changes our thinking of what 2026 would be starting to look like.\n\n**Ross Seymore** (Managing Director)\nThank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Harlan Sur with JPMorgan. Your line is open.\n\n**Harlan Sur** (Executive Director - Equity Research)\nHi, good afternoon. Congratulations on a well-executed quarter and strong free cash flow. I know everybody's going to ask a lot of questions on AI, Hock. I'm going to ask about the non-AI semi-business. If I look at your guidance for Q4, it looks like the non-AI semi-business is going to be down about 7%, 8% year-over-year in fiscal 2025 if you hit the midpoint of the Q4 guidance. Good news is that the negative year-over-year trends have been improving through the year. In fact, I think you guys are going to be positive year-over-year in the fourth quarter. You've characterized it as relatively close to the cyclical bottom, relatively slow to recover. However, we have seen some green shoots of positivity, right? Broadband, server storage, enterprise networking, you're still driving the DOCSIS 4 upgrade in broadband cable. You've got next-gen PON upgrades in China and the U.S.\n\n**Harlan Sur** (Executive Director - Equity Research)\nin front of you. Enterprise spending on network upgrades is accelerating. Near-term, from the cyclical bottom, how should we think about the magnitude of the cyclical upturn? Given your 30 to 40-week lead times, are you seeing continued order improvements in the non-AI segment, which would point you to continued cyclical recovery into next fiscal year?\n\n**Hock Tan** (President, CEO &amp; Director)\nIf you take a look at that non-AI segment, you're right. From a year-on-year Q4 guidance, we are actually up, as you say, slightly, a couple, 1% or 2% from a year ago. It's not much really to shout about at this point. The big issue is the puts and takes. The puts and takes and the bottom line to all this is, other than seasonality that we perceive, if you look at it short term, we are looking year-on-year, but looking sequentially, we see in things like wireless, and we even start to see some seasonality in server storage these days. It kind of all washes out so far. The only consistent trend we've seen over the last three quarters that is moving up strongly is broadband.\n\n**Hock Tan** (President, CEO &amp; Director)\nNothing else, if you look at it from a cyclical point of view, seems to be able to sustain an uptrend so far. I don't think it's getting, but as a whole, they're not getting worse, as you pointed out, Harlan. They're not showing a V-shaped recovery as a whole that we would like to see and expect to see in cyclical semiconductor cycles. The only thing that gives us some hope is broadband at this point, and it is recovering very strongly. It was the business that was most impacted in the sharp downturn of 2024 and early 2025. One takes that with a grain of salt. The best answer for you is non-AI semiconductor is kind of slow to recover, as I said. Q4 year-on-year is up maybe low single digits is the best way to describe it at this point.\n\n**Hock Tan** (President, CEO &amp; Director)\nI'm expecting to see more of a U-shaped recovery in non-AI, and perhaps by mid 2026, late 2026, we start to see some meaningful recovery. As of right now, not clear.\n\n**Harlan Sur** (Executive Director - Equity Research)\nAre you starting to see that in your order trend, in your order book, just because your lead times are like 40 weeks, right?\n\n**Hock Tan** (President, CEO &amp; Director)\nWe have been quick before. The bookings are up, and they're up year-on-year in excess of 20%. Nothing like what AI bookings look like, but 23% is still pretty good, right?\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Vivek Arya with Bank of America. Your line is open.\n\n**Vivek Arya** (Managing Director)\nThanks for taking my question, and best wishes, Hock, for the next part of your tenure. My question is on, you know, if you could help us quantify what is the new fiscal 2026 AI guidance, because I think the last call you mentioned, fiscal 2026 could grow at the 60% growth rate. What is the updated number? Is it 60% plus the $10 billion that you mentioned? Related to that, do you expect the custom versus networking mix to stay broadly what it has been this past year or evolve more towards custom? Any quantification on this, you know, networking versus custom mix would be really helpful for fiscal 2026.\n\n**Hock Tan** (President, CEO &amp; Director)\nOkay, let's answer the first part first. If I could be so bold as to suggest to you, when I last quarter, when I said, hey, the trend of growth of 2026 will mirror that of 2025, which is 50, 60% year-on-year. That's really all I said. I didn't quote, but of course, it comes up 50, 60% because that's what 2025 is. All I'm saying, if you want to put another way of looking at what I'm saying, which is perhaps more accurate, is we're seeing the growth rate accelerate as opposed to just remain steady at that 50, 60%. We are expecting and seeing 2026 to accelerate more than the growth rate we see in 2025. I know you love me to throw in a number at you, but you know what? We're not supposed to be giving you a forecast for 2026.\n\n**Hock Tan** (President, CEO &amp; Director)\nThe best way to describe it, it will be fairly material improvement.\n\n**Vivek Arya** (Managing Director)\nThe networking versus custom?\n\n**Hock Tan** (President, CEO &amp; Director)\nGood point. Thanks for reminding me. As we see, a big part of this driver of growth will be XPUs. At the risk of repeating what I said in my remarks, it comes from the fact that we continue to gain share at our three original customers. They have to, they're on their journey, and each passing generation, they go more to XPUs. We are gaining share from these three. We now have the benefit of an additional fourth significant customer. I should say fourth and very significant customer. That combination will mean more XPUs. As I said, as the ratio, as we create more and more XPUs among four guys, the networking, we get the networking with these four guys, but now the mix of networking from outside these four guys will now be a smaller, be diluted, be a smaller share.\n\n**Hock Tan** (President, CEO &amp; Director)\nI expect actually networking percentage of the pool to be a declining percentage going into 2026.\n\n**Vivek Arya** (Managing Director)\nThank you, Hock.\n\n**Operator**\nOne moment for our next question. That will come from the line of Stacy Rasgon with Bernstein Research. Your line is open.\n\n**Stacy Rasgon** (MD &amp; Senior Analyst)\nHi, guys. Thanks for taking my question. I was wondering if you could help me parse out this $110 billion backlog. Did I hear that number right? Could you give us some color on the makeup of that? How far out does that go? How much of that $110 billion is AI versus non-AI versus software?\n\n**Hock Tan** (President, CEO &amp; Director)\nStacy, we generally don't break our backlog. I'm just giving you a total number to give you a sense of how strong the business is as a whole for the company. It's largely driven by AI in terms of growth. Software continues to add on a steady basis, and non-AI, as I indicated, has grown double digits. Nothing compared to AI, which has grown very strongly. Give you a sense, perhaps fully 50% of it at least is semiconductors.\n\n**Stacy Rasgon** (MD &amp; Senior Analyst)\nOkay. It's fair to say that of that semiconductor piece, it's going to be much more AI than non-AI.\n\n**Hock Tan** (President, CEO &amp; Director)\nRight.\n\n**Stacy Rasgon** (MD &amp; Senior Analyst)\nYeah, got it. That's helpful. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Ben Reitzes with Melius. Your line is open.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nHey, guys. Thanks a lot. I appreciate it. Hock, congrats on being able to guide to the AI revenue well above 60% for next year. I wanted to be a little greedy and ask you about maybe 2027 and the other three customers or so. How's the dialogue going beyond these four customers? In the past, you've talked about having seven. Now we've added a fourth to production, and then there were three. Are you hearing from others? How's the trend going maybe with the other three, maybe beyond the 2026, into 2027 and beyond? How's that momentum, you think, going to shape up? Thanks so much.\n\n**Hock Tan** (President, CEO &amp; Director)\nBen, you are definitely greedy and definitely overthinking this for me. Thank you. That's asking for subjective qualification. Frankly, I don't want to give that. I'm not comfortable giving that because sometimes we stumble into production in timeframes that are fairly unexpected, surprisingly. Equally, it could get delayed. I'd rather not give you any more color on prospects than to tell you these prospects are real prospects and continue to be very closely engaged towards developing each of their own XPUs with every intent of going into substantial production, like the four we have today who are custom.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nYeah, you still think that million units by, you know, goal for these seven, though, is still intact?\n\n**Hock Tan** (President, CEO &amp; Director)\nOh, for the three, I said. Now they're four. That's still in only for the customers. For the prospects, no comment. I'm not positioned to judge on that. For our three, four customers now, yes.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nAll right. Thanks a lot. Congrats.\n\n**Operator**\nOne moment for our next question. That will come from the line of Jim Schneider with Goldman Sachs. Your line is open.\n\n**Jim Schneider** (Senior Equity Analyst)\nGood afternoon. Thanks for taking my question. Hock, I was wondering if you could give us a little bit more color, not necessarily on the prospects which you still have in the pipeline, but how you view the universe of additional prospects beyond the seven customers and prospects you've already identified. Do you still see there being additional prospects that would be worthy of a custom chip? I know you've been relatively circumspect in terms of the number of customers that are out there and the volume that they can provide and selective in terms of the opportunities you're interested in. Maybe frame for us the additional prospects as you see them beyond the seven. Thank you.\n\n**Hock Tan** (President, CEO &amp; Director)\nThat's a very good question. Let me answer it in a fairly broader basis. As I said before, and perhaps repeat a bit more, we look at this market in two broad segments. One is simply the guys, the parties, the customers who develop their own LLM. The rest of the other market I consider is collectively lumped as enterprise. That is, markets that run, that will run AI workloads for enterprise, whether it's on-prem or GPU, XPU, or whatever as a service, the enterprise. We don't address that market, to be honest. We don't. That's because that's a hard market for us to address, and we're not set up to address that. We instead address this LLM market.\n\n**Hock Tan** (President, CEO &amp; Director)\nAs I said many times before, it's a very few narrow markets, few players driving frontier models on a consistent, on a very accelerated trend towards superintelligence for one, plagiarizing the term of someone else, but you know what I mean. There are the other guys who would invest, who need to invest a lot initially, my view, on training, training of ever larger and larger clusters of ever more capable accelerators. Also, as for these guys, they got to be accountable to shareholders or accountable to being able to create cash flows that can sustain their path. They start to also invest in inference in a massive way to monetize their models. These are the players we work with. These are individually people or players who spend a lot of money on a lot of compute capacity. It's just that there are only so few of them.\n\n**Hock Tan** (President, CEO &amp; Director)\nI have indicated, identified seven, four of which now are customers, three continue to be prospects we engage with. We're very careful, I should say, shouldn't use the word picky, careful who qualifies under them. I indicated it. They are building a platform or have a platform, and are investing very much on leading LLMs models. We have seven, and I think that's about it. We may see one more, perhaps, as a prospect. Again, we are very thoughtful and careful about even making that qualification. Right now, for sure, we have seven. That's for now, it's pretty much what we have.\n\n**Jim Schneider** (Senior Equity Analyst)\nThank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Tom O'Malley with Barclays. Your line is open.\n\n**Thomas O'Malley** (Director - Equity Research)\nHey, guys. Thanks for taking my question and congrats on the really good results. I wanted to ask on the Jericho 4 commentary. NVIDIA talked about the XGS switch and now is talking about scale across. You're talking about Jericho 4. It sounds like this market is really starting to develop. Maybe you could talk about when you see material uplift in revenue there and why it's important to start thinking about those types of switches as we move more towards inferencing. Thank you, Hock.\n\n**Hock Tan** (President, CEO &amp; Director)\nGreat. Thanks for picking that up. Yes, scale across is the new term now, right, thrown in. There's scale-up, which is within a rack, you know, within a rack, which is computing within the rack. Scale-out, doing across racks, but within a data center. Now when you get to clusters that are, I'm not 100% sure where the cutoff is, but say above 100,000 GPU or XPUs, that's you're talking about probably many cases because of limitation of power shell that the data center that you don't do one single data center footprint site to hand to sit with over 100,000 of those XPUs in one site. Power may not be easily available. Land may not be. It's cumbersome. Many, some outcomes, most of all our customers now we see create multiple data center sites close at hand, not far away, within range 100 kilometers.\n\n**Hock Tan** (President, CEO &amp; Director)\nIt's kind of the level, but be able to then put in homogeneous XPUs or GPUs in this multiple location, three or four, and network across them so that they behave like, in fact, a single cluster. That's the coolest part. That technology, which requires, because of distance, deep buffering, very intelligent congestion control, is technology that exists for many, many years in the likes of the telcos of AT&T and Verizon doing network routing, except this is for even somewhat more trickier workload, but the same. We've been shipping that to a couple of hyperscalers over the last two years as Jericho 3. As the scale of these clusters and the bandwidth required for AI training extends, we now launched this Jericho 4, 51 terabit per second to handle more bandwidth. Same technology we have tested, proven for the last 10, 20 years. Nothing new.\n\n**Hock Tan** (President, CEO &amp; Director)\nDon't need to create something new for that. It's running in Ethernet and very proven, very stable. As I said, last two years under Jericho 3, which runs 256 connections on no compute nodes, we've been selling to a couple of our hyperscale customers.\n\n**Operator**\nOne moment for our next question. That will come from the line of Carl Ackerman with BNP Paribas. Your line is open.\n\n**Karl Ackerman** (MD - Equity Research, Semiconductors &amp; IT Hardware)\nYeah, thank you. Hock, have you completely converted your top 10,000 accounts from vSphere to the entire VMware Cloud Foundation virtualization stack? I ask because I think last quarter, 87% of accounts had adopted that, and that's certainly a marked increase versus less than 10% of those customers who bought the entire suite before the deal. As you address that, what interest level are you seeing with the longer tail of enterprise customers adopting VCF? Are you seeing tangible cross-selling benefits of your merchant semiconductor storage and networking business as those customers adopt VMware? Thank you.\n\n**Hock Tan** (President, CEO &amp; Director)\nOkay. To answer your first part of the question, yeah, pretty much virtually, way over 90% has bought VCF. Now, I'm careful about the choice of words. Because we have sold them on it and they've bought licenses to deploy it, it doesn't mean they're fully deployed. Here comes the other part of our work, which is to take these 10,000 customers or a big chunk of them who have taken, who have bought the vision of a private cloud on-prem and working with them to enable them to deploy it and operate it successfully on their infrastructure on-prem. That's the hard work over the next two years that we see happening. As we do it, we see expansion across their IT footprint on VCF, private cloud running on their data set within their data center. That's the key part of it. We see that continuing.\n\n**Hock Tan** (President, CEO &amp; Director)\nThat's the second phase of my VMware story. The first phase is convince these people to convert from perpetual subscription and so doing purchase VCF. The second phase now is make that purchase they made on VCF create the value they look for in private cloud on their premise, on their IT data center. That's what's happening. That will sustain for quite a while because on top of that, we will start selling advanced services, security, disaster recovery, even AI, running AI workloads on it. All that is very exciting. Your second question is, is that able to enable me to sell more hardware? No, it's quite independent. In fact, as they virtualize their data centers, we consciously accept the fact that we are commoditizing the underlying hardware in the data center, commoditizing servers, commoditizing storage, commoditizing even networking. That's fine.\n\n**Hock Tan** (President, CEO &amp; Director)\nBy so commoditizing, we're actually reducing the cost of investments in hardware in data centers for enterprises. Now, beyond the largest 10,000, are we seeing a lot of success? We're seeing some. Again, two reasons why we do not expect it to be necessarily successful. One is the value, the TCO, as they call it, that comes from it will be much less. The more important thing is the skill sets that need to not just deploy that you can get services and ourselves to help them, but to keep operating it might not be something that they can take on. We shall see. This is an area we're still learning, and it'll be interesting to see. VMware has 300,000 customers. We see the top 10,000 as making for as being people where it makes a lot of sense, derive a lot of value in deploying private cloud using VCF.\n\n**Hock Tan** (President, CEO &amp; Director)\nWe now are looking at whether the next 20,000, 30,000 mid-sized companies see the same way. Stay tuned. I'll let you know.\n\n**Karl Ackerman** (MD - Equity Research, Semiconductors &amp; IT Hardware)\nVery clear. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of CJ Muse with Cantor Fitzgerald. Your line is open.\n\n**CJ Muse** (Senior Managing Director)\nYeah, good afternoon. Thanks for taking the question. I was hoping to focus on gross margins. I understand that they are down 70 bps, particularly with software lower sequentially and greater contributions from wireless and XPU. To hit that 77.7%, I either have to model semiconductor margins flat, which I would think would be lower, or software gross margins to 95%, up 200 bps. Can you help me better understand the moving parts there to allow only a 70 bp drop?\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nYeah. I mean, the TPUs will be going up along with wireless, as I said on the call. Software revenue will be coming up just a bit as well.\n\n**CJ Muse** (Senior Managing Director)\nYou mean TPUs?\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nXPUs, yes.\n\n**Operator**\nOne last question.\n\n**Kirsten Spears** (CFO &amp; Chief Accounting Officer)\nWireless is typically our heaviest quarter, right, of the year for wireless. You have wireless and TPUs with generally lower margins, right, and then our software revenue coming up.\n\n**Operator**\nOne moment for our next question. That will come from the line of Joe Moore with Morgan Stanley. Your line is open.\n\n**Joseph Moore** (Managing Director)\nGreat. Thank you. In terms of the fourth customer, I think you've talked in the past about potential customers four and five were more hyperscale, and six and seven were more like, you know, the LLM makers themselves. Can you give us a sense for if you could help us categorize that? If not, that's fine. The $10 billion of orders, can you give us a timeframe on that? Thank you.\n\n**Hock Tan** (President, CEO &amp; Director)\nOkay. Yeah. No, it's towards the end of the day, all seven do LLMs. Not all of them have a current, have the huge platform we're talking about. One could imagine eventually all of them will have or create a platform. It's hard to differentiate the two. Coming on the second and third delivery of the $10 billion, I'll probably be in around, I would say, the second half of our fiscal year 2026. I would say, to be even more precise, likely to be Q3 of our fiscal 2026.\n\n**Joseph Moore** (Managing Director)\nQ3, it starts, or Q3, what timeframe does it take to deploy $10 billion?\n\n**Hock Tan** (President, CEO &amp; Director)\nIt starts and ends in Q3.\n\n**Joseph Moore** (Managing Director)\nOkay. All right. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Joshua Buchhalter with TD Cowan. Your line is open.\n\n**Joshua Buchalter** (Director - Equity Research)\nHey, guys. Thank you for taking my question and congrats on the results. I was hoping you could provide some comments on momentum for scale-up Ethernet and how it compares with, you know, UA Link and PCIe solutions out there. How big of a, how meaningful is it to have the Tomahawk Ultras product out there with a lower latency? How meaningful do you think the scale-up Ethernet opportunity could be over the next year as we think about your AI networking business? Thank you.\n\n**Hock Tan** (President, CEO &amp; Director)\nThat's a good question. We ourselves are thinking about that too, because to begin with, Ethernet, our Ethernet solutions are very disaggregated from the AI accelerators anybody does. It's separate. We treat them as separate. Even though you're right, the network is the computer. We have always believed that Ethernet is open source. Anybody should be able to have choices, and we keep it separate from our XPU. The truth of the matter is, for our customers who use the XPU, we develop and we optimize our networking switches and other components that relate to being able to network signals in any clusters hand in hand with it. In fact, all these XPUs have developed with interface that handles Ethernet, very, very much so. In a way, with XPUs, with our customers, we are openly enabling Ethernet as a networking protocol of choice, very, very openly.\n\n**Hock Tan** (President, CEO &amp; Director)\nIt need not be our Ethernet switches. It could be any other, but somebody else's Ethernet switcher that does it. It just happens to be we're in the lead in this business, so we get that. Beyond it, especially when it comes to a closed system of GPUs, we see less of it, except in the hyperscalers, where the hyperscalers are able to architect the GPUs clusters very separate from the networking side, especially in scale-out. In which case, on those hyperscalers, we sell a lot of these Ethernet switches that do scaling out. We suspect when it goes to scaling across now, even more Ethernet that are disaggregated from the GPUs that are in the place. As far as XPUs are concerned, for sure, it's all Ethernet.\n\n**Joshua Buchalter** (Director - Equity Research)\nThank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Christopher Rolland with Susquehanna. Your line is open.\n\n**Christopher Rolland** (Senior Equity Analyst - Semiconducters)\nThank you for the question and congrats on the contract extension, Hock. My questions are about competition, both on the networking side and the ASIC side. You kind of answered some of that, I think, in the last question. Do you view any competition on the ASIC side, particularly from U.S. or Asian vendors, or do you think this is decreasing? On the networking side, do you think UA Link or PCIe even has a chance of displacing SUE in 2027 when it's expected to ramp? Thanks.\n\n**Hock Tan** (President, CEO &amp; Director)\nThank you for embracing SUE. Thank you. I didn't expect that to come out, and I appreciate that. You know I'm biased, to be honest. It's so obvious I can't help but being biased because Ethernet is well proven. Ethernet is so known to the engineers, the architects that sit in all these hyperscalers developing, designing AI data center, data AI infrastructure. It's the logical thing for them to use. They are using it, and they are focusing on it. The development of separate individualized protocols, frankly, it's beyond my imagination why they bought it. Ethernet is there. It's been well used. It's proven it can keep going up. The only thing people talk about is perhaps latency, especially in scaling up, hence the emergence of NVLink. Even then, as I indicated, it's not hard for us, and we are not the only ones who can do that.\n\n**Hock Tan** (President, CEO &amp; Director)\nQuite a few others in Ethernet can do it in the switches. You can just tweak the switches to make the latency super good, better than NVLink, better than Infiniband, less than 250 nanoseconds easily. That's what we did. It's not that hard. Perhaps I say that because we have been doing it as the Ethernet has been around the last 25 years at length. It's there, the technology. There's no need to go and create some cooked-up protocols that now you have to bring people around. Ethernet is the way to go. There's plenty of competition too because it's an open-source system. I think Ethernet is the way to go. For sure, in developing XPUs for our customers, all these XPUs with the agreement of customers are made compatible interface with Ethernet and not some fancy other interface that one has to keep going as bandwidth increases.\n\n**Hock Tan** (President, CEO &amp; Director)\nI assure you, we have competition, which is one of the reasons why the hyperscalers like Ethernet. It's not just us. They can find somebody else if for whatever reason they don't like us, and we're open to that. It's always good to do that. It's an open-source system, and there are players in that market, not any closed system. Switching on to XPU competition, we hear about competition and all that. It's just that it's a competition that's an area that we always see competition. Our only way to secure our position is we try to out-invest and out-innovate anybody else in this game. We have been fortunate to be the first one creating this XPU model of ASICs on silicon. We also have been fortunate to be probably one of the largest IP developers of semiconductor out there.\n\n**Hock Tan** (President, CEO &amp; Director)\nThings like serializer, deserializer sets, SERDES, being able to develop the best packaging, being able to design things that are very low power. We just have to keep investing in it, which we do, to outrun the competition in this space. I believe we're doing a fairly decent job of doing it at this point.\n\n**Christopher Rolland** (Senior Equity Analyst - Semiconducters)\nVery clear. Thanks, Hock.\n\n**Hock Tan** (President, CEO &amp; Director)\nSure.\n\n**Operator**\nThank you. We do have time for one last question. That will come from the line of Harsh Kumar with Piper Sandler. Your line is open.\n\n**Harsh Kumar** (MD &amp; Senior Research Analyst)\nHey, guys. Thanks for squeezing me in, Hock. Congratulations on all the exciting AI metrics, and thanks for everything you do for Broadcom and sticking around. Hock, my question is, you've got three to four existing customers that are ramping. As the data centers for AI clusters get bigger and bigger, it makes sense to have differentiation, efficiency, et cetera. Therefore, the case for XPUs. Why should I not think that your XPU share at these three or four customers that are existing will be bigger than the GPU share in the longer term?\n\n**Hock Tan** (President, CEO &amp; Director)\nIt will be. It's a logical conclusion. Hass, you're correct. We are seeing that step by step. As I say, it's a journey. It's a multi-year journey because it's multigenerational, because these XPUs don't stay still either. I'm doing multiple versions, at least two versions, two-generational versions for each of these customers we have. With each newer generation, they increase the consumption, the usage of the XPU. As they gain confidence, as the model improves, they deploy it even more. That's the logical trend that XPUs will keep in these few customers of ours, where they are successfully deployed and their software stabilizes, the software stack, the library that sits on these chips stabilizes and proves itself out. They will have the confidence to keep using a higher and higher % of their compute footprint in their own XPUs, for sure. We see that. That's why I say we progressively gain share.\n\n**Harsh Kumar** (MD &amp; Senior Research Analyst)\nThank you, Hock.\n\n**Operator**\nThank you. I would now like to turn the call back over to Ji Yoo, Head of Investor Relations, for any closing remarks.\n\n**Ji Yoo** (Investor Relations)\nThank you, Cheri. This quarter, Broadcom will be presenting at the Goldman Sachs Communicopia and Technology Conference on Tuesday, September 9, in San Francisco, and at the JPMorgan US All-Stars Conference on Tuesday, September 16, in London. Broadcom currently plans to report its earnings for the fourth quarter and fiscal year 2025 after close of market on Thursday, December 11, 2025. A public webcast of Broadcom's earnings conference call will follow at 2:00 P.M. Pacific. That will conclude our earnings call today. Thank you all for joining. Cheri, you may end the call.\n\n**Operator**\nThis concludes today's program. Thank you all for participating. You may now.",
        "fetched_at": "2026-02-04T16:13:24.832Z"
      },
      {
        "ticker": "AVGO",
        "title": "Yahoo Finance",
        "published_date": "Jun 5, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/AVGO/earnings/AVGO-Q2-2025-earnings_call-325316.html",
        "content": "**Operator**\nWelcome to Broadcom's second quarter fiscal year 2025 financial results conference call. At this time, for opening remarks and introductions, I would like to turn the call over to Goo Gai, Head of Investor Relations of Broadcom.\n\n**Jihyung Yoo** (Head of Investor Relations)\nThank you, Operator, and good afternoon, everyone. Joining me on today's call are Hock Tan, President and CEO; Kirsten Spears, Chief Financial Officer; and Charlie Kawwas, President, Semiconductor Solutions Group. Broadcom distributed a press release and financial tables after the market closed, describing our financial performance for the second quarter of fiscal year 2025. If you did not receive a copy, you may obtain the information from the investor section of Broadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the call can be accessed for one year through the investor section of Broadcom's website. During the prepared comments, Hock and Kirsten will be providing details of our second quarter fiscal year 2025 results, guidance for our third quarter of fiscal year 2025, as well as commentary regarding the business environment. We'll take questions after the end of our prepared comments.\n\n**Jihyung Yoo** (Head of Investor Relations)\nPlease refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our actual results to differ materially from the forward-looking statements made on this call. In addition to U.S. GAAP reporting, Broadcom reports certain financial measures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release. Comments made during today's call will primarily refer to our non-GAAP financial results. I will now turn the call over to Hock.\n\n**Hock Tan** (CEO)\nThank you, Goo, and thank you, everyone, for joining us today. In our fiscal Q2 2025, total revenue was a record $15 billion, up 20% year on year. This 20% year on year growth was all organic, as Q2 last year was the first full quarter with VMware. Now, revenue was driven by continued strength in AI semiconductors and the momentum we have achieved in VMware. Now, reflecting excellent operating leverage, Q2 consolidated adjusted EBITDA was $10 billion, up 35% year on year. Now, let me provide more color. Q2 semiconductor revenue was $8.4 billion, with growth accelerating to 17% year on year, up from 11% in Q1. And of course, driving this growth was AI semiconductor revenue of over $4.4 billion, which is up 46% year on year and continues the trajectory of nine consecutive quarters of strong growth.\n\n**Hock Tan** (CEO)\nWithin this, custom AI accelerators grew double digits year on year, while AI networking grew over 170% year on year. AI networking, which is based on Ethernet, was robust and represented 40% of our AI revenue. As a standards-based open protocol, Ethernet enables one single fabric for both scale-out and scale-up, and remains the preferred choice by our hyperscale customers. Our networking portfolio of Tomahawk switches, Jericho routers, and NICs is what's driving our success within AI clusters in hyperscalers. The momentum continues with our breakthrough Tomahawk 6 switch just announced this week. This represents the next generation 102.4 terabits per second switch capacity. Tomahawk 6 enables clusters of more than 100,000 AI accelerators to be deployed in just two tiers instead of three.\n\n**Hock Tan** (CEO)\nThis flattening of the AI cluster is huge because it enables much better performance in training next generation frontier models through a lower latency, higher bandwidth, and lower power. Turning to XPUs, or custom accelerators, we continue to make excellent progress on the multi-year journey of enabling our three customers and four prospects to deploy custom AI accelerators. As we had articulated over six months ago, we eventually expect at least three customers to each deploy 1 million AI accelerator clusters in 2027, largely for training their frontier models. We forecast and continue to do so a significant percentage of these deployments to be custom XPUs. These partners are still unwavering in their plan to invest despite this certain economic environment. In fact, what we've seen recently is that they are doubling down on inference in order to monetize their platforms.\n\n**Hock Tan** (CEO)\nReflecting this, we may actually see an acceleration of XPU demand into the back half of 2026 to meet urgent demand for inference on top of the demand we have indicated from training. Accordingly, we do anticipate now our fiscal 2025 growth rate of AI semiconductor revenue to sustain into fiscal 2026. Turning to our Q3 outlook, as we continue our current trajectory of growth, we forecast AI semiconductor revenue to be $5.1 billion, up 60% year on year, which would be the 10th consecutive quarter of growth. Turning to non-AI semiconductors in Q2, revenue of $4 billion was down 5% year on year. Non-AI semiconductor revenue is close to the bottom and has been relatively slow to recover. There are bright spots. In Q2, broadband, enterprise networking, and server storage revenues were up sequentially.\n\n**Hock Tan** (CEO)\nHowever, industrial was down, and as expected, wireless was also down due to seasonality. In Q3, we expect enterprise networking and broadband to continue to grow sequentially, but server storage, wireless, and industrial are expected to be largely flat. Overall, we forecast non-AI semiconductor revenue to stay around $4 billion. Now, let me talk about our infrastructure software segment. Q2 infrastructure software revenue of $6.6 billion was up 25% year on year, above our outlook of $6.5 billion. As we have said before, this growth reflects our success in converting our enterprise customers from perpetual vSphere to the full VCF software stack subscription. Customers are increasingly turning to VCF to create a modernized private cloud on-prem, which will enable them to repatriate workloads from public clouds while being able to run modern container-based applications and AI applications. Of our 10,000 largest customers, over 87% have now adopted VCF.\n\n**Hock Tan** (CEO)\nThe momentum from strong VCF sales over the past 18 months since the acquisition of VMware has created annual recurring revenue, or otherwise known as ARR, growth of double digits in our core infrastructure software. In Q3, we expect infrastructure software revenue to be approximately $6.7 billion, up 16% year on year. In total, we're guiding Q3 consolidated revenue to be approximately $15.8 billion, up 21% year on year. We expect Q3 adjusted EBITDA to be at least 66%. With that, let me turn the call over to Kirsten.\n\n**Kirsten Spears** (CFO)\nThank you, Hock. Let me now provide additional detail on our Q2 financial performance. Consolidated revenue was a record $15 billion for the quarter, up 20% from a year ago. Gross margin was 79.4% of revenue in the quarter, better than we originally guided on product mix. Consolidated operating expenses were $2.1 billion, of which $1.5 billion was related to R&D. Q2 operating income of $9.8 billion was up 37% from a year ago, with operating margin at 65% of revenue. Adjusted EBITDA was $10 billion, or 67% of revenue, above our guidance of 66%. This figure excludes $142 million of depreciation. Now, a review of the P&L for our two segments, starting with semiconductors. Revenue for our semiconductor solution segment was $8.4 billion, with growth accelerating to 17% year on year, driven by AI. Semiconductor revenue represented 56% of total revenue in the quarter.\n\n**Kirsten Spears** (CFO)\nGross margin for our semiconductor solution segment was approximately 69%, up 140 basis points year on year, driven by product mix. Operating expenses increased 12% year on year to $971 million on increased investment in R&D for leading-edge AI semiconductors. Semiconductor operating margin of 57% was up 200 basis points year on year. Now, moving on to infrastructure software. Revenue for infrastructure software of $6.6 billion was up 25% year on year and represented 44% of total revenue. Gross margin for infrastructure software was 93% in the quarter compared to 88% a year ago. Operating expenses were $1.1 billion in the quarter, resulting in infrastructure software operating margin of approximately 76%. This compares to operating margin of 60% a year ago. This year-on-year improvement reflects our disciplined integration of VMware. Moving on to cash flow. Free cash flow in the quarter was $6.4 billion and represented 43% of revenue.\n\n**Kirsten Spears** (CFO)\nFree cash flow as a percentage of revenue continues to be impacted by increased interest expense from debt related to the VMware acquisition and increased cash taxes. We spent $144 million on capital expenditures. Day sales outstanding were 34 days in the second quarter compared to 40 days a year ago. We ended the second quarter with inventory of $2 billion, up 6% sequentially in anticipation of revenue growth in future quarters. Our days of inventory on hand were 69 days in Q2, as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the second quarter with $9.5 billion of cash and $69.4 billion of gross principal debt. Subsequent to quarter end, we repaid $1.6 billion of debt, resulting in gross principal debt of $67.8 billion.\n\n**Kirsten Spears** (CFO)\nThe weighted average coupon rate and years to maturity of our $59.8 billion in fixed-rate debt is 3.8% and 7 years, respectively. The weighted average interest rate and years to maturity of our $8 billion in floating-rate debt is 5.3% and 2.6 years, respectively. Turning to capital allocation, in Q2, we paid stockholders $2.8 billion of cash dividends based on a quarterly common stock cash dividend of $0.59 per share. In Q2, we repurchased $4.2 billion, or approximately 25 million shares of common stock. In Q3, we expect the non-GAAP diluted share count to be approximately 4.97 billion shares, excluding the potential impact of any share repurchases. Now, moving on to guidance. Our guidance for Q3 is for consolidated revenue of $15.8 billion, up 21% year on year. We forecast semiconductor revenue of approximately $9.1 billion, up 25% year on year.\n\n**Kirsten Spears** (CFO)\nWithin this, we expect Q3 AI semiconductor revenue of $5.1 billion, up 60% year on year. We expect infrastructure software revenue of approximately $6.7 billion, up 16% year on year. For modeling purposes, we expect Q3 consolidated gross margin to be down approximately 130 basis points sequentially, primarily reflecting a higher mix of XPUs within AI revenue. As a reminder, consolidated gross margins through the year will be impacted by the revenue mix of infrastructure software and semiconductors. We expect Q3 adjusted EBITDA to be at least 66%. We expect the non-GAAP tax rate for Q3 in fiscal year 2025 to remain at 14%. With this, that concludes my prepared remarks. Operator, please open up the call for questions.\n\n**Operator**\nThank you. To ask a question, you will need to press star 11 on your telephone. To withdraw your question, please press star 11 again. Due to time restraints, we ask that you please limit yourself to one question. Please stand by while we compile the Q&A roster. Our first question will come from the line of Ross Seymore with Deutsche Bank. Your line is open.\n\n**Ross Seymore** (Managing Director)\nHi, guys. Thanks for letting me ask a question. Hock, I wanted to jump onto the AI side and specifically some of the commentary you had about next year. Can you just give a little bit more color on the inference commentary you gave? Is it more the XPU side, the connectivity side, or both that's giving you the confidence to talk about the growth rate that you have this year being matched next fiscal year?\n\n**Hock Tan** (CEO)\nThank you, Ross. Good question. I think we're indicating that what we are seeing and what we have quite a bit of visibility increasingly is increased deployment of XPUs next year, much more than we originally thought, and hand in hand with it, of course, more and more networking. It is a combination of both.\n\n**Ross Seymore** (Managing Director)\nThe inference side of things?\n\n**Hock Tan** (CEO)\nYeah. We're seeing much more inference now.\n\n**Ross Seymore** (Managing Director)\nThank you.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Harlan Sur with JPMorgan. Your line is open.\n\n**Harlan Sur** (Executive Director of Equity Research)\nGood afternoon. Thanks for taking my question and great job on the quarterly execution. Hock, good to see the positive growth inflection quarter to quarter, year over year growth rates in your AI business. As the team has mentioned, the quarters can be a bit lumpy. If I smooth out kind of first three quarters of this fiscal year, your AI business is up 60% year over year. It is kind of right in line with your three-year kind of SAM growth figure. Given your prepared remarks and knowing that your lead times remain at 35 weeks or better, do you see the Broadcom team sustaining the 60% year over year growth rate exiting this year?\n\n**Harlan Sur** (Executive Director of Equity Research)\nI assume that that potentially implies that you see your AI business sustaining the 60% year over year growth rate into fiscal 2026, again, based on your prepared commentary, which again is in line with your SAM growth figure. Is that kind of a fair way to think about the trajectory this year and next year?\n\n**Hock Tan** (CEO)\nHarlan, that's a very insightful set of analysis here. That's exactly what we're trying to do here because over six months ago, we gave you guys a point, a year, 2027. As we come into the second half of 2025 and with improved visibility and updates we're seeing in the way our hyperscale partners are deploying data centers, AI clusters, we are providing you some level of guidance, visibility, what we are seeing, how the trajectory of 2026 might look like. I'm not giving you any update on 2027. We're just still establishing the update we have in 2027 six months ago. What we're doing now is giving you more visibility into where we're seeing 2026 headed.\n\n**Harlan Sur** (Executive Director of Equity Research)\nIs the framework that you laid out for us, like second half of last year, which implies 60% kind of growth figure in your SAM opportunity, is that kind of the right way to think about it as it relates to the profile of growth in your business this year and next year?\n\n**Hock Tan** (CEO)\nYes.\n\n**Harlan Sur** (Executive Director of Equity Research)\nOkay. Thank you, Hock.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Ben Reitzes with Melius Research. Your line is open.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nHey, how you doing? Thanks, guys. Hey, Hock. AI networking was really strong in the quarter, and it seemed like it must have beat expectations. I was wondering if you could just talk about the networking in particular, what caused that, and how much of that is your acceleration into next year? When do you think you see Tomahawk kicking in as part of that acceleration? Thanks.\n\n**Hock Tan** (CEO)\nI think AI networking, as you probably would know, goes pretty hand in hand with deployment of AI accelerator clusters. It does not deploy on a timetable that is very different from the way the accelerators get deployed, whether they are XPUs or GPUs. It does happen. They deploy a lot in scale-out where Ethernet, of course, is the choice or protocol, but it is also increasingly moving into the space of what we all call scale-up within those data centers, where you have much higher, more than we originally thought, consumption or density of switches than you have in the scale-out scenario. In fact, the increased density in scale-up is 5-10 times more than in scale-out.\n\n**Hock Tan** (CEO)\nThat is the part that kind of pleasantly surprised us, which is why this past quarter, Q2, the AI networking portion continues at about 40% from what we reported a quarter ago for Q1. At that time, I said I expect it to drop. It has not.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nYour thoughts on Tomahawk driving acceleration for next year and when it kicks in?\n\n**Hock Tan** (CEO)\nOh, Tomahawk 6. Oh, yeah. That's extremely strong interest. Now, we're not shipping big orders or any orders other than basic proof of concepts out to customers, but there is tremendous demand for this new 102 terabit per second Tomahawk switches.\n\n**Ross Seymore** (Managing Director)\nThanks, Hock.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Blaine Curtis with Jefferies. Your line is open.\n\n**Blayne Curtis** (Managing Director)\nHey. Thanks. Great results. I just wanted to ask maybe following up on the scale-out opportunity. Today, I guess your main customer is not really using an NVLink switch-style scale-up. I'm just kind of curious your visibility or the timing in terms of when you might be shipping a switch Ethernet scale-up network to your customers.\n\n**Hock Tan** (CEO)\nThe talking scale-up.\n\n**Blayne Curtis** (Managing Director)\nScale-up.\n\n**Hock Tan** (CEO)\nYeah. Scale-up is very rapidly converting to Ethernet now, very much so. For our fairly narrow band of hyperscale customers, scale-up is very much Ethernet.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Stacy Rasgon with Bernstein. Your line is open.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst of U.S. Semiconductors and Semiconductor Capital Equipment)\nHi, guys. Thanks for taking my questions. Hock, I still wanted to follow up on that AI 2026 question. I want to just put some numbers on it just to make sure I've got it right. So you did 60% in the first three quarters of this year. If you grow 60% year over year in Q4, it'd put you at, I don't know, $5.8 billion, something like $19 billion or $20 billion for the year. And then are you saying you're going to grow 60% in 2026, which would put you $30 billion plus in AI revenues for 2026? I just want to make sure. Is that the math that you're trying to communicate to us directly?\n\n**Hock Tan** (CEO)\nI think you're doing the math. I'm giving you the trend. I did answer that question, I think Harlan asked earlier. The rate we are seeing now so far in fiscal 2025, and we'll presumably continue. We don't see any reason why it doesn't, given lead time visibility in 2025. What we're seeing today, based on what we have visibility on 2026, is to be able to ramp up this AI revenue in the same trajectory. Yes.\n\n**Stacy Rasgon** (Analyst)\nIs the SAM going up? Is the SAM going up as well? Because now you have inference on top of training. Is the SAM still 60-90, or is the SAM higher now as you see it?\n\n**Hock Tan** (CEO)\nI'm not playing a SAM game here. I'm just giving a trajectory towards where we drew the line on 2027 before. So I have no response to is the SAM going up or not. Stop talking about SAM now. Thanks.\n\n**Stacy Rasgon** (Analyst)\nOkay. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Vivek Arya with Bank of America. Your line is open.\n\n**Vivek Arya** (Managing Director)\nThanks for taking my question. I had a near and then a longer-term question on the XPU business. Hock, for near term, if your networking upside in Q2 and overall AI was in line, it means XPU was perhaps not as strong. I realize it's lumpy, but anything more to read into that, any product transition or anything else? Just a clarification there. Longer term, you have outlined a number of additional customers that you're working with. What milestones should we look forward to, and what milestones are you watching to give you the confidence that you can now start adding that addressable opportunity into your 2027 or 2028 or other numbers? How do we get the confidence that these projects are going to turn into revenue in some reasonable timeframe from now? Thank you.\n\n**Hock Tan** (CEO)\nOkay. On the first part that you're asking, it's like you're trying to count how many angels on the head of a pin here. I mean, whether it's XPU or networking. Networking is hot, but that doesn't mean XPU is any softer. It's very much along the trajectory we expect it to be. There's no lumpiness. There's no softening. It's pretty much what we expect the trajectory to go so far and into next quarter as well and probably beyond. We have a fairlyit's a fairly, I guess, in our view, a fairly clear visibility on the short-term trajectory. In terms of going on to 2027, no, we are not updating any numbers here. Six months ago, we drew a sense for the size of the SAM based on a million GPU XPU clusters for three customers.\n\n**Hock Tan** (CEO)\nThat is still very valid at that point that you will be there. We have not provided any further updates here, nor are we intending to at this point. When we get better visibility, a clearer sense of where we are, and that probably will not happen until 2026, we will be happy to give an update to the audience. Right now, though, in today's prepared remarks and answering a couple of questions, we are, as we have done here, intending to give you guys more visibility of what we are seeing, the growth trajectory in 2026.\n\n**Vivek Arya** (Managing Director)\nThank you, Hock.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of CJ Muse with Cantor Fitzgerald. Your line is open.\n\n**CJ Muse** (Senior Managing Director)\nYeah. Good afternoon. Thank you for taking the question. I was hoping to follow up on Ross's question regarding inference opportunity. Can you discuss workloads that are optimal that you're seeing for custom silicon? And that over time, what percentage of your XPU business could be inference versus training? Thank you.\n\n**Hock Tan** (CEO)\nI think there's no differentiation between training and inference in using merchant accelerators versus custom accelerators. I think the whole premise behind going towards custom accelerators continues, which is not a matter of cost alone. It is that as custom accelerators get used and get developed on a roadmap with any particular hyperscaler, there's a learning curve, a learning curve on how they could optimize the way their algorithms on their large language models get written and tied to silicon. That ability to do so is a huge value added in creating algorithms that can drive their LLMs to higher and higher performance, much more than basically a segregation approach between hardware and the software. You literally combine end-to-end hardware and software as they take that journey. It is a journey. They don't learn that in one year.\n\n**Hock Tan** (CEO)\nDo it a few cycles, get better and better at it, and then realize the fundamental value in creating your own hardware versus using a third-party merchant silicon. You are able to optimize your software to the hardware and eventually achieve way higher performance than you otherwise could. We see that happening.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Carl Ackerman with BNP Paribas. Your line is open.\n\n**Karl Ackerman** (Managing Director and Equity Research of Semiconductors and IT Hardware)\nYes. Thank you. Hock, you spoke about the much higher content opportunity in scale-up networking. I was hoping you could discuss how important is demand adoption for copackage optics in achieving this 5-10x higher content for scale-up networks? Or should we anticipate much of the scale-up opportunity will be driven by Tomahawk and Thor NICs? Thank you.\n\n**Hock Tan** (CEO)\nI'm trying to decipher this question of yours. Let me try to answer it perhaps in a way I think you want me to clarify. First and foremost, I think most of what's scaling up, a lot of the scaling up that's going in, as I call it, which means a lot of XPU or GPU to GPU interconnects, is done on copper interconnects. Because the size of this scale-up cluster is still not that huge yet, you can get away with using copper interconnects. They're still doing it. Mostly, they're doing it today. At some point soon, I believe, when you start trying to go beyond maybe 72 GPU to GPU interconnects, you may have to push towards a different protocol mode at a different media from copper to optical.\n\n**Hock Tan** (CEO)\nWhen we do that, yeah, perhaps then things like exotic stuff like copackaging might become of silicon with optical might become relevant. Truly, what we really are talking about is that at some stage, as the clusters get larger, which means scale-up becomes much bigger, and you need to interconnect GPU or XPU to each other in scale-up, many more than just 72 or 100, maybe even 128. You start going more and more. You want to use optical interconnects simply because of distance. That is when optical will start replacing copper. When that happens, the question is, what's the best way to deliver on optical? One way is copackage optics, but it's not the only way. You can just simply use continuous, perhaps pluggable, at low-cost optics, in which case then you can interconnect the bandwidth, the radix of a switch.\n\n**Hock Tan** (CEO)\nOur switch is now 512 connections. You can now connect all these XPUs, GPUs, 512 for scale-up phenomenon. That was huge. When you go to optical, that's going to happen, in my view, within a year or two. We will be right in the forefront of it. It may be copackage optics, which we are very much in development, but it is a lock-in copackage. It could just be, as a first step, pluggable optics. Whatever it is, I think the bigger question is, when does it go from optical and from copper connecting GPU to GPU to optical connecting it? The step in that move will be huge. It is not necessarily copackage optics, though that is definitely one path we are pursuing.\n\n**Karl Ackerman** (Managing Director and Equity Research of Semiconductors and IT Hardware)\nVery clear. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Joshua Buckhalter with TD Cowen. Your line is open.\n\n**Joshua Buchalter** (Director of Equity Research Semiconductors)\nHey, guys. Thank you for taking my question. I realize it's a bit nitpicky, but I wanted to ask about gross margins in the guide. Your revenue implies sort of $800 million incremental increase, but gross profit up, I think, $400 million-$450 million, which is kind of pretty well below corporate average fall-through. I appreciate that SEMIs is dilutive and custom is probably dilutive within SEMIs. Anything else going on with margins that we should be aware of? How should we think about the margin profile of custom longer term as that business continues to scale and diversify? Thank you.\n\n**Kirsten Spears** (CFO)\nYeah. We've historically said that the XPU margins are slightly lower than the rest of the business, other than wireless. There is really nothing else going on other than that. It is just exactly what I said, that the majority of it, quarter over quarter, the 130 basis point decline is being driven by more XPUs.\n\n**Hock Tan** (CEO)\nThere are more moving parts here than your simple analysis proves here. I think your simple analysis is totally wrong in that regard.\n\n**Joshua Buchalter** (Director of Equity Research Semiconductors)\nAll right then. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Timothy Arcuri with UBS. Your line is open.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot, Hock. I also wanted to ask about scale-up, Hock. There's a lot of competing ecosystems. There's UA Link, which of course you left. Now there's the big GPU company opening up NVLink. They're both trying to build ecosystems. There's an argument that you're an ecosystem of one. What would you say to that debate? Does opening up NVLink change the landscape? How do you view your AI networking growth next year? Do you think it's going to be primarily driven by scale-up or will it still be pretty scale-out heavy things?\n\n**Hock Tan** (CEO)\nPeople do like to create platforms and new protocols and systems. The fact of the matter is scale-up can just be done easily. It is currently available. It is open standards, open source, Ethernet. Just as well. You do not need to create new systems for the sake of doing something that you could easily be doing in networking in Ethernet. Yeah, I hear a lot of these interesting new protocols, standards that are trying to be created. Most of them, by the way, are proprietary, much as they like to call it otherwise. What is really open source and open standards is Ethernet. We believe Ethernet will prevail as it does for the last 20 years in traditional networking. There is no reason to create a new standard for something that could be easily done in transferring bits and bytes of data.\n\n**Timothy Arcuri** (Managing Director)\nGot it, Hock. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Christopher Rolland with Susquehanna. Your line is open.\n\n**Christopher Rolland** (Senior Equity Analyst Semiconductors)\nThanks for the question. Yeah. My question is for you, Hock. It's kind of a bigger picture one here. And this kind of acceleration that we're seeing in AI demand, do you think that this acceleration is because of a marked improvement in ASICs or XPUs closing the gap on the software side at your customers? Do you think it's these tokenomics around inference, test-time compute driving that? For example, what do you think is actually driving the upside here? And do you think it leads to a market share shift faster than we were expecting towards XPU from GPU? Thanks.\n\n**Hock Tan** (CEO)\nYeah. Interesting question. No, none of the foregoing that you outlined. It's very simple. The way inference has come out very, very hot lately is, remember, we're only selling to a few customers, hyperscalers with platforms and LLMs. That's it. There are not that many. We told you how many we have, and we haven't increased any. What is happening is these hyperscalers and those with LLMs need to justify all this spending they're doing. Doing training makes your frontier models smarter. That's no question. It's almost like research and science. Make your frontier models by creating very clever algorithms that consume a lot of compute for training smarter. Training makes it smarter. You want to monetize inference. That's what's driving it. Monetize, I indicated in my prepared remarks, to drive to justify a return on investment. A lot of that investment is training.\n\n**Hock Tan** (CEO)\nThat return on investment is by creating use cases, a lot of AI use cases, AI consumption out there through availability of a lot of inference. That is what we are now starting to see among a small group of customers.\n\n**Christopher Rolland** (Senior Equity Analyst Semiconductors)\nExcellent. Thank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Vijay Rakesh with Mizuho. Your line is open.\n\n**Vijay Rakesh** (Managing Director)\nYeah. Thanks. Hey, Hock. Just going back on the AI server revenue side, I know you said fiscal 2025 kind of tracking to that up 60%-ish growth. If you look at fiscal 2026, you have many new customers racking with a Meta and probably you have the four or the six hyperscalers that you're talking about. Would you expect that growth to accelerate into fiscal 2026 above that kind of 60% you talked about?\n\n**Hock Tan** (CEO)\nMy prepared remarks, which I clarified, that the rate of growth we are seeing in 2025 will sustain into 2026 based on improved visibility and the fact that we're seeing inference coming in on top of the demand for training as the clusters get bigger and bigger and bigger still stands. I don't think we are getting very far by trying to pass through my words or data here. It's just a trick.\n\n**Vijay Rakesh** (Managing Director)\nGot it.\n\n**Hock Tan** (CEO)\nWe see that going from 2025 into 2026 as the best forecast we have at this point.\n\n**Vijay Rakesh** (Managing Director)\nGot it. On the NVLink, the NVLink Fusion versus the scale-up, do you expect that market to go the route of top of the rack where you're seeing some move to the Ethernet side in kind of the scale-out? Do you expect scale-up to kind of go the same route? Thanks.\n\n**Hock Tan** (CEO)\nBroadcom do not participate in NVLink. So I'm really not qualified to answer that question, I think.\n\n**Vijay Rakesh** (Managing Director)\nGot it. Thank you.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Aaron Rakers with Wells Fargo. Your line is open.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYeah. Thanks for taking the question. I think all my questions on scale-up have been asked. I guess, Hock, given the execution that you guys have been able to do with the VMware integration, looking at the balance sheet, looking at the debt structure, I'm curious if you could give us your thoughts on how the company thinks about capital return versus the thoughts on M&A and the strategy going forward. Thank you.\n\n**Hock Tan** (CEO)\nOkay. That's an interesting question. I agree. Not too untimely, I would say. Because, yeah, we have done a lot of the integration of VMware now. You can see that in the level of free cash flow we're generating from operations. As we said, the use of capital has always been very, I guess, measured and upfront with a return through dividends, which is half our free cash flow of the preceding year. Frankly, as Kirsten has mentioned three months ago and six months ago during the last two earnings call, the first choice typically of the other part of the free cash flow is to bring down our debt to a level that we feel closer to no more than two ratio of debt to EBITDA.\n\n**Hock Tan** (CEO)\nThat does not mean that opportunistically we may go out there and buy back our shares as we did last quarter. As indicated by Kirsten when we did $4.2 billion of stock buyback. Now, part of it is used to basically when employee RSUs vest, we basically buy back part of the shares used to be paying taxes on the vested RSU. The other part of it, I do admit we used opportunistically last quarter when we see an opportunity situation when basically we think that it is a good time to buy some shares back. We do. Having said all that, our use of cash outside of dividends would be at this stage used towards reducing our debt. I know you are going to ask, what about M&A?\n\n**Hock Tan** (CEO)\nThe kind of M&A we will do in our view would be significant, would be substantial enough that we need debt in any case. It is a good use of our free cash flow to bring down debt to, in a way, expand, if not preserve, our borrowing capacity if we have to do another M&A deal.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Srini Pajjuri with Raymond James. Your line is open.\n\n**Srini Pajjuri** (Managing Director)\nThank you. Hock, a couple of clarifications. First, on your 2026 expectation, are you assuming any meaningful contribution from the four prospects that you talked about?\n\n**Hock Tan** (CEO)\nNo comment. We don't talk on prospects. We only talk on customers.\n\n**Srini Pajjuri** (Managing Director)\nOkay. Fair enough. My other clarification is that I think you talked about networking being about 40% of the mix within AI. Is that the right kind of mix that you expect going forward, or is that going to materially change as we, I guess, see XPUs ramping going forward?\n\n**Hock Tan** (CEO)\nNo. I've always said and expect that to be the case going forward in 2026 as we grow, that networking should be a ratio to XPU should be closer in the range of less than 30%, not the 40%.\n\n**Operator**\nThank you. One moment for our next question. That will come from the line of Joe Moore with Morgan Stanley. Your line is open.\n\n**Joe Moore** (Managing Director)\nGreat. Thank you. You've said you're not going to be impacted by export controls on AI. I know there's been a number of changes in the industry since the last time you made the call. Is that still the case? Can you give people comfort that there's no impact from that down the road?\n\n**Hock Tan** (CEO)\nNobody can give anybody comfort in this environment, Joe. You know that. Rules are changing quite dramatically as bilateral trade agreements continue to be negotiated in a very, very dynamic environment. I'll be honest, I don't know. I know as little as probably you probably know more than I do, maybe, in which case then I know very little about this whole thing about whether there's any export control, how the export control will take place. We're guessing. I'd rather not answer that because, no, I don't know whether it will be.\n\n**Operator**\nThank you. We do have time for one final question. That will come from the line of William Stein with Truist Securities. Your line is open.\n\n**William Stein** (Managing Director and Senior Analyst Technology)\nYeah. Great. Thank you for squeezing me in. I wanted to ask about VMware. Can you comment as to how far along you are in the process of converting customers to the subscription model? Is that close to complete, or is there still a number of quarters that we should expect that that conversion continues?\n\n**Hock Tan** (CEO)\nThat's a good question. Let me start off by saying a good way to measure it is most of our VMware contracts are typically three years. That was what VMware did before we acquired them. That's pretty much what we continue to do, three years, very traditional. Based on that, the renewals were like two-thirds of the way, almost halfway, more than halfway through the renewals. We probably have at least another year plus maybe a year and a half to go.\n\n**Operator**\nThank you. And with that, I'd like to turn the call over to Goo for closing remarks.\n\n**Operator**\nThank you, operator. Broadcom currently plans to report its earnings for the third quarter of fiscal year 2025 after close of market on Thursday, September 4, 2025. A public webcast of Broadcom's earnings conference call will follow at 2:00 P.M. Pacific. That will conclude our earnings call today. Thank you all for joining. Operator, you may end the call.",
        "fetched_at": "2026-02-04T16:13:28.507Z"
      },
      {
        "ticker": "AVGO",
        "title": "Yahoo Finance",
        "published_date": "Mar 6, 2025, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/AVGO/earnings/AVGO-Q1-2025-earnings_call-295237.html",
        "content": "**Operator**\nWelcome to the Broadcom Inc.'s first quarter, fiscal year 2025 financial results conference call. At this time, for opening remarks and introductions, I would like to turn the call over to Ji Yoo, Head of Investor Relations of Broadcom Inc.\n\n**Ji Yoo** (Head of Investor Relations)\nThank you, Cherie, and good afternoon, everyone. Joining me on today's call are Hock Tan, President and CEO. Kirsten Spears, Chief Financial Officer. And Charlie Kawwas, President, Semiconductor Solutions Group. Broadcom distributed a press release and financial tables after the market closed, describing our financial performance for the first quarter of fiscal year 2025. If you did not receive a copy, you may obtain the information from the investor section of Broadcom's website at broadcom.com. This conference call is being webcast live, and an audio replay of the call can be accessed for one year through the investor section of Broadcom's website. During the prepared comments, Hock and Kirsten will be providing details of our first quarter fiscal year 2025 results, guidance for our second quarter of fiscal year 2025, as well as commentary regarding the business environment. We'll take questions after the end of our prepared comments.\n\n**Ji Yoo** (Head of Investor Relations)\nPlease refer to our press release today and our recent filings with the SEC for information on the specific risk factors that could cause our actual results to differ materially from the forward-looking statements made on this call. In addition to U.S. GAAP reporting, Broadcom reports certain financial measures on a non-GAAP basis. A reconciliation between GAAP and non-GAAP measures is included in the tables attached to today's press release. Comments made during today's call will primarily refer to our non-GAAP financial results. I'll now turn the call over to Hock.\n\n**Hock Tan** (President and CEO)\nThank you, Ji, and thank you, everyone, for joining today. In our fiscal Q1 2025, total revenue was a record $14.9 billion, up 25% year-on-year, and consolidated adjusted EBITDA was a record, again, $10.1 billion, up 41% year-on-year, so let me first provide color on our semiconductor business. Q1 semiconductor revenue was $8.2 billion, up 11% year-on-year. Growth was driven by AI, as AI revenue of $4.1 billion was up 77% year-on-year. We beat our guidance for AI revenue of $3.8 billion due to stronger shipments of networking solutions to hyperscalers on AI. Our hyperscale partners continue to invest aggressively in their next-generation frontier models, which do require high-performance accelerators, as well as AI data centers with larger clusters, and consistent with this, we are stepping up our R&D investment on two fronts. One, we're pushing the envelope of technology in creating the next generation of accelerators.\n\n**Hock Tan** (President and CEO)\nWe're tipping out the industry's first 2-nanometer AI XPU, packaged in 3.5D, as we drive towards a 10,000-teraflops XPU. Secondly, we have a view towards scaling clusters of 500,000 accelerators for our hyperscale customers. We have doubled the Radix capacity of the existing Tomahawk 5. And beyond this, to enable AI clusters to scale up on Ethernet towards 1 million XPUs, we have taped out our next-generation 100-terabit Tomahawk 6 switch running 200G studies at 1.6-terabit bandwidth. We will be delivering samples to customers within the next few months. These R&D investments are very aligned with the roadmap of our three hyperscale customers, as they each race towards 1 million XPU clusters by the end of 2027.\n\n**Hock Tan** (President and CEO)\nAccordingly, we do reaffirm what we said last quarter, that we expect these three hyperscale customers will generate a serviceable, addressable market, or SAM, in the range of $60-$90 billion in fiscal 2027. Beyond these three customers, we had also mentioned previously that we are deeply engaged with two other hyperscalers in enabling them to create their own customized AI accelerator. We are on track to tape out their XPUs this year. In the process of working with the hyperscalers, it has become very clear that while they are excellent in software, Broadcom is the best in hardware. Working together is what optimizes their large language models. It is therefore no surprise to us, since our last earnings call, that two additional hyperscalers have selected Broadcom to develop custom accelerators to train their next-generation frontier models.\n\n**Hock Tan** (President and CEO)\nSo even as we have three hyperscale customers who are shipping XPUs in volume today, there are now four more who are deeply engaged with us to create their own accelerators. And to be clear, of course, these four are not included in our estimated SAM of $60-$90 billion in 2027. So we do see an exciting trend here. New frontier models and techniques put unexpected pressures on AI systems. It's difficult to serve all classes of models with a single system design point. And therefore, it is hard to imagine that a general-purpose accelerator can be configured and optimized across multiple frontier models. And as I mentioned before, the trend towards XPUs is a multi-year journey. So coming back to 2025, we see a steady ramp in deployment of our XPUs and networking products.\n\n**Hock Tan** (President and CEO)\nIn Q1, AI revenue was $4.1 billion, and we expect Q2 AI revenue to grow to $4.4 billion, which is up 44% year-on-year. Turning to non-AI semiconductors, revenue of $4.1 billion was down 9% sequentially on a seasonal decline in wireless. In aggregate, during Q1, the recovery in non-AI semiconductors continued to be slow. Broadband, which bottomed in Q4 2024, showed a double-digit sequential recovery in Q1 and is expected to be up similarly in Q2, as service providers and telcos step up spending. Server storage was down single digits sequentially in Q1, but is expected to be up high single digits sequentially in Q2. Meanwhile, enterprise networking continues to remain flattish in the first half of fiscal 2025, as customers continue to work through channel inventory. While wireless was down sequentially due to a seasonal decline, it remained flat year-on-year.\n\n**Hock Tan** (President and CEO)\nIn Q2, wireless is expected to be the same, flat again year-on-year. Resales in industrial were down double digits in Q1 and are expected to be down in Q2, so reflecting the foregoing puts and takes, we expect non-AI semiconductor revenue in Q2 to be flattish sequentially, even though we are seeing bookings continue to grow year-on-year. In summary, for Q2, we expect total semiconductor revenue to grow 2% sequentially and up 17% year-on-year to $8.4 billion. Turning now to infrastructure software segment. Q1 infrastructure software revenue of $6.7 billion was up 47% year-on-year and up 15% sequentially, exaggerated, though, by deals which slipped from Q4 into Q1. Now, this is the first quarter, Q1 2025, where the year-on-year comparables include VMware in both quarters. We're seeing significant growth in the software segment for two reasons.\n\n**Hock Tan** (President and CEO)\nOne, we're converting from a footprint of largely perpetual license to one of full subscription. And as of today, we are over 60% done. Two, these perpetual licenses were only largely for compute virtualization, otherwise called vSphere. We are upselling customers to a full-stack vCF, which enables the entire data center to be virtualized. And this enables customers to create their own private cloud environment on-prem. And as of the end of Q1, approximately 70% of our largest 10,000 customers have adopted vCF. As these customers consume vCF, we do see a further opportunity for future growth. As large enterprises adopt AI, they have to run their AI workloads on their on-prem data centers, which will include both GPU servers as well as traditional CPUs.\n\n**Hock Tan** (President and CEO)\nJust as vCF virtualizes these traditional data centers using CPUs, vCF will also virtualize GPUs on a common platform and enable enterprises to import AI models to run their own data on-prem. This platform, which virtualizes the GPU, is called the VMware Private AI Foundation. And as of today, in collaboration with NVIDIA, we have 39 enterprise customers for the VMware Private AI Foundation. Customer demand has been driven by our open ecosystem, superior load balancing and automation capabilities that allows them to intelligently pull and run workloads across both GPU and CPU infrastructure, leading to very reduced costs. Moving on to Q2 outlook for software, we expect revenue of $6.5 billion, up 23% year-on-year. So in total, we're guiding Q2 consolidated revenue to be approximately $14.9 billion, up 19% year-on-year. And we expect this will drive Q2 adjusted EBITDA to approximately 66% of revenue.\n\n**Hock Tan** (President and CEO)\nWith that, let me turn the call over to Kirsten.\n\n**Kirsten Spears** (CFO)\nThank you, Hock. Let me now provide additional detail on our Q1 financial performance. From a year-on-year comparable basis, keep in mind that Q1 of fiscal 2024 was a 14-week quarter, and Q1 of fiscal 2025 is a 13-week quarter. Consolidated revenue was $14.9 billion for the quarter, up 25% from a year ago. Gross margin was 79.1% of revenue in the quarter, better than we originally guided on higher infrastructure software revenue and more favorable semiconductor revenue mix. Consolidated operating expenses were $2 billion, of which $1.4 billion was for R&D. Q1 operating income of $9.8 billion was up 44% from a year ago, with operating margin at 66% of revenue. Adjusted EBITDA was a record $10.1 billion, or 68% of revenue, above our guidance of 66%. This figure excludes $142 million of depreciation.\n\n**Kirsten Spears** (CFO)\nNow a review of the P&L for our two segments, starting with semiconductors. Revenue for our semiconductor solutions segment was $8.2 billion and represented 55% of total revenue in the quarter. This was up 11% year-on-year. Gross margin for our semiconductor solutions segment was approximately 68%, up 70 basis points year-on-year, driven by revenue mix. Operating expenses increased 3% year-on-year to $890 million on increased investment in R&D for leading-edge AI semiconductors, resulting in semiconductor operating margin of 57%. Now moving on to infrastructure software. Revenue for infrastructure software of $6.7 billion was 45% of total revenue and up 47% year-on-year, based primarily on increased revenue from VMware. Gross margin for infrastructure software was 92.5% in the quarter, compared to 88% a year ago.\n\n**Kirsten Spears** (CFO)\nOperating expenses were approximately $1.1 billion in the quarter, resulting in infrastructure software operating margin of 76%.\n\n**Kirsten Spears** (CFO)\nThis compares to operating margin of 59% a year ago. This year-on-year improvement reflects our disciplined integration of VMware and sharp focus on deploying our vCF strategy. Moving on to cash flow. Free cash flow in the quarter was $6 billion and represented 40% of revenue. Free cash flow, as a percentage of revenue, continues to be impacted by cash interest expense from debt related to the VMware acquisition and cash taxes due to the mix of U.S. taxable income, the continued delay in the reenactment of Section 174, and the impact of corporate AMT. We spent $100 million on capital expenditures. Day sales outstanding were 30 days in the first quarter, compared to 41 days a year ago. We ended the first quarter with inventory of $1.9 billion, up 8% sequentially to support revenue in future quarters.\n\n**Kirsten Spears** (CFO)\nOur days of inventory on hand were 65 days in Q1, as we continue to remain disciplined on how we manage inventory across the ecosystem. We ended the first quarter with $9.3 billion of cash and $68.8 billion of gross principal debt. During the quarter, we repaid $495 million of fixed-rate debt and $7.6 billion of floating-rate debt with new senior notes, commercial paper, and cash on hand, reducing debt by a net $1.1 billion. Following these actions, the weighted average coupon rate and years to maturity of our $58.8 billion in fixed-rate debt is 3.8% and 7.3 years, respectively. The weighted average coupon rate and years to maturity of our $6 billion in floating-rate debt is 5.4% and 3.8 years, respectively, and our $4 billion in commercial paper is at an average rate of 4.6%. Turning to capital allocation.\n\n**Kirsten Spears** (CFO)\nIn Q1, we paid stockholders $2.8 billion of cash dividends based on a quarterly common stock cash dividend of $0.59 per share. We spent $2 billion to repurchase 8.7 million AVGO shares from employees as those shares vested for withholding taxes. In Q2, we expect the non-GAAP diluted share count to be approximately 4.95 billion shares. Now moving on to guidance. Our guidance for Q2 is for consolidated revenue of $14.9 billion, with semiconductor revenue of approximately $8.4 billion, up 17% year-on-year. We expect Q2 AI revenue of $4.4 billion, up 44% year-on-year. For non-AI semiconductors, we expect Q2 revenue of $4 billion. We expect Q2 infrastructure software revenue of approximately $6.5 billion, up 23% year-on-year. We expect Q2 adjusted EBITDA to be about 66%.\n\n**Kirsten Spears** (CFO)\nFor modeling purposes, we expect Q2 consolidated gross margin to be down approximately 20 basis points sequentially on the revenue mix of infrastructure software and product mix within semiconductors. As Hock discussed earlier, we are increasing our R&D investment in leading-edge AI in Q2, and accordingly, we expect adjusted EBITDA to be approximately 66%. We expect the non-GAAP tax rate for Q2 and fiscal year 2025 to be approximately 14%. That concludes my prepared remarks. Operator, please open up the call for questions.\n\n**Operator**\nThank you. To ask a question, you will need to press star 11 on your telephone. To withdraw your question, press star 11 again. Due to time restraints, we ask that you please limit yourself to one question. Please stand by while we compile the Q&A roster. And our first question will come from the line of Ben Rietzes with Melius. Your line is open.\n\n**Ben Reitzes** (Managing Director)\nHey, guys.\n\n**Ben Reitzes** (Managing Director)\nThanks a lot, and congrats on the results. Hock, you talked about four more customers coming online. Can you just talk a little bit more about the trend you're seeing? Can any of these customers be as big as the current three? And what does this say about the custom silicon trend overall and your optimism and upside to the business long-term? Thanks.\n\n**Hock Tan** (President and CEO)\nWell, very interesting question, Ben, and thanks for your kind wishes. But what we're seeing is, and by the way, these four are not yet customers as we define it. As I've always said, in developing and creating XPUs, we are not really the creator of those XPUs, to be honest. We enable those hyperscalers' partners we engage with to create that chip, basically to create that compute system, call it that way.\n\n**Hock Tan** (President and CEO)\nAnd it comprises the software model working closely with the compute engine, the XPU, and the networking that ties together the clusters, those multiple XPUs as a whole to train those large frontier models. And so the fact that we create the hardware, it still has to work with the software models and algorithms of those partners of ours before it becomes fully deployable at scale, which is why we define customers in this case as those where we know they're deployed at scale and we receive the production volume to enable it to run. And for that, we only have three, just to reiterate. The four are, I call it, partners who are trying to create the same thing as the first three and to run their own frontier models. Each of them don't have to train their own frontier models.\n\n**Hock Tan** (President and CEO)\nAnd as I also said, it doesn't happen overnight. To do the first chip would take typically a year and a half, and that's very accelerated, which we could accelerate given that we essentially have a framework and a methodology that works right now. It works for the three customers. No reason for it to not work for the four. But we still need those four partners to create and to develop the software, which we don't do, to make it work. And to answer your question, there's no reason why these four guys would not create a demand in the range of what we're seeing with the first three guys, but probably later. It's a journey. They started it later, and so they will probably get there later.\n\n**Ben Reitzes** (Managing Director)\nThank you very much.\n\n**Operator**\nThank you.\n\n**Operator**\nOne moment for our next question, and that will come from the line of Harlen Sur with J.P. Morgan. Your line is open.\n\n**Harlan Sur** (Executive Director)\nGood afternoon and great job on the strong quarterly execution, Hock and team. Great to see the continual momentum in the AI business here in the first half of your fiscal year and the continued broadening out of your AI ASIC customers. I know, Hock, last earnings you did call out a strong ramp in the second half of the fiscal year driven by new three-nanometer AI accelerated programs kind of ramping. Can you just help us either qualitatively, quantitatively profile this second-half step up relative to what the team just delivered here in the first half? Has the profile changed either favorably, less favorably versus what you thought maybe 90 days ago? Because quite frankly, I mean, a lot has happened since last earnings, right?\n\n**Harlan Sur** (Executive Director)\nYou've had the dynamics like DeepSeek and focus on AI model efficiency, but on the flip side, you've had strong CapEx outlooks by your cloud and hyperscale customers, so any color on the second-half AI profile would be helpful, asking me to look into the minds of my customers, and I hate to tell you, they don't show me the entire mindset here, but why we're beating the numbers so far in Q1 and seems to be encouraging in Q2. Partly from improved networking shipments, as I indicated, to cluster those XPUs and AI accelerators, even in some cases GPUs together for the hyperscalers, and that's good, and partly also we think there is some pull-ins of shipments and acceleration, call it that way, of shipments in fiscal 2025.\n\n**Hock Tan** (President and CEO)\nOn the second half that you talked about 90 days ago, the second half 3-nanometer ramp, is that still very much on track? Harlen, thank you. I only got Q2. Sorry. Let's not speculate on the second half.\n\n**Harlan Sur** (Executive Director)\nOkay. Thank you, Hock.\n\n**Hock Tan** (President and CEO)\nThank you.\n\n**Operator**\nThank you. One moment for our next question, and that will come from the line of William Stein with Truist Securities. Your line is open.\n\n**William Stein** (Managing Director)\nGreat. Thank you for taking my question. Congrats on these pretty great results. It seems from the news headlines about tariffs and about DeepSeek that there may be some disruptions. Some customers and some other complementary suppliers seem to feel a bit paralyzed, perhaps, and have difficulty making tough decisions. Those tend to be really useful times for great companies to sort of emerge as something bigger and better than they were in the past.\n\n**William Stein** (Managing Director)\nYou've grown this company in a tremendous way over the last decade-plus, and you're doing great now, especially in this AI area. But I wonder if you're seeing that sort of disruption from these dynamics that we suspect are happening based on headlines, what we see from other companies, and aside from adding these customers in AI, I'm sure there's other great stuff going on, but should we expect some bigger changes to come from Broadcom as a result of this?\n\n**Hock Tan** (President and CEO)\nYou pose a very interesting set of issues and questions, and those are very relevant, interesting issues. The only problem we have at this point is, I would say it's really too early to know where we all land. I mean, there's the threat, the noise of tariffs, especially on chips, that hasn't materialized yet. Nor do we know how it will be structured, so we don't know.\n\n**Hock Tan** (President and CEO)\nBut we do experience, and we are living it now, is the disruption that is in a positive way, I should add. A very positive disruption in semiconductors on generative AI. Generative AI, for sure. And I said that before also, at the risk of repeating here, but we feel it more than ever. It's really accelerating the development of semiconductor technology, both process and packaging, as well as design, towards higher and higher performance accelerators and networking functionality. We're seeing that innovation, those upgrades occur every month as we face new interesting challenges. And particularly with XPUs, we've been asked to optimize to frontier models of our partners, our customers, as well as our hyperscale partners. And it's a lot of, I mean, it's a privilege almost for us to participate in it and try to optimize.\n\n**Hock Tan** (President and CEO)\nTo optimize, I mean you look at an accelerator. You can look at it for simple terms, high level, to perform. You want to make the dimension not just on one single metric, which is compute capacity, how many teraflops. It's more than that. It's also tied to the fact that this is a distributed computing problem. It's not just the compute capacity of a single XPU or GPU. It's also the network bandwidth. It ties itself to the next adjacent XPU or GPU, so that has an impact, so you're doing that. You have to balance with that, then you decide, are you doing training or you're doing pre-training, post-training, fine-tuning, and again, then comes how much memory do you balance against that, and with it, how much latency you can afford, which is memory bandwidth.\n\n**Hock Tan** (President and CEO)\nYou look at at least four variables, maybe even five if you include in memory bandwidth, not just memory capacity when you go straight to inference. So we have all these variables to play with, and we try to optimize it. So all this is very, very, I mean, it's a great experience for our engineers to push their envelope on how to create all those chips. And so that's the biggest disruption we see right now from sheer trying to create and push the envelope on generative AI, trying to create the best hardware infrastructure to run it. Beyond that, yeah, there are other things too that come into play because with AI, as I indicated, it does not just drive hardware for enterprises. It drives the way they architect their data centers. Keeping data private under control becomes important.\n\n**Hock Tan** (President and CEO)\nSo suddenly, the push of workloads towards public cloud may take a little pause as large enterprises, particularly, have to take to recognize that you want to run AI workloads. You probably think very hard about running them on-prem. And suddenly, you push yourself towards saying, \"You got to upgrade your own data centers to do and manage your own data to run it on-prem.\" And that's also pushing a trend that we have been seeing now over the past 12 months. Hence my comments on VMware Private AI Foundation. It's true, especially enterprises pushing direction are quickly recognizing where do they run their AI workloads. So those are trends we see today, and a lot of it coming out of AI, a lot of it coming out of sensitive rules on sovereignty in cloud and in data.\n\n**Hock Tan** (President and CEO)\nAs far as your mentioning tariffs is concerned, I think that's too early for us to figure out where it'll all land. And probably maybe give it another three, six months, we probably have a better idea of where it's going.\n\n**William Stein** (Managing Director)\nThank you.\n\n**Operator**\nThank you. One moment for our next question. And that will come from the line of Ross Seymour with Deutsche Bank. Your line is open.\n\n**Ross Seymore** (Managing Director)\nNice to meet you. Thanks for asking the question. Hock, I want to go back to the XPU side of things. And going from the four new engagements, not yet named customers, two last quarter and two more today that you announced, I want to talk about going from kind of design win to deployment. How do you judge that?\n\n**Ross Seymore** (Managing Director)\nBecause there is some debate about tons of design wins, but the deployments actually don't happen either, that they never occur, or that the volume is never what is originally promised. How do you view that kind of conversion ratio? Is there a wide range around it, or is there some way you could help us kind of understand how that works?\n\n**Hock Tan** (President and CEO)\nRoss, that's an interesting question. I'll take the opportunity to say the way we look at design win is probably very different from the way many of our peers look at it out there. Number one, to begin with, we believe design win when we know our product is produced at scale and is actually deployed, literally deployed in production. So that takes a long time.\n\n**Hock Tan** (President and CEO)\nBecause from taping out, getting in the product, it takes a year easily from the product in the hands of our partner to when it goes into scale production. It will take six months to a year, is our experience that we've seen. Number one. And number two, I mean, producing and deploying 5,000 XPUs, that's a joke. That's not real production in our view. And so we also limit ourselves in selecting partners to people who really need that large volume. You need that large volume from our viewpoint in scale right now in mostly training, training of large language models, frontier models in a continuing trajectory. So we limit ourselves to how many customers or how many potential customers that exist out there, Ross. And we tend to be very selective who we pick to begin with. So when we say design win, it really is at scale.\n\n**Hock Tan** (President and CEO)\nIt's not something that starts in six months and die or a year and die again. Basically, it's a selection of customers. It's just the way we run our ASIC business in general for the last 15 years. We pick and choose the customers because we know this guy and we do multi-year roadmaps with these customers because we know these customers are sustainable. I put it bluntly. We don't do it for startups.\n\n**Ross Seymore** (Managing Director)\nThank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Stacy Rasgon with Bernstein Research. Your line is open.\n\n**Stacy Rasgon** (Senior Analyst)\nHi guys. Thanks for taking my question. I wanted to go to the three customers that you do have in volume today.\n\n**Stacy Rasgon** (Senior Analyst)\nWhat I wanted to ask was, is there any concern about some of the new regulations or the AI diffusion rules that are going to get put in place supposedly in May impacting any of those design wins or shipments? It sounds like you think all three of those are still on at this point. But anything you could tell us about worries about new regulations or AI diffusion rules impacting any of those wins would be helpful.\n\n**Hock Tan** (President and CEO)\nThank you. In this era or this current era of geopolitical tensions and fairly dramatic actions all around by governments, there's always some concern at the back of everybody's mind. But to answer your question directly, no. We don't have any concerns.\n\n**Stacy Rasgon** (Senior Analyst)\nGot it. So none of those are going into China or to Chinese customers then?\n\n**Hock Tan** (President and CEO)\nNo comment. Are you trying to locate who they are?\n\n**Stacy Rasgon** (Senior Analyst)\nOkay. That's helpful.\n\n**Stacy Rasgon** (Senior Analyst)\nThank you.\n\n**Hock Tan** (President and CEO)\nThank you.\n\n**Operator**\nOne moment for our next question. And that will come from the line of Vivek Arya with Bank of America. Your line is open.\n\n**Vivek Arya** (Managing Director)\nThanks for taking my question. Hock, whenever you have described your AI opportunity, you have always emphasized the training workload. But the perception is that the AI market could be dominated by the inference workload, especially with these new reasoning models. So what happens to your opportunity and share if the mix moves more toward inference? Does it create a bigger SAM for you than the $60-$90 billion? Does it keep it the same, but there's a different mix of product? Or does a more inference-heavy market favor a GPU over an XPU?\n\n**Hock Tan** (President and CEO)\nThank you. That's a good question. Interesting question. By the way, I do talk a lot about training.\n\n**Hock Tan** (President and CEO)\nOur XPUs also focus on inference as a separate product line. They do. And that's why I can say the architecture of those chips are very different from the architecture of the training chips. And so it's a combination of those two, I should add, that adds up to this $60-$90 billion. So if I have not been clear, I do apologize. It's a combination of both. But having said that, the larger part of the dollars come from training, not inference within the service of the SAM that we've talked about so far.\n\n**Vivek Arya** (Managing Director)\nThank you.\n\n**Operator**\nOne moment for our next question. That will come from the line of Harsh Kumar with Piper Sandler. Your line is open.\n\n**Harsh Kumar** (Managing Director)\nThanks, Broadcom team. Again, great execution. Just Hock, I had a quick question.\n\n**Harsh Kumar** (Managing Director)\nWe've been hearing that almost all of the large clusters that are 100K plus, they're all going to Ethernet. I was wondering if you could help us understand the importance of when the customer is making a selection, choosing between a guy that has the best switch ASIC such as you versus a guy that might have the compute there. Can you talk about what the customer is thinking and what are the final points that they want to hit upon when they make that selection for the NIC cards?\n\n**Hock Tan** (President and CEO)\nOkay. I see. No, yeah, it's down to in the case of the hyperscalers, not very much so, it's very driven by performance. And it's performance, what you're mentioning about on connecting, scaling up, and scaling out those AI accelerators, be they XPU or GPU among hyperscalers.\n\n**Hock Tan** (President and CEO)\nIn most cases among those hyperscalers we engage with when it comes to connecting those clusters, they're very driven by performance. I mean, if you are in a race to really get the best performance out of your hardware as you train and continue to train your frontier models, that matters more than anything else. The basic first thing they go for is proven. That's a proven piece of hardware. It's a proven system, subsystem in our case that makes it work. In that case, we tend to have a big advantage because, I mean, networking ASICs, switching and routing ASICs for the last 10 years at least. The fact that it's AI just makes it more interesting for our engineers to work on.\n\n**Hock Tan** (President and CEO)\nBut it's basically based on proven technology and experience in pushing the envelope on going from 800 gigabit per second bandwidth to 1.6 and moving on 3.2, which is exactly why we keep stepping up the rate of investment in coming up with a product where we take Tomahawk 5, we double the radix to deal with just one hyperscaler because they want high radix to create larger clusters while running bandwidth that are smaller. But that doesn't stop us from moving ahead to the next generation of Tomahawk 6. And I dare say we're even planning Tomahawk 7 and 8 right now. And we're speeding up the rate of development. And it's all largely for that few guys, by the way. So we're making a lot of investment for very few customers, hopefully with very large serviceable addressable markets. If anything else, that's the big bets we are placing.\n\n**Harsh Kumar** (Managing Director)\nThank you, Hock.\n\n**Operator**\nThank you. One moment for our next question, and that will come from the line of Timothy Arcuri with UBS. Your line is open.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Hock, in the past, you have mentioned XPU units growing from about 2 million last year to about 7 million, you said, in the 2027, 2028 timeframe. My question is, do these four new customers, do they add to that 7 million unit number? I know in the past you've sort of talked about an ASP of $20,000 by then. So the first three customers are clearly a subset of that 7 million unit. So do these new four engagements drive that 7 higher, or do they just fill in to get to that 7 million? Thanks,\n\n**Hock Tan** (President and CEO)\nand thanks, Tim, for asking that.\n\n**Hock Tan** (President and CEO)\nTo clarify, as I thought I made it clear in my comments, no, the market we're talking about, when you translate the unit, is only among the three customers we have today. The other four, we talk about engagement partners, we don't consider that as customers yet, and therefore are not in our serviceable addressable market.\n\n**Timothy Arcuri** (Managing Director)\nOkay. So they would add to that number. Okay. Thanks, Hock.\n\n**Hock Tan** (President and CEO)\nThanks.\n\n**Operator**\nOne moment for our next question. And that will come from the line of C.J. Muse with Cantor Fitzgerald.\n\n**Operator**\nYour line is open.\n\n**CJ Muse** (Senior Managing Director)\nYeah. Good afternoon. Thank you for taking the question.\n\n**CJ Muse** (Senior Managing Director)\nI guess, Hock, to follow up on your prepared remarks and comments earlier around optimization with your best hardware and hyperscalers with their great software, I'm curious how you're expanding your portfolio now to six megascale kind of frontier models will enable you to, in one fell swoop, share tremendous information, but at the same time, a world where these six truly want to differentiate, so obviously, the goal for all of these players is ExaFLOPS per second per dollar of CapEx per watt, and I guess, to what degree are you aiding them in this effort? And where does maybe the Chinese wall kind of start where they want to kind of differentiate and not share with you kind of some of the work that you're doing? Thank you.\n\n**Hock Tan** (President and CEO)\nWe only provide very basic fundamental technology in semiconductors to enable these guys to use what we have and optimize it to their own particular models and the algorithms that relate to those models. That's it. That's all we do, so that's the level of a lot of that optimization we do for each of them, and as I mentioned earlier, there are maybe five degrees of freedom that we do, and we play with that, and so even if there are five degrees of freedom, there's only so much we can do at that point, but it is, and how they basically, how we optimize it, is all tied to the partner telling us how they want to do it, so there's only so much we also have visibility on, but it's what we do now is what the XPU model is.\n\n**Hock Tan** (President and CEO)\nShare optimization translating to performance, but also power. That's very important how they play it. It's not just cost. Power translates into total cost of ownership eventually. It's how design it in power and how we balance it in terms of the size of the cluster and whether they use it for training, pre-training, post-training, inference, test time scaling. All of them have their own characteristics. And that's the advantage of doing that XPU and working closely with them to create that stuff. Now, as far as your question on China and all that, frankly, I don't have any opinion on that at all. To us, it's a technical game.\n\n**CJ Muse** (Senior Managing Director)\nThank you very much.\n\n**Operator**\nOne moment for our next question. And that will come from the line of Christopher Rolland with Susquehanna. Your line is open.\n\n**Christopher Rolland** (Senior Equity Analyst)\nHey, thanks so much for the question.\n\n**Christopher Rolland** (Senior Equity Analyst)\nAnd this one's maybe for Hock and for Kirsten. I'd love to know, just because you have kind of the complete connectivity portfolio, how you see new greenfield scale-up opportunities playing out here between could be optical or copper or really anything and what additive this could be for your company. And then, Kirsten, I think OpEx is up. Maybe just talk about where those OpEx dollars are going towards within the AI opportunity and whether they relate. Thanks so much.\n\n**Hock Tan** (President and CEO)\nYour question is very broad reaching and our portfolio. Yeah, we have the advantage. And a lot of the hyperscale customers we deal with, they're talking about a lot of expansion. But it's almost all greenfield. Less so brownfield. It's very greenfield. It's all expansion. And it all tends to be next-generation that we do it, which is very exciting. So the opportunity is very, very high.\n\n**Hock Tan** (President and CEO)\nAnd we deploy. I mean, we can do it in copper, but what we see a lot of opportunity from is when you provide the networking connectivity through optical. So there are a lot of active elements, including either multi-mode lasers, which are called vixels, or edge-emitting lasers for basically single mode. And we do both. So there's a lot of opportunity. Just as in scale-up versus scale-out, we used to do, we still do a lot of other protocols beyond Ethernet to consider PCI Express, where we are on the leading edge of that PCI Express. And the architecture or networking switching, so to speak, we offer both. One is a very intelligent switch, which is like our Jericho family with a dumb NIC or a very smart NIC with a dumb switch, which is a Tomahawk. We offer both architectures as well.\n\n**Hock Tan** (President and CEO)\nSo yeah, we have a lot of opportunities from it. All things said and done, all this nice wide portfolio and all that adds up to probably, as I said in prior quarters, about 20% of our total AI revenue, maybe going to 30%. Though last quarter, we hit almost 40%, but that's not the norm. I would say typically, all those other portfolio products still add up to a nice decent amount of revenue for us, but within the sphere of AI, they add up to, I would say on average, be close to 30%. And XPUs, the accelerators, be 70%. If that's what you're driving, perhaps that gives you some shed some light on towards where how one matters over the other. But we have a wide range of products in the connectivity networking side of it. They just add up, though, to that 30%.\n\n**Christopher Rolland** (Senior Equity Analyst)\nThanks so much, Hock.\n\n**Kirsten Spears** (CFO)\nAnd then on the R&D front, as I outlined, on a consolidated basis, we spent $1.4 billion in R&D in Q1, and I stated that it would be going up in Q2. Hock clearly outlined in his script the two areas where we're focusing on. Now, I would tell you, as a company, we focus on R&D across all of our product lines so that we can stay competitive with next-generation product offerings. But he did line out that we were focusing on taping out the industry's first 2-nanometer AI XPU packaged in 3D. That was one in his script, and that's an area that we're focusing on. And then he mentioned that we've doubled the radix capacity of existing Tomahawk 5s to enable our AI customers to scale up on Ethernet towards the one million XPUs.\n\n**Kirsten Spears** (CFO)\nSo I mean, that's a huge focus of the company.\n\n**Christopher Rolland** (Senior Equity Analyst)\nYep. Thank you very much, Kirsten.\n\n**Operator**\nAnd one moment for our next question. And that will come from the line of Vijay Rakesh with Mizuho. Your line is open.\n\n**Vijay Rakesh** (Managing Director)\nYeah. Hi, Hock. Thanks, Tim. Just a quick question on the networking side. Just wondering how much is up sequentially on the AI side and any thoughts around M&A going forward? I've seen a lot of headlines around the Intel product group, etc. So thanks.\n\n**Hock Tan** (President and CEO)\nOkay. On the networking side, as I indicated, Q1 showed a bit of a surge, but I don't expect that to be that mix of 60-40, 60% compute and 40% networking to be something that is normal. I think the norm is closer to 70-30, maybe at best 30%. And so who knows what Q2 is?\n\n**Hock Tan** (President and CEO)\nWe kind of see Q2 as continuing, but that's just, in my mind, a temporary blip. The norm will be 70, 30. And if you take it across a period of time, like six months, a year, to answer your question. M&A, no, I'm too busy. We're too busy doing AI and VMware at this point. We're not thinking of it at this point.\n\n**Vijay Rakesh** (Managing Director)\nThanks, Hock.\n\n**Operator**\nThank you. That is all the time we have for our question-and-answer session. I would now like to turn the call back over to Ji Yoo for any closing remarks.\n\n**Ji Yoo** (Head of Investor Relations)\nThank you, Cherie. Broadcom currently plans to report its earnings for the second quarter of fiscal year 2025 after close of market on Thursday, June 5th, 2025. A public webcast of Broadcom's earnings conference call will follow at 2:00 P.M. Pacific. That will conclude our earnings call today. Thank you all for joining.\n\n**Ji Yoo** (Head of Investor Relations)\nCherie, you may end the call. Thank you.\n\n**Operator**\nLadies and gentlemen, thank you for participating. This concludes today's program. You may now disconnect.",
        "fetched_at": "2026-02-04T16:13:32.342Z"
      }
    ]
  },
  "AMD": {
    "ticker": "AMD",
    "last_updated": "2026-02-04T16:14:06.179Z",
    "total_transcripts": 5,
    "transcripts": [
      {
        "ticker": "AMD",
        "title": "Yahoo Finance",
        "published_date": "Feb 3, 2026, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/AMD/earnings/AMD-Q4-2025-earnings_call-395057.html",
        "content": "**Operator**\nGreetings, and welcome to the AMD Fourth Quarter and Full Year 2025 Conference Call. At this time, all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. If anyone should require operator assistance during the conference, please press star zero on your telephone keypad. Please note that this conference is being recorded. I will now turn the conference over to Matt Ramsay, VP Financial Strategy and IR. Thank you. You may begin.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nThank you, and welcome to AMD's Fourth Quarter and 2025 Full Year Financial Results Conference Call. By now, you should have had the opportunity to review a copy of our earnings press release and accompanying slides. If you have not had the opportunity to review these materials, they can be found on the investor relations page of amd.com. Today, we will refer primarily to non-GAAP financial measures on the call. The full non-GAAP-to-GAAP reconciliations are available in today's press release and in the slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and CEO, and Jean Hu, our Executive Vice President, CFO, and Treasurer. This is a live call and will be replayed via webcast on our website.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nBefore we begin, I would like to note that Mark Papermaster, Executive Vice President and CTO, will present at Morgan Stanley's TMT conference on Tuesday, March 3rd. Today's discussions contain forward-looking statements based on our current beliefs, assumptions, and expectations, speak only as of today, and as such involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause actual results to differ materially. With that, I will hand the call to Lisa.\n\n**Lisa Su** (Chairman and CEO)\nThank you, Matt, and good afternoon to all those listening today. 2025 was a defining year for AMD, with record revenue, net income, and free cash flow driven by broad-based demand for high-performance computing and AI products. We ended the year with significant momentum, with every part of our business performing very well. We saw demand accelerate across the data center, PC, gaming, and embedded markets, launched the broadest set of leadership products in our history, gained significant server and PC processor share, and rapidly scaled our data center AI business as Instinct and ROCm adoption increased with cloud, enterprise, and AI customers. Looking at our fourth quarter, fourth quarter revenue grew 34% year-over-year to $10.3 billion, led by record EPYC, Ryzen, and Instinct processor sales.\n\n**Lisa Su** (Chairman and CEO)\nNet income increased 42% to a record $2.5 billion, and free cash flow nearly doubled year-over-year to a record $2.1 billion. For the full year, revenue grew 34% to $34.6 billion, and we added more than $7.6 billion of data center segment and client revenue. Turning to our fourth quarter segment results, data center segment revenue increased 39% year-over-year to a record $5.4 billion, led by accelerating Instinct MI350 series GPU deployments and server share gains. In server, adoption of 5th-gen EPYC Turin CPUs accelerated in the quarter, accounting for more than half of the total server revenue. 4th-gen EPYC sales were also robust, as our prior generation CPUs continued to deliver superior performance and TCO compared to competitive offerings across a wide range of workloads.\n\n**Lisa Su** (Chairman and CEO)\nAs a result, we had record server CPU sales to both cloud and enterprise customers in the quarter and exited the year with record share. In cloud, hyperscaler demand was very strong as North American customers expanded deployments. EPYC-powered public cloud offerings grew significantly in the quarter, with AWS, Google, and others launching more than 230 new AMD instances. Hyperscalers launched more than 500 AMD-based instances in 2025, increasing the number of EPYC cloud instances more than 50% year over year to nearly 1,600. In the enterprise, we are seeing a meaningful shift in EPYC adoption driven by our leadership performance, expanded platform availability, broad software enablement, and increased go-to-market programs. The leading server providers now offer more than 3,000 solutions powered by fourth- and fifth-gen EPYC CPUs that are optimized for all major enterprise workloads.\n\n**Lisa Su** (Chairman and CEO)\nAs a result, the number of large businesses deploying EPYC on-prem more than doubled in 2025, and we exited the year with record server sell-through. Looking ahead, server CPU demand remains very strong. Hyperscalers are expanding their infrastructure to meet growing demand for cloud services and AI, while enterprises are modernizing their data centers to ensure they have the right compute required to enable new AI workflows. Against this backdrop, EPYC has become the processor of choice for the modern data center, delivering leadership performance, efficiency, and TCO. Our next-generation Venice CPU extends our leadership across each of these metrics. Customer pull for Venice is very high, with engagements underway to support large-scale cloud deployments and broad OEM platform availability when Venice launches later this year.\n\n**Lisa Su** (Chairman and CEO)\nTurning to our data center AI business, we delivered record Instinct GPU revenue in the fourth quarter, led by the ramp of MI350 series shipments. We also had some revenue from MI308 sales to customers in China. Instinct adoption broadened in the quarter. Today, 8 of the top 10 AI companies use Instinct to power production workloads across a growing range of use cases. With the MI350 series, we are entering the next phase of Instinct adoption, expanding our footprint with existing partners and adding new customers. In the fourth quarter, hyperscalers expanded MI350 series availability, leading AI companies scale their deployments to support additional workloads, and multiple neocloud providers launched MI350 series offerings that deliver on-demand access to Instinct infrastructure in the cloud.\n\n**Lisa Su** (Chairman and CEO)\nTurning to our AI software stack, we expanded the ROCm ecosystem in the fourth quarter, enabling customers to deploy Instinct faster and with higher performance across a broader range of workloads. Millions of large language and multimodal models run out of the box on AMD, with the leading models launching with day zero support for Instinct GPUs. This capability highlights our rapidly expanding open-source community enablement, including new upstream integration of AMD GPUs in vLLM, one of the most widely used inference engines. To drive Instinct adoption with industry-specific use cases, we're also adding support for domain-specific models in key verticals. As one example, in healthcare, we added ROCm support for the leading medical imaging framework to enable developers to train and deploy highly performant deep learning models on Instinct GPUs.\n\n**Lisa Su** (Chairman and CEO)\nFor large businesses, we introduced our Enterprise AI Suite, a full-stack software platform with enterprise-grade tools, inference microservices, and solutions blueprints designed to simplify and accelerate production deployments at scale. We also announced a strategic partnership with Tata Consultancy Services to co-develop industry-specific AI solutions and help customers deploy AI across their operations. Looking ahead, customer engagements for our next-gen MI400 series and Helios platform continue expanding. In addition to our multi-generation partnership with OpenAI to deploy 6 GW of Instinct GPUs, we are in active discussions with other customers on at-scale multi-year deployments starting with Helios and MI450 later this year. With the MI400 series, we are also expanding our portfolio to address the full range of cloud, HPC, and enterprise AI workloads.\n\n**Lisa Su** (Chairman and CEO)\nThis includes MI455X and Helios for AI superclusters, MI430X for HPC and sovereign AI, and MI440X servers for enterprise customers requiring leadership training and inference performance in a compact 8-GPU solution that integrates easily into existing infrastructure. Multiple OEMs publicly announced plans to launch Helios systems in 2026, with deep engineering engagement underway to support smooth production ramps. In December, HPE announced that they will offer Helios racks with purpose-built HPE Juniper Ethernet switches and optimized software for high-bandwidth scale-up networking. And in January, Lenovo announced plans to offer Helios racks. MI430X adoption also grew in the quarter, with new Exascale-class supercomputers announced by GENCI in France and HLRS in Germany. Looking further ahead, development of our next-generation MI500 series is well underway. MI500 is powered by our CDNA six architecture, built on advanced 2-nanometer process technology, and features high-speed HBM4e memory.\n\n**Lisa Su** (Chairman and CEO)\nWe are on track to launch MI500 in 2027 and expect MI500 to deliver another major leap in AI performance to power the next wave of large-scale multimodal models. In summary, our AI business is accelerating, with the launch of MI400 series and Helios representing a major inflection point for the business as we deliver leadership performance and TCO at the chip, compute tray, and rack level. Based on the strength of our EPYC and Instinct roadmaps, we are well positioned to grow data center segment revenue by more than 60% annually over the next three to five years and scale our AI business to tens of billions in annual revenue in 2027. Turning to client and gaming, segment revenue increased 37% year-over-year to $3.9 billion. In client, our PC processor business performed exceptionally well.\n\n**Lisa Su** (Chairman and CEO)\nRevenue increased 34% year-over-year to a record $3.1 billion, driven by increased demand for multiple generations of Ryzen desktop and mobile CPUs. Desktop CPU sales set a record for the fourth consecutive quarter. Ryzen CPUs topped the bestseller lists at major global retailers and e-tailers throughout the holiday period, with strong demand across all price points in every region driving record desktop channel sellout. In mobile, strong demand for AMD-powered notebooks drove record Ryzen PC sell-through in the quarter. That momentum extended into commercial PCs, where Ryzen adoption accelerated as we established a new long-term growth engine for our client business. Sell-through of Ryzen CPUs for commercial notebooks and desktops grew by more than 40% year-over-year in the fourth quarter, and we closed large wins with major telecom, financial services, aerospace, automotive, energy, and technology customers.\n\n**Lisa Su** (Chairman and CEO)\nAt CES, we expanded our Ryzen portfolio with CPUs that further extend our performance leadership. Our new Ryzen AI 400 mobile processors deliver significantly faster content creation and multitasking performance than the competition. Notebooks powered by Ryzen AI 400 are already available, with the broadest lineup of AMD-based consumer and commercial AI PCs set to launch throughout the year. We also introduced our Ryzen AI Halo platform, the world's smallest AI development system, featuring our highest-end Ryzen AI Max processor with 128 GB of unified memory that can run models with up to 200 billion parameters locally. In gaming, revenue increased 50% year-over-year to $843 million. Semi-custom sales increased year-over-year and declined sequentially, as expected. For 2026, we expect semi-custom SoC annual revenue to decline by a significant double-digit percentage as we enter the seventh year of what has been a very strong console cycle.\n\n**Lisa Su** (Chairman and CEO)\nFrom a product standpoint, Valve is on track to begin shipping its AMD-powered Steam Machine early this year, and development of Microsoft's next-gen Xbox featuring an AMD semi-custom SoC is progressing well to support a launch in 2027. Gaming GPU revenue also increased year-over-year, with higher channel sellout driven by demand throughout the holiday sales period for our latest generation Radeon RX 9000 Series GPUs. We also launched FSR 4 Redstone in the quarter, our most advanced AI-powered upscaling technology, delivering higher image quality and smoother frame rates for gamers. Turning to our embedded segment, revenue increased 3% year-over-year to $950 million, led by strength with test and measurement and aerospace customers and growing adoption of our embedded x86 CPUs. Channel sell-through accelerated in the quarter as end-customer demand improved across several end markets, led by test, measurement, and emulation.\n\n**Lisa Su** (Chairman and CEO)\nDesign win momentum remains one of the clearest indicators of long-term growth for our embedded business, and we delivered another record year. We closed $17 billion in design wins in 2025, up nearly 20% year-over-year, as we've now won more than $50 billion of embedded designs since acquiring Xilinx. We also strengthened our embedded portfolio in the quarter. We began production of our Versal AI Edge Gen 2 SoCs for low-latency inference workloads and started shipping our highest-end Spartan UltraScale+ devices for cost-optimized applications. We also launched new embedded CPUs, including our EPYC 2005 Series for network security and industrial edge applications, Ryzen P100 Series for in-vehicle infotainment and industrial systems, and Ryzen X100 Series for physical AI and autonomous platforms. In summary, 2025 was an excellent year for AMD, marking the start of a new growth trajectory for the company.\n\n**Lisa Su** (Chairman and CEO)\nWe are entering a multi-year demand supercycle for high performance and AI computing that is creating significant growth opportunities across each of our businesses. AMD is well positioned to capture that growth, with highly differentiated products, a proven execution engine, deep customer partnerships, and significant operational scale. As AI reshapes the compute landscape, we have the breadth of solutions and partnerships required for end-to-end leadership, from Helios in the cloud for at-scale training and inference to an expanded Instinct portfolio for sovereign supercomputing and enterprise AI deployment. At the same time, demand for EPYC CPUs is surging as agentic and emerging AI workloads require high-performance CPUs to power head nodes and run parallel tasks alongside GPUs. At the edge and in PCs where AI adoption is just beginning, our industry-leading Ryzen and embedded processors are powering real-time on-device AI.\n\n**Lisa Su** (Chairman and CEO)\nAs a result, we expect significant top-line and bottom-line growth in 2026, led by increased adoption of EPYC and Instinct, continued client share gains, and a return to growth in our embedded segment. Looking further ahead, we see a clear path to achieve the ambitious targets we laid out at our financial analyst day last November, including growing revenue at greater than 35% CAGR over the next three to five years, significantly expanding operating margins, and generating annual EPS of more than $20 in the strategic time frame, driven by growth in all of our segments and the rapid scaling of our data center AI business. Now I'll turn the call over to Jean to provide additional color on our fourth quarter results and full-year results. Jean?\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the first quarter of fiscal 2026. AMD executed very well in 2025, delivering record revenue of $34.6 billion, up 34% year-over-year, driven by 32% growth in our data center segment and 51% growth in our client and gaming segment. Gross margin was 52%, and we delivered record earnings per share of $4.17, up 26% year-over-year while continuing to invest aggressively in AI and the data center to support our long-term growth. For the fourth quarter of 2025, revenue was a record $10.3 billion, growing 34% year-over-year, driven by strong growth in the data center and client gaming segments, including approximately $390 million in revenue from MI308 sales to China, which was not included in our fourth quarter guidance.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nRevenue was up 11% sequentially, primarily driven by continued strong growth in data center from both server and data center AI businesses, as well as a return to year-over-year growth in the embedded segment. Gross margin was 57%, up 290 basis points year-over-year. We benefited from the release of $360 million in previously written-down MI308 inventory reserves. Excluding the inventory reserve release and the MI308 revenue from China, gross margin would have been approximately 55%, up 80 basis points year-over-year, driven by favorable product mix. Operating expenses were $3 billion, an increase of 42% year-over-year as we continue to invest in R&D go-to-market activities to support our AI roadmap and long-term growth opportunities, as well as higher employee performance-based incentives.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nOperating income was a record $2.9 billion, representing a 28% operating margin, tax increase, and other, resulting in a net expense of approximately $335 million. For the fourth quarter, diluted earnings per share was a record $1.53, an increase of 40% year-over-year, reflecting strong execution and operating leverage in our business model. Now turning to our reportable segment. Starting with the data center segment, revenue was a record $5.4 billion, up 39% year-over-year and 24% sequentially, driven by strong demand for EPYC processors and the continued ramp of MI350 products. Data center segment operating income was $1.8 billion, or 33% of revenue, compared to $1.2 billion, or 30% a year ago, reflecting higher revenue and the inventory reserve release, partially offset by continued investment to support our AI hardware and software roadmaps.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nClient gaming segment revenue was $3.9 billion, up 37% year-over-year, driven primarily by strong demand for our leadership AMD Ryzen processors. On a sequential basis, revenue was down 3% due to lower semi-customer revenue. The client business revenue was a record $3.1 billion, up 34% year-over-year and 13% sequentially, led by strong demand from both the channel and the PC OEMs and continued market share gains. The gaming business revenue was $843 million, up 50% year-over-year, primarily driven by higher semi-customer revenue and strong demand for AMD Radeon GPUs. Sequentially, gaming revenue was down 35% due to lower semi-customer sales. Client gaming segment operating income was $725 million, or 18% of revenue, compared to $496 million, or 17% a year ago. Embedded segment revenue was $950 million, up 3% year-over-year and 11% sequentially as demand strengthened across several end markets.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nEmbedded segment operating income was $357 million, or 38% of revenue, compared to $362 million, or 39% a year ago. Before I reveal the balance sheet and the cash flow, as a reminder, we closed the sale of ZT Systems manufacturing business to Sanmina in late October. The fourth quarter financial results of the ZT manufacturing business are reported separately in our financial statement as discontinued operations and are excluded from our non-GAAP financials. Turning to the balance sheet and the cash flow. During the quarter, we generated a record $2.3 billion in cash from continuing operations and a record of $2.1 billion in free cash flow. Inventory increased sequentially by approximately $607 million-$7.9 billion to support strong data center demand. At the end of the quarter, cash, cash equivalents, and short-term investment were $10.6 billion.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nFor the year, we repurchased 12.4 million shares and returned $1.3 billion to shareholders. We ended the year with $9.4 billion authorization remaining and our share repurchase program. Now turning to our first quarter 2026 outlook. We expect revenue to be approximately $9.8 billion, plus or minus $300 million, including approximately $100 million of MI308 sales to China. At the middle point of our guidance, revenue is expected to be up 32% year-over-year, driven by strong growth in our data center and client gaming segments and modest growth in our embedded segment. Sequentially, we expect revenue to be down approximately 5%, driven by seasonal decline in our client gaming and embedded segment, partially offset by growth in our data center segment.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nIn addition, we expect fourth quarter non-GAAP gross margin to be approximately 55%, non-GAAP operating expense to be approximately $3.05 billion, non-GAAP other net income to be approximately $35 million, non-GAAP effective tax rate to be 13%, and diluted share count is expected to be approximately 1.65 billion shares. In closing, 2025 was an outstanding year for AMD, reflecting disciplined execution across the business to deliver strong revenue growth, increase profitability, and cash generation while investing aggressively in AI and innovation to support our long-term growth strategy. Looking ahead, we are very well positioned for continued strong top-line revenue growth and earnings expansion in 2026 with a focus on driving data center AI growth, operating leverage, and delivering long-term value to shareholders. With that, I'll turn it back to Matt for the Q&A session.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nYes. Thank you very much, Jean. Operator, please go ahead and open the Q&A session. Thank you.\n\n**Operator**\nThank you, Matt. We will now be conducting the question-and-answer session. If you would like to ask a question, please press star one on your telephone keypad. A confirmation tone will indicate that your line is in the queue. You may press star two to remove yourself from the queue. For participants using speaker equipment, it may be necessary to pick up your handset before pressing the star keys. One moment, please, while we pull for questions. And the first question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.\n\n**Aaron Rakers** (Managing Director and Senior Equity Research Analyst)\nYeah. Thanks for taking the question. Lisa, at your analyst day back in November, you seemed to kind of endorse the high $20 billion AI revenue expectation that was out there on the street for 2027. I know today you're reaffirming the path to strong double-digit growth. So I guess my question is, can you talk a little bit about what you've seen as far as customer engagements, how those might have expanded? I think you've alluded to in the past multiple multi-gigawatt opportunities. Just double-click on what you've seen for the MI455 and Helios platform from a demand-shaping perspective as we look into the back half of the year.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Sure, Aaron. Thanks for the question. So first of all, I think the MI450 series development is going extremely well. So we're very happy with the progress that we have. We're right on track for a second-half launch and beginning of production. And as it relates to sort of the shape of the ramp and the customer engagements, I would say the customer engagements continue to proceed very well. We have, obviously, a very strong relationship with OpenAI, and we're planning that ramp starting in the second half of the year, going into 2027. That is on track. We're also working closely with a number of other customers who are very interested in ramping MI450 quickly, just given the strength of the product. And we see that across both inference and training. And that is the opportunity that we see in front of us.\n\n**Lisa Su** (Chairman and CEO)\nSo we feel very good about sort of the data center growth overall for us in 2026. And then certainly, going into 2027, we've talked about $ tens of billions of data center AI revenue, and we feel very good about that.\n\n**Operator**\nThank you. The next question comes from the line of Tim Arcuri with UBS. Please proceed with your question.\n\n**Tim Arcuri** (Managing Director and Senior Equity Analyst)\nThanks a lot. Jean, I'm wondering if you can maybe give us a little bit of detail under the hood for the March guidance. I know you basically told us that you told us about what embedded's going to be up a bit year over year. Client sounds like it's down seasonally, which I take to be maybe down 10. So can you give us a sense maybe of the other pieces? And then also, can you give us a sense of how data center GPU is going to ramp through the year? I know it's a back half loaded year, but I think people are thinking, Lisa, somewhere in the $14 billion range this year. That's what investors were thinking. I'm not asking you to endorse that.\n\n**Tim Arcuri** (Managing Director and Senior Equity Analyst)\nIf you can give us a little flavor for sort of how the ramp will look through the year, that'd be great. Thanks.\n\n**Lisa Su** (Chairman and CEO)\nHi, Tim. Thanks for your question. We're guiding one quarter at a time, but I can give you some color about our Q1 guide. First, it's right sequentially, we guided the decline around 5%, but data center is actually going to be up. And when you think about it, it's right. Our CPU business seasonal, actually, in a regular seasonal pattern, it's going to be down high single digit. And in our current guide, we actually guide CPU revenue up sequentially very nicely. Also, with the data center GPU side, we also feel really good about GPU revenue, including China, will be also up. So very nice guide for the data center overall. On the client side, we do see seasonality, sequentially decline. Embedded and gaming, they also have a seasonal decline.\n\n**Lisa Su** (Chairman and CEO)\nAnd maybe, Tim, if I just give you a little bit on the full-year commentary. I think the important thing, as we look at the full year, we're very bullish on the year. We're not, if you look at the key themes, we're seeing very strong growth in the data center. And that's across two growth vectors. We see server CPU growth, actually, very strong. I mean, we've talked about the fact that CPUs are very important as AI continues to ramp. And we've seen the CPU order book continue to strengthen as we go through the last few quarters and especially over the last 60 days. So we see that as a strong growth driver for us. As Jean said, we see server CPU growing from Q4 into Q1 in what normally is seasonally down. And that continues throughout the year.\n\n**Lisa Su** (Chairman and CEO)\nThen on the data center AI side, it's a very important year for us. It's really an inflection point. MI355 has done well, and we were pleased with the performance in Q4. We continue to ramp that in the first half of the year. As we get into the second half of the year, the MI450 is really an inflection point for us. That revenue will start in the third quarter, but it will ramp significant volume in the fourth quarter as we get into 2027. That gives you a little bit of sort of what the data center ramp looks like throughout the year.\n\n**Tim Arcuri** (Managing Director and Senior Equity Analyst)\nThank you, Lisa.\n\n**Operator**\nThe next question comes from the line of Vivek Arya with Bank of America. Please proceed.\n\n**Vivek Arya** (Managing Director and Senior Equity Research Analyst)\nThank you. First, just clarification on what you're assuming for your China MI308 sales beyond Q1. And then, Lisa, specific to 2026, can your data center revenues grow at your target 60%+ growth rate? I realize that that's a multi-year target, but do you think that there are enough drivers, whether it's on the server CPU side or GPU side, for you to grow at that target base even in 2026? Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Sure, Vivek. So let me talk a little bit about China first because that's, I think, important for us to make sure that's clear. Look, we were pleased to have some MI308 sales in the fourth quarter. They were actually a license that was approved through work with the administration. And those orders were actually from very early in 2025. And so we saw some revenue in Q4, and we're forecasting for about $100 million of revenue in Q1. We are not forecasting any additional revenue from China just because it's a very dynamic situation. So given that it's a dynamic situation, we're still waiting. We've submitted licenses for the MI325, and we're continuing to work with customers and understanding sort of their customer demand. We thought it prudent not to forecast any additional revenue other than the $100 million that we called out in the Q1 guide.\n\n**Lisa Su** (Chairman and CEO)\nNow, as it relates to overall data center, as I mentioned in the question to Tim, we're very bullish about data center. I think the combination of drivers that we have across our CPU franchise, I mean, the EPYC product line, both Turin and Genoa, continue to ramp well. And in the second half of the year, we will be launching Venice, which we believe actually extends our leadership. And the MI450 ramp, which is also very significant in the second half of 2026. We're not, obviously, guiding specifically by segment, but the long-term target of, let's call it, greater than 60% is certainly possible in 2026.\n\n**Vivek Arya** (Managing Director and Senior Equity Research Analyst)\nThank you, Lisa.\n\n**Operator**\nThank you. And as a reminder, if you would like to ask a question, please press star one. We ask that you limit yourself to one question and one follow-up. Thank you. The next question comes from the line of CJ Muse with Cantor. Please proceed.\n\n**C.J. Muse** (Senior Managing Director and Senior Equity Research Analyst)\nYeah. Good afternoon. Thanks for taking the question. I'm curious on the server CPU side of the house. And given the dramatic tightness, curious your ability to source incremental capacity from TSMC and elsewhere. And I guess how long will it take for that to see wafers out? And how should we think about the implications for kind of the growth trajectory throughout all of calendar 2026? And I guess as part of that, if you could speak to how we should be thinking about inflection in pricing as well, that would be very helpful.\n\n**Lisa Su** (Chairman and CEO)\nSure, CJ. So a couple of points about the server CPU market. First of all, we think the overall server CPU TAM is going to grow, let's call it, strong double digits in 2026, just given, as we said, the relationship between CPU demand and overall AI ramp. So I think that's a positive. Relative to our ability to support that, we've been seeing this trend for the last couple of quarters. So we have increased our supply capacity capability for server CPUs. And that's one of the reasons we're able to increase our Q1 guide as it relates to the server business. And we see the ability to continue to grow that throughout the year. There's no question that demand continues to be strong. And so we're working with our supply chain partners to increase supply as well.\n\n**Lisa Su** (Chairman and CEO)\nFrom what we see today, I think the overall server situation is strong. We are increasing supply to address that.\n\n**Operator**\nHey, C.J. Do you have a follow-up question?\n\n**C.J. Muse** (Senior Managing Director and Senior Equity Research Analyst)\nI do. Maybe for Jean, if you could kind of touch on gross margins through the year. And as you balance kind of strengthening server CPU with perhaps greater GPU accelerating in the second half, is there kind of a framework that we should be working off of? Thanks so much.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nYeah. Thank you for the question. We are very pleased with our gross margin Q4 performance and the Q1 guide at 55%, which actually is 130 basis points up year-over-year while we continue to ramp our MI355 year-over-year very significantly. I think we are benefiting from a very favorable product mix across all our business. If you think about it in data center, we're ramping our new product, new generation product, Turin, and the MI355, which helps the gross margin in client. We continue to move up the stack and also gaining momentum in our commercial business. Our client business gross margin has been improving nicely. In addition, certainly, we see the recovery of our embedded business, which is also margin accretive. So all those tailwinds we are seeing, we continue to see in the next few quarters.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nWhen MI450 ramp, of course, in Q4, our gross margin will be driven largely by mix. I think we'll give you more color when we get there. Overall, we feel really good about our gross margin progression this year.\n\n**Operator**\nThank you. The next question comes from the line of Joe Moore with Morgan Stanley. Please proceed.\n\n**Joe Moore** (Managing Director and Head of U.S. Semiconductors Research)\nGreat. Thank you. On the MI455 ramp, will 100% of the business be racks? Will there be kind of an eight-way server business around that architecture? And then is the revenue recognition when you ship to the rack vendor, or is there something to understand about that? Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYes, Joe. So we do have multiple variants of the MI450 series, including an eight-way GPU form factor. But for 2026, I would say the vast majority of it is going to be rack-scale solutions. And yes, we will take revenue when we ship to the rack builder.\n\n**Joe Moore** (Managing Director and Head of U.S. Semiconductors Research)\nOkay. Great. And then can you talk to any risks that you may have in terms of once you get silicon out, turning that into racks, any potential issues as you ramp that? I know your competitor had some last year, and you said you learned from that. Is there anything you've done with kind of pre-building racks to sort of ensure you won't have those issues? Just any risk do we need to understand around that?\n\n**Lisa Su** (Chairman and CEO)\nYeah. I mean, Joe, the main thing is the development's going really well. We're right on track with the MI450 series as well as the Helios rack development. We've done a lot of testing already, both at the rack-scale level as well as at the silicon level. So far, so good. We are getting, let's call it, a lot of input from our customers on things to test so that we can do a lot of testing in parallel. And our expectation is that we will be on track for our second-half launch.\n\n**Operator**\nThank you. Our next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nHi, guys. Thanks for taking my questions. First one, Lisa, I just wanted to ask about OpEx. Every quarter, you guys are guiding it up, and then it's coming in even higher, and then you're guiding it up again. And I understand, given the growth trajectory, that you need to invest. But how should we think about the ramp of that OpEx and that spending number, especially as the GPU revenue starts to inflect? Do we get leverage on that, or should we be expecting the OpEx to be growing even more materially as the AI revenue starts to ramp?\n\n**Lisa Su** (Chairman and CEO)\nYeah. Sure, Stacy. Thanks for the question. Look, I think in terms of OpEx, we're at a point where we have very high conviction in the roadmap that we have. And so in 2025, as the revenue increased, we did lean in on OpEx. And I think it was for all the right reasons. As we get into 2026 and as we see some of the significant growth that we're expecting, we should absolutely see leverage. And the way to think about it is we've always said in our long-term model that OpEx should grow slower than revenue. And we would expect that in 2026 as well, especially as we get into the second half of the year and we see inflection in the revenue.\n\n**Lisa Su** (Chairman and CEO)\nBut at this point, I think if you look at our free cash flow generation and the overall revenue growth, I think the investment in OpEx is absolutely the right thing to do.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nThank you. For my follow-up, I actually have two sort of one-line answers I'm looking for. Just first, the $100 million in China revenue in Q1, does that also drop through a zero-cost basis like we had in Q4, and is that a margin headwind? And number two, I know you don't give us the AI number, but could you just give us the annual 2025 Instinct number now that we're through the year? How big was it?\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nStacy, let me answer your first question on the $100 million revenue in Q1. Actually, the inventory reserve reversed in Q4, which was $360 million, not only is associated with Q4 revenue, China revenue, but also covers the $100 million revenue we expect to ship in Q1 to China with our MI308. The Q1 gross margin guide is a very clean guide.\n\n**Lisa Su** (Chairman and CEO)\nStacy, for your second question, as you know, we don't guide at the business level. But to help you with your models, I think you can if you look at the Q4 data center AI number, even if you were to back out the China number, which was, let's call it, not a recurring number, you would still see growth. You'll see growth from Q3 to Q4. So that should help you a little bit with your modeling.\n\n**Operator**\nThank you. The next question comes from the line of Joshua Buchalter with TD Cowen. Please proceed.\n\n**Joshua Buchalter** (Director and Senior Equity Research Analyst)\nHey, guys. Thanks for taking my question. I wanted to ask about clients. So the segment beat pretty handily in the fourth quarter. And I recognize you guys have been gaining share with Ryzen. But I think given what we've been seeing in the memory market, there's a lot of concern about inflationary costs and the potential for pull-ins. Were there any changes in your order patterns during the quarter? And maybe bigger picture, how are you thinking about client growth and the health of that market into 2026?\n\n**Lisa Su** (Chairman and CEO)\nYeah. Thanks for the question, Josh. The client market has performed extremely well for us throughout 2025. Very strong growth for us, both in terms of ASP mixing up the stack as well as just unit growth. Going into 2026, we are certainly watching the development of the business. I think the PC market is an important market. Based on everything that we see today, we're probably seeing the PC TAM down a bit, just given some of the inflationary pressures of the commodities pricing, including memory. The way we are modeling the year is, let's call it, second half a bit subseasonal to first half, just given everything that we see. Even in that environment with the PC market down, we believe we can grow our PC business. Our focus areas are enterprise.\n\n**Lisa Su** (Chairman and CEO)\nThat's a place where we're making very nice progress in 2025, and we expect that into 2026, and just continuing to grow sort of at the premium, higher end of the market.\n\n**Joshua Buchalter** (Director and Senior Equity Research Analyst)\nThank you for the color there. Then I wanted to ask about the Instinct family. So we've seen your big GPU competitor make a deal with an SRAM-based spatial architecture provider. And then OpenAI has reportedly been linked to one as well. Could you speak to the competitive implications of that? You've done well in inferencing, I think, partly because of your leadership in HBM content. So I was wondering if you could maybe address the pull seemingly motivated by lower latency inference and how Instinct is positioned to service this if you're indeed seeing it as well. Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah. I think, Josh, it's really, I think, the evolution that you might expect as the AI market matures. What we're seeing is, as inference ramps, really the tokens per dollar or the efficiency of the inference stack becomes more and more important. As you know, with our chiplet architecture, we have a lot of ability to optimize across inference, training, and even across sort of the different stages of inference as well. So I think I view this as very much as you go into the future, you'll see more workload-optimized products. And you can do that with GPUs as well as with other more ASIC-like architectures. I think we have the full compute stack to do all of those things.\n\n**Lisa Su** (Chairman and CEO)\nFrom that standpoint, we're going to continue to lean into inference as we view that as a significant opportunity for us in addition to ramping our training capabilities.\n\n**Operator**\nThank you. The next question comes from the line of Ben Reitzes with Melius Research. Please proceed.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nYeah. Hey. Thanks. Appreciate it. Hey, Lisa, I wanted to ask you about OpenAI. I'm sure a lot of the volatility out there is not lost on you. Is everything on track for the second half for starting the 6 GW and the three and a half year timeline as far as you know? And is there any other color that you'd just like to give on that relationship? And then I have a follow-up. Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah. I mean, Ben, what I would say is we're very much working in partnership with OpenAI as well as our CSP partners to deliver on MI450 series and deliver on the ramp. The ramp is on schedule to start in the second half of the year. MI450 is doing great. Helios is doing well. We are in, let's call it, deep co-development across all of those parties. And as we look forward, I think we are optimistic about the MI450 ramp for OpenAI. But I also want to remind everyone that we have a broad set of customers that are very excited about MI450 series. And so in addition to the work that we're doing with OpenAI, there are a number of customers that we're working to ramp in that timeframe as well.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nAll right. I appreciate that. I wanted to shift to the server CPU and just talk about x86 versus ARM. There's some view out there that x86 has particular edge in agents, big picture. Do you agree with that? And what are you seeing from customers? And in particular, obviously, your big competitor is going to be selling an ARM CPU separately now in the second half. So if there's just anything on that competitive dynamic versus ARM and what NVIDIA is doing and your views on that, that'd be great to hear. Thanks.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Ben, what I would say about the CPU market is there is a great need for high-performance CPUs right now. And that goes towards agentic workloads where when you have these AI processes or AI agents that are spinning off a lot of work in an enterprise, they're actually going to a lot of traditional CPU tasks. And the vast majority of them are on x86 today. I think the beauty of EPYC is that we've optimized. We've done workload optimization. So we have the best cloud processor out there. We have the best enterprise processor. We also have some lower-cost variants for storage and other elements. And I think all of that comes into play as we think about the entirety of the AI infrastructure that needs to be put in place.\n\n**Lisa Su** (Chairman and CEO)\nI think the CPUs are going to continue to be as important as a piece of the AI infrastructure ramp. That's one of the things that we mentioned at our Analyst Day back in November, really this multi-year CPU cycle. We continue to see that. I think we've optimized EPYC to satisfy all of those workloads. We're going to continue to work with our customers to expand our EPYC footprint.\n\n**Operator**\nThe next question comes from the line of Tom O'Malley with Barclays. Please proceed.\n\n**Tom O'Malley** (Director and Senior Equity Research Analyst)\nHey, Lisa. How are you? I just wanted to ask, you mentioned on memory earlier as a sticking point in terms of inflationary cost. Different customers do this in different ways. Different suppliers do this in different ways. But could you maybe talk about your procurement of memory, when that takes place, particularly on the HBM side? Is that something that gets done a year in advance, six months in advance? Different accelerator guys have talked about different timelines. We'd be curious to kind of hear when you do the procurement.\n\n**Lisa Su** (Chairman and CEO)\nYeah. I mean, given the lead times for things like HBM and wafers and these parts of the supply chain, I mean, we're working closely with our suppliers over a multi-year timeframe in terms of what we see in demand, how we ramp, how we ensure that our development is very closely tied together. So I feel very good about our supply chain capabilities. We have been planning for this ramp. So independent of the current market conditions, we've been planning for a significant ramp in both CPU as well as our GPU business over the past couple of years. And so from that standpoint, I think we're well-positioned to grow substantially in 2026. And now we're also doing multi-year agreements that extend beyond that given tightness of the supply chain.\n\n**Tom O'Malley** (Director and Senior Equity Research Analyst)\nThanks. And just as a follow-up, you've seen a variety of different things in the industry in terms of system accelerator, so KV cache offload, more discrete ASIC-style compute, CPX. If you look at what your competitors are doing and you look at your first generation of system architecture coming out, maybe spend some time on, do you see yourself following in the footsteps of some of these different types of architectural changes? Do you think that you'll go in a different direction? Anything just on the evolution of your system-based architecture and then the adjoining products and/or silicon within. Thank you.\n\n**Lisa Su** (Chairman and CEO)\nI think, Tom, what we have is the ability with a very flexible architecture with our chiplet architecture. And then we also have a flexible platform architecture that allows us to really have different system solutions for the different requirements. I think we're very cognizant that there will be different solutions. So there's noI've often said there's no one-size-fits-all. And I'll say that again. There's no one-size-fits-all. But that being the case, it's clear that the rack scale architecture is very, very good for the highest-end applications when you're talking about distributed inference and training. But we also see an opportunity with enterprise AI to use some of these other form factors. And so we're investing across that spectrum.\n\n**Operator**\nThe next question comes from the line of Ross Seymore with Deutsche Bank. Please proceed.\n\n**Ross Seymore** (Managing Director and Senior Equity Research Analyst)\nHi. Thanks for my last couple of questions. I guess my first question is back on the gross margin side of things. As you go from the MI300 to the 400 to the 500 eventually, do you see any changes in the gross margin throughout that period? In the past, you've talked about optimizing dollars more so than percentages. But just on the percentage side, does it go up, down? Is there volatility as you go from one to the next for any reason? Just wondered on the trajectory there.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nRoss, thank you for the question. At a very high level, each generation, we actually provide much more capabilities, more memory, help our customer more. So in general, the gross margin should progress each generation when you offer more capabilities to your customers. But typically, when you first ramp at the beginning of ramp of a generation, it tends to be lower. When you get to the scale, get to the yield improvement, the test improvement, and also overall performance improvement, you will see gross margin improving within each generation. So it's kind of a dynamic gross margin. But in the longer term, you should expect each generation should have a higher gross margin.\n\n**Ross Seymore** (Managing Director and Senior Equity Research Analyst)\nThanks for that, Jean. Then one small segment of your business, but it seems quite volatile. You talked a little bit about further off than you usually do, is the gaming side of things. What is the magnitude down you're talking about this year? Because in 2025, you thought it was going to be flat. And it ended up growing 50%, which was a nice positive surprise. But now that you're talking about this year being down, but then the next-gen Xbox ramping in 2027, I just hope to get some color on what you see as kind of the annual trajectory there.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nYeah. So Lisa can add more. So 2026, actually, it's the seventh year of a current product cycle. Typically, when you're at this stage of the cycle, revenue tends to come down. We do expect the revenue on the semi-customer revenue side to come down significantly, double-digit for 2026, as Lisa mentioned in her prepared remarks. For the next generation?\n\n**Lisa Su** (Chairman and CEO)\nYeah. Yeah. I think we'll certainly talk about that going forward. But as we ramp the new generation, you would expect a reversal of that.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nOperator, I think we have time for one more caller on the call, please. Thank you.\n\n**Operator**\nOur final question comes from the line of Jim Schneider with Goldman Sachs. Please proceed.\n\n**Jim Schneider** (Senior Equity Analyst)\nGood afternoon. Thanks for taking my question. Relative to the ramp of your rack-scale systems, would you expect any kind of bottleneck in terms of supply constraints in terms of the ramp as you ramp the second half of the year to potentially impact or limit the revenue growth? In other words, maybe talk about whether you expect supply to really kind of meet the growth in Q4 sequentially relative to sorry, Q3 relative to Q4.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Jim, we are planning this at every component level. So I think relative to our data center AI ramp, I do not believe that we will be supply-limited in terms of the ramp that we put in place. I think we have an aggressive ramp. I think it's a very doable ramp. And as we think about the size and scale of AMD, clearly, our priority is ensuring that the data center ramps go very well. And that's both on the data center AI, the GPU side, as well as on the CPU side.\n\n**Jim Schneider** (Senior Equity Analyst)\nThank you. And then maybe as a follow-up to the earlier question on OPEX, could you maybe address what are some of the largest investment areas you made in 2025? And then what are the largest incremental OPEX investment areas for 2026? Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah, Jim. On the 2025 investment, the priority and the largest investment in data center AI, our hardware roadmap, we accelerated that roadmap. We expand our software capabilities. We also acquired ZT Systems, which add significant system-level solutions and capabilities. Those are the primary investment in 2025. We also invest heavily in go-to-market to really expand our go-to-market capabilities to support revenue growth and also expand our commercial business and enterprise business for our CPU franchise. In 2026, you should expect us to continue to invest aggressively. But as Lisa mentioned earlier, we do expect revenue to expand faster than operating expense increase to drive the earnings per share expansion.\n\n**Jim Schneider** (Senior Equity Analyst)\nAll right. Thank you, everybody, for participating on the call. Operator, I think we can go ahead and close the call now. Thank you. Good evening.\n\n**Operator**\nThank you. Ladies and gentlemen, that does conclude the question-and-answer session. That also concludes today's teleconference. You may disconnect your lines at this time and have a great rest of the day.",
        "fetched_at": "2026-02-04T16:13:47.194Z"
      },
      {
        "ticker": "AMD",
        "title": "Yahoo Finance",
        "published_date": "Feb 3, 2026, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q4",
        "url": "https://finance.yahoo.com/quote/AMD/earnings/AMD-Q4-2025-earnings_call-395057.html",
        "content": "**Operator**\nGreetings, and welcome to the AMD Fourth Quarter and Full Year 2025 Conference Call. At this time, all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. If anyone should require operator assistance during the conference, please press star zero on your telephone keypad. Please note that this conference is being recorded. I will now turn the conference over to Matt Ramsay, VP Financial Strategy and IR. Thank you. You may begin.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nThank you, and welcome to AMD's Fourth Quarter and 2025 Full Year Financial Results Conference Call. By now, you should have had the opportunity to review a copy of our earnings press release and accompanying slides. If you have not had the opportunity to review these materials, they can be found on the investor relations page of amd.com. Today, we will refer primarily to non-GAAP financial measures on the call. The full non-GAAP-to-GAAP reconciliations are available in today's press release and in the slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and CEO, and Jean Hu, our Executive Vice President, CFO, and Treasurer. This is a live call and will be replayed via webcast on our website.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nBefore we begin, I would like to note that Mark Papermaster, Executive Vice President and CTO, will present at Morgan Stanley's TMT conference on Tuesday, March 3rd. Today's discussions contain forward-looking statements based on our current beliefs, assumptions, and expectations, speak only as of today, and as such involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause actual results to differ materially. With that, I will hand the call to Lisa.\n\n**Lisa Su** (Chairman and CEO)\nThank you, Matt, and good afternoon to all those listening today. 2025 was a defining year for AMD, with record revenue, net income, and free cash flow driven by broad-based demand for high-performance computing and AI products. We ended the year with significant momentum, with every part of our business performing very well. We saw demand accelerate across the data center, PC, gaming, and embedded markets, launched the broadest set of leadership products in our history, gained significant server and PC processor share, and rapidly scaled our data center AI business as Instinct and ROCm adoption increased with cloud, enterprise, and AI customers. Looking at our fourth quarter, fourth quarter revenue grew 34% year-over-year to $10.3 billion, led by record EPYC, Ryzen, and Instinct processor sales.\n\n**Lisa Su** (Chairman and CEO)\nNet income increased 42% to a record $2.5 billion, and free cash flow nearly doubled year-over-year to a record $2.1 billion. For the full year, revenue grew 34% to $34.6 billion, and we added more than $7.6 billion of data center segment and client revenue. Turning to our fourth quarter segment results, data center segment revenue increased 39% year-over-year to a record $5.4 billion, led by accelerating Instinct MI350 series GPU deployments and server share gains. In server, adoption of 5th-gen EPYC Turin CPUs accelerated in the quarter, accounting for more than half of the total server revenue. 4th-gen EPYC sales were also robust, as our prior generation CPUs continued to deliver superior performance and TCO compared to competitive offerings across a wide range of workloads.\n\n**Lisa Su** (Chairman and CEO)\nAs a result, we had record server CPU sales to both cloud and enterprise customers in the quarter and exited the year with record share. In cloud, hyperscaler demand was very strong as North American customers expanded deployments. EPYC-powered public cloud offerings grew significantly in the quarter, with AWS, Google, and others launching more than 230 new AMD instances. Hyperscalers launched more than 500 AMD-based instances in 2025, increasing the number of EPYC cloud instances more than 50% year over year to nearly 1,600. In the enterprise, we are seeing a meaningful shift in EPYC adoption driven by our leadership performance, expanded platform availability, broad software enablement, and increased go-to-market programs. The leading server providers now offer more than 3,000 solutions powered by fourth- and fifth-gen EPYC CPUs that are optimized for all major enterprise workloads.\n\n**Lisa Su** (Chairman and CEO)\nAs a result, the number of large businesses deploying EPYC on-prem more than doubled in 2025, and we exited the year with record server sell-through. Looking ahead, server CPU demand remains very strong. Hyperscalers are expanding their infrastructure to meet growing demand for cloud services and AI, while enterprises are modernizing their data centers to ensure they have the right compute required to enable new AI workflows. Against this backdrop, EPYC has become the processor of choice for the modern data center, delivering leadership performance, efficiency, and TCO. Our next-generation Venice CPU extends our leadership across each of these metrics. Customer pull for Venice is very high, with engagements underway to support large-scale cloud deployments and broad OEM platform availability when Venice launches later this year.\n\n**Lisa Su** (Chairman and CEO)\nTurning to our data center AI business, we delivered record Instinct GPU revenue in the fourth quarter, led by the ramp of MI350 series shipments. We also had some revenue from MI308 sales to customers in China. Instinct adoption broadened in the quarter. Today, 8 of the top 10 AI companies use Instinct to power production workloads across a growing range of use cases. With the MI350 series, we are entering the next phase of Instinct adoption, expanding our footprint with existing partners and adding new customers. In the fourth quarter, hyperscalers expanded MI350 series availability, leading AI companies scale their deployments to support additional workloads, and multiple neocloud providers launched MI350 series offerings that deliver on-demand access to Instinct infrastructure in the cloud.\n\n**Lisa Su** (Chairman and CEO)\nTurning to our AI software stack, we expanded the ROCm ecosystem in the fourth quarter, enabling customers to deploy Instinct faster and with higher performance across a broader range of workloads. Millions of large language and multimodal models run out of the box on AMD, with the leading models launching with day zero support for Instinct GPUs. This capability highlights our rapidly expanding open-source community enablement, including new upstream integration of AMD GPUs in vLLM, one of the most widely used inference engines. To drive Instinct adoption with industry-specific use cases, we're also adding support for domain-specific models in key verticals. As one example, in healthcare, we added ROCm support for the leading medical imaging framework to enable developers to train and deploy highly performant deep learning models on Instinct GPUs.\n\n**Lisa Su** (Chairman and CEO)\nFor large businesses, we introduced our Enterprise AI Suite, a full-stack software platform with enterprise-grade tools, inference microservices, and solutions blueprints designed to simplify and accelerate production deployments at scale. We also announced a strategic partnership with Tata Consultancy Services to co-develop industry-specific AI solutions and help customers deploy AI across their operations. Looking ahead, customer engagements for our next-gen MI400 series and Helios platform continue expanding. In addition to our multi-generation partnership with OpenAI to deploy 6 GW of Instinct GPUs, we are in active discussions with other customers on at-scale multi-year deployments starting with Helios and MI450 later this year. With the MI400 series, we are also expanding our portfolio to address the full range of cloud, HPC, and enterprise AI workloads.\n\n**Lisa Su** (Chairman and CEO)\nThis includes MI455X and Helios for AI superclusters, MI430X for HPC and sovereign AI, and MI440X servers for enterprise customers requiring leadership training and inference performance in a compact 8-GPU solution that integrates easily into existing infrastructure. Multiple OEMs publicly announced plans to launch Helios systems in 2026, with deep engineering engagement underway to support smooth production ramps. In December, HPE announced that they will offer Helios racks with purpose-built HPE Juniper Ethernet switches and optimized software for high-bandwidth scale-up networking. And in January, Lenovo announced plans to offer Helios racks. MI430X adoption also grew in the quarter, with new Exascale-class supercomputers announced by GENCI in France and HLRS in Germany. Looking further ahead, development of our next-generation MI500 series is well underway. MI500 is powered by our CDNA six architecture, built on advanced 2-nanometer process technology, and features high-speed HBM4e memory.\n\n**Lisa Su** (Chairman and CEO)\nWe are on track to launch MI500 in 2027 and expect MI500 to deliver another major leap in AI performance to power the next wave of large-scale multimodal models. In summary, our AI business is accelerating, with the launch of MI400 series and Helios representing a major inflection point for the business as we deliver leadership performance and TCO at the chip, compute tray, and rack level. Based on the strength of our EPYC and Instinct roadmaps, we are well positioned to grow data center segment revenue by more than 60% annually over the next three to five years and scale our AI business to tens of billions in annual revenue in 2027. Turning to client and gaming, segment revenue increased 37% year-over-year to $3.9 billion. In client, our PC processor business performed exceptionally well.\n\n**Lisa Su** (Chairman and CEO)\nRevenue increased 34% year-over-year to a record $3.1 billion, driven by increased demand for multiple generations of Ryzen desktop and mobile CPUs. Desktop CPU sales set a record for the fourth consecutive quarter. Ryzen CPUs topped the bestseller lists at major global retailers and e-tailers throughout the holiday period, with strong demand across all price points in every region driving record desktop channel sellout. In mobile, strong demand for AMD-powered notebooks drove record Ryzen PC sell-through in the quarter. That momentum extended into commercial PCs, where Ryzen adoption accelerated as we established a new long-term growth engine for our client business. Sell-through of Ryzen CPUs for commercial notebooks and desktops grew by more than 40% year-over-year in the fourth quarter, and we closed large wins with major telecom, financial services, aerospace, automotive, energy, and technology customers.\n\n**Lisa Su** (Chairman and CEO)\nAt CES, we expanded our Ryzen portfolio with CPUs that further extend our performance leadership. Our new Ryzen AI 400 mobile processors deliver significantly faster content creation and multitasking performance than the competition. Notebooks powered by Ryzen AI 400 are already available, with the broadest lineup of AMD-based consumer and commercial AI PCs set to launch throughout the year. We also introduced our Ryzen AI Halo platform, the world's smallest AI development system, featuring our highest-end Ryzen AI Max processor with 128 GB of unified memory that can run models with up to 200 billion parameters locally. In gaming, revenue increased 50% year-over-year to $843 million. Semi-custom sales increased year-over-year and declined sequentially, as expected. For 2026, we expect semi-custom SoC annual revenue to decline by a significant double-digit percentage as we enter the seventh year of what has been a very strong console cycle.\n\n**Lisa Su** (Chairman and CEO)\nFrom a product standpoint, Valve is on track to begin shipping its AMD-powered Steam Machine early this year, and development of Microsoft's next-gen Xbox featuring an AMD semi-custom SoC is progressing well to support a launch in 2027. Gaming GPU revenue also increased year-over-year, with higher channel sellout driven by demand throughout the holiday sales period for our latest generation Radeon RX 9000 Series GPUs. We also launched FSR 4 Redstone in the quarter, our most advanced AI-powered upscaling technology, delivering higher image quality and smoother frame rates for gamers. Turning to our embedded segment, revenue increased 3% year-over-year to $950 million, led by strength with test and measurement and aerospace customers and growing adoption of our embedded x86 CPUs. Channel sell-through accelerated in the quarter as end-customer demand improved across several end markets, led by test, measurement, and emulation.\n\n**Lisa Su** (Chairman and CEO)\nDesign win momentum remains one of the clearest indicators of long-term growth for our embedded business, and we delivered another record year. We closed $17 billion in design wins in 2025, up nearly 20% year-over-year, as we've now won more than $50 billion of embedded designs since acquiring Xilinx. We also strengthened our embedded portfolio in the quarter. We began production of our Versal AI Edge Gen 2 SoCs for low-latency inference workloads and started shipping our highest-end Spartan UltraScale+ devices for cost-optimized applications. We also launched new embedded CPUs, including our EPYC 2005 Series for network security and industrial edge applications, Ryzen P100 Series for in-vehicle infotainment and industrial systems, and Ryzen X100 Series for physical AI and autonomous platforms. In summary, 2025 was an excellent year for AMD, marking the start of a new growth trajectory for the company.\n\n**Lisa Su** (Chairman and CEO)\nWe are entering a multi-year demand supercycle for high performance and AI computing that is creating significant growth opportunities across each of our businesses. AMD is well positioned to capture that growth, with highly differentiated products, a proven execution engine, deep customer partnerships, and significant operational scale. As AI reshapes the compute landscape, we have the breadth of solutions and partnerships required for end-to-end leadership, from Helios in the cloud for at-scale training and inference to an expanded Instinct portfolio for sovereign supercomputing and enterprise AI deployment. At the same time, demand for EPYC CPUs is surging as agentic and emerging AI workloads require high-performance CPUs to power head nodes and run parallel tasks alongside GPUs. At the edge and in PCs where AI adoption is just beginning, our industry-leading Ryzen and embedded processors are powering real-time on-device AI.\n\n**Lisa Su** (Chairman and CEO)\nAs a result, we expect significant top-line and bottom-line growth in 2026, led by increased adoption of EPYC and Instinct, continued client share gains, and a return to growth in our embedded segment. Looking further ahead, we see a clear path to achieve the ambitious targets we laid out at our financial analyst day last November, including growing revenue at greater than 35% CAGR over the next three to five years, significantly expanding operating margins, and generating annual EPS of more than $20 in the strategic time frame, driven by growth in all of our segments and the rapid scaling of our data center AI business. Now I'll turn the call over to Jean to provide additional color on our fourth quarter results and full-year results. Jean?\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the first quarter of fiscal 2026. AMD executed very well in 2025, delivering record revenue of $34.6 billion, up 34% year-over-year, driven by 32% growth in our data center segment and 51% growth in our client and gaming segment. Gross margin was 52%, and we delivered record earnings per share of $4.17, up 26% year-over-year while continuing to invest aggressively in AI and the data center to support our long-term growth. For the fourth quarter of 2025, revenue was a record $10.3 billion, growing 34% year-over-year, driven by strong growth in the data center and client gaming segments, including approximately $390 million in revenue from MI308 sales to China, which was not included in our fourth quarter guidance.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nRevenue was up 11% sequentially, primarily driven by continued strong growth in data center from both server and data center AI businesses, as well as a return to year-over-year growth in the embedded segment. Gross margin was 57%, up 290 basis points year-over-year. We benefited from the release of $360 million in previously written-down MI308 inventory reserves. Excluding the inventory reserve release and the MI308 revenue from China, gross margin would have been approximately 55%, up 80 basis points year-over-year, driven by favorable product mix. Operating expenses were $3 billion, an increase of 42% year-over-year as we continue to invest in R&D go-to-market activities to support our AI roadmap and long-term growth opportunities, as well as higher employee performance-based incentives.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nOperating income was a record $2.9 billion, representing a 28% operating margin, tax increase, and other, resulting in a net expense of approximately $335 million. For the fourth quarter, diluted earnings per share was a record $1.53, an increase of 40% year-over-year, reflecting strong execution and operating leverage in our business model. Now turning to our reportable segment. Starting with the data center segment, revenue was a record $5.4 billion, up 39% year-over-year and 24% sequentially, driven by strong demand for EPYC processors and the continued ramp of MI350 products. Data center segment operating income was $1.8 billion, or 33% of revenue, compared to $1.2 billion, or 30% a year ago, reflecting higher revenue and the inventory reserve release, partially offset by continued investment to support our AI hardware and software roadmaps.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nClient gaming segment revenue was $3.9 billion, up 37% year-over-year, driven primarily by strong demand for our leadership AMD Ryzen processors. On a sequential basis, revenue was down 3% due to lower semi-customer revenue. The client business revenue was a record $3.1 billion, up 34% year-over-year and 13% sequentially, led by strong demand from both the channel and the PC OEMs and continued market share gains. The gaming business revenue was $843 million, up 50% year-over-year, primarily driven by higher semi-customer revenue and strong demand for AMD Radeon GPUs. Sequentially, gaming revenue was down 35% due to lower semi-customer sales. Client gaming segment operating income was $725 million, or 18% of revenue, compared to $496 million, or 17% a year ago. Embedded segment revenue was $950 million, up 3% year-over-year and 11% sequentially as demand strengthened across several end markets.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nEmbedded segment operating income was $357 million, or 38% of revenue, compared to $362 million, or 39% a year ago. Before I reveal the balance sheet and the cash flow, as a reminder, we closed the sale of ZT Systems manufacturing business to Sanmina in late October. The fourth quarter financial results of the ZT manufacturing business are reported separately in our financial statement as discontinued operations and are excluded from our non-GAAP financials. Turning to the balance sheet and the cash flow. During the quarter, we generated a record $2.3 billion in cash from continuing operations and a record of $2.1 billion in free cash flow. Inventory increased sequentially by approximately $607 million-$7.9 billion to support strong data center demand. At the end of the quarter, cash, cash equivalents, and short-term investment were $10.6 billion.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nFor the year, we repurchased 12.4 million shares and returned $1.3 billion to shareholders. We ended the year with $9.4 billion authorization remaining and our share repurchase program. Now turning to our first quarter 2026 outlook. We expect revenue to be approximately $9.8 billion, plus or minus $300 million, including approximately $100 million of MI308 sales to China. At the middle point of our guidance, revenue is expected to be up 32% year-over-year, driven by strong growth in our data center and client gaming segments and modest growth in our embedded segment. Sequentially, we expect revenue to be down approximately 5%, driven by seasonal decline in our client gaming and embedded segment, partially offset by growth in our data center segment.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nIn addition, we expect fourth quarter non-GAAP gross margin to be approximately 55%, non-GAAP operating expense to be approximately $3.05 billion, non-GAAP other net income to be approximately $35 million, non-GAAP effective tax rate to be 13%, and diluted share count is expected to be approximately 1.65 billion shares. In closing, 2025 was an outstanding year for AMD, reflecting disciplined execution across the business to deliver strong revenue growth, increase profitability, and cash generation while investing aggressively in AI and innovation to support our long-term growth strategy. Looking ahead, we are very well positioned for continued strong top-line revenue growth and earnings expansion in 2026 with a focus on driving data center AI growth, operating leverage, and delivering long-term value to shareholders. With that, I'll turn it back to Matt for the Q&A session.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nYes. Thank you very much, Jean. Operator, please go ahead and open the Q&A session. Thank you.\n\n**Operator**\nThank you, Matt. We will now be conducting the question-and-answer session. If you would like to ask a question, please press star one on your telephone keypad. A confirmation tone will indicate that your line is in the queue. You may press star two to remove yourself from the queue. For participants using speaker equipment, it may be necessary to pick up your handset before pressing the star keys. One moment, please, while we pull for questions. And the first question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.\n\n**Aaron Rakers** (Managing Director and Senior Equity Research Analyst)\nYeah. Thanks for taking the question. Lisa, at your analyst day back in November, you seemed to kind of endorse the high $20 billion AI revenue expectation that was out there on the street for 2027. I know today you're reaffirming the path to strong double-digit growth. So I guess my question is, can you talk a little bit about what you've seen as far as customer engagements, how those might have expanded? I think you've alluded to in the past multiple multi-gigawatt opportunities. Just double-click on what you've seen for the MI455 and Helios platform from a demand-shaping perspective as we look into the back half of the year.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Sure, Aaron. Thanks for the question. So first of all, I think the MI450 series development is going extremely well. So we're very happy with the progress that we have. We're right on track for a second-half launch and beginning of production. And as it relates to sort of the shape of the ramp and the customer engagements, I would say the customer engagements continue to proceed very well. We have, obviously, a very strong relationship with OpenAI, and we're planning that ramp starting in the second half of the year, going into 2027. That is on track. We're also working closely with a number of other customers who are very interested in ramping MI450 quickly, just given the strength of the product. And we see that across both inference and training. And that is the opportunity that we see in front of us.\n\n**Lisa Su** (Chairman and CEO)\nSo we feel very good about sort of the data center growth overall for us in 2026. And then certainly, going into 2027, we've talked about $ tens of billions of data center AI revenue, and we feel very good about that.\n\n**Operator**\nThank you. The next question comes from the line of Tim Arcuri with UBS. Please proceed with your question.\n\n**Tim Arcuri** (Managing Director and Senior Equity Analyst)\nThanks a lot. Jean, I'm wondering if you can maybe give us a little bit of detail under the hood for the March guidance. I know you basically told us that you told us about what embedded's going to be up a bit year over year. Client sounds like it's down seasonally, which I take to be maybe down 10. So can you give us a sense maybe of the other pieces? And then also, can you give us a sense of how data center GPU is going to ramp through the year? I know it's a back half loaded year, but I think people are thinking, Lisa, somewhere in the $14 billion range this year. That's what investors were thinking. I'm not asking you to endorse that.\n\n**Tim Arcuri** (Managing Director and Senior Equity Analyst)\nIf you can give us a little flavor for sort of how the ramp will look through the year, that'd be great. Thanks.\n\n**Lisa Su** (Chairman and CEO)\nHi, Tim. Thanks for your question. We're guiding one quarter at a time, but I can give you some color about our Q1 guide. First, it's right sequentially, we guided the decline around 5%, but data center is actually going to be up. And when you think about it, it's right. Our CPU business seasonal, actually, in a regular seasonal pattern, it's going to be down high single digit. And in our current guide, we actually guide CPU revenue up sequentially very nicely. Also, with the data center GPU side, we also feel really good about GPU revenue, including China, will be also up. So very nice guide for the data center overall. On the client side, we do see seasonality, sequentially decline. Embedded and gaming, they also have a seasonal decline.\n\n**Lisa Su** (Chairman and CEO)\nAnd maybe, Tim, if I just give you a little bit on the full-year commentary. I think the important thing, as we look at the full year, we're very bullish on the year. We're not, if you look at the key themes, we're seeing very strong growth in the data center. And that's across two growth vectors. We see server CPU growth, actually, very strong. I mean, we've talked about the fact that CPUs are very important as AI continues to ramp. And we've seen the CPU order book continue to strengthen as we go through the last few quarters and especially over the last 60 days. So we see that as a strong growth driver for us. As Jean said, we see server CPU growing from Q4 into Q1 in what normally is seasonally down. And that continues throughout the year.\n\n**Lisa Su** (Chairman and CEO)\nThen on the data center AI side, it's a very important year for us. It's really an inflection point. MI355 has done well, and we were pleased with the performance in Q4. We continue to ramp that in the first half of the year. As we get into the second half of the year, the MI450 is really an inflection point for us. That revenue will start in the third quarter, but it will ramp significant volume in the fourth quarter as we get into 2027. That gives you a little bit of sort of what the data center ramp looks like throughout the year.\n\n**Tim Arcuri** (Managing Director and Senior Equity Analyst)\nThank you, Lisa.\n\n**Operator**\nThe next question comes from the line of Vivek Arya with Bank of America. Please proceed.\n\n**Vivek Arya** (Managing Director and Senior Equity Research Analyst)\nThank you. First, just clarification on what you're assuming for your China MI308 sales beyond Q1. And then, Lisa, specific to 2026, can your data center revenues grow at your target 60%+ growth rate? I realize that that's a multi-year target, but do you think that there are enough drivers, whether it's on the server CPU side or GPU side, for you to grow at that target base even in 2026? Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Sure, Vivek. So let me talk a little bit about China first because that's, I think, important for us to make sure that's clear. Look, we were pleased to have some MI308 sales in the fourth quarter. They were actually a license that was approved through work with the administration. And those orders were actually from very early in 2025. And so we saw some revenue in Q4, and we're forecasting for about $100 million of revenue in Q1. We are not forecasting any additional revenue from China just because it's a very dynamic situation. So given that it's a dynamic situation, we're still waiting. We've submitted licenses for the MI325, and we're continuing to work with customers and understanding sort of their customer demand. We thought it prudent not to forecast any additional revenue other than the $100 million that we called out in the Q1 guide.\n\n**Lisa Su** (Chairman and CEO)\nNow, as it relates to overall data center, as I mentioned in the question to Tim, we're very bullish about data center. I think the combination of drivers that we have across our CPU franchise, I mean, the EPYC product line, both Turin and Genoa, continue to ramp well. And in the second half of the year, we will be launching Venice, which we believe actually extends our leadership. And the MI450 ramp, which is also very significant in the second half of 2026. We're not, obviously, guiding specifically by segment, but the long-term target of, let's call it, greater than 60% is certainly possible in 2026.\n\n**Vivek Arya** (Managing Director and Senior Equity Research Analyst)\nThank you, Lisa.\n\n**Operator**\nThank you. And as a reminder, if you would like to ask a question, please press star one. We ask that you limit yourself to one question and one follow-up. Thank you. The next question comes from the line of CJ Muse with Cantor. Please proceed.\n\n**C.J. Muse** (Senior Managing Director and Senior Equity Research Analyst)\nYeah. Good afternoon. Thanks for taking the question. I'm curious on the server CPU side of the house. And given the dramatic tightness, curious your ability to source incremental capacity from TSMC and elsewhere. And I guess how long will it take for that to see wafers out? And how should we think about the implications for kind of the growth trajectory throughout all of calendar 2026? And I guess as part of that, if you could speak to how we should be thinking about inflection in pricing as well, that would be very helpful.\n\n**Lisa Su** (Chairman and CEO)\nSure, CJ. So a couple of points about the server CPU market. First of all, we think the overall server CPU TAM is going to grow, let's call it, strong double digits in 2026, just given, as we said, the relationship between CPU demand and overall AI ramp. So I think that's a positive. Relative to our ability to support that, we've been seeing this trend for the last couple of quarters. So we have increased our supply capacity capability for server CPUs. And that's one of the reasons we're able to increase our Q1 guide as it relates to the server business. And we see the ability to continue to grow that throughout the year. There's no question that demand continues to be strong. And so we're working with our supply chain partners to increase supply as well.\n\n**Lisa Su** (Chairman and CEO)\nFrom what we see today, I think the overall server situation is strong. We are increasing supply to address that.\n\n**Operator**\nHey, C.J. Do you have a follow-up question?\n\n**C.J. Muse** (Senior Managing Director and Senior Equity Research Analyst)\nI do. Maybe for Jean, if you could kind of touch on gross margins through the year. And as you balance kind of strengthening server CPU with perhaps greater GPU accelerating in the second half, is there kind of a framework that we should be working off of? Thanks so much.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nYeah. Thank you for the question. We are very pleased with our gross margin Q4 performance and the Q1 guide at 55%, which actually is 130 basis points up year-over-year while we continue to ramp our MI355 year-over-year very significantly. I think we are benefiting from a very favorable product mix across all our business. If you think about it in data center, we're ramping our new product, new generation product, Turin, and the MI355, which helps the gross margin in client. We continue to move up the stack and also gaining momentum in our commercial business. Our client business gross margin has been improving nicely. In addition, certainly, we see the recovery of our embedded business, which is also margin accretive. So all those tailwinds we are seeing, we continue to see in the next few quarters.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nWhen MI450 ramp, of course, in Q4, our gross margin will be driven largely by mix. I think we'll give you more color when we get there. Overall, we feel really good about our gross margin progression this year.\n\n**Operator**\nThank you. The next question comes from the line of Joe Moore with Morgan Stanley. Please proceed.\n\n**Joe Moore** (Managing Director and Head of U.S. Semiconductors Research)\nGreat. Thank you. On the MI455 ramp, will 100% of the business be racks? Will there be kind of an eight-way server business around that architecture? And then is the revenue recognition when you ship to the rack vendor, or is there something to understand about that? Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYes, Joe. So we do have multiple variants of the MI450 series, including an eight-way GPU form factor. But for 2026, I would say the vast majority of it is going to be rack-scale solutions. And yes, we will take revenue when we ship to the rack builder.\n\n**Joe Moore** (Managing Director and Head of U.S. Semiconductors Research)\nOkay. Great. And then can you talk to any risks that you may have in terms of once you get silicon out, turning that into racks, any potential issues as you ramp that? I know your competitor had some last year, and you said you learned from that. Is there anything you've done with kind of pre-building racks to sort of ensure you won't have those issues? Just any risk do we need to understand around that?\n\n**Lisa Su** (Chairman and CEO)\nYeah. I mean, Joe, the main thing is the development's going really well. We're right on track with the MI450 series as well as the Helios rack development. We've done a lot of testing already, both at the rack-scale level as well as at the silicon level. So far, so good. We are getting, let's call it, a lot of input from our customers on things to test so that we can do a lot of testing in parallel. And our expectation is that we will be on track for our second-half launch.\n\n**Operator**\nThank you. Our next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nHi, guys. Thanks for taking my questions. First one, Lisa, I just wanted to ask about OpEx. Every quarter, you guys are guiding it up, and then it's coming in even higher, and then you're guiding it up again. And I understand, given the growth trajectory, that you need to invest. But how should we think about the ramp of that OpEx and that spending number, especially as the GPU revenue starts to inflect? Do we get leverage on that, or should we be expecting the OpEx to be growing even more materially as the AI revenue starts to ramp?\n\n**Lisa Su** (Chairman and CEO)\nYeah. Sure, Stacy. Thanks for the question. Look, I think in terms of OpEx, we're at a point where we have very high conviction in the roadmap that we have. And so in 2025, as the revenue increased, we did lean in on OpEx. And I think it was for all the right reasons. As we get into 2026 and as we see some of the significant growth that we're expecting, we should absolutely see leverage. And the way to think about it is we've always said in our long-term model that OpEx should grow slower than revenue. And we would expect that in 2026 as well, especially as we get into the second half of the year and we see inflection in the revenue.\n\n**Lisa Su** (Chairman and CEO)\nBut at this point, I think if you look at our free cash flow generation and the overall revenue growth, I think the investment in OpEx is absolutely the right thing to do.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst)\nThank you. For my follow-up, I actually have two sort of one-line answers I'm looking for. Just first, the $100 million in China revenue in Q1, does that also drop through a zero-cost basis like we had in Q4, and is that a margin headwind? And number two, I know you don't give us the AI number, but could you just give us the annual 2025 Instinct number now that we're through the year? How big was it?\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nStacy, let me answer your first question on the $100 million revenue in Q1. Actually, the inventory reserve reversed in Q4, which was $360 million, not only is associated with Q4 revenue, China revenue, but also covers the $100 million revenue we expect to ship in Q1 to China with our MI308. The Q1 gross margin guide is a very clean guide.\n\n**Lisa Su** (Chairman and CEO)\nStacy, for your second question, as you know, we don't guide at the business level. But to help you with your models, I think you can if you look at the Q4 data center AI number, even if you were to back out the China number, which was, let's call it, not a recurring number, you would still see growth. You'll see growth from Q3 to Q4. So that should help you a little bit with your modeling.\n\n**Operator**\nThank you. The next question comes from the line of Joshua Buchalter with TD Cowen. Please proceed.\n\n**Joshua Buchalter** (Director and Senior Equity Research Analyst)\nHey, guys. Thanks for taking my question. I wanted to ask about clients. So the segment beat pretty handily in the fourth quarter. And I recognize you guys have been gaining share with Ryzen. But I think given what we've been seeing in the memory market, there's a lot of concern about inflationary costs and the potential for pull-ins. Were there any changes in your order patterns during the quarter? And maybe bigger picture, how are you thinking about client growth and the health of that market into 2026?\n\n**Lisa Su** (Chairman and CEO)\nYeah. Thanks for the question, Josh. The client market has performed extremely well for us throughout 2025. Very strong growth for us, both in terms of ASP mixing up the stack as well as just unit growth. Going into 2026, we are certainly watching the development of the business. I think the PC market is an important market. Based on everything that we see today, we're probably seeing the PC TAM down a bit, just given some of the inflationary pressures of the commodities pricing, including memory. The way we are modeling the year is, let's call it, second half a bit subseasonal to first half, just given everything that we see. Even in that environment with the PC market down, we believe we can grow our PC business. Our focus areas are enterprise.\n\n**Lisa Su** (Chairman and CEO)\nThat's a place where we're making very nice progress in 2025, and we expect that into 2026, and just continuing to grow sort of at the premium, higher end of the market.\n\n**Joshua Buchalter** (Director and Senior Equity Research Analyst)\nThank you for the color there. Then I wanted to ask about the Instinct family. So we've seen your big GPU competitor make a deal with an SRAM-based spatial architecture provider. And then OpenAI has reportedly been linked to one as well. Could you speak to the competitive implications of that? You've done well in inferencing, I think, partly because of your leadership in HBM content. So I was wondering if you could maybe address the pull seemingly motivated by lower latency inference and how Instinct is positioned to service this if you're indeed seeing it as well. Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah. I think, Josh, it's really, I think, the evolution that you might expect as the AI market matures. What we're seeing is, as inference ramps, really the tokens per dollar or the efficiency of the inference stack becomes more and more important. As you know, with our chiplet architecture, we have a lot of ability to optimize across inference, training, and even across sort of the different stages of inference as well. So I think I view this as very much as you go into the future, you'll see more workload-optimized products. And you can do that with GPUs as well as with other more ASIC-like architectures. I think we have the full compute stack to do all of those things.\n\n**Lisa Su** (Chairman and CEO)\nFrom that standpoint, we're going to continue to lean into inference as we view that as a significant opportunity for us in addition to ramping our training capabilities.\n\n**Operator**\nThank you. The next question comes from the line of Ben Reitzes with Melius Research. Please proceed.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nYeah. Hey. Thanks. Appreciate it. Hey, Lisa, I wanted to ask you about OpenAI. I'm sure a lot of the volatility out there is not lost on you. Is everything on track for the second half for starting the 6 GW and the three and a half year timeline as far as you know? And is there any other color that you'd just like to give on that relationship? And then I have a follow-up. Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah. I mean, Ben, what I would say is we're very much working in partnership with OpenAI as well as our CSP partners to deliver on MI450 series and deliver on the ramp. The ramp is on schedule to start in the second half of the year. MI450 is doing great. Helios is doing well. We are in, let's call it, deep co-development across all of those parties. And as we look forward, I think we are optimistic about the MI450 ramp for OpenAI. But I also want to remind everyone that we have a broad set of customers that are very excited about MI450 series. And so in addition to the work that we're doing with OpenAI, there are a number of customers that we're working to ramp in that timeframe as well.\n\n**Ben Reitzes** (Managing Director and Head of Technology Research)\nAll right. I appreciate that. I wanted to shift to the server CPU and just talk about x86 versus ARM. There's some view out there that x86 has particular edge in agents, big picture. Do you agree with that? And what are you seeing from customers? And in particular, obviously, your big competitor is going to be selling an ARM CPU separately now in the second half. So if there's just anything on that competitive dynamic versus ARM and what NVIDIA is doing and your views on that, that'd be great to hear. Thanks.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Ben, what I would say about the CPU market is there is a great need for high-performance CPUs right now. And that goes towards agentic workloads where when you have these AI processes or AI agents that are spinning off a lot of work in an enterprise, they're actually going to a lot of traditional CPU tasks. And the vast majority of them are on x86 today. I think the beauty of EPYC is that we've optimized. We've done workload optimization. So we have the best cloud processor out there. We have the best enterprise processor. We also have some lower-cost variants for storage and other elements. And I think all of that comes into play as we think about the entirety of the AI infrastructure that needs to be put in place.\n\n**Lisa Su** (Chairman and CEO)\nI think the CPUs are going to continue to be as important as a piece of the AI infrastructure ramp. That's one of the things that we mentioned at our Analyst Day back in November, really this multi-year CPU cycle. We continue to see that. I think we've optimized EPYC to satisfy all of those workloads. We're going to continue to work with our customers to expand our EPYC footprint.\n\n**Operator**\nThe next question comes from the line of Tom O'Malley with Barclays. Please proceed.\n\n**Tom O'Malley** (Director and Senior Equity Research Analyst)\nHey, Lisa. How are you? I just wanted to ask, you mentioned on memory earlier as a sticking point in terms of inflationary cost. Different customers do this in different ways. Different suppliers do this in different ways. But could you maybe talk about your procurement of memory, when that takes place, particularly on the HBM side? Is that something that gets done a year in advance, six months in advance? Different accelerator guys have talked about different timelines. We'd be curious to kind of hear when you do the procurement.\n\n**Lisa Su** (Chairman and CEO)\nYeah. I mean, given the lead times for things like HBM and wafers and these parts of the supply chain, I mean, we're working closely with our suppliers over a multi-year timeframe in terms of what we see in demand, how we ramp, how we ensure that our development is very closely tied together. So I feel very good about our supply chain capabilities. We have been planning for this ramp. So independent of the current market conditions, we've been planning for a significant ramp in both CPU as well as our GPU business over the past couple of years. And so from that standpoint, I think we're well-positioned to grow substantially in 2026. And now we're also doing multi-year agreements that extend beyond that given tightness of the supply chain.\n\n**Tom O'Malley** (Director and Senior Equity Research Analyst)\nThanks. And just as a follow-up, you've seen a variety of different things in the industry in terms of system accelerator, so KV cache offload, more discrete ASIC-style compute, CPX. If you look at what your competitors are doing and you look at your first generation of system architecture coming out, maybe spend some time on, do you see yourself following in the footsteps of some of these different types of architectural changes? Do you think that you'll go in a different direction? Anything just on the evolution of your system-based architecture and then the adjoining products and/or silicon within. Thank you.\n\n**Lisa Su** (Chairman and CEO)\nI think, Tom, what we have is the ability with a very flexible architecture with our chiplet architecture. And then we also have a flexible platform architecture that allows us to really have different system solutions for the different requirements. I think we're very cognizant that there will be different solutions. So there's noI've often said there's no one-size-fits-all. And I'll say that again. There's no one-size-fits-all. But that being the case, it's clear that the rack scale architecture is very, very good for the highest-end applications when you're talking about distributed inference and training. But we also see an opportunity with enterprise AI to use some of these other form factors. And so we're investing across that spectrum.\n\n**Operator**\nThe next question comes from the line of Ross Seymore with Deutsche Bank. Please proceed.\n\n**Ross Seymore** (Managing Director and Senior Equity Research Analyst)\nHi. Thanks for my last couple of questions. I guess my first question is back on the gross margin side of things. As you go from the MI300 to the 400 to the 500 eventually, do you see any changes in the gross margin throughout that period? In the past, you've talked about optimizing dollars more so than percentages. But just on the percentage side, does it go up, down? Is there volatility as you go from one to the next for any reason? Just wondered on the trajectory there.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nRoss, thank you for the question. At a very high level, each generation, we actually provide much more capabilities, more memory, help our customer more. So in general, the gross margin should progress each generation when you offer more capabilities to your customers. But typically, when you first ramp at the beginning of ramp of a generation, it tends to be lower. When you get to the scale, get to the yield improvement, the test improvement, and also overall performance improvement, you will see gross margin improving within each generation. So it's kind of a dynamic gross margin. But in the longer term, you should expect each generation should have a higher gross margin.\n\n**Ross Seymore** (Managing Director and Senior Equity Research Analyst)\nThanks for that, Jean. Then one small segment of your business, but it seems quite volatile. You talked a little bit about further off than you usually do, is the gaming side of things. What is the magnitude down you're talking about this year? Because in 2025, you thought it was going to be flat. And it ended up growing 50%, which was a nice positive surprise. But now that you're talking about this year being down, but then the next-gen Xbox ramping in 2027, I just hope to get some color on what you see as kind of the annual trajectory there.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nYeah. So Lisa can add more. So 2026, actually, it's the seventh year of a current product cycle. Typically, when you're at this stage of the cycle, revenue tends to come down. We do expect the revenue on the semi-customer revenue side to come down significantly, double-digit for 2026, as Lisa mentioned in her prepared remarks. For the next generation?\n\n**Lisa Su** (Chairman and CEO)\nYeah. Yeah. I think we'll certainly talk about that going forward. But as we ramp the new generation, you would expect a reversal of that.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nOperator, I think we have time for one more caller on the call, please. Thank you.\n\n**Operator**\nOur final question comes from the line of Jim Schneider with Goldman Sachs. Please proceed.\n\n**Jim Schneider** (Senior Equity Analyst)\nGood afternoon. Thanks for taking my question. Relative to the ramp of your rack-scale systems, would you expect any kind of bottleneck in terms of supply constraints in terms of the ramp as you ramp the second half of the year to potentially impact or limit the revenue growth? In other words, maybe talk about whether you expect supply to really kind of meet the growth in Q4 sequentially relative to sorry, Q3 relative to Q4.\n\n**Lisa Su** (Chairman and CEO)\nYeah. Jim, we are planning this at every component level. So I think relative to our data center AI ramp, I do not believe that we will be supply-limited in terms of the ramp that we put in place. I think we have an aggressive ramp. I think it's a very doable ramp. And as we think about the size and scale of AMD, clearly, our priority is ensuring that the data center ramps go very well. And that's both on the data center AI, the GPU side, as well as on the CPU side.\n\n**Jim Schneider** (Senior Equity Analyst)\nThank you. And then maybe as a follow-up to the earlier question on OPEX, could you maybe address what are some of the largest investment areas you made in 2025? And then what are the largest incremental OPEX investment areas for 2026? Thank you.\n\n**Lisa Su** (Chairman and CEO)\nYeah, Jim. On the 2025 investment, the priority and the largest investment in data center AI, our hardware roadmap, we accelerated that roadmap. We expand our software capabilities. We also acquired ZT Systems, which add significant system-level solutions and capabilities. Those are the primary investment in 2025. We also invest heavily in go-to-market to really expand our go-to-market capabilities to support revenue growth and also expand our commercial business and enterprise business for our CPU franchise. In 2026, you should expect us to continue to invest aggressively. But as Lisa mentioned earlier, we do expect revenue to expand faster than operating expense increase to drive the earnings per share expansion.\n\n**Jim Schneider** (Senior Equity Analyst)\nAll right. Thank you, everybody, for participating on the call. Operator, I think we can go ahead and close the call now. Thank you. Good evening.\n\n**Operator**\nThank you. Ladies and gentlemen, that does conclude the question-and-answer session. That also concludes today's teleconference. You may disconnect your lines at this time and have a great rest of the day.",
        "fetched_at": "2026-02-04T16:13:51.187Z"
      },
      {
        "ticker": "AMD",
        "title": "Yahoo Finance",
        "published_date": "Nov 4, 2025, 5:00 PM EST",
        "fiscal_year": "2025",
        "quarter": "Q3",
        "url": "https://finance.yahoo.com/quote/AMD/earnings/AMD-Q3-2025-earnings_call-370771.html",
        "content": "**Operator**\nGreetings and welcome to the AMD Third Quarter 2025 conference call. At this time, all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. If anyone should require operator assistance, please press star zero on your telephone keypad. As a reminder, this conference call is being recorded. It is now my pleasure to introduce to you Matt Ramsay, VP, Financial Strategy and Investor Relations. Thank you, Matt. You may begin.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nThank you and welcome to AMD Third Quarter 2025 Financial Results Conference Call. By now, you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the opportunity to review these materials, they can be found on the Investor Relations page of AMD.com. We will refer primarily to non-GAAP financial measures during today's call. The full non-GAAP to GAAP reconciliations are available in today's press release and the slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and CEO, and Jean Hu, our Executive Vice President, CFO, and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin the call, I would like to note that Dr.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nLisa Su, along with members of AMD's executive team, will present our long-term financial strategy at our Financial Analyst Day next Tuesday, November 11th, in New York. Dr. Lisa Su will present at the UBS Global Technology and AI Conference on Wednesday, December 3rd. And finally, Jean Hu will present at the 23rd Annual Barclays Global Technology Conference on Wednesday, December 10th. Today's discussion contains forward-looking statements based on our current beliefs, assumptions, and expectations, speak only as of today, and as such involve risks and uncertainties that could cause results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on these factors that could cause actual results to differ materially. And with that, I will hand the call over to Lisa.\n\n**Lisa Su** (Chair and CEO)\nThank you, Matt, and good afternoon to all those listening today. We delivered an outstanding quarter with record revenue and profitability reflecting broad-based demand across our data center AI, server, and PC businesses. Revenue grew 36% year over year to $9.2 billion. Net income rose 31% and free cash flow more than tripled, led by record EPYC, Ryzen, and Instinct processor sales. Our record third-quarter performance marks a clear step up in our growth trajectory as a combination of our expanding compute franchise and rapidly scaling data center AI business drives significant revenue and earnings growth. Turning to our segments, data center segment revenue increased 22% year over year to a record $4.3 billion, led by the ramp of our Instinct MI350 series GPUs and server share gains.\n\n**Lisa Su** (Chair and CEO)\nServer CPU revenue reached an all-time high as adoption of fifth-gen EPYC Turin processors accelerated rapidly, accounting for nearly half of overall EPYC revenue in the quarter. Sales of our prior-generation EPYC processors were also very robust in the quarter, reflecting their strong competitive positioning across a wide range of workloads. In cloud, we had record sales as hyperscalers expanded EPYC CPU deployments to power both their own first-party services and public cloud offerings. Hyperscalers launched more than 160 EPYC-powered instances in the quarter, including new Turin offerings from Google, Microsoft Azure, Alibaba, and others that deliver unmatched performance and price performance across a wide range of workloads. There are now more than 1,350 public EPYC cloud instances available globally, a nearly 50% increase from a year ago.\n\n**Lisa Su** (Chair and CEO)\nAdoption of EPYC in the cloud by large businesses more than tripled year over year, as our on-prem share gains are driving increased demand from enterprise customers for AMD cloud instances to support hybrid compute. We expect cloud demand to remain very strong as hyperscalers are significantly increasing their general-purpose compute capacity as they scale their AI workloads. Many customers are now planning substantially larger CPU buildouts over the coming quarters to support increased demands from AI, serving as a powerful new catalyst for our server business. Turning to enterprise adoption, EPYC server sell-through increased sharply year over year and sequentially, reflecting accelerating enterprise adoption. More than 170 fifth-gen EPYC platforms are in market from HPE, Dell, Lenovo, Supermicro, and others, our broadest portfolio to date, with solutions optimized for virtually every enterprise workload.\n\n**Lisa Su** (Chair and CEO)\nWe close large new wins in the quarter with leading Fortune 500 technology, telecom, financial services, retail, streaming, social, and automotive companies as we expand our footprint across major verticals. The performance and TCO advantages of our EPYC portfolio, combined with our increased go-to-market investments and the expanded breadth of offerings from the leading server and solutions providers, position us well for continued enterprise share gains. Looking ahead, we remain on track to launch our next-generation 2-nanometer Venice EPYC processors in 2026. Venice silicon is in the labs and performing very well, delivering substantial gains in performance, efficiency, and compute density. Customer pull and engagement for Venice are the strongest we have seen, reflecting our competitive positioning and the growing demand for more data center compute.\n\n**Lisa Su** (Chair and CEO)\nMultiple cloud and OEM partners have already brought their first Venice platforms online, setting the stage for broad solution availability and cloud deployments at launch. Turning to data center AI, our Instinct GPU business continues to accelerate. Revenue grew year over year, driven by the sharp ramp of MI350 series GPU sales and broader MI300 series deployments. Multiple MI350 series deployments are underway with large cloud and AI providers, with additional large-scale rollouts on track to ramp over the coming quarters. Oracle became the first hyperscaler to publicly offer MI355X instances, delivering significantly higher performance for real-time inference and multimodal training workloads on OCI ZetaScale Supercluster. Neocloud providers Crusoe, DigitalOcean, TensorWave, Vultr, and others also began ramping availability of their MI350 series public cloud offerings in the quarter. MI300 series GPU deployments with AI developers also broadened in the quarter.\n\n**Lisa Su** (Chair and CEO)\nIBM and Zyphra will train multiple generations of future multimodal models on a large-scale MI300X cluster, and Cohere is now using MI300X at OCI to train its command family of models. For inference, a number of new partners, including Character AI and Luma AI, are now running production workloads on MI300 series, demonstrating the performance and TCO advantages of our architecture for real-time AI applications. We also made significant progress on the software front in the quarter. We launched ROCm7, our most advanced and feature-rich release to date, delivering up to 4.6x higher inference and 3x higher training performance compared to ROCm6. ROCm7 also introduces seamless distributed inference, enhanced code portability across hardware, and new enterprise tools that simplify the deployment and management of Instinct solutions. Importantly, our open software strategy is resonating with developers.\n\n**Lisa Su** (Chair and CEO)\nHugging Face, VLLM, SGLang, and others contributed directly to ROCm7, as we make ROCm the open platform for AI development at scale. Looking ahead, our data center AI business is entering its next phase of growth, with customer momentum building rapidly ahead of the launch of our next-gen MI400 series accelerators and Helios Rack Scale solutions in 2026. The MI400 series combines a new compute engine with industry-leading memory capacity and advanced networking capabilities to deliver a major leap in performance for the most demanding AI training and inference workloads. The MI400 series brings together our Silicon software and systems expertise to power Helios, our Rack Scale AI platform. Designed to redefine performance and efficiency at data center scale.\n\n**Lisa Su** (Chair and CEO)\nHelios integrates our Instinct MI400 series GPUs, Venice EPYC CPUs, and Pensando NICs in a double-wide rack solution optimized for the performance, power, cooling, and serviceability required for the next generation of AI infrastructure and supports Meta's new open rack wide standard. Development of both our MI400 series GPUs and Helios rack is progressing rapidly, supported by deep technical engagements across a growing set of hyperscalers, AI companies, and OEM and ODM partners to enable large-scale deployments next year. The ZT Systems team we acquired last year is playing a critical role in Helios development, leveraging their decades of experience building infrastructure for the world's largest cloud providers to ensure customers can deploy and scale Helios quickly within their environments. In addition, last week we completed the sale of the ZT manufacturing business to Sanmina and entered a strategic partnership that makes them our lead manufacturing partner for Helios.\n\n**Lisa Su** (Chair and CEO)\nThis collaboration will accelerate large customer deployments of our Rack Scale AI solutions. On the customer front, we announced a comprehensive multi-year agreement with OpenAI to deploy 6 gigawatts of Instinct GPUs, with the first gigawatt of MI450 series accelerators scheduled to start coming online in the second half of 2026. The partnership establishes AMD as a core compute provider for OpenAI and underscores the strength of our hardware, software, and full-stack solutions strategy. Moving forward, AMD and OpenAI will work even more closely on future hardware, software, networking, and system-level roadmaps and technologies. OpenAI's decision to use AMD Instinct platforms for its most sophisticated and complex AI workloads sends a clear signal that our Instinct GPUs and ROCm open software stack deliver the performance and TCO required for the most demanding deployments.\n\n**Lisa Su** (Chair and CEO)\nWe expect this partnership will significantly accelerate our data center AI business, with the potential to generate well over $100 billion in revenue over the next few years. Oracle announced they will also be a lead launch partner for the MI450 series, deploying tens of thousands of MI450 GPUs across Oracle Cloud Infrastructure beginning in 2026 and expanding through 2027 and beyond. Our Instinct platforms are also gaining traction with sovereign AI and national supercomputing programs. In the UAE, Cisco and G42 will deploy a large-scale AI cluster powered by Instinct MI350X GPUs to support the nation's most advanced AI workloads. In the US, we are partnering with the Department of Energy and Oak Ridge National Labs to build Lux AI, the first AI factory dedicated to scientific discovery, together with our industrial partners OCI and HPE.\n\n**Lisa Su** (Chair and CEO)\nPowered by our Instinct MI350 series GPUs, EPYC CPUs, and Pensando networking, Lux AI will provide a secure open platform for large-scale training and distributed inference when it comes online in early 2026. The US Department of Energy also selected our upcoming MI430X GPUs and EPYC Venice CPUs to power Discovery, the next flagship supercomputer at Oak Ridge, designed to set the standard for AI-driven scientific computing and extend US high-performance computing leadership. Our MI430X GPUs are designed specifically to power nation-scale AI and supercomputing programs, extending our leadership powering the world's most powerful computers to enable the next generation of scientific breakthroughs. In summary, our AI business is entering a new phase of growth and is on a clear trajectory towards tens of billions in annual revenue in 2027, driven by our leadership, Rack Scale solutions, expanding customer adoption, and an increasing number of large-scale global deployments.\n\n**Lisa Su** (Chair and CEO)\nI look forward to providing more details on our data center AI growth plans at our Financial Analyst Day next week. In client and gaming, segment revenue increased 73% year over year to $4 billion. Our PC processor business is performing exceptionally well, with record quarterly sales as the strong demand environment and breadth of our leadership Ryzen portfolio accelerates growth. Desktop CPU sales reach an all-time high, with record channel sell-in and sell-out led by robust demand for our Ryzen 9000 processors, which deliver unmatched performance across gaming, productivity, and content creation applications. OEM sell-through of Ryzen-powered notebooks also increased sharply in the quarter, reflecting sustained end-customer pull for premium gaming and commercial AMD PCs.\n\n**Lisa Su** (Chair and CEO)\nCommercial momentum accelerated in the quarter, with Ryzen PC sell-through up more than 30% year over year as enterprise adoption grew sharply, driven by large wins with Fortune 500 companies across healthcare, financial services, manufacturing, automotive, and pharmaceuticals. Looking ahead, we see significant opportunity to continue growing our client business faster than the overall PC market, based on the strength of our Ryzen portfolio, broader platform coverage, and expanded go-to-market investments. In gaming, revenue increased 181% year over year to $1.3 billion. Semi-custom revenue increased as Sony and Microsoft prepare for the upcoming holiday sales period. In gaming graphics, revenue and channel sell-out grew significantly, driven by the performance-per-dollar leadership of our Radeon 9000 family. FSR4, our machine learning upscaling technology that boosts frame rates and creates more immersive visuals, saw rapid adoption this quarter, with the number of supported games doubling since launch to more than 85.\n\n**Lisa Su** (Chair and CEO)\nTurning to our embedded segment, revenue decreased 8% year over year to $857 million. Sequentially, revenue and sell-through increased as the demand environment strengthened across multiple markets, led by tests in emulation, aerospace and defense, and industrial vision and healthcare. We expanded our embedded product portfolio with new solutions that extend our leadership across adaptive and x86 computing. We began shipping industry-leading Versal Prime Series Gen 2 adaptive SoCs to lead customers, delivered our first Versal RF development platforms to support several next-generation design wins, and introduced the Ryzen embedded 9000 series with industry-leading performance per watt and latency for robotics, edge computing, and smart factory applications. The design momentum remains very strong across our embedded portfolio.\n\n**Lisa Su** (Chair and CEO)\nWe are on track for a second straight year of record design wins, already totaling more than $14 billion year to date, reflecting the growing adoption of our leadership products across a broad range of markets and expanding set of applications. In summary, our record third-quarter results and strong fourth-quarter outlook reflect the significant momentum building across our business, driven by sustained product leadership and disciplined execution. Our data center AI, server, and PC businesses are each entering periods of strong growth, led by an expanding TAM, accelerating adoption of our Instinct platforms, and EPYC and Ryzen CPU share gains. The demand for compute has never been greater, as every major breakthrough in business, science, and society now relies on access to more powerful, efficient, and intelligent computing. These trends are driving unprecedented growth opportunities for AMD.\n\n**Lisa Su** (Chair and CEO)\nI look forward to sharing more on our strategy, roadmaps, and long-range financial targets at our Financial Analysts meeting next week. Now I'll turn the call over to Jean to provide additional color on our third-quarter results. Jean?\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our outlook for the fourth quarter of fiscal 2025. We're pleased with our strong third-quarter financial results. We delivered a record revenue of $9.2 billion, up 36% year over year, exceeding the high end of our guidance, reflecting strong momentum across our business. Our third-quarter results do not include any revenue from shipment of the MI308 GPU products to China. Revenue increased 20% sequentially, driven by strong growth in the data center and client and gaming segment, and modest growth in the embedded segment.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nGross margin was 54%, up 40 basis points year over year, primarily driven by product mix. Operating expenses were approximately $2.8 billion, an increase of 42% year over year as we continue to invest aggressively in R&D to capitalize on significant AI opportunities and go-to-market activities for revenue growth. Operating income was $2.2 billion, representing a 24% operating margin. Taxes, interest expense, and other totaled $273 million. For the third quarter of 2025, diluted earnings per share were $1.20 compared to $0.92 a year ago, an increase of 30% year over year. Now turning to our reportable segments, starting with the data center. Data center segment revenue was a record of $4.3 billion, up 22% year over year, primarily driven by the strong demand for fifth-generation EPYC processors and Instinct MI350 series GPUs. On a sequential basis, data center revenue increased 34%.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nPrimarily driven by strong ramp of our AMD Instinct MI350 series GPUs. The data center segment operating income was $1.1 billion, or 25% of revenue, compared to $1 billion a year ago, or 29% of revenue, driven by higher revenue, partially offset by higher R&D investment to capitalize on significant AI opportunities. Client and gaming segment revenue was a record of $4 billion, up 73% year over year and 12% sequentially, driven by strong demand for the latest generation of client and graphics processors and stronger sales of console gaming products. In the client business, revenue was a record $2.8 billion, up 46% year over year and 10% sequentially, driven by record sales of our Ryzen processors and the richer product mix. Gaming revenue rose to $1.3 billion, up 181% year over year and 16% sequentially, reflecting higher semi-custom revenue and strong demand for our Radeon GPUs.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nClient and gaming segment operating income was $867 million, or 21% of revenue, compared to $288 million, or 12% a year ago, driven by higher revenue, partially offset by increase in go-to-market investment to support our revenue growth. Embedded segment revenue was $857 million, down 8% year over year. Embedded was up 4% sequentially as we saw certain end-market demand strengthen. Embedded segment operating income was $283 million, or 33% of revenue, compared to $372 million, or 40% a year ago. The decline in operating income was primarily due to lower revenue and end-market mix. Before I review the balance sheet and the cash flow, as a reminder, we closed the sale of ZT Systems Manufacturing business to Sanmina last week. The third-quarter financial results of the ZT Manufacturing business are reported separately in our financial statements as discontinued operations and are excluded from our non-GAAP financials.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nTurning to the balance sheet and the cash flow, during the quarter, we generated $1.8 billion in cash from operating activities of continuing operations, and the free cash flow was a record of $1.5 billion. We returned $89 million to shareholders through share repurchases, resulting in $1.3 billion in share repurchases for the first three quarters of 2025. Exiting the quarter, we have $9.4 billion authorization remaining and our share repurchase program. At the end of the quarter, cash, cash equivalent, and short-term investment was $7.2 billion. Our total debt was $3.2 billion. Now turning to our fourth quarter 2025 outlook, please note that our fourth quarter outlook does not include any revenue from AMD Instinct MI308 shipment to China. For the fourth quarter of 2025, we expect revenue to be approximately $9.6 billion, plus or minus $300 million.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nThe midpoint of our guidance represents approximately 25% year-over-year revenue growth, driven by strong double-digit growth in our data center and client and gaming segment, and a return to growth in our embedded segment. Sequentially, we expect revenue to grow by approximately 4%. Driven by double-digit growth in the data center segment, with strong growth in server and continued ramp of our MI350 series GPUs. A decline in our client and gaming segment, with client revenue increasing and gaming revenue down strong double digits. And double-digit growth in our embedded segment. In addition, we expect fourth-quarter non-GAAP gross margin to be approximately 54.5%. And we expect non-GAAP operating expenses to be approximately $2.8 billion. We expect net interest and other expenses to be gain of approximately $37 million. We expect our non-GAAP effective tax rate to be 13%. And diluted share count is expected to be approximately 1.65 billion shares.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nIn closing, we executed very well, delivering record revenue for the first three quarters of the year. The strategic investment we are making positions us well to capitalize on expanding AI opportunities across all our end markets, driving sustainable long-term revenue growth and earnings expansion for compelling shareholder value creation. With that, I'll turn it back to Matt for the Q&A session.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nThank you very much, Jean. John, we can go ahead and poll the audience for questions now.\n\n**Operator**\nThank you. We will now be conducting a question-and-answer session. If you would like to ask a question, please press star one on your telephone keypad. A confirmation tone will indicate that your line is in the queue. You may press star two to remove yourself from the queue. For participants using speaker equipment, it may be necessary to pick up your handset before pressing the star keys.\n\n**Operator**\nWe ask that you please limit yourself to one question and one follow-up. Thank you. One moment while we poll for questions. And the first question comes from the line of Vivek Arya with Bank of America Securities. Please proceed with your question.\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nThank you for the question. I had a near-term and a medium-term question. For the near-term, Lisa, I was hoping if you could give us some sense of the CPU/GPU mix in Q3 and Q4. And just tactically, how are you managing this transition from your MI355 towards MI400 in the second half of next year? Can you continue to grow in the first half of next year from these Q4 levels, or should we expect some kind of pause or digestion before customers get on board the MI400 series?\n\n**Lisa Su** (Chair and CEO)\nSure, Vivek. Thanks for the question. So a couple of comments.\n\n**Lisa Su** (Chair and CEO)\nWe had a very strong Q3 for the data center business. I think we saw strong outperformance in both the server as well as the data center AI business. And a reminder that that was without any MI308 sales. The MI355 has ramped really nicely. We expected a sharp ramp into the third quarter, and that proceeded well. And as I mentioned, we've also seen some strengthening of the server CPU sales. And not just, let's call it near-term, but we're seeing our customers are giving us some visibility in the next few quarters that they see elevated demand, which is positive. Going into the fourth quarter, again, strong data center performance, up double digits sequentially, and up in both server and data center AI, again, on the strength of those businesses.\n\n**Lisa Su** (Chair and CEO)\nAnd to your question, I mean, we're not diving into 2026 yet, obviously, but given what we see today, we see a very good demand environment into 2026. So we would expect that MI355 continue to ramp in the first half of 2026. And then. As we mentioned, MI450 series comes online in the second half of 2026, and we would expect a sharper ramp as we go into the second half of 2026 of our data center AI business.\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nGot it. And from my follow-up, there is some industry debate, Lisa, about OpenAI's ability to kind of simultaneously engage with all three merchants and the ASIC suppliers, just given the constraints around power and CapEx and their existing kind of CSP partners and so forth. So how are you thinking about that?\n\n**Vivek Arya** (Managing Director and Senior Analyst)\nWhat is your level of visibility in the initial engagement, and then, more importantly, how it kind of broadens out into 2027? Is there a way that one can model what the allocation would be, or just how should we think about the level of visibility in this very important customer? Thank you.\n\n**Lisa Su** (Chair and CEO)\nYeah, absolutely, Vivek. Look, we're very, obviously, very excited about our relationship with OpenAI. It's a very significant relationship. Think about it as it's a pretty unique time for AI right now. There's just so much compute demand across all of the workloads. I think in our work with OpenAI, we are planning multiple quarters out, ensuring that the power is available, that the supply chain is available. The key point is the first gigawatt we will start deploying in the second half of 2026, and that work is well underway.\n\n**Lisa Su** (Chair and CEO)\nAnd we continue, just given where lead times are and things like that, we are planning very closely with OpenAI as well as the CSP partners to ensure that we're all prepared with Helios so that we can deploy the technology as we stated. So I think overall, we're working very closely together. I think we have good visibility into the MI450 ramp, and things are progressing very well.\n\n**Operator**\nAnd the next question comes from the line of Thomas O'Malley with Barclays. Please proceed with your question.\n\n**Thomas O'Malley** (Director of Equity Research)\nGood morning. Thanks for taking my question and congrats on the good results. I had a first question on Helios. Obviously, with the announcement of OCP, customer interaction has to be growing. Could you talk about into next year, what your view is on discrete sales versus system sales? When do you see that crossover kind of happening?\n\n**Thomas O'Malley** (Director of Equity Research)\nAnd just what initial responses have been from customers after getting a better look at it at the show?\n\n**Lisa Su** (Chair and CEO)\nYeah, sure. Tom, thanks for the question. There's a lot of excitement around MI450 and Helios. I think the OCP reception was phenomenal. We had numerous customers and, frankly, bringing their engineering teams to understand more about the system, more about how it's built. There's always been some discussion about just how complex these rack scale systems are, and they certainly are. And we are very proud of the Helios design. I think it has all of the features, functions, reliability, performance, power performance that you would expect. I think the interest in MI450 and Helios has just expanded over the last number of weeks, certainly with some of the announcements that we've made with OpenAI and OCI, as well as the OCP show with Meta.\n\n**Lisa Su** (Chair and CEO)\nI think overall, from our perspective, I think things are going really well in both the development as well as the customer engagement there. So in terms of rack scale solutions, we would expect that the early customers for MI450 will really be around the rack scale solutions. We will have other form factors as well for the MI450 series, but there's a lot of interest in the full rack scale solution.\n\n**Thomas O'Malley** (Director of Equity Research)\nSuper helpful. Then as my follow-up, it's a broader question as well and similar to kind of what Vivek asked. If you look at the power requirements that are out there for some of the early announcements into next year, they're pretty substantial. Then you also have component issues that you're seeing across interconnected memory. Just from your perspective as an industry leader, where do you think that the constraint will be?\n\n**Thomas O'Malley** (Director of Equity Research)\nWill it come first with components not being available, or do you think that both data center footprint in terms of infrastructure and/or power is the gating factor to some of these deployments into next year, just as we really see some larger numbers start to get deployed? Thank you.\n\n**Lisa Su** (Chair and CEO)\nYeah, sure, Tom. I think what you're pointing out is what we as an industry have to do together. The entire ecosystem has to plan together, and that is exactly what we're doing. We're working with our customers on their power plans over the next, actually, I would say, two years. From a silicon and a memory and a packaging and a component supply chain, we're working with our supply chain partners to make sure all of that capacity is available.\n\n**Lisa Su** (Chair and CEO)\nI can tell you from our visibility, we feel very good that we have a strong supply chain that is prepared to deliver sort of these very significant growth rates and large amounts of compute that is out there. I think all of this is going to be tight. There is ayou can see from some of the CapEx spending that there's a desire to put on more compute, and we're working closely together. I will say that the ecosystem is veryI would say works very hard when there are these types of, let's call it, tightness out there. We also see things open up as that we're working, getting more power, getting more supply, all of those things. The net-net is I think we are well positioned to grow significantly as we transition into the second half of 2026, into 2027 with the MI450 and Helios.\n\n**Operator**\nThe next question comes from the line of Joshua Buchalter with TD Cowen. Please proceed with your question.\n\n**Joshua Buchalter** (Director and Senior Analyst of Semiconductors Equity Research)\nHey, guys. Thank you for taking my question. Actually, I wanted to start on the CPU side. You and your largest competitor in that space have talked about near-term strength supporting AI workloads on general-purpose servers from Agentic. Maybe you could speak to the sustainability of these trends. They called out supply constraints. Are you seeing any of those in your supply chain? And are we in a period where we should think about the CPU business on the data center side as being aseasonal, or should we expect normal seasonality in the first half of next year? Thank you.\n\n**Lisa Su** (Chair and CEO)\nSure, Josh. So a couple of comments on the CPU server side. I think we've been watching this trend for the last couple of quarters.\n\n**Lisa Su** (Chair and CEO)\nAnd we started seeing, let's call it, some positive signs in CPU demand, actually, a couple of quarters ago. And what's happened as we've gone through 2025 is now we see sort of a broadening of that CPU demand. So we have a number of our large hyperscale clients are now forecasting significant CPU builds into 2026. And so from that standpoint, I think it's a positive demand environment. And it is because AI is requiring quite a bit of general-purpose compute, and that's great. It catches our cycle as we're ramping Turin. So the Turin ramp has gone extremely fast, and we see good pull for that product, as well as consistent, strong demand for our general product line as well. So back to seasonality as we go into 2026, I think we expect that the CPU demand environment into 2026 is going to be, let's call it, positive.\n\n**Lisa Su** (Chair and CEO)\nAnd so we'll guide more as we get into the end of the year, but I would expect a positive demand environment for CPUs as we see this demand. I do feel like it's durable. It is not a short-term thing. I think it is a multi-quarter phenomenon as we're seeing just much more demand as these AI workloads really turn into have to do real work.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nSo, Josh, on the supply side, we have supplies to support our growth, and especially in 2026, we're prepared for the ramp.\n\n**Joshua Buchalter** (Director and Senior Analyst of Semiconductors Equity Research)\nGot it. Thank you both. And for my follow-up, Lisa, in your prepared remarks, you highlighted progress you guys have made on ROCm 7. I know this has been an area of focus. And can you maybe spend a minute or two talking about where you feel you're at competitively with ROCm?\n\n**Joshua Buchalter** (Director and Senior Analyst of Semiconductors Equity Research)\nHow wide is the breadth of support you're able to offer to the developer community? And what areas do you still have work to do to close any potential competitive gap? Thank you.\n\n**Lisa Su** (Chair and CEO)\nYeah, Josh, thanks for the question. Look, we've made great progress with ROCm. ROCm 7 is a significant step forward in terms of performance and sort of all the frameworks that we support. It's been really, really important for us to get sort of day-zero support of all the newest models and native support for all the newest frameworks. I would say most customers who are starting with AMD now have a very smooth experience as they're bringing on their workloads to AMD. There's obviously always more work to do.\n\n**Lisa Su** (Chair and CEO)\nWe're continuing to augment the libraries and the overall environment that we have, especially as we go to some of the newer workloads where you see training and inference really coming together with reinforcement learning. But overall, I think very strong progress with ROCm. And by the way, we're going to continue to invest in this area because it's so important to really make our customer development experience as smooth as we can.\n\n**Operator**\nAnd the next question comes from the line of C J Muse with Tanner Fitzgerald. Please proceed with your question.\n\n**CJ Muse** (Senior Managing Director)\nYeah, good afternoon. Thank you for taking the question. I guess first question, as you think about the 355 to 400 transition and moving to full rack scale, is there a framework that we should be thinking about for gross margins throughout calendar 2026?\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nYes, C J, thanks for the question.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nI think in general, as we said in the past, for our data center GPU business, the gross margin continues to improve when we ramp a new generation of product. Typically, at the beginning of the ramp, you go through a transition period, then you will normalize the gross margin. We're not guiding 2026, but our priority in data center GPU business is to really expand the top-line revenue growth and the gross margin dollars. And of course, at the same time, we'll continue to drive a gross margin percentage up too.\n\n**CJ Muse** (Senior Managing Director)\nVery helpful. And I guess maybe, Lisa, to kind of probe kind of your growth expectations through 2026 and beyond, and you talked about tens of billions of dollars in 2027.\n\n**CJ Muse** (Senior Managing Director)\nCan you kind of speak at a high level how you're thinking about OpenAI and other large customers and how we should be thinking about the breadth of your customer kind of penetration throughout calendar 2026, 2027? Any help on that would be super. Thank you.\n\n**Lisa Su** (Chair and CEO)\nSure, C J. And we'll certainly address this topic in more detail at our analyst day next week. But let me give you some maybe higher-level points. Look, I think we're really excited about our roadmap. I think we have seen great traction amongst the largest customers. The OpenAI relationship is extremely important to us. And it's great to be able to talk at the multi-gigawatt scale because I think that really is what we believe we can deliver to the marketplace. But there are numerous other customers that we are in deep engagements with. We talked about OCI.\n\n**Lisa Su** (Chair and CEO)\nWe also announced a couple of systems with the Department of Energy that are significant systems. And we have many other engagements. So the way you should think about it is there are multiple customers that we would expect to have, let's call it, very significant scale in the MI450 generation. And that's sort of the breadth of the customer engagements that we've built. And it's also how we're dimensioning the supply chain to ensure that we can supply certainly our. OpenAI partnership as well as the numerous other partnerships that are well underway.\n\n**Operator**\nAnd the next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed with your question.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst of U.S. Semiconductors and Semiconductor Capital Equipment)\nHi, guys. Thanks for taking my questions. My first one, for data center in the quarter, what grew more year over year. On a dollar-to-percentage basis, the servers or the GPUs? In data center.\n\n**Lisa Su** (Chair and CEO)\nYeah, Stacy, I think our commentary was data center grew nicely year over year in both of the areas, both for servers as well as data center AI.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst of U.S. Semiconductors and Semiconductor Capital Equipment)\nYeah, but could youI mean, just directionally, which one grew more than the other? I'm not even asking for numbers just directionally.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nDirectionally, they are similar, but servers a little bit better. Servers a little bit better.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst of U.S. Semiconductors and Semiconductor Capital Equipment)\nOkay. And then on the guidance. You said that serversI mean, data center overall up double digits. You said servers up strong double digits. What does that mean? Is that more than 20%? Or how do I think about what you mean by strong double digits? Because again, I'm trying toI mean, for the GPUs for the year, do you think you'reI mean, you were saying roughly like $6.5 billion or something last quarter for the year. Do you think it's still in that range? It kind of feels like they're still there.\n\n**Jean Hu** (EVP, CFO, and Treasurer)\nStacy, here's what we guided. We guided sequentially data center will be up double digits. And we said server will go up strongly. And at the same time, we also said that MI350 also going to ramp. So we did notI don't think what you just mentioned was what we guided.\n\n**Stacy Rasgon** (Managing Director and Senior Analyst of U.S. Semiconductors and Semiconductor Capital Equipment)\nOh, okay. So I mean, if you say servers are up strongly, does that mean they're up more than the Instinct? Because you didn't really make that commentary on Instinct.\n\n**Lisa Su** (Chair and CEO)\nNo, look, Stacy, let me say it. So data center up sequentially double-digit percentage, both server and data center AI are going to be up as well. And from the standpoint of where they are, I think we're pleased with how both of them are performing. The strong double-digit percentage comment perhaps was applying to the year-over-year commentary.\n\n**Operator**\nThank you. And the next question comes from the line of Timothy Arcuri with UBS. Please proceed with your question.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Lisa, I know it's only been a month since you announced this idea with OpenAI, but can you give us maybe some anecdotes of how this has influenced your position in the market with other customers? Are you engaged with customers that you wouldn't have been engaged with if you hadn't done this deal? That's the first part of the question. And then the second part relates to a prior question, which is that it looks like they could be something like half of your data center GPU revenue in the 2027, 2028 timeframe. So how much risk in your mind is there around that single customer for you?\n\n**Lisa Su** (Chair and CEO)\nSure, Tim. So let me say a couple of things.\n\n**Lisa Su** (Chair and CEO)\nFirst of all, the OpenAI deal has been in the works for quite some time. We're happy to be able to talk about it broadly and also talk about the scale of the deployment and the scale of the engagement being multi-year, multi-gigawatt. I think all those things were very positive. We've had a number of other engagements as well. I think over the lastif you were asked to ask specifically over the last monthI would say that. It's been a number of factors. I think the OpenAI deal was one of them. I think. Being able to show the Helios rack in full force at OpenCompute was also a very important milestone because people could see the engineering and sort of the capabilities of the Helios rack. And if you're asking whether we've seen an increase of interest or an acceleration of interest, I think the answer is yes.\n\n**Lisa Su** (Chair and CEO)\nI think customers are broadly engaged and perhaps broadly engaged at a higher scale, which is a good thing. And then from the standpoint of customer concentration, I think a very key foundation for us in this business is to have a broad set of customers. We've always been engaged with a number of customers. I think we're dimensioning the supply chain in such a way that we would have ample supply to have multiple customers at similar scale as we go into the 2027, 2028 timeframe. And that's certainly the goal.\n\n**Operator**\nThank you. And the next question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYeah, thanks for taking the question.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nI'm curious on the server strength that you're seeing, if there's a way to unpack how we think about unit growth versus ASP expansion as we move through the Turin product cycle. And how do you guys just kind of think about that going forward?\n\n**Lisa Su** (Chair and CEO)\nYeah. So, Aaron, on the server CPU side, Turin certainly is more content. So we see ASPs grow as Turin ramps. But I also mentioned in the prepared remarks that we're actually seeing a very good mix of Genoa still there. So Turin is ramping very quickly, but we are also seeing Genoa demand continue well as the hyperscalers are not able to move everything to the latest generation immediately. So from our standpoint, I think it's broad-based CPU demand across a number of different workloads.\n\n**Lisa Su** (Chair and CEO)\nThis is a little bit, let's call it server refresh, but it seems like from our customer conversations, the workloads are broadly due to the fact that AI workloads are spawning more traditional compute, so more buildout is necessary. I think going forward, one of the things that we see is there is more of a desire for the latest generation. And so as much as we're happy with how Turin is ramping. We're seeing actually a strong pull on Venice and a lot of early engagements in Venice, which kind of says a lot about kind of the importance of general-purpose compute at this point in time.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nYeah, thanks. As a quick follow-up, I'm curious and not to steal maybe the discussion from next week, but Lisa, you've been very consistent, like 500 billion of total AI silicon TAM opportunity and obviously progressing above that.\n\n**Aaron Rakers** (Managing Director and Technology Analyst)\nI'm curious, as we think about these large megawatt kind of deployments, how you think about the updated views on that AI silicon TAM as we look forward.\n\n**Lisa Su** (Chair and CEO)\nWell, Aaron, as you said, not to take too much away from what we're going to talk about next week. Look. We're going to give you a full picture of how we see the market next week, but suffice it to say, from everything that we see, we see the AI compute TAM just going up. So we'll have some updated numbers for you, but the view is whereas 500 billion sounded like a lot when we first talked about it, we think there is a larger opportunity for us over the next few years, and that's pretty exciting.\n\n**Operator**\nThank you. The next question comes from Antoine Chikaban with New Street Research. Please proceed with your question.\n\n**Antoine Chkaiban** (Equity Research Analyst)\nHi, thank you so much for taking my question. So I'd like to ask about whether the developing relationship with OpenAI could be a tailoring to the development of your software stack. Can you maybe tell us about how the collaboration works in practice and whether the partnership contributed in making ROCm more robust?\n\n**Lisa Su** (Chair and CEO)\nYeah, Antoine, thanks for the question. I think the answer is yes. I think all of our large customers contribute to, let's call it a, broadening and deepening of our software stack overall. I think the relationship with OpenAI is certainly one where our plans are to work deeply together on hardware as well as software as well as systems and future roadmap. And from that standpoint, the work that we're doing together with them on Triton is certainly very valuable.\n\n**Lisa Su** (Chair and CEO)\nBut I will say beyond OpenAI, the work that we do with all of our largest customers are super helpful to strengthen the software stack. And we have put significant new resources into not just the largest customers, but we are working with a broad set of AI native companies who are actively developing on the ROCm stack. We get lots of feedback. I think we've made significant progress in the training and inference stack, and we're going to continue to double down and triple down in this area. So more customers that use AMD, I think all of that goes to enhancing the ROCm stack. And we'll talk a little bit more about this next week, but we're also using AI to. Help us accelerate the rate and pace of some of the ROCm kernel development and just the overall ecosystem.\n\n**Antoine Chkaiban** (Equity Research Analyst)\nThanks, Lisa.\n\n**Antoine Chkaiban** (Equity Research Analyst)\nAnd maybe as a quick follow-up, could you tell us about the useful lives of GPUs? I know that most CSPs depreciate them over five, six years, but in your conversations with them, I'm just wondering if you see or hear any early indication that in practice they may be planning to sweat those GPUs for longer than that.\n\n**Lisa Su** (Chair and CEO)\nI think we have seen some early indications of that, Antoine. I think the key point being. Clearly, there's a desire to get on the latest and greatest GPUs when you're building new data center infrastructure. And certainly when we're looking at MI355s, they're often going into. New liquid-cooled facilities, MI450 series as well. But then we're also seeing the other trend, which is there's just a need for more AI compute. And from that standpoint, some of the older generations, MI300X is still doing quite well in terms of just where we see people deploying and using, especially for inference. And from that standpoint. I think you see a little bit of both.\n\n**Operator**\nAnd the next question comes from the line of Joe Moore with Morgan Stanley. Please proceed with your question.\n\n**Joe Moore** (Managing Director and Semiconductor Industry Analyst)\nGreat. Thank you. You mentioned MI308. I guess what's your posture there to the extent that if there is some relief that you're able to ship, do you have readiness to do that? Can you give us a sense for how much of a swing factor that could be?\n\n**Lisa Su** (Chair and CEO)\nSure, Joe. So look, it's still a pretty dynamic situation with MI308. So that's the reason that we did not include any MI308 revenue in the Q4 guide. We have received some licenses for MI308, so we're appreciative of the administration supporting some licenses for MI308.\n\n**Lisa Su** (Chair and CEO)\nWe're still working with our customers on the demand environment and sort of what the overall opportunity is. And so we'll be able to update that more in the next couple of months.\n\n**Joe Moore** (Managing Director and Semiconductor Industry Analyst)\nOkay. But you do have. Product to support that market. If it does open up, or are you going to have to start to kind of rebuild inventory for that?\n\n**Lisa Su** (Chair and CEO)\nWe've had some work in process. I think we continue to have that. Work in process, but we'll have to see sort of how the demand environment shapes up.\n\n**Joe Moore** (Managing Director and Semiconductor Industry Analyst)\nOkay. Thank you very much.\n\n**Lisa Su** (Chair and CEO)\nThanks.\n\n**Matt Ramsay** (VP of Financial Strategy and Investor Relations)\nOperator, I think we might have time for just one more caller, please. Thank you very much.\n\n**Operator**\nNo problem. And the final question comes from the line of Ross Seymore with Deutsche Bank. Please proceed with your question.\n\n**Ross Seymore** (Managing Director)\nThanks for squeezing me in.\n\n**Ross Seymore** (Managing Director)\nLisa, this might take longer than the amount of time we have left before the top of the hour, but there's been so many of these multi-gigawatt announcements from OpenAI. How does AMD truly differentiate in there? When you see that big customer signing deals with other GPU vendors and ASIC vendors, etc., how do you attack that market differently than those competitors to not only get the 6 gigawatt initially, but hopefully more after that?\n\n**Lisa Su** (Chair and CEO)\nSure, Ross. Well, look, what I see is actually this environment where the world needs more AI compute. And from that standpoint, I think OpenAI has kind of led in the quest for more AI compute, but they're not alone. I think when you look across the large customers, there is really a demand for more AI compute as you go forward over the next couple of years.\n\n**Lisa Su** (Chair and CEO)\nI think we each have our advantages in terms of how we are positioning our products. I think MI450 series in particular, I think, is an extremely strong product, rack-scale solution. Overall, when we look at compute performance, when we look at memory performance, we think it's extremely well-positioned for both inference as well as training. I think the key here is time to market, its total cost of ownership. Its deep partnership, and thinking about not just MI450 series, but what happens after that. So we're deep in conversations on MI500 and beyond. And we certainly think we're well-positioned to not only participate, but participate in a very meaningful way across the sort of the demand environment here. And I think we have certainly learned a ton over the last couple of years with our AI roadmap.\n\n**Lisa Su** (Chair and CEO)\nWe've made significant inroads in terms of just what the largest customer needs from a workload standpoint. So I'm pretty optimistic about our ability to capture a significant piece of this market going forward.\n\n**Ross Seymore** (Managing Director)\nGreat. And I guess as my follow-up, it'll be a direct follow-on to that. You did a unique structure by granting some warrants with this deal. And I know they've asked according to a price that would be very creative and make everybody happy. Do you think that was a relatively unique agreement, or given that the world needs more processing power, that AMD is open to somewhat similar, conceptually similar creative ways to address that demand over time with other equity vehicles, etc.?\n\n**Lisa Su** (Chair and CEO)\nSure, Ross. So I would say it was a unique agreement from the standpoint that unique time in AI.\n\n**Lisa Su** (Chair and CEO)\nWhat we wanted, what we prioritized was really deep partnership and multi-year, multi-generation, significant scale. And I think we got that. We got a structure that has extremely aligned incentives. Everybody wins, right? We win, OpenAI wins, and our shareholders win. Sort of benefits from this, and all of that accrues to the overall roadmap. I think as we look forward, I think we have a lot of very interesting partnerships that are developing, whether they're with the largest AI users or you think about sovereign AI opportunities. And we look at each one of these as a unique opportunity where we're bringing sort of the whole of AMD. Both technically as well as all the rest of our capabilities to the party.\n\n**Lisa Su** (Chair and CEO)\nSo I would say OpenAI was pretty unique, but I would imagine that there are lots of other opportunities for us to bring our capabilities into the ecosystem and participate in a significant way.\n\n**Operator**\nLadies and gentlemen, that does conclude the question and answer session, and that also concludes today's teleconference. We thank you for your participation. You may disconnect your lines at this time.",
        "fetched_at": "2026-02-04T16:13:55.019Z"
      },
      {
        "ticker": "AMD",
        "title": "Yahoo Finance",
        "published_date": "Aug 5, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q2",
        "url": "https://finance.yahoo.com/quote/AMD/earnings/AMD-Q2-2025-earnings_call-343098.html",
        "content": "**Operator**\nGreetings, and welcome to the AMD Second Quarter twenty twenty five Conference Call. At this time, all participants are in a listen only mode. A question and answer session will follow the formal presentation. As a reminder, this conference is being recorded. And it is now my pleasure to introduce to you Matthew Ramsey, VP of Investor Relations and Financial Strategy. Thank you, sir. Please go ahead.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nThank you, and welcome to AMD's twenty twenty five second quarter financial results conference call. By now, you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations page of amd.com. We will refer primarily to non GAAP financial measures during today's call. The full non GAAP to GAAP reconciliations are available in today's press release and slides posted on our website.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nParticipants in today's conference call are Doctor. Lisa Su, our Chair and Chief Executive Officer and Jean Hu, our Executive Vice President, Chief Financial Officer and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Jean Hu, Executive Vice President, Chief Financial Officer and Treasurer will present at Citi's twenty twenty five Global TMT Conference on Wednesday, September 3. And Forrest Norad, Executive Vice President and General Manager of Data Center Solutions Business Unit will present at the Goldman Sachs Communicopia and Technology Conference on Monday, September 8.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nToday's discussion contains forward looking statements based on our current beliefs, assumptions and expectations, speaks only as of today and as such involves risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause actual results to differ materially. With that, I will hand the call over to Lisa.\n\n**Lisa Su** (Chair &amp; CEO)\nThank you, Matt, and good afternoon to all those listening today. We delivered very strong second quarter results with revenue exceeding the midpoint of guidance as higher EPYC and Ryzen processor sales more than offset headwinds from export controls that impacted Instinct sales. We set records for both EPYC and Ryzen CPU sales, reflecting the broad based demand for our differentiated high performance data center, PC and embedded processors. Second quarter revenue increased 32% year over year to a record $7,700,000,000 and we delivered over $1,000,000,000 in free cash flow. Excluding the $800,000,000 inventory write down related to data center AI export controls, gross margin was 54, marking our sixth consecutive quarter of year over year margin expansion led by a richer product mix.\n\n**Lisa Su** (Chair &amp; CEO)\nTurning to the segments, Data Center segment revenue increased 14% year over year to 3,200,000,000.0 We saw robust demand across our EPYC portfolio to power cloud and enterprise workloads and increasingly for emerging AI use cases. In particular, adoption of AgenTeq AI is creating additional demand for general purpose compute infrastructure as customers quickly realize that each token generated by a GPU triggers multiple CPU intensive tasks. Against this backdrop, fifth gen EPYC TURN shipments ramped significantly and we had sustained demand for our prior generation EPYC processors. As a result, we set records for both cloud and enterprise CPU sales and delivered our thirty third consecutive quarter of year over year share gains. In cloud, adoption expanded with the largest hyperscalers as they deployed Epic to power more of their mission critical infrastructure, services and public cloud products.\n\n**Lisa Su** (Chair &amp; CEO)\nMore than 100 new AMD powered cloud instances launched in the quarter, including multiple Turin instances from Google and Oracle Cloud that deliver up to twice the performance of our previous generation, which were already the industry's highest performing offerings. There are now nearly 1,200 EPYC Cloud instances available globally as providers continue expanding both the breadth and regional availability of their AMD offerings. This continued expansion is accelerating enterprise adoption of Epic in the cloud with deployments growing significantly from the prior quarter as we closed large wins with dozens of large aerospace streaming, financial services, retail and energy companies. EPYC adoption also grew with telecom customers as providers modernize their infrastructure for next generation networks. For example, KDDI announced plans to deploy EPYC processors to power its five gs virtualized network.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd Nokia selected Epic for its cloud platform used by service providers to build, deploy and manage core network functions. Turning to enterprise on prem adoption, HPE, Dell, Lenovo and Super Micro launched 28 new TURN platforms in the quarter that deliver leadership performance, efficiency and TCO across a wide range of enterprise workloads. EPIC enterprise deployments grew significantly from the prior quarter, supported by new wins with large technology, automotive, manufacturing, financial services and public sector customers. To extend our momentum with SMB and hosted IT service customers, we launched the EPYC 4,005 series that combine enterprise grade performance and features in cost optimized platforms, purpose built for smaller scale deployments. Turning to HPC, AMD now powers more than one third of the world's fastest supercomputers, including El Capitan and Frontier, which retained the number one and number two spots on the latest top 500 list.\n\n**Lisa Su** (Chair &amp; CEO)\nWe also powered 12 of the top 20 systems on the green 500, highlighting the performance per watt advantages of EPYC and Instinct for large scale deployments. Looking ahead, we remain bullish on our server CPU business, driven by durable tailwinds, including growing demand for cloud and on prem compute, sustained share gains and the growing investments in general purpose infrastructure required to enable AI. Turning to our Data Center AI business, revenue declined year over year as U. S. Export restrictions effectively eliminated MI-three zero eight sales to China and we began transitioning to our next generation MI-three 50 series accelerators.\n\n**Lisa Su** (Chair &amp; CEO)\nWe made solid progress with MI300 and MI325 in the quarter, closing new wins and expanding adoption with Tier one customers, next generation AI cloud providers and end users. Today, seven of the top 10 model builders and AI companies use Instinct, underscoring the performance and TCO advantages of our data center AI solutions. We launched our Instinct MI350 series with industry leading memory bandwidth and capacity and broad adoption across hyperscalers, AI companies and OEMs. From a competitive standpoint, MI355 matches or exceeds B200 in critical training and inference workloads and delivers comparable performance to GB200 for key workloads at significantly lower cost and complexity. For at scale inferencing, MI355 delivers up to 40% more tokens per dollar, providing leadership performance and clear TCO advantages.\n\n**Lisa Su** (Chair &amp; CEO)\nWith the MI three fifty series, we're also expanding our system level capabilities to support deployments powered by AMD CPUs, GPUs and NICs. As one example, Oracle is building a 27,000 plus node AI cluster combining MI355 X Accelerators, fifth Gen EPYC TURN CPUs and Polarra 400 SmartNICs. We began volume production of the MI350 Series ahead of schedule in June and expect a steep production ramp in the second half of the year to support large scale production deployments with multiple customers. Our sovereign AI engagements accelerated in the quarter as governments around the world adopt AMD technology to build secure AI infrastructure and advance their economies. As one example, we announced a multibillion dollar collaboration with Humane to build AI infrastructure powered entirely on AMD CPUs, GPUs and software.\n\n**Lisa Su** (Chair &amp; CEO)\nInitial deployments are underway in key regions with quarterly expansions planned over the coming years. In addition, we have more than 40 active engagements globally and see significant opportunities to power an increasingly larger portion of national computing centers and sovereign AI initiatives. On the AI software front, we made significant progress this quarter, increasing the performance, improving the usability and expanding the adoption of ROCCM. We announced ROCCM seven with major upgrades across every layer of the stack, delivering more than 3x higher inferencing and training performance compared to our prior generation and adding support for large scale training, distributed inference and lower precision data types. To deepen developer engagement, we introduced nightly ROCCM builds and expanded access to instant compute infrastructure, including launching our first developer cloud that provides pre configured containers for instant access to AMD GPUs.\n\n**Lisa Su** (Chair &amp; CEO)\nWe also expanded native support for ROCCM across key frameworks, including VLLM and SGLANG, enabling frontier models like LAMA-four, Gemma-three and DeepSeek R1 to launch with DayZero AMD support. To accelerate enterprise adoption, we introduced Rockham Enterprise AI, a full stack platform that integrates seamlessly with existing IT infrastructure and includes everything needed for an enterprise to deploy, manage and scale AI across their business. Looking ahead, the development of our next generation MI400 series is progressing rapidly. These are the most advanced GPUs we have ever built with up to 40 petaflops of FP4 AI performance and 50% more memory, memory bandwidth and scale out throughput than the competition. With the MI400 series, we're bringing together everything we've learned across silicon software and systems to deliver Helios, a full stack rack scale AI platform.\n\n**Lisa Su** (Chair &amp; CEO)\nHelios is purpose built for the most demanding AI workloads with each rack connecting up to 72 GPUs that can operate as a single massive AI accelerator. Helios is expected to deliver up to a 10x generational performance increase for the most advanced frontier models. And we believe it will be the highest performance AI system in the world when it launches. MI-four 100 series development is progressing well towards our planned launch in 2026 with significant interest in large scale deployments from multiple high profile customers. To accelerate our development, we have invested significantly to expand our AI software and hardware capabilities, both organically and inorganically with a number of acquisitions and strategic investments.\n\n**Lisa Su** (Chair &amp; CEO)\nWe strengthened our software stack last quarter with the addition of the Brium and Lamini teams, building on our acquisitions of Nod dot ai, Nipsology and Silo dot ai. On the hardware side, we added a world class rack and data center scale design team in the second quarter with our acquisition of ZT Systems. The ZT team is integrated seamlessly and they are actively engaging with multiple customers to accelerate deployments of our Helios solutions at scale. We also announced last quarter that Sannina intends to acquire ZT's U. S.\n\n**Lisa Su** (Chair &amp; CEO)\nBased manufacturing business, becoming our lead partner for AI rack manufacturing. Turning to the AI regulatory environment, earlier this quarter, we were notified by the Department of Commerce that it is moving forward with the review of our license applications to export MI-three zero eight to China. We appreciate the focus the Trump administration is placing on assuring that The U. S. Technology remains central to global AI infrastructure and we expect to resume MI-three zero eight shipments as licenses are approved subject to end customer demand and supply chain readiness.\n\n**Lisa Su** (Chair &amp; CEO)\nAs our licenses are still under review, we are not including any MI-three zero eight revenue in our third quarter guidance. Despite that, we expect Instinct revenue to grow year over year in the third quarter, driven by the ramp of MI350 at multiple customers. In Clients and Gaming, segment revenue increased 69% year over year to 3,600,000,000 driven by record client CPU sales and strong demand for our semi custom game console SoCs and Radeon GPUs. Client revenue increased 67% year over year to $2,500,000,000 led by record desktop CPU sales. Demand for our latest generation Ryzen 9,000 series was strong, especially for our differentiated X3D processors.\n\n**Lisa Su** (Chair &amp; CEO)\nWe delivered record desktop channel CPU sales as Ryzen processors consistently topped the best selling CPU lists at major global e tailers throughout the quarter. We also expanded our Zen five desktop portfolio with the launch of our latest Threadripper processors that feature up to 96 cores and deliver up to double the performance of the competition in many popular content creation and design workloads. In mobile, demand for AMD powered notebooks was strong with sellout growing by a large double digit percentage year over year. We drove a richer mix of higher ASP mobile parts year over year as we expanded our share in the premium notebook segment, where our Ryzen AI 300 CPUs deliver leadership performance and value for both general purpose and AI workloads. In commercial PCs, Ryzen adoption accelerated as OEM consumption increased more than 25% year over year.\n\n**Lisa Su** (Chair &amp; CEO)\nWe saw a strong sell through for AMD commercial notebooks with Lenovo and HP and a significant uptick in Dell sales as they ramp availability of their AMD commercial portfolio. We also closed new enterprise wins with Forbes two thousand pharma, tech, automotive, financial services, aerospace and healthcare companies. We expect continue growing our commercial client share based on the strength of our product portfolio and expanded breadth of OEM offerings. Looking more broadly, we remain confident we can continue growing client processor revenue ahead of the market over the coming quarters, driven by increased adoption of our desktop and notebook products, growing commercial momentum and a richer product mix. In gaming, revenue increased 73% year over year to 1,100,000,000.0 Semi custom revenue increased by a large double digit percentage year over year as console inventories normalized and our customers began preparing for the holiday season.\n\n**Lisa Su** (Chair &amp; CEO)\nWe announced a new multi year collaboration with Microsoft for custom chips that will power the next generation of Xbox devices, including consoles, PCs and handhelds. We also deepened our collaboration with Sony through Project Amethyst, a co engineering program that will use machine learning to power the next wave of immersive gaming experiences. In PC gaming, demand for our latest generation Radeon 9,000 series GPUs was very strong with desktop GPU sell through accelerating in the quarter as demand outpaced supply. We launched the Radeon 9,600 XT extending the performance advantages of RDNA four to mainstream gamers and delivering a significant uplift in gaming performance, including more than double the ray tracing of our prior generation. As part of our end to end AI strategy, we introduced the Radeon AI Pro R9700 GPU for local inferencing, model fine tuning and other data intensive workloads.\n\n**Lisa Su** (Chair &amp; CEO)\nThe R9700 features more memory, full ROCCM support and multi GPU scalability, enabling advanced AI development and deployment directly on the desktop. Turning to our Embedded segment, revenue decreased 4% year over year to $824,000,000 Demand continues recovering gradually with sell through in the second quarter picking up as strength in most markets was offset by a few pockets of softness and inventory reduction actions, largely with industrial customers. We expanded our embedded portfolio with the first production shipments of Spartan UltraScale plus FPGAs that deliver leadership performance and advanced security for cost sensitive low power applications. Adoption of our Versal Adaptive SoCs continues expanding in high end applications, including next generation Robotaxi platforms developed by Bosch in Europe, where Versal serves as a high performance controller, enabling real time processing, security and encryption in fully electric automated vehicles. Looking ahead, we expect improving demand in the test and measurement, communications and aerospace markets will drive a return to sequential growth in the 2025.\n\n**Lisa Su** (Chair &amp; CEO)\nLonger term, design win momentum continues to build tracking ahead of this point last year and putting us on pace to surpass the record $14,000,000,000 in design wins we achieved in 2024. In summary, demand is very strong across our product portfolio and we are well positioned to deliver significant growth in the second half of the year, led by the steep ramp of MI350 Series accelerators and ongoing EPYC and Ryzen share gains. Our server and PC CPU businesses are accelerating, driven by growing demand for high performance compute, sustained share gains, the strength of our product portfolio and expanded go to market investments. Our embedded and gaming businesses are returning to growth and are well positioned for long term success supported by strong design win momentum. And in AI, we are seeing strong adoption of our MI350 Series and ROCCM seven as we deliver leadership performance and TCO advantages across a broader range of workloads and ramp deployments with an expanded set of cloud and enterprise customers.\n\n**Lisa Su** (Chair &amp; CEO)\nLooking ahead, we see a clear path to scaling our AI business to tens of billions of dollars in annual revenue. We are very excited about our next generation MI400 series, which is another giant step forward on our roadmap and has been designed to deliver leadership performance at the chip, server and rack levels. Customer interest for the MI-four 100 series is very strong and we're actively engaging with an expanding set of customers to support large scale deployments in 2026. We are in the early stages of an industry wide AI transformation that will drive a step function increase in compute demand across all of our markets, positioning us for significant revenue and earnings growth over the coming years. Now I'd like to turn the call over to Jean to provide some additional color on our second quarter results. Jean?\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our outlook for the 2025. We are pleased with our strong second quarter financial results. We delivered record revenue of 7,700,000,000.0 exceeding the midpoint of our guidance, up 32% year over year, reflecting strong momentum across our business. Record sales of Ryzen and EPYC processors and the higher semi customer shipment more than offset the impact of The U.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nS. Export controls, restricting MI308 sales to China. Revenue increased 3% sequentially due to strong growth in the client and the gaming segment, partially offset by the data center revenue decrease due to export controls. Gross margin was 43%, down 10 points from 53% a year ago. The decrease was due to the $800,000,000 inventory and the related charges associated with the export restrictions.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nExcluding this charge, non GAAP gross margin would have been approximately 54%. Operating expenses were approximately $2,400,000,000 an increase of 32% year over year as we continue to invest aggressively in go to market activities for revenue growth and in R and D to capitalize on significant future AI expansion opportunities. Operating income was $897,000,000 representing a 12% operating margin compared to $1,300,000,000 or 22% a year ago. The decline was primarily due to the inventory and the related charges. Taxes, interest expense and other totaled 126,000,000 For the 2025, diluted earnings per share were $0.48 compared to $0.69 a year ago.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nThe inventory and the related charges reduced earnings per share by approximately $0.43 Now turning to our reportable segment, starting with the data center. Data center segment revenue was $3,200,000,000 up 14% year over year, driven by strong added CPU revenue and the share gains across both cloud and enterprise customers. On a sequential basis, data center revenue decreased 12% due to the impact of the XBOP controls on MI-three zero eight. The data center segment operating loss was $155,000,000 compared to operating income of $743,000,000 a year ago or 26% of revenue. The loss was primarily due to the inventory and related charges.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nClient and Gaming segment revenue was $3,600,000,000 up 69% year over year and 20% sequentially, driven by record client CPU sales and strong demand for our PC and console gaming products. In the client business, revenue was a record of $2,500,000,000 up 67% year over year, driven by record sales of our Ryzen desktop CPUs and the richer product mix. Gaming revenue rose to 1,100,000,000 up 73% year over year, reflecting strong demand for our newly launched gaming GPUs and higher semi customer revenue as inventory has now normalized and the customers prepare for the holiday season. Client and Gaming segment operating income was $767,000,000 or 21% of revenue compared to $166,000,000 or 8% a year ago, driven by richer client product mix and operating leverage on higher revenue. Embedded segment revenue was $824,000,000 down 4% year over year and flat sequentially as embedded end market demand remains mixed.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nEmbedded segment operating income was $275,000,000 or 33% of revenue compared to $345,000,000 or 40% a year ago. The decline in operating income was primarily due to product mix. Before I review the balance sheet and the cash flow, as a reminder, we closed the acquisition of ZT Systems early in the second quarter as we had announced our intent to divest ZT manufacturing business. The financial results of the ZT manufacturing business are reported separately in our financial statement as discontinued operations and are excluded from our non GAAP financials. Subsequently, in May, we entered into agreement with the Samina Corporation to sell the ZTE manufacturing business for $3,000,000,000 in cash and stock, inclusive of contingent payment.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nThe transaction is expected to close near the 2025, subject to regulatory approvals and the customary closing conditions. Turning to the balance sheet and the cash flow. During the quarter, we generated $1,500,000,000 in cash from operating activities of continuing operations. And the free cash flow was a record of $1,200,000,000 We returned $478,000,000 to shareholders through share repurchase, resulting in $1,200,000,000 in share repurchases for the 2025. In May, our Board of Directors approved additional $6,000,000,000 authorization.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nExiting the quarter, have 9,500,000,000 remaining under our share repurchase program. At the end of the quarter, cash, cash equivalents and short term investment were $5,900,000,000 Our long term debt was $3,200,000,000 During the quarter, we paid down $950,000,000 of commercial paper used to finance the ZT system acquisition close. Now turning to our third quarter twenty twenty five outlook. Please note that our third quarter outlook does not include the annual revenue from AMD Instinct MI-three zero eight shipment to China, as our license applications are currently under review by U. S.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nGovernment. For the 2025, we expect revenue to be approximately 8,700,000,000.0 plus or minus $300,000,000 The midpoint of our guidance represents approximately 28% year over year revenue growth, driven by strong double digit growth in our client and the gaming and the data center segments. Sequentially, we expect revenue to grow by approximately 13%, driven by strong double digit growth in the data center segment with the ramp of our AMD Instinct MI350 Series GPU product, modest growth in our client and gaming segment with the client revenue increasing and the gaming revenue to be flattish. And our embedded segment revenue to return to growth. In addition, we expect third quarter non GAAP gross margin to be approximately 54% and we expect non GAAP operating expenses to be approximately 2,550,000,000 We expect net interest and other expenses to be again of approximately $10,000,000 We expect our non GAAP effective tax rate to be 13% and diluted share count is expected to be approximately 1,630,000,000.00 shares.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nIn closing, we executed very well in the first half of the year, delivering record revenue and building strong momentum for growth in the second half. The strategic investment we're making position us to capitalize on the expanding AI opportunities across all our end markets, driving sustainable long term revenue growth and earnings expansion for compelling value creation. With that, I'll turn it back to Matt for the Q and A session.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nOperator, will you please poll the audience for questions? Thank you.\n\n**Operator**\nYes. Thank you, Matt. We will now be conducting a question and answer session. And the first question comes from the line of Thomas O'Malley with Barclays. Please proceed with your question.\n\n**Thomas OMalley** (Director - Equity Research)\nHey, thank you for taking my questions and I appreciate it. Lisa, I wanted to start on the client business. So you had previously laid out a second half outlook that was roughly flattish with the first half as you're kind of protecting against some pull forward. So first, do you think that your Q2 results included some pull forwards and the second half should still be flattish? And longer term after the Intel commentary regarding 18A, maybe what that means as a knee jerk reaction just right away for AMD longer term in terms of share in ASPs?\n\n**Lisa Su** (Chair &amp; CEO)\nSure, Tom. Thanks for the question. So first of all, our client and gaming segment, and particularly our client business, just performed very well in the first half of the year. I think if you look at the entire first half, was up 68% year over year. I think if you look underneath that, what we're seeing is strength in every part of our client business.\n\n**Lisa Su** (Chair &amp; CEO)\nSo we saw very strong sales in our desktop channel area. We have a leadership product there, best gaming GPUs with our X3D GPUs. We've had strong Ryzen AI adoption as well in the first half of the year. We see that in sell through. And in addition, we've had strong enterprise sell through as we brought that forward.\n\n**Lisa Su** (Chair &amp; CEO)\nSo to your question of how much is pulled forward, we don't think a whole lot of that is. We actually when we look at the sell through patterns, the end user consumption is actually quite strong In terms of going into the second half of the year, as we said in Q3 guide, the primary driver of our Q3 guide is a very strong data center driven by MI350 ramping. We are expecting some growth in the client business. So I wouldn't say it'll be flat to the first half, but it will be we're planning for it to be a little bit less than seasonal, just given some of the uncertainties out there.\n\n**Lisa Su** (Chair &amp; CEO)\nBut the client business is performing extremely well for us. We believe we are gaining share in all the right places. So if you look at the numbers in the first quarter, and it will show through in the second quarter as well, a lot of the uplift in revenue is in ASPs. And that is basically, we're selling up the stack on the strength of our portfolio. And I think we're still quite underrepresented in the enterprise portion of the business.\n\n**Lisa Su** (Chair &amp; CEO)\nThat is where we have increased our go to market resources and focus, and we're seeing nice traction there, especially with the portfolios that we have from HP and Lenovo in enterprise PCs. And now we're adding Dell as well as it's ramping here, started in the second quarter, we'll ramp more in the second half of the year. So I think all of those are tailwinds for our client business beyond the 2025, but really into the next number of quarters as we think about the portfolio and the opportunities for us.\n\n**Thomas OMalley** (Director - Equity Research)\nSuper helpful. And then secondly, was hopeful you could provide us a little more color on China. So the guide doesn't include MI-three zero eight, but perhaps you could comment on when you get approval, if the supply chain is ready, what's currently in inventory and maybe compare what you think the contribution will look like versus the $700,000,000 in Q2 and the $800,000,000 for the second half you spoke about in April?\n\n**Lisa Su** (Chair &amp; CEO)\nSure, Tom. So yes, let me answer some of the questions on China. I'm sure that there are some questions. Look, we're very pleased with the progress that's been made with the administration over the last couple of months. We've been working very closely with the administration.\n\n**Lisa Su** (Chair &amp; CEO)\nI think the focus here on ensuring that US technology gets utilized throughout the world is something that we certainly support and very much want to contribute to. China is an important market for us. Given the timing of licenses, we have a number of licenses that are under review now. We are working with the Department of Commerce to get those reviewed. We do expect that once those licenses are approved, we will start MI-three zero eight shipments.\n\n**Lisa Su** (Chair &amp; CEO)\nIn terms of the supply chain, most of our inventory was not in finished goods. So it was work in process and it'll take us a couple of quarters to run through that. The exact timing of revenue and contribution will depend a bit on when those are when the licenses are actually granted. But overall, I think this is a better position than we were ninety days ago. And we certainly view China as a market that we would like to service with MI-three zero eight.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd we're working closely with the administration to do that.\n\n**Operator**\nAnd the next question comes from the line of Vivek Arya with Bank of America Securities. Please proceed with your question.\n\n**Vivek Arya** (Managing Director)\nThank you for taking my question. Lisa, if we look into 2026, right, that's when I think the sovereign opportunity could get quite meaningful for AMD. What is the right way to size that? You know, what does this JV structure structure mean with some of the contracts that you have signed? Would you consider this incremental to the kind of growth rate that you're seeing with your current MI business, or would this be instead of?\n\n**Vivek Arya** (Managing Director)\nSo just if you could give us a way to size what is that incremental opportunity from sovereign customers when it comes to 26, is it dependent on MI 400, right? In which case it might be more backup data, etcetera. So, just some ways to think about sovereign for AMD next year.\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, absolutely, Vivek. Thanks for the question. So look, we're really excited about the overall AI opportunity for us with MI three fifty five and the MI 400 series as we go through the back half of this year and into 2026. I think it's there's a very large opportunity with, let's call it hyperscalers, some of the leading AI companies as well as Sovereign. I think Sovereign is additive to that for sure. From the standpoint of what to expect, there are also some regulatory things that need to be worked through on the sovereign side. But again, we were working closely with the administration as they go through the various regulatory decisions that need to be made.\n\n**Lisa Su** (Chair &amp; CEO)\nBut from my perspective, I think the fact that countries want their own sovereign computing capability is very, very clear. I think we see that all over the world. The humane opportunity that you're referring to that we announced with the Kingdom Of Saudi Arabia, think is a great example of where together with their ambitions, our technology, I think you heard from Tarek that was he was at our event saying that that would start with MI-three 55, that we would expect that that would continue on. I think what's attractive about our offering is our open ecosystem. And I think that really resonates with the sovereign community.\n\n**Lisa Su** (Chair &amp; CEO)\nBut to your original question, I think it's an additive opportunity and it's one that we believe will continue to be very important for us going forward with both MI-three 55 as well as the MI-four 100 series.\n\n**Vivek Arya** (Managing Director)\nAnd for my follow-up, I wanted to ask about gross margins for your MI product. So I understand in the early days, right, it has been dilutive. What kind of sales level is required for it to start becoming, you know, additive to margins? And let's say if I fast forward to Q4 and assume that, you know, your Q4 sales are growing year on year roughly the same rate as Q3 sales, Should we expect gross margins to kind of stay at these Q3 levels? Or are there other plusminus drivers we should think about in terms of gross margins as you go into Q4? Thank you.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nYes. Vivek, thank you for the question. The gross margin of our MI product, we said it's a little bit below corporate average. I think at this point, our priority is really to address the larger, faster growing revenue opportunities that we have and provide customers the better TCO to really expand our presence in the marketplace. I think that the way to think about our gross margin, there are different dynamics, right, different customers, different generations.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nBut also our operation team has been continuing to really drive operational efficiency to improve our MI family's gross margin. That has been ongoing. So it's not necessarily really tied to, okay, the revenue level each quarter, but you should think about is a trend in the longer term, it should improve continually going forward. Overall, the way I think about these gross margin dollars, right, this is one of the fastest growing market opportunities for any financial metrics, gross margin dollars is what we try to grab as much as we can. Hopefully, that helped your question.\n\n**Operator**\nAnd the next question comes from the line of Timothy Arcuri with UBS. Please proceed with your question.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Lisa, so my question is on data center GPU. You did say that June is up year over year, so it sounds like it's maybe a little more than $1,000,000,000 And you use words like strong ramp into the back half of the year. Can you give us just any color on what that means? Can you get to say $7,000,000,000 for the year?\n\n**Timothy Arcuri** (Managing Director)\nAnd can you give us some maybe a milepost on what you're assuming for Q3 would be great?\n\n**Lisa Su** (Chair &amp; CEO)\nYes. Thanks, Tim, for the question. I think what we said in the prepared remarks is that we are seeing a strong ramp from Q2 into Q3. MI-three fifty five, we actually started production in June. So we had some shipments in sort of in the month of June, but it really is ramping as we go through this quarter and the third quarter.\n\n**Lisa Su** (Chair &amp; CEO)\nSo in terms of guideposts, we said it would grow year on year from last year and that I think is a strong ramp. And then we would expect it to grow into the fourth quarter as well. The demand, I should say, what we're seeing from customers is, I think, really positive around MI 355. Sort of the way I would contrast it with maybe the MI 300 ramp, I think MI 300 started with perhaps some smaller deployments. I think what we're seeing with MI355 is very competitive versus the B200, GB200 family of products.\n\n**Lisa Su** (Chair &amp; CEO)\nI think there's a strong desire to really use us at scale. The MI-three 55 is very strong for inferencing. We're also working with a number of customers on training. And this is also an opportunity for us to build into the MI-four 100 series as we go into 2026. So we're bullish on MI-three 55 and where the AI opportunity is for us.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd I think we're right on track to what we expected to be as we were going through the development of the roadmap.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. And then Lisa, just on that point also, you did talk about a new developer cloud. So, obviously, you're beginning you're, you know, beginning to lease back some of the, you know, capacity that you're selling into the clouds and the neo clouds. Is that gonna be a material portion of the revenue you're gonna recognize for MI $3.55 in the back half of the year? Can you just talk about that and maybe how to think about how much demand that's going to stimulate and what the ultimate goal is for that cloud? Thanks.\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, so there are a couple of things in that question. So let me answer. So the developer cloud is simply we want to make it super easy for developers to get on AMD Instinct GPUs. One could say, again, if we look back at the MI300 family, we were very focused on the largest hyperscalers and the largest customers. But there's a lot of interest in our GPUs across a number of customers who just wanted easier access.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd so by ensuring that developer cloud is there, that it has ready to deploy containers, you can run training and inference easily, you don't necessarily have to make longer term commitments. I think that's the purpose of the Developer Cloud. I don't think it adds meaningfully to revenue in the second half of the year, but it certainly adds to customers getting experience with AMD. I think the larger revenue opportunities for us are really with large customer adoption as they ramp to larger deployments. And we're very actively trying to get those deployments up and running as soon as possible.\n\n**Lisa Su** (Chair &amp; CEO)\nOne of the things just as a reminder that the MI355 is, given that it's similar a infrastructure to MI300, we actually think it's going to ramp very quickly and very well for customers. And I think that's one of the attractive portions of it as well.\n\n**Operator**\nAnd the next question comes from the line of Ross Seymore with Deutsche Bank. Please proceed with your question.\n\n**Ross Seymore** (Managing Director)\nHi, thanks for letting me ask a question. Lisa, want to go back to the instinct side of things and the MI 355 ramp. It looks like the second half is going to ramp really significantly. You said it's going to be up year over year in the third quarter. I believe a quarter ago, you said roughly the same thing, and the MI-three 08 is out of both numbers, so that shouldn't really matter, and I guess it would be upside.\n\n**Ross Seymore** (Managing Director)\nBut I just wondered how have things changed from a quarter ago as far as the MI-three 50 family adoption, especially because you launched a little bit early. Is the growth a little bit more than you would have expected a quarter ago, about the same or a little worse? Just any sort of color on that would be helpful.\n\n**Lisa Su** (Chair &amp; CEO)\nYes, Ross, thanks for the question. I think the main thing I would say is, I think the adoption is a bit faster than we might have expected. Again, whenever you launch a product, we want to make sure that we go through the full validation and all of that with our customers. I think there's a lot of interest, broad based interest in MI-three 55. And so I feel like over the last ninety days, I think we've had significant sort of new customer interest and that's certainly positive.\n\n**Lisa Su** (Chair &amp; CEO)\nWill say, I'm sorry, Ross, I was just going to add, our engagements are, I think the other pieces, I think there's also a lot of excitement around MI-four Hundred and what we can do with the Helios rack. And so there are a number of customers who based on sort of the strong roadmap that we're showing, to get familiar and really work with us earlier in the life cycle, which I think is again positive.\n\n**Ross Seymore** (Managing Director)\nGreat, thank you for that. I guess as my follow-up, an earlier question you talked about a little bit below seasonality in the second half of the year for your client business. It seems like there's just I don't even know if seasonality is a framework that matters, but how are you thinking about that for the second half as a whole for a client? And then gaming was just up a huge amount sequentially in the second quarter. You described a little bit of what you're expecting there.\n\n**Ross Seymore** (Managing Director)\nBut how do you think about seasonality for the second half in its entirety in the gaming side as well?\n\n**Lisa Su** (Chair &amp; CEO)\nYes, let me try and then Jean might add if you want a little bit more color. So the way to think about it is, we do expect some growth sequential growth in clients as we go into the third quarter. I would say, sort of single digit type growth. We continue to see good traction for our products in that portfolio. On the gaming side, I would call it flattish to Q2.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd we're coming off of such a strong Q2 that I think flattish is actually to be expected. As we go into the fourth quarter, the dynamics that we would see is, we would see that the console business would actually be down substantially. So think about it as down strong double digits. The customers usually build for the holiday season sort of before that and then that will be completed by the fourth quarter. So we would expect as the client and gaming segment that the segment would probably be down in the fourth quarter.\n\n**Lisa Su** (Chair &amp; CEO)\nSo hopefully that helps. Jean, did you want to add to that?\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nNo, I think you covered it.\n\n**Operator**\nAnd the next question comes from the line of Joshua Buchalter with TD Cowen. Please proceed with your question.\n\n**Joshua Buchalter** (Director - Equity Research)\nHey, guys. Thank you for taking my question. I wanted to ask about lead times on your on the Instinct family both for the MI three fifty group family and MI 400. I mean, as you move into larger cluster sizes, which it sounds like you're doing at least with Oracle on three fifty and then endeavor to do more so on 400, how much visibility and lead time do you need from your customers? Because I would imagine the lead time for your parts is measured in months, but on the infrastructure side in particular for the larger scale deployments, I mean, those things are measured in years at this point.\n\n**Joshua Buchalter** (Director - Equity Research)\nSo maybe you could speak to the visibility specifically on the 400. Thank you.\n\n**Lisa Su** (Chair &amp; CEO)\nYes, sure, Josh. So, yes, I mean, our lead times are long given all of the processing steps that we have to go through. Think about it as somewhere between eight, nine months, that type of thing. We have a very, very strong supply chain. We've been preparing for these ramps of both MI350 series and MI400 series, and that preparation is ongoing.\n\n**Lisa Su** (Chair &amp; CEO)\nSo, we feel like we have a very strong supply chain there. In terms of visibility with customers, we're absolutely working with customers very closely on near term MI350 Series deployments, getting those deployments up as quickly as possible. Again, one of the things about the MI350 series that is good is that it can go into existing data centers, just given the platform that it is in. So we have been certainly working with our customers there. And then for the MI400 series, there are lots and lots of details sort of full rack scale design implementation and we're actively working with the largest customers right now on just ensuring that our Helios rack is fully compatible with their data center build outs as we go into 2026.\n\n**Lisa Su** (Chair &amp; CEO)\nSo that visibility is important. I think that co development, co engineering is important as we get into the RackScale architecture. And the ZT team that we brought in has been extremely, extremely helpful in terms of both internal platform build out as well as ensuring that we're working closely with our customers on their data center needs.\n\n**Joshua Buchalter** (Director - Equity Research)\nThank you for that, Lisa. Maybe for Gene, I wanted to follow-up on Vivek's question earlier on gross margins. So if we add back the charges in 2Q and then your gross margin implied in the guidance is roughly flat sequentially. And that's despite what's implied to be data center GPUs up meaningfully sequentially. Like it doesn't seem like console is falling off in the third quarter.\n\n**Joshua Buchalter** (Director - Equity Research)\nI mean, you maybe talk to the underlying drivers of how you're able to keep the flat gross margins despite what sounds like still margin dilutive data center GPUs up significantly within the mix? Thank you.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nYes. Justin, thanks for the question. Yes, we are guiding our Q3 gross margin around 54%. And Q2, you're right, excluding the $800,000,000 charge, was close to 54%. I think the gaming business actually is quite high.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nSo the mix actually is unfavorable. But we do have some tailwinds that we have been really driving. First is we have been expanding our server business, which has really nice gross margin. And then on the client business side, we are expanding the commercial PC business. So that really helps us to drive the gross margin up.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nIn addition, we do have a really strong operational team. They are driving the gross margin improvement just from operational efficiency perspective across the board. So overall, our objective is to continue to improve gross margin despite MI350 very strong ramp in Q3, we are able to continue to drive the margin up.\n\n**Operator**\nAnd the next question comes from the line of Joe Moore with Morgan Stanley. Please proceed with your question.\n\n**Joseph Moore** (Managing Director)\nGreat, thank you. You've used this language before of the kind of tens of billions opportunity around MI-four hundred. Can you talk about the timeframe when that might occur and not to pin you down too much, but and what would help you get to that level sooner rather than later? Should we think of that as a 2027 realistic outcome that you could be looking at 20,000,000,000 plus? Just a little bit more color on that tens of billions comment.\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, I mean, maybe without being specific, Joe, I can give you sort of the way I look at it and back to this notion of, are we incrementally more confident? I think we're seeing a lot of positive signs in our AI customer adoption. I think the strength of the MI350 series, the very positive feedback that we're getting on MI400 from customers, the work that we're doing in terms of ensuring that we are fully ready for large scale deployments of not just inference, but training. I think when we get to tens of billions of dollars, we're talking about significant gigawatt scale type deployments. And those would be important for us to get there.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd we're certainly, I think, engaged with all of the right customers that can enable that type of ramp. But I won't necessarily speculate on the exact time other than to say, certainly that would be our set of aspirations.\n\n**Joseph Moore** (Managing Director)\nGreat, that's helpful. Thank you. And then as these workloads evolve, I mean, you've sort of talked about inference and training as sort of different opportunities for AMD. Are you seeing those start to come together? It seems like with inference, the reasoning models are requiring much higher complexity.\n\n**Joseph Moore** (Managing Director)\nIs rack scale more important to the inference market than you thought it might be? Just any color around how that complexity of inference is impacting you guys?\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, think that's absolutely true, Joe. I think with the proliferation of models, I think what we're seeing is GPUs continue to be very sort of the computing of choice as you think about all the models that are out there. And then as you go into distributed inference and some of the newer techniques, we are seeing the importance of the scale up and scale out architecture, which we are investing in. But I think the overarching thing is, think we have a very competitive roadmap across the next couple of generations. I think that has now gotten strong customer validation.\n\n**Lisa Su** (Chair &amp; CEO)\nWe're getting a lot of feedback from customers on where they would like to see us continue to add more resources and add more focus. And so that is very helpful. And the key is to be a full scale solution provider for these large customer deployments. That's what we're working on.\n\n**Operator**\nAnd the next question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nYes. Thanks for taking the question. I do have a follow-up as well. I guess the first question is, when we look at the data center guide, Gene, you had alluded to double digit sequential growth. Obviously, the MI three fifty five series kind of ramping.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nI'm curious, how could we conceptualize what you're expecting in the server side? And where do you think your market share is today in traditional enterprise servers outside of cloud?\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nYes. I think when you look at our data center business, we do have a strong double digit growth, both the server and MI both sides are growing sequentially. Of course, MI ramp is the most significant one. As far as the server market share, we do think we continue to drive the market share up compared to Q1. Not a third party has not published a report yet, but we feel really good about the Q2 market share increase versus Q1.\n\n**Lisa Su** (Chair &amp; CEO)\nErin, if I just add to that, one of the things that it's important for people to understand is in some of the cloud CapEx numbers that have come out that have been quite positive, That is not only a GPU statement, but there's actually significant CPU CapEx in there as well. We've started to see more robust forecasts going out a number of quarters on the server CPU side, because all of that AI content really requires traditional CPUs as well. And so we're very bullish on the opportunity in servers. I think the team has really executed extremely well. I mean, if you look at our portfolio now, Turin and Genoa are very well adopted, broadening workloads.\n\n**Lisa Su** (Chair &amp; CEO)\nEnterprise adoption is also increasing. And so I think all of those are positive for the server opportunity in the 2025, as well as going into 2026 and beyond.\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nYeah. And then as a follow-up, I'm kind of thinking about the China, the MI-three zero eight opportunity. When we do see a license, I think you alluded to this earlier, it's going to take a little bit of time to kind of ramp and get the supply chain to satisfy the demand. But I'm curious, the 800,000,000 write down that you had taken, is there no kind of finished inventory there? Does that come back?\n\n**Aaron Rakers** (Managing Director &amp; Technology Analyst)\nDo you have any reversal aspects of that once a license gets approved?\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nLet me start first, then Lisa First, on the $800,000,000 majority of them are WIPs. We really don't have on the shelf finished goods that we can ship immediately. So we do need to take time if we get a license. That's perfect.\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, thank you.\n\n**Operator**\nAnd the next question comes from the line of C. J. Muse with Cantor Fitzgerald. Please proceed with your question.\n\n**CJ Muse** (Senior Managing Director)\nYeah, good afternoon. Thank you for taking the question. I guess Lisa was hoping you could level set us on the instinct ramp into 2026. How are thinking about the timing of the handoff three fifty to four hundred? How are you thinking about Helios contributions?\n\n**CJ Muse** (Senior Managing Director)\nAnd I guess very importantly from a customer contribution perspective, how you might see that evolve from traditional hyperscalers to perhaps more sovereign and Neo Cloud within the mix?\n\n**Lisa Su** (Chair &amp; CEO)\nSure, CJ. So certainly as second half this year, it's all about MI three fifty five ramp into first half of next year. I think the MI 400 series development is right on track. The development of the Helios platform is also right on track. We would expect significant revenue contribution from Helios in 2026.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd then relative to the contribution of the various things hyperscalers, sort of some of the versus Neo Clouds versus Sovereign. I think it's a little early to really talk about the different pieces other than to say, you would expect that hyperscalers and let's call it Neo Clouds that would be working for other large AI natives, maybe significant pieces of the initial ramp. And then sovereign may come a little bit later in time, just given sort of the timing of when different build outs would happen. So hopefully that gives you some color, CJ.\n\n**CJ Muse** (Senior Managing Director)\nYes, very helpful. And then Jean, I guess a question for you with the sale of ZT for $3,000,000,000 of cash and stock and you only have $3,000,000,000 of debt outstanding. How are you thinking about the use of proceeds? Is there saving for a rainy day or bolt on acquisitions, perhaps more aggressive share buyback? How are you thinking about it today?\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nYes, thanks for the question. Our business model actually generate a lot of free cash flow as you see in Q2, free cash flow generation was $1,200,000,000 So if we close the ZT sale and we'll get more cash. Overall, our capital allocation principle continue to be the first things investing, especially with the tremendous AI opportunities ahead of us. And then we'll continue to return cash to shareholders. We did a $1,200,000,000 repurchase in the first half of the year.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nWe are committed to continue to return cash to shareholders through share repurchase.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nOperator, I think we have time for one more caller, please.\n\n**Operator**\nOkay. The final question comes from the line of Ben Reitzis with Melius Research. Please proceed with your question.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nHey, thanks for squeaking me in here. I wanted to clarify a little bit on the $1,000,000,000 increase in sequential sales. It would seem like it's coming from GPUs primarily. I was wondering if you could back that. And that's with nothing in China.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nAnd if the answer to the prior question that GPUs are over $1,000,000,000 that kind of puts you at a $2,000,000,000 run rate. And I was just wondering if that was accurate in terms of thinking. And then I have just a very quick follow-up. Thanks.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nHi, Ben. Thanks for the question. If you look at the sequential revenue increase, as I mentioned during the prepared remarks, we see data center strong double digit increase, which include both GPU and the CPU, but the GPU definitely drives largest incremental amount increase. We also mentioned the client actually is going to increase sequentially. In addition, the embedded business will return to sequential growth.\n\n**Jean Hu** (EVP, CFO &amp; Treasurer)\nSo multiple business contributed to sequential increase, but the majority of increase is really driven by MI three fifty five with a strong ramp.\n\n**Ben Reitzes** (MD &amp; Head - Technology Research)\nOkay, great. And then if indeed that gets you pretty close to a couple billion dollars, if the MI-three 100 comes in, do you see it at the same run rate that you exited? And then you have the ability to get at that 800 mil run rate right away? Or you think it will take several quarters to ramp when you get the license? Thanks.\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, Ben, it will take some time to ramp just given particularly today. I mean, we're sitting already in early August. So I don't think you would see a lot of it in Q3. But certainly, as licenses would be approved, would schedule that and it would take a little while to ramp.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nAll right, operator, thank you very much. We appreciate everybody that joined the call today and we just like to end the call now. Thank you.\n\n**Operator**\nYep, ladies and gentlemen, that does conclude today's teleconference. We thank you for your participation. You may disconnect your lines at this time.",
        "fetched_at": "2026-02-04T16:13:59.013Z"
      },
      {
        "ticker": "AMD",
        "title": "Yahoo Finance",
        "published_date": "May 6, 2025, 5:00 PM EDT",
        "fiscal_year": "2025",
        "quarter": "Q1",
        "url": "https://finance.yahoo.com/quote/AMD/earnings/AMD-Q1-2025-earnings_call-312657.html",
        "content": "**Operator**\nGreetings, and welcome to the AMD First Quarter twenty twenty five Conference Call. At this time, all participants are in a listen only mode. A question and answer session will follow the formal presentation. And as a reminder, this conference is being recorded. It is now my pleasure to introduce to you Matt Ramsay, Vice President, Financial Strategy and Investor Relations. Thank you, sir. You may begin.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nThank you, and welcome to AMD's twenty twenty five first quarter financial results conference call. By now, you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations portion of amd.com. We will refer primarily to non GAAP financial measures during today's call. The full non GAAP to GAAP reconciliations are available in today's press release and the slides posted on our website.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nParticipants on today's conference call are Doctor. Lisa Su, our Chair and Chief Executive Officer and Jean Hu, Executive Vice President, Chief Financial Officer and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to take note that Mark Papermaster, our Executive Vice President and Chief Technology Officer, will attend the T. D.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nCowan TMT Conference on Wednesday, May 28 and Jean Hu will attend the Bank of America Global Technology Conference on Tuesday, June 3. Today's discussion contains forward looking statements based on our current beliefs, assumptions and expectations, speak only of today and as such involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement on our press release for more information on factors that could cause actual results to differ materially. You will also find detailed discussion of our risk factors in our filings with the SEC, in particular, AMD's most recent quarterly report on Form 10 Q and annual report on Form 10 ks. And with that, I would like to hand the call over to Lisa.\n\n**Lisa Su** (Chair &amp; CEO)\nThank you, Matt, and good afternoon to all those listening today. We delivered an outstanding start to the year despite the evolving dynamics related to tariffs and the regulatory environment. Growth accelerated for the fourth consecutive quarter year over year, driven by strength in our core businesses and expanding data center and AI momentum. Revenue and EPS both exceeded consensus estimates as Instinct AI Accelerator, EPYC and Ryzen CPU sales grew significantly year over year. As a result, first quarter revenue increased 36% year over year to 7,400,000,000.0 as our Data Center and Client and Gaming segments both grew by a large double digit percentage.\n\n**Lisa Su** (Chair &amp; CEO)\nWe expanded gross margin year over year for the fifth straight quarter and increased net income by 55%, driven by a higher overall percentage of data center product sales and a richer Ryzen processor mix. Despite the uncertain macroeconomic backdrop, our first quarter performance highlights the strength of our differentiated product portfolio and execution and positions us well for strong growth in 2025. Turning to the segments. Data Center segment revenue increased 57% year over year to 3,700,000,000 We gained server CPU share driven by the ramp of our latest fifth gen EPYC TURN processors and sustained demand for fourth gen EPYC. Hyperscaler demand remained strong as cloud providers expanded EPYC deployments to to power their critical infrastructure and public services.\n\n**Lisa Su** (Chair &amp; CEO)\nMore than 30 new instances launched from Alibaba, AWS, Google, Oracle, Tencent and others in the quarter, including the initial wave of fifth gen EPYC Turing instances. In addition, AWS launched new FPGA accelerated instances in the quarter powered by EPYC processors with Xilinx Vertex FPGAs that are optimized for data and compute intensive workloads like genomics, multimedia processing, network security and cloud based video broadcasting. Every major cloud provider is deep in development on Turin programs with a steady stream of public instances and internal deployments expected to ramp into production over the coming quarters. Enterprise adoption of EPYC instances was very strong in the quarter. The number of EPYC powered cloud instances activated by Forbes two thousand enterprise customers more than doubled year over year, including new wins with Internet native streaming, transportation, financial services and social media companies.\n\n**Lisa Su** (Chair &amp; CEO)\nFor example, CrowdStrike achieved major performance improvements by broadly deploying EPYC instances across its multi cloud infrastructure. At the same time, we're also actively partnering with leading application and cloud providers to deploy EPYC optimized solutions tailored for specialized industry verticals. Siemens launched their latest software defined vehicle solution powered by EPYC CPUs and Radeon Pro GPUs on Azure, leveraging digital twin technology to significantly speed up automotive design and validation. Oracle launched a new version of its Exadata Database platform, which is used by more than half of the Fortune Global one hundred. The latest Exadata X11M has been optimized for fifth gen EPYC processors deliver up to 25% faster performance in transaction processing and analytics compared to the prior generation.\n\n**Lisa Su** (Chair &amp; CEO)\nTurning to enterprise on prem adoption, EPYC CPU sales grew by a large double digit percentage year over year for the seventh straight quarter, driven by new public sector wins and high volume deployments with large automotive, semiconductor, financial services, retail, energy and technology companies. We have built significant enterprise momentum over the last few years as our partners expanded the number of Epic based platforms to more than four fifty and we scaled our joint go to market programs. As a result, EPIC is now deployed by all of the top 10 telecom, aerospace and semiconductor companies, nine out of the top 10 automotive, seven out of the top 10 manufacturing, and six out of the top 10 energy companies on the Forbes two thousand. We expect enterprise adoption to accelerate over the coming quarters as more than 150 TURN platforms become broadly available from Dell, Cisco, HPE, Lenovo, Super Micro and others. Looking forward, we see a clear path to continued share gains as customers ramp their fifth gen EPYC offerings that deliver unmatched performance, efficiency and TCO across every major cloud and enterprise data center workload.\n\n**Lisa Su** (Chair &amp; CEO)\nWe passed key milestones in April to begin manufacturing fifth gen EPYC at TSMC's new Arizona fab with first production shipments expected in the second half of twenty twenty five. Longer term, we announced our next gen EPYC Venice processors are the lead HPC products for TSMC's two nanometer process node. Venice silicon is in our labs and performing well, with bring up and validation progressing to plan to support a 2026 launch. Turning to our data center AI business. Revenue increased by a significant double digit percentage year over year as MI325X shipments ramp to support new enterprise and cloud deployments.\n\n**Lisa Su** (Chair &amp; CEO)\nMore than 35 MI-three hundred series platforms are in production from all the leading service providers, supporting the expanding number of Instinct GPU deployments with cloud, enterprise and AI customers. Several hyperscalers expanded their use of Instinct accelerators to cover an increasing range of generative AI search, ranking and recommendation use cases. We also added multiple Tier one cloud and enterprise customers in the quarter, including one of the largest frontier model developers that is now using Instinct GPUs to serve a significant portion of their daily inference traffic. The depth and breadth of our customer engagements continues to expand as breakthroughs in large scale AI models like OpenAI's O3 and DeepSeq's R1 drive increased demand for traditional inferencing and increasingly as a critical part of pre training. The industry leading memory capacity and bandwidth of our Instinct portfolio is ideally suited for these workloads, and we are actively working with multiple customers to scale Instinct from single node deployments to distributed inferencing clusters.\n\n**Lisa Su** (Chair &amp; CEO)\nTraining engagements also ramped in the quarter as multiple Tier one hyperscale AI and enterprise customers scaled Instinct GPU clusters to train internal and next gen frontier models. In parallel, we're making meaningful progress with sovereign AI deployments as countries expand investments to establish domestic nation scale AI infrastructure. In February, we announced a strategic partnership with G42 to build one of France's most powerful AI compute facilities powered by Instinct accelerators. On the AI software front, we significantly accelerated our release cadence in the first quarter, shifting from quarterly ROCCM updates to delivering ready to deploy training and inferencing containers on a biweekly basis that include performance optimizations and support for the latest libraries, kernels and algorithms. We expanded our open source community enablement in the quarter, making significantly more instant compute infrastructure available to enable developers to automatically build, test and deploy updates to Rock'em code nightly.\n\n**Lisa Su** (Chair &amp; CEO)\nAs a result, more than 2,000,000 models on Hugging Face now run out of the box on AMD. We're also enabling an increasing number of models to launch with Day Zero support for Instinct accelerators, including Meta's LAMA-four, Google's Gemma-three and DeepSeq's R1 models that were released in the first quarter. Beyond launch, we are delivering regular software updates that increase performance for new models. For example, in the weeks following the launch of DeepSeq's R1 model, we introduced ROCCM optimizations that enabled MI 300 to deliver leadership inferencing throughput. We released ROCCM 6.4 in the quarter with major upgrades that increased training and inferencing performance across popular AI frameworks like PyTorch, JAX and VLLM.\n\n**Lisa Su** (Chair &amp; CEO)\nThe release also adds multiple ease of use features, including new cluster management tools that simplify the scaling and optimization of large scale Instinct deployments. Turning to our AI solutions capabilities. Earlier this quarter, we completed our acquisition of ZT Systems, adding world class systems design expertise to complement our silicon and software leadership. With ZT, we can provide ready to deploy rack level AI solutions based on industry standards built with AMD CPUs, GPUs and networking, reducing deployment time for hyperscalers and accelerating time to market for OEM and ODM partners. The team is fully engaged and already co designing with key customers on rack level designs optimized for our upcoming MI-four hundred series and working with customers and OEM partners to accelerate time to market for our MI350 series.\n\n**Lisa Su** (Chair &amp; CEO)\nWe have received significant interest in ZT's manufacturing business and expect to announce a strategic partner shortly. We began sampling our next gen MI350 Series with multiple customers in the first quarter and remain on track to begin accelerated production by midyear. MI350 Series performance is very strong based on the advances in architecture. We designed cDNA four to deliver leadership performance across a wide range of AI workloads, increasing memory capacity and bandwidth 1.5 x, adding support for new data types and improving network efficiency to deliver 35x higher throughput and performance compared to MI300x. Customer interest in the MI350 Series is very strong, setting the stage for broad deployment in the second half of this year.\n\n**Lisa Su** (Chair &amp; CEO)\nAs one example, we are partnering with Oracle to deploy a large scale cluster powered by Mi355X accelerators, fifth gen EPYC TURN processors and Polara four hundred AI NICs. This multibillion dollar initiative highlights the expanding AMD and OCI partnership and the growing demand for AMD Instinct to power the next wave of large scale AI infrastructure. Looking ahead, our MI400 series development remains on track to launch next year. The MI400 series is designed to deliver leadership performance for both inferencing and training, scaling seamlessly from single servers to full data center deployments. Early customer feedback has been very positive, marking a major step forward in our Instinct roadmap and significantly expanding our AI accelerator TAM as customers plan broader Instinct deployments to power a larger share of their AI infrastructure.\n\n**Lisa Su** (Chair &amp; CEO)\nI'm looking forward to sharing more details on the MI350 Series, future MI400 Rack Scale solutions and the growing customer adoption of our Instinct platforms at our Advancing AI event on June 12. Turning to our Client and Gaming segment. Segment revenue increased 28% year over year to $2,900,000,000 Client revenue grew 68% year over year, marking our fifth consecutive quarter of revenue share gains. We delivered record client CPU ASP, driven by a richer mix of high end desktop and mobile Ryzen processors. Desktop channel sellout increased by more than 50% year over year.\n\n**Lisa Su** (Chair &amp; CEO)\nWe set new sellout records in multiple regions as our latest generation Ryzen processors became the CPU of choice for gamers, topping bestseller lists at leading global e tailers. To build on this momentum, we extended our desktop CPU portfolio with the launch of our 16 core Ryzen 9,950 X3D processor that delivers significantly higher gaming and productivity performance than the competition. In mobile, AMD based notebook sell through was very strong in the quarter. We also saw strong demand for our latest generation AI PC processors as sales ramped, increasing by more than 50% quarter on quarter. The first notebooks powered by our new high end Ryzen AI Max plus and the first mainstream Ryzen AI seven and five three hundred series processors launched to very positive reviews.\n\n**Lisa Su** (Chair &amp; CEO)\nThese new processors set the standard for traditional computing and graphics performance, while also delivering unmatched AI capabilities and battery life, positioning Ryzen as a CPU of choice for gaming, ultra thin and commercial notebooks. Demand for AMD based commercial PCs was also very strong in the quarter. Ryzen Pro PC sell through grew more than 30% year over year, driven by new end customer wins and an 80% increase from 2024 in the number of AMD powered commercial systems from HP, Lenovo, Dell and ASUS. We closed multiple wins with large auto, energy, healthcare, financial services companies in the quarter. Looking more broadly across the PC market, we remain confident we can grow client processor revenue well ahead of the market in 2025, led by expanding adoption of our desktop channel and consumer and commercial notebook portfolio as well as a richer mix.\n\n**Lisa Su** (Chair &amp; CEO)\nTurning to our Gaming business results. Gaming revenue decreased 30% year over year as higher Radeon graphic sales were more than offset by lower semi custom sales. While our semi custom SoC sales declined year over year, console channel inventories have normalized and demand signals have strengthened for 2025. For PC gaming, we launched our Radeon 9,070 series to strong demand as our new RDNA four architecture delivers leadership performance for mainstream gamers. First week sellout set a record and was more than 10x higher than our previous best Radeon launch.\n\n**Lisa Su** (Chair &amp; CEO)\nDemand remains very strong and we are working closely with our board partners to replenish inventory weekly and meet the sustained demand. We also introduced FSR4, our first machine learning based rendering technology that delivers significantly higher frame rates and more immersive gaming experiences. FSR4 is already enabled in over 30 games with support expected to reach 75 titles by year end. Turning to our Embedded segment. First quarter revenue decreased 3% year over year to $823,000,000 Embedded demand continues to recover gradually.\n\n**Lisa Su** (Chair &amp; CEO)\nWe expect improving demand in the Test and Measurement, Communications and Aerospace markets will drive a return to growth in the second half of twenty twenty five. We completed initial shipments of our cost optimized Spartan UltraScale plus FPGAs and second generation Versal AI edge SoCs to meet growing demand for AI at the edge. As a part of continuing to grow our embedded x86 business, we launched our EPYC embedded 9,005 series CPUs that deliver leadership performance for networking, storage and industrial edge applications. Cisco selected our new EPYC embedded processors for their latest high end firewall solutions, and IBM is using them to power its latest storage scale system 6,000 for performance intensive enterprise analytics and AI workloads. We also released our latest Vitis AI software suite, expanding support for the latest models and accelerating edge AI deployment across a broader range of applications, further strengthening our leadership in the rapidly emerging edge AI market.\n\n**Lisa Su** (Chair &amp; CEO)\nIn summary, our strong first quarter results and second quarter outlook reflect the momentum we are building across our business. While we faced some headwinds from the dynamic macro and regulatory environments, including the recently announced export controls for Instinct MI-308X shipments to China, we believe they are more than offset by the powerful tailwinds from our leadership product portfolio. Against this backdrop, we remain confident we can deliver strong double digit percentage revenue growth in 2025 based on accelerating share gains with our latest generation of Zen five Epic and Ryzen CPUs and Radeon GPUs and ramping production of our Instinct MI350 Series accelerators in the second half of the year to support an expanded set of customers and AI workloads. We also expect full year growth in our semi custom business and for our Embedded business to return to year over year growth in the second half of the year, driven by the reduced inventory levels and improving demand environment. To capitalize on our unprecedented growth opportunities and deliver our next major growth arc, we are expanding investments in our product and technology roadmaps, go to market initiatives and full stack AI software and data center scale solutions capabilities.\n\n**Lisa Su** (Chair &amp; CEO)\nWe're also doubling down on our execution to deliver and where possible accelerate our industry leading roadmaps. We view the current environment as a strategic opportunity to further differentiate AMD as we deliver an expanding product portfolio that combine leadership compute and AI capabilities for data centers, edge, PCs and embedded end devices. Now I'd like to turn the call over to Jean to provide some additional color on our first quarter results. Jean?\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nThank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the second quarter of fiscal twenty twenty five. As a reminder, for comparative purposes, our first quarter fiscal year twenty twenty five financial statement disclosures include the combination of our client and the gaming businesses into a single reportable segment to align with how we manage the business. We continue to provide distinct revenue disclosures for our data center, client gaming and embedded businesses. We are pleased with our record first quarter revenue of $7,400,000,000 exceeding the high end of our guidance, up 36% year over year, driven by 57% revenue growth in the data center segment and a 28% revenue growth in the client and the gaming segment.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nRevenue declined 3% sequentially due to lower revenue in the embedded and data center segments, partially offset by sequential growth in the client and the gaming segment. Gross margin was 54%, up 140 basis points from a year ago. Operating expenses were $2,200,000,000 an increase of 28% year over year, as we continue to invest aggressively in go to market activities and in R and D to address the significant growth opportunities ahead of us. Operating income was $1,800,000,000 representing a 24% operating margin. Taxes, interest expenses and other was $213,000,000 For the first quarter of twenty twenty five, diluted earnings per share was $0.96 an increase of 55% year over year.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nNow turning to our reportable segments. Starting with the data center. Data center segment revenue was $3,700,000,000 up 57% year over year, primarily driven by continued CPU server share gains across both the cloud and enterprise customers and the strong growth of AMD Instinct GPUs. On a sequential basis, data center segment revenue decreased 5%. Data center segment operating income was $932,000,000 or 25% of revenue compared to $541,000,000 or 23% a year ago.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nClient and Gaming segment revenue was $2,900,000,000 up 28% year over year, driven primarily by strong customer demand for our latest generation Zen five AMD Ryzen processor, partially offset by lower semi customer revenue. Client revenue was $2,300,000,000 up 68% year over year. More than half of the growth was driven by higher ASPs from a richer mix of high end Ryzen processors. On a sequential basis, the client and the gaming segment revenue increased by 2%, primarily driven by stronger than seasonal performance of our client product portfolio and increased the semi customer product revenue. Client and Gaming segment operating income was $496,000,000 or 17% of revenue compared to $237,000,000 or 10% of a year ago, driven by operating leverage on higher revenue.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nEmbedded segment revenue was $823,000,000 down 3% year over year. Embedded demand continues to recover gradually. Sequentially, embedded was down 11% consistent with our expectations. Embedded segment operating income was $328,000,000 or 40% of revenue compared to $342,000,000 or 41% a year ago. Turning to the balance sheet and the cash flow.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nDuring the quarter, we generated $939,000,000 in cash from operations. And our free cash flow for the quarter was $727,000,000 We returned $749,000,000 to shareholders through the repurchase of common stock and our repurchase program. We have a $4,000,000,000 remaining in our share repurchase authorization. At the end of the quarter, cash, cash equivalents and short term investment was 7,300,000,000.0 Within the quarter, we reached CAD 1,500,000,000.0 of debt and issued CAD $950,000,000 of commercial paper to help fund our acquisition of ZT Systems, which was completed on March 31. Now turning to our second quarter twenty twenty five outlook.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nAs a reminder, in April, a new export license requirement was put in place for MI-three zero eight shipments to China, the impact of which is included in our guidance. We expect revenue to be approximately $7,400,000,000 plus or minus $300,000,000 This includes an estimated $700,000,000 revenue reduction as a result of the new export license requirement. Despite this headwind, the middle point of our guidance represents 27% year over year revenue growth. For the full year 2025, we estimated the revenue impact due to the XPOP license requirement to be approximately $1,500,000,000 Sequentially, we expect client and the gaming segment revenue to increase by double digit percentage. Embedded segment revenue to be flattish, and we expect data center segment revenue to decrease due to the exclusion of MI-three zero eight revenue.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nIn addition, we expect second quarter non GAAP gross margin is estimated to be 43%, inclusive of approximately $800,000,000 in charges for inventory and related reserves. Excluding this charge, our non GAAP gross margin would be approximately 54%. Non GAAP operating expenses to be approximately 2,300,000,000 which includes approximately $50,000,000 in OpEx due to the addition of the ZT Systems design team. The financials for the ZT manufacturing business will be reported as discontinued operations starting in the second quarter. We expect net interest and other expenses to be $5,000,000 due to the debt associated with the ZT system transaction.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nNon GAAP effective tax rate to be 13% and the diluted share count is expected to be approximately 1,640,000,000.00 shares, which includes 9,000,000 shares related to the ZT transaction. Looking forward, despite ongoing macro and the trade policy related uncertainties, we believe the investment we are making will position us well to address the large growth opportunities ahead as AI expand the use of high performance computing across all our end market. In closing, 2025 is off to a strong start as we continue to execute on key strategic financial goals. We delivered strong top line revenue growth, expanded the growth and operating margins and closed the key acquisition of ZT Systems to expand and accelerate our data center GPU and the systems road maps. With that, I'll turn it back to Matt for the Q and A session.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nThank you very much, Jean. John, can you go ahead and pull the callers for the Q and A session, please? Thank you.\n\n**Operator**\nThank you, Matt. We will now be conducting a question and answer session. You. In the interest of time, we ask that you please limit yourself to one question and one follow-up. Thank you.\n\n**Operator**\nOne moment please while we poll for questions. And the first question comes from the line of Joshua Buchalter with TD Cowen. Please proceed with your question.\n\n**Joshua Buchalter** (Director - Equity Research)\nHi, team. Thank you for taking my questions and congrats on the results. I was hoping you maybe expand on the drivers of upside in both the Print and in particular the guide. How should we think about 2Q growth by segment? Wanted to double click on client in particular.\n\n**Joshua Buchalter** (Director - Equity Research)\nThat business is up 67% year over year in the first quarter and there's obviously a lot of concerns on pull ins. So I was hoping you could walk through some of the drivers of the strength in client in particular and how you're thinking about that in 2Q. Thank you.\n\n**Lisa Su** (Chair &amp; CEO)\nOkay, great, Josh. Thanks for the question. Look, we were very pleased with our performance in Q1. We actually saw a strength across a number of our businesses. We saw strength certainly in the client business, very strong desktop performance.\n\n**Lisa Su** (Chair &amp; CEO)\nWe saw strength in our gaming business as well, which was really due to our strong Radeon launch. And we also saw some strength in our data center business across both stronger CPU and GPU. So those are some of the drivers for our Q1 performance. And in particular, on your question of client performance, we've certainly looked very carefully at the ordering patterns and what customers are telling us. We have not seen a lot of tariff related activity in that business.\n\n**Lisa Su** (Chair &amp; CEO)\nI would say though, what we have seen is a real stronger mix and strength in our overall ASPs. So the desktop channel, which is an area where we have a very strong gaming products right now, actually performed well above seasonality in Q1. And that is really the strength of the ASPs there. So that's what we saw in Q1. And then to your question about the guide for Q2, as Jean mentioned, we do have the new export control limitation on MI-three 0 8.\n\n**Lisa Su** (Chair &amp; CEO)\nSo we have taken out that revenue, which is a $700,000,000 headwind in Q2. But with that, we have a strong outlook given the strength across the rest of our businesses. So we continue to see strength in clients going into the second quarter. Again, the desktop business continues to perform above typical seasonality. We're also seeing the beginning of the commercial ramp, which is a place where we have traditionally been quite underrepresented.\n\n**Lisa Su** (Chair &amp; CEO)\nWe see continued strength in gaming, I would say much better than typical seasonality. That is really our AIB business with the Radeon products ramping, as well as consoles have now drained all of their inventory. And so they are starting their ramp into the year. And from a data center side, we see sequential growth on the CPU side. We see the GPU right on track minus the China export controls.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd so for all of those reasons, we're pleased with where the performance of the business is right now.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nYes. I'll just add one point to what Lisa just said on the client business. We had really strong performance in Q1. Sequentially, client revenue is largely flattish versus Q4. When you look behind it, our unit actually declined double digit.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nSo the revenue flattish is largely driven by the ASP increases sequentially due to the richer mix that Lisa just mentioned.\n\n**Joshua Buchalter** (Director - Equity Research)\nThank you for all that color. To follow-up, I wanted to ask about how the X X three zero eight INSTAINT family performed in the quarter and how you're thinking about the back half of the year. I think you mentioned in the prepared remarks significant double digit year over year. Could you maybe provide some color on how Instinct did in the first quarter? How you're thinking about the first half ahead of the three fifty ramp next month? Thank you.\n\n**Lisa Su** (Chair &amp; CEO)\nSure. So on the Instinct ramp, I would say a Q1 performance of data center GPU was in line with maybe a little bit better than expected. I think the key point that we've always said about the Instinct ramp is very excited about the MI350 launch. We're right on track for that launching midyear. I would say customer interest has been very high.\n\n**Lisa Su** (Chair &amp; CEO)\nSo from a competitiveness standpoint, we feel really good about where it's positioned. Overall, I think one of the advantages that we have with the MI350 launch is that from a systems overall environment, it's actually a very similar to the MI300. So we believe it's going to ramp fast. And we already have a couple of deals that have been announced, including a very important relationship with Oracle in terms of the MI350 Series for a number of joint customers. So we're excited about the overall AI business.\n\n**Lisa Su** (Chair &amp; CEO)\nI think we continue to see strength there. I know there are some uncertainties as it relates to tariffs and other things, But this is one of those areas where from an infrastructure standpoint, there continues to be investment in AI infrastructure. And so with that, we would expect strong growth into the second half of the year.\n\n**Operator**\nAnd the next question comes from the line of Timothy Arcuri with UBS. Please proceed with your question.\n\n**Timothy Arcuri** (Managing Director)\nThanks a lot. Lisa, you said that data center GPU grew significant double digit, but it was like $600,000,000 last March. So I would think that I mean, I think a lot of us thought it was going to be like 1.7 to 1.75. So is that the wrong way to sort of interpret that? Because it seems like it more than it went up triple digits at least.\n\n**Timothy Arcuri** (Managing Director)\nSo can you help us there? And also, I'm curious, the additional $800,000,000 that sort of has to come out of from the ban, does that all come out in September? Or is there some remnants of that that have to come out in the fourth quarter as well?\n\n**Lisa Su** (Chair &amp; CEO)\nYeah, so again, what I would say is the data center GPU business did perform very well in the first quarter. I think we have to go back and look at what you had for first quarter twenty twenty four. But overall standpoint, it performed right where we would expect. Relative to your conversation as to where does it come out, I would say the vast majority comes out in the September. So think about, Jean mentioned $1,500,000,000 you would see the majority of it in Q2 and Q3 with very little in Q4.\n\n**Lisa Su** (Chair &amp; CEO)\nSo we had always expected that the fourth quarter because it would be very focused on the MI350 family would be non China revenue and that's how it was planned.\n\n**Timothy Arcuri** (Managing Director)\nGot it. And then Jean, just on the inventory, it was up a lot. Is that just due to ZT or is there something else happening there? Thanks.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nWell, on the inventory side, we built some inventory primarily to support very strong client and the server ramp and also the second half data center GPU ramp. As you probably know, the lead time is really long to build for the Q3, Q4 ramp. We really need to start wafers right now. That's why the inventory has increased.\n\n**Operator**\nAnd the next question comes from the line of Harlan Sur with JPMorgan. Please proceed with your question.\n\n**Harlan Sur** (Executive Director - Equity Research)\nHey, good afternoon. Thanks for taking my question. I know there's been a lot of focus in your upcoming MI three fifty series, Lisa, but MI four hundred next year is where you potentially close the competitive gap in a big way, right? You're bringing Frontier class model training performance GPU in a rack scale solution. More and more of the challenges has been standing up these RackScale platforms, power, cooling, footprint, networking, connectivity, telemetry, etcetera, right?\n\n**Harlan Sur** (Executive Director - Equity Research)\nLots of well telegraphed issues with standing up these RackScale architectures. So as you've shared your MI 400 RackScale solution architecture with customers, what is the AMD team doing to potentially address the ease of these deployments with the MI 400? And just in general, what's been the overall feedback been like on MI-four hundred?\n\n**Lisa Su** (Chair &amp; CEO)\nYes, Harlan, thank you for the question. I think, look, we're excited about the MI-three 50 series launch that's coming up, but we are extremely excited as well about the MI400 Series and the roadmap there. I think we've been very active with customers on our roadmap. As you know, this is one of those areas where you absolutely have to be planning many quarters in advance for that. One of the primary reasons we acquired ZT Systems was exactly to address this rack scale architecture.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd so from that standpoint, the closing of the ZT acquisition has been very timely. What we're doing right now is together with our ZT design team as well as our customers' design teams and our own systems design capability, really actively planning what those rack scale systems are going to look like. I would say the MI400 series enthusiasm from customers is high. And there's a lot of activities that are going on right now to ensure that we do in fact learn from some of the, let's call it some of the challenges that have occurred with some of the recent deployments.\n\n**Harlan Sur** (Executive Director - Equity Research)\nThanks for that. And then I continue to be impressed. Mean, seven consecutive quarters of strong year over year growth in your epic enterprise and on prem traction. Right? You have high thirties, low forties type share of the overall server market and enterprise and on prem.\n\n**Harlan Sur** (Executive Director - Equity Research)\nYour share is probably in the sort of low 20% range, but significant share momentum. Can you just remind us, like, what has the AMD team done? What have you put in place sort of go to market wise to drive the strong tailwind here? And what has been a very, very tough market segment to crack?\n\n**Lisa Su** (Chair &amp; CEO)\nI think there are a couple of things, Harlan. First of all, the strength of the product cannot be under sold, right? At this moment with fifth gen Epic, the overall cloud adoption has been fantastic. And then on the enterprise side, we've really broadened the product portfolio for Turin that includes, let's call it, low core count up through the highest core count and frequency ranges. So that's very helpful.\n\n**Lisa Su** (Chair &amp; CEO)\nBut probably the largest impact has been in go to market. In the go to market space, we have added significant headcount and capability to address end users directly. And with the use cases, think some of the things that we talked about across industries, we're actually learning from each deployment and replicating that across many of the industrial partners. So overall, I think it's been a strong effort on enterprise and we're really still in the very early stages of that. I would say we're still quite underrepresented in enterprise, but with the platform coverage and the processor coverage, I think we feel good about the opportunities.\n\n**Operator**\nAnd the next question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.\n\n**Aaron Raikers** (Analyst)\nYeah, thanks for taking the question. Going back to kind of the data center business and particularly the GPU business, You know, I think last quarter, you had alluded to the fact that that you'd expected the data center revenue to be roughly flat, in the first half of the year. I guess if we were to take out the 700,000,000, impact from China, would the expectation still be flat for the year? Is that a fair assumption?\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nSo, Erin, so you're right. Last time, we did mention the first half data center GPU, it's flattish versus second half. The way to think about what Lisa mentioned is the 1,500,000,000 impact largely will be in Q2 and Q3. And so when you take out $700,000,000 in Q2 and majority in Q3, that is what impact in Q2 and Q3. But remember what Lisa mentioned is that we do see second half weighted as we launch MI three fifty five, we will see significant ramp.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nYear over year, we see strong double digit growth of our data center business and the GPU business also.\n\n**Aaron Raikers** (Analyst)\nOkay. And then as a quick follow-up, kind of thinking about the gross margin, obviously, this quarter's guidance reflective of charge that you're taking. Should we assume that in the back half with mixed attributes to be considered that you would see a return to that 54 plus percent gross margin in the second half of the year. Is that a fair assessment?\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nYeah. Yeah. Erin, thank you for the question. Yeah, there are a few puts takes on the gross margin. If you think about the Q2, excluding $800,000,000 charge related to the MI308, our gross margin actually is around 54%.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nSo at the company level, right, the mix is less favorable because the client and the gaming business is growing sequentially. But we do have a few drivers to drive the gross margin up. First, as I mentioned earlier, if you look at our client business, the gross margin has been improving because the richer mix of our latest generation product portfolio, that really helps. And also secondly, within data center, when we expand enterprise market share, we do see gross margin improvement. Of course, in addition, MI308 data center GPU gross margin is on the low end of our data center GPU margin.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nSo that also helps us overall. When we think about the second half, actually think the gross margin will improve slightly because data center continues to be very strong growth driver, number one growth driver second half versus the first half, which will be partially offset by continued strength on the client and the gaming side. Hope that answer your question.\n\n**Operator**\nAnd the next question comes from the line of Thomas O'Malley with Barclays. Please proceed with your question.\n\n**Thomas O'Malley** (Director - Equity Research)\nHey, Lisa and others. Thanks for taking my question. Really appreciate it. And Gene, thanks for that helpful answer there. I just wanted to understand your view on system based architectures and whether you feel like you have what you need right now.\n\n**Thomas O'Malley** (Director - Equity Research)\nObviously, UA Link 1.0 is coming out. You can use third party providers to kind of do the interconnect. ZT system does do a lot for you in terms of the system architecture, but from the interconnect side, do you think that you need more? Is that something that you're going to do internally, look externally? Just want to understand where you think the portfolio is today and whether you can address system based architectures of what you have today.\n\n**Lisa Su** (Chair &amp; CEO)\nSure, Tom. Absolutely, I think we feel like we have all the pieces required as well as deep partnerships in the ecosystem. And I consider it a system level optimization between CPU, GPU, networking capability, rack scale architecture. I think all of those pieces are things that we are investing in. And we're also partnering with others in the industry who are offering these capabilities.\n\n**Lisa Su** (Chair &amp; CEO)\nI think when we look at the architectures that our customers want, our customers are really asking for one that we have a reference architecture that works, but also that we work with them as they want to interchange various pieces, particularly on the networking side. I think there are a couple of different solutions out there. And we are very much focused on ensuring that we interoperate across the spectrum.\n\n**Thomas O'Malley** (Director - Equity Research)\nHelpful. And then if we look at the full year, I mean, we'll get the units with the filing, but it looks like there's some material share gains here in the first quarter. When you look at the full year, just to level set us on share gains versus market growth, could you maybe talk about what you see the client business growing as a base level? And then just obviously, it's difficult to kind of predict where share will go. But just any comments on what you're seeing thus far?\n\n**Thomas O'Malley** (Director - Equity Research)\nIs a couple of points of shares kind of what you're seeing in the first quarter as well? We'll get a little more later, but mostly just on the market growth for 2025. Thank you.\n\n**Lisa Su** (Chair &amp; CEO)\nSure, Tom. So if you're asking about share in the client business, I think that was the conversation. Look, we are very pleased with our client business performance over the last couple of quarters. I think we are seeing unit growth, particularly in desktop, but where we're seeing probably the most growth is overall revenue share. And so it's we're gaining share in the right places, which is in sort of high end notebook and commercial as well as in desktop overall.\n\n**Lisa Su** (Chair &amp; CEO)\nSo from that standpoint, that's where we think we're going. As we go through the year, I know there's a good amount of conversation about what happens in the macro and what happens with tariffs and does that change things going forward. We are spending quite a bit of time ensuring that we are aligning with our customers, looking at inventory levels, looking at sort of consumption and overall sell through. And we believe that we have a good overall inventory position and there is not, let's call it a tremendous amount of pull ins or other things that are coming into play. And we will continue to be very agile in how we look at that going forward.\n\n**Operator**\nAnd the next question comes from the line of Vivek Arya with Bank of America Securities. Please proceed with your question.\n\n**Vivek Arya** (Analyst)\nThank you. I had two questions as well. On the first one, just near term, Lisa, did your GPU sales grew sequentially in Q1? How much was MI three zero eight in that number? And if you look at twenty twenty five overall, do you think GPUs can still grow despite this China headwind that you mentioned relative to the $5,000,000,000 plus you did last year?\n\n**Lisa Su** (Chair &amp; CEO)\nYes, sure, Vivek. So, let me answer the second question first. We absolutely believe the data center GPU will grow and we think it'll grow strong double digits. We had a plan that was second half weighted, and it still is. Relative to the MI-three zero eight situation, it's certainly a headwind, but one which we think is well contained given everything else that we have going on.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd relative to the Q1 performance of data center GPU, it was down very modestly from Q4, which is what we expected. We did see good overall demand actually in the first quarter driven by MI325. So we had a significant adoption by a large foundational model company, which was very positive there. And as we go forward, we expect that we will continue to broaden both customers as well as workloads within our current customers for Instinct portfolio.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nAnd Vivek, in Q1 MI three twenty five and MI '3 hundred are majority of our revenue.\n\n**Vivek Arya** (Analyst)\nGreat. And then longer term, Lisa, you know, the past you described, I believe almost a $500,000,000,000 or so addressable market for AI accelerators. How much of that, you know, roughly is China? Because that now seems to be somewhat restricted for US companies. And then also kind of related to that, how should we think about these AI diffusion rules that I think there is an implementation date that is coming up on May 15.\n\n**Vivek Arya** (Analyst)\nI'm curious what you have heard. So just sort of the implication of China restrictions and these AI diffusion rules on thinking about the addressable opportunity for you longer term. Thank you.\n\n**Lisa Su** (Chair &amp; CEO)\nVivek, I think it's a good question. I think overall, it is a very dynamic market. So you'll appreciate that. On the China export controls, I think we always expected that there would be some amount of, let's call it, limitation on sort of leading edge GPUs going into China.\n\n**Lisa Su** (Chair &amp; CEO)\nSo that was factored in to our TAM expectation when we talked about $500,000,000,000 So I think that dramatically changes the TAM. But what I will say is on the AI diffusion side, what we're very actively working with the government as they're thinking through these rules, and it's a very fine balance that we have to have. At the end of the day, when we look at sort of The US AI companies, we have leading edge technology. We want to ensure that the rest of the world can really use us as the primary platform. So I think it'll be important to work through the AI diffusion rules and all of that as we think about longer term TAM.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd we're certainly spending quite a bit of efforts trying to ensure that it's well understood, the importance of the overall ecosystem and having the rest of the world really adopt The U. S. Ecosystem given our strength and leadership overall.\n\n**Operator**\nAnd the next question comes from the line of C. J. Muse with Cantor Fitzgerald. Please proceed with your question.\n\n**CJ Muse** (Senior Managing Director)\nYeah. Good afternoon. Thank you for taking the question. I wanted to revisit your assumptions around client. If you were to just flat line the q one actual, you would grow the business about 30%.\n\n**CJ Muse** (Senior Managing Director)\nYou're you're obviously very bullish on on taking share. You talked about, huge tailwinds from ASPs. But curious, when you put it all together, how should we think about traditional seasonality into the second half, particularly with, the potential of some pull ins here in the first half?\n\n**Lisa Su** (Chair &amp; CEO)\nSure, CJ. It's a fair question. Look, we want to be very clear that our client business performance is primarily driven by the strength of the product portfolio, and it's driven by some of the desktop channel products that traditionally are not so well tracked, if you look at sort of the IDCs of the world. We are planning for, let's call it, a second half sub seasonal, given that we're off to such a strong start in the first half of the year. And that is what we're putting into our sort of internal planning numbers.\n\n**Lisa Su** (Chair &amp; CEO)\nSo you wouldn't see necessarily typical seasonality since the first half is better than seasonal. That being the case, I think we feel strongly that from a consumption basis standpoint, we can see the data. So the when we look at the Q1 performance, it was a very, very strong Q1 in terms of sellout and consumption for our desktop business. And as we start Q2, we're now four weeks into it, we see those patterns continuing. So we're in an upgrade cycle right now.\n\n**Lisa Su** (Chair &amp; CEO)\nGaming CPUs are usually purchased when they're gaming GPUs that come out in new cycles. And I think we're benefiting from that on both the CPU and the GPU side, which is great. I mean, we're very happy with that and we're ramping up production to ensure that we keep the channel full.\n\n**CJ Muse** (Senior Managing Director)\nVery helpful. And then I guess looking to next year, can you talk about 400 series and rack level solution go to market strategy? You talked about kind of trying to obtain partners. Is there a certain number that you're targeting? And then how are you thinking about kind of getting through some of the learning curve challenges of getting the rack scale working with your OEM partners such that you can deliver that ramp in 2026? Thanks so much.\n\n**Lisa Su** (Chair &amp; CEO)\nSure, CJ. So I think the right answer is we're getting a very early start and that's what we have to do is so that we maximize the overall learning cycle that is required for RackScale solutions. We are working very closely with a number of our hyperscale partners today to define those solutions and make sure that we're thinking about all of the various areas that could require work. And we're also working with our OEM partners who also have, let's call it, learned quite a bit over the past couple of months and quarters as other RackScale solutions have been coming online. So I think we're doing everything to, let's call it, move ahead the learning cycle.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd again, we have the benefit of the MI350 series being a relatively, let's call it, not large lift. And so the focus on the RAC scale stuff is on MI400.\n\n**Operator**\nAnd the next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed with your question.\n\n**Stacy Rasgon** (Analyst)\nHi, guys. Thanks for taking my questions. For the first one, given the China Data Center GPU headwinds in Q2 and Q3, do you think that GPU business actually grows year over year in Q2 and Q3? Understanding your comments for the full year on it, but do you think given those headwinds in Q2 and Q3, it can actually grow year over year?\n\n**Lisa Su** (Chair &amp; CEO)\nI think you're let's see, Stacy, the best way to answer that question is, in Q2, it's not going to grow year over year, just given what we've said about the $700,000,000 coming out of Q2 and how we had previously talked about the evolution. But we do believe that we'll grow year over year going forward in Q3 and Q4, certainly for us to do the full year with strong double digit growth.\n\n**Stacy Rasgon** (Analyst)\nOkay. So you do think it can grow year over year in Q3. Okay. For my second question, I wanted to ask about kind of the trends in in q one. So you said it was data center GPU was down, I guess, modestly in q one as expected.\n\n**Stacy Rasgon** (Analyst)\nBut again, I go back to your sort of double digit year over year comments, I mean, it it couldn't have been any more than, 1,400,000,000 in q one for these two b and feels like it's less than that, which means it would have been down at least 20% sequentially, maybe more, which also implies that the server CPUs in Q1 were up sequentially, which is also well above seasonal similar to clients. I guess what I'm asking is, are those trends correct? Am I modeling that correct? And I guess, what are the implications in that case of server CPUs actually up well above seasonal in Q1 given this environment?\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nI think Stacy, this is Jean. I think when you think about the Q1 data center performance, it's declined 5%. So it's a little bit better from a server perspective because it is declined sequentially. Same thing like this on the GPU, like Lisa mentioned earlier, is a decline. So I think that is the overall data center performance.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nI think I don't know about your model, but that is how we really look at the numbers, how we think about it.\n\n**Operator**\nAnd the next question comes from the line of Ross Seymore with Deutsche Bank. Please proceed with your question.\n\n**Ross Seymore** (Analyst)\nHi, guys. Thanks for letting me ask a couple of questions. I'm going to go to the Embedded space. I know it's not the biggest one, but everything else has been addressed pretty detailed. You mentioned the second half getting up to year over year growth. Seems like that requires some significant double digit growth sequentially in both quarters just to get the full half there. What gives you the confidence in that sort of ramp?\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nYes. Ross, thank you for the question. On the embedded side, we started to see gradual recovery. I think there are signs, especially the order pattern, the book to bill ratios, we see improving in the, like aerospace defense and also test and measurement side, we see very visible improvement. Industrial side, the improvement is less so their inventory still among different customers.\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nBut overall, the trend, the demand pattern does improve. I think Q2, we did guided sequentially flattish. And I think we'll start to see Q3, especially Q4, you will see year over year increase, especially in Q4.\n\n**Ross Seymore** (Analyst)\nOkay. Thanks for that. And I guess as my last question, on the OpEx side of things, guided to the overt number for the second quarter, '2 point '3 billion. You said there's $50,000,000 from ZTE in there. Is that the entirety of the ZT side of things?\n\n**Ross Seymore** (Analyst)\nOr what should we think for kind of full year OpEx or the second half, however you want to discuss it?\n\n**Jean Hu** (Executive VP, CFO &amp; Treasurer)\nYes, Ross, thank you for the question. For the ZT design team, we view it quarterly, the incremental OpEx is about $50,000,000 that $2,300,000,000 include everything from ZT because we closed the transaction on March 31. I think when you look at the overall, our OpEx increase year over year, we continue to drive revenue growth to increase more than OpEx. Looking at the Q2 at the middle point of our guidance, the revenue will be increasing 27% and we do expect the earnings per share growing much faster than the top line revenue growth. So OpEx side, we'll be very disciplined to continue to manage it.\n\n**Matt Ramsay** (Corporate VP - Financial Strategy &amp; IR)\nOperator, I think we have time for one more caller, please. Thank you.\n\n**Operator**\nNo problem. And the final question comes from the line of Joe Moore with Morgan Stanley. Please proceed with your question.\n\n**Joseph Moore** (Analyst)\nGreat. Thank you. One of the things your cloud customers have been talking about is this kind of growth in inference costs, this sort of reasoning models using a lot of inference compute and some tightness. Can you talk about that from AMD's perspective? Are you seeing that in your business?\n\n**Joseph Moore** (Analyst)\nDoes that change the focus that you have going forward?\n\n**Lisa Su** (Chair &amp; CEO)\nSure, Joe. So I think overall, what we're seeing is that with these new reasoning models, the inferencing is more important and there's also a move to more distributed inferencing. So I think that plays into our strengths. I think we have demonstrated with MI 300 that we are an excellent inference solution and that holds true for three fifty and three fifty series as well. So we continue to see with our memory bandwidth and memory capacity advantages, that's a positive.\n\n**Lisa Su** (Chair &amp; CEO)\nI will say that as we're going into this, the number of workloads that we're seeing overall is expanding. So we're seeing both training and inferencing as important workloads that we're working on. And our customers continue to demonstrate. I think the desire that we're seeing probably from a trend standpoint is that there are many models that people are using today. So they're not necessarily using one model, they're actually using several different models.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd so the optimizations around that are the things that we're doing with our ROCCOM software suite.\n\n**Joseph Moore** (Analyst)\nGreat. And then just an update on your thoughts on competing with custom silicon with ASICs in AI space. Most of your largest customers also have a custom silicon offering. So will they invest in both AMD and ASICs? And just how do they decide how to apportion that investment?\n\n**Lisa Su** (Chair &amp; CEO)\nYes. I mean, Joe, I view them as really two different things. I think one of the primary aspects, as we've talked about the $500,000,000,000 TAM and the opportunities there, look, we think ASICs have a place. We happen to think GPUs have a larger piece of that because the models are changing so much. And from our standpoint, it's really important to have competitive TCO.\n\n**Lisa Su** (Chair &amp; CEO)\nAnd people want choice to get there, especially as inference costs become so important. And we're working on trying to expand the overall inferencing capability out there. So I don't think it's an either or. I think it's a let's get the best solutions out there and we will certainly believe that we're very competitive in inferencing. And I think we are also becoming a much more sort of solution for training as well.\n\n**Operator**\nAnd ladies and gentlemen, that does conclude the question and answer session. And that also concludes today's teleconference. We thank you for your participation. You may disconnect your lines at this time.",
        "fetched_at": "2026-02-04T16:14:03.173Z"
      }
    ]
  }
}